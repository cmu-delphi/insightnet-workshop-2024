{
  "hash": "b16cd71bdbc3f6fb0577beb700b9d7a4",
  "result": {
    "markdown": "---\ntalk-title: \"Forecasting and Time-Series Models\"\ntalk-short-title: \"{{< meta talk-title >}}\"\ntalk-subtitle: \"\"\nauthor: \"\"\nother-authors: \"\"\nrepo-address: \"cmu-delphi/insightnet-workshop-2024\"\ntalk-date: \"Venue -- dd Somemonth yyyy\"\nformat: revealjs\nexecute:\n  cache: false\n---\n\n\n<!-- Set any of the above to \"\" to omit them -->\n\n<!-- Or adjust the formatting in _titleslide.qmd -->\n---\n---\n\n\\DeclareMathOperator*{\\minimize}{minimize}\n\n\n\n\n\n\n\n::: flex\n::: w-20\n\n:::\n::: w-80\n## {{< meta talk-title >}} {background-image=\"gfx/cover-art-1.svg\" background-position=\"bottom\"}\n\n### {{< meta talk-subtitle >}}\n\n<br>\n\n#### {{< meta author >}} \n{{< meta other-authors >}}\n\n{{< meta talk-date >}}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## Outline\n\n1. Linear Regression for Time Series Data\n\n1. Evaluation Methods\n\n1. ARX Models\n\n1. Considerations for Different Horizons \n\n1. Overfitting and Regularization\n\n1. Prediction Intervals\n\n1. Forecasting with Versioned Data\n\n1. Modeling Multiple Time Series\n\n\n# Linear Regression for Time Series Data\n\n## Basics of linear regression \n\n* Assume we observe a predictor $x_i$ and an outcome $y_i$ for $i = 1, \\dots, n$.\n\n* Linear regression seeks coefficients $\\beta_0$ and $\\beta_1$ such that\n\n$$y_i \\approx \\beta_0 + \\beta_1 x_i$$\n\nis a good approximation for every $i = 1, \\dots, n$.\n\n* In R, the coefficients are found by running `lm(y ~ x)`, where `y` is the vector \nof responses and `x` the vector of predictors.\n\n\n## Multiple linear regression \n\n* Given $p$ different predictors, we seek $(p+1)$ coefficients such that\n\n$$y_i \\approx \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip}$$\nis a good approximation for every $i = 1, \\dots, n$.\n\n\n## Linear regression with lagged predictor\n\n* In time series, outcomes and predictors are usually indexed by time $t$. \n\n* [Goal]{.primary}: predicting future $y$, given present $x$. \n\n* [Model]{.primary}: linear regression with lagged predictor\n\n$$\\hat y_t = \\hat \\beta + \\hat \\beta_0 x_{t-k}$$\n\ni.e. regress the outcome $y$ at time $t$ on the predictor $x$ at time $t-k$.\n\n* [Equivalent]{.primary} way to write the model: \n\n$$\\hat y_{t+k} = \\hat \\beta + \\hat \\beta_0 x_t$$\n\n\n## Example: predicting COVID deaths  \n\n* During the pandemic, interest in predicting COVID deaths 7, 14, 21, 28 days ahead.\n\n* Can we reasonably [predict COVID deaths 28 days ahead]{.primary} by just using cases today?\n\n* If we let\n\n$$y_{t+28} = \\text{deaths at time } t+28 \\quad\\quad x_{t} = \\text{cases at time } t$$\n  is the following a good model?\n\n  $$\\hat y_{t+28} = \\hat\\beta_0 + \\hat\\beta_1 x_{t}$$\n\n\n## Example: COVID cases and deaths in California \n\n* Let's focus on California.\n\n* Cases seem highly correlated with deaths several weeks later.\n\n::: flex\n::: w-50\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-ca-cases-deaths-1.svg){fig-align='center'}\n:::\n:::\n\n\n:::\n::: w-50\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(ca)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn `epi_df` object, 6 x 4 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-10-23 20:07:29.405142\n\n# A tibble: 6 × 4\n  geo_value time_value cases deaths\n* <chr>     <date>     <dbl>  <dbl>\n1 ca        2020-04-01  3.17 0.0734\n2 ca        2020-04-02  3.48 0.0835\n3 ca        2020-04-03  3.44 0.0894\n4 ca        2020-04-04  3.05 0.0778\n5 ca        2020-04-05  3.28 0.0876\n6 ca        2020-04-06  3.37 0.0848\n```\n:::\n:::\n\n:::\n:::\n\n\n## Checking correlation\n\n* Let’s split the data into a training and a test set (before/after 2021-03-01).\n\n* On training set: [large correlation]{.primary}\nbetween cases and deaths 28 days ahead (> 0.95).\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/correlation-cases-deaths-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n* Let's use (base) R to prepare the data and fit \n\n$$\\hat y_{t+28} = \\hat\\beta + \\hat\\beta_0 x_{t}$$\n\n\n## Preparing the data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Add column with cases lagged by k\nca$lagged_cases <- dplyr::lag(ca$cases, n = k)\n\n# Split into train and test (before/after t0_date)\nt0_date <- as.Date('2021-03-01')\ntrain <- ca %>% filter(time_value <= t0_date)\ntest <- ca %>% filter(time_value > t0_date)\n```\n:::\n\n\n* Check if `deaths` is approximately linear in `lagged_cases`:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-lag-cases-1.svg){fig-align='center'}\n:::\n:::\n\n\n## Fitting lagged linear regression in R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nreg_lagged = lm(deaths ~ lagged_cases, data = train)\ncoef(reg_lagged)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept) lagged_cases \n  0.09853776   0.01132312 \n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-linear-fit-1.svg){fig-align='center'}\n:::\n:::\n\n\n# Evaluation\n\n## Error metrics\n\n* Assume we have predictions $\\hat y_{new, t}$ for the unseen observations \n$y_{new,t}$ over times $t = 1, \\dots, N$.\n\n* Four commonly used error metrics are:\n\n  * mean squared error (MSE)\n\n  * mean absolute error (MAE)\n\n  * mean absolute percentage error (MAPE)\n\n  * mean absolute scaled error (MASE)\n\n## Error metrics: MSE and MAE\n\n$$MSE = \\frac{1}{N} \\sum_{t=1}^N (y_{new, t}- \\hat y_{new, t})^2$$\n$$MAE = \\frac{1}{N} \\sum_{t=1}^N |y_{new, t}- \\hat y_{new, t}|$$\n\n* MAE gives less importance to extreme errors than MSE.\n\n* [Drawback]{.primary}: both metrics are scale-dependent, so they are not universally \ninterpretable.\n(For example, if $y$ captures height, MSE and MAE will vary depending on whether we measure in feet or meters.)\n\n## Error metrics: MAPE\n\n* Fixing scale-dependence:\n\n$$MAPE = 100 \\times \\frac{1}{N} \\sum_{t=1}^N \n\\left|\\frac{y_{new, t}- \\hat y_{new, t}}{y_{new, t}}\\right|$$\n\n* [Drawbacks]{.primary}:\n\n  * Erratic behavior when $y_{new, t}$ is close to zero\n\n  * It assumes the unit of measurement has a meaningful zero (e.g. using \nFahrenheit or Celsius to measure temperature will lead to different MAPE)\n\n## Comparing MAE and MAPE\n\n::: {.callout-important icon=\"false\"}\n## Note\n\nThere are situations when MAPE is problematic!\n:::\n\n::: flex\n::: w-70\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/mae-mape-example-1.svg){fig-align='center'}\n:::\n:::\n\n\n:::\n\n::: {.w-30 .align-end}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n           MAE     MAPE\nyhat1 2.873328 43.14008\nyhat2 5.382247 36.08279\n```\n:::\n:::\n\n\n:::\n:::\n\n\n## Error metrics: MASE\n\n$$MASE = 100 \\times \\frac{\\frac{1}{N} \\sum_{t=1}^N \n|y_{new, t}- \\hat y_{new, t}|}\n{\\frac{1}{N-1} \\sum_{t=2}^N \n|y_{new, t}- y_{new, t-1}|}$$\n\n* [Advantages]{.primary}:\n\n  * is universally interpretable (not scale dependent)\n\n  * avoids the zero-pitfall\n\n* MASE in words: we normalize the error of our forecasts by that of a naive method \nwhich always predicts the last observation.\n\n\n## Comparing MAE, MAPE and MASE\n\n::: flex\n::: w-65\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/mae-mape-mase-example-1.svg){fig-align='left'}\n:::\n:::\n\n:::\n\n::: w-35\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n           MAE     MAPE      MASE\nyhat1 2.873328 43.14008  66.10004\nyhat2 5.382247 36.08279 123.81696\n```\n:::\n:::\n\n\n:::\n:::\n\n## Defining the error metrics in R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nMSE <- function(truth, prediction) {\n  mean((truth - prediction)^2)}\n\nMAE <- function(truth, prediction) {\n  mean(abs(truth - prediction))}\n\nMAPE <- function(truth, prediction) {\n  100 * mean(abs(truth - prediction) / truth)}\n\nMASE <- function(truth, prediction) {\n  100 * MAE(truth, prediction) / mean(abs(diff(truth)))}\n```\n:::\n\n\n## Estimating the prediction error\n\n* Given an error metric, we want to estimate the prediction error under that metric. \n\n* This can be accomplished in different ways, using the\n\n  * Training error\n\n  * Split-sample error\n\n  * Time series cross-validation error (using all past data or a trailing window)\n\n\n## Training error\n\n* The easiest but [worst]{.primary} approach to estimate the prediction error is \nto use the training error, i.e. the average error on the training set that was \nused to fit the model.\n\n* The training error is\n\n  * generally too optimistic as an estimate of prediction error\n\n  * [more optimistic the more complex the model!]{.primary}^[More on this when we talk about overfitting.]\n\n\n## Training error\n#### Linear regression of COVID deaths on lagged cases\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Getting the predictions for the training set\npred_train <- predict(reg_lagged)\n```\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/plot-train-predictions-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                MAE     MASE\ntraining 0.05985631 351.4848\n```\n:::\n:::\n\n\n\n## Split-sample error {.smaller}\n\n* To compute the split-sample error  \n\n  1. Split data into training (up to time $t_0$), and test set (after $t_0$)\n\n  1. Fit the model to the training data only\n\n  1. Make predictions for the test set\n\n  1. Compute the selected error metric on the test set only\n\n* Formally, the split-sample MSE is\n\n$$\\text{SplitMSE} = \\frac{1}{n-t_0} \\sum_{t = t_0 +1}^n (\\hat y_t - y_t)^2$$\n\n* Split-sample estimates of prediction error don't mimic a situation where we \nwould refit the model in the future. \nThey are [pessimistic]{.primary} if the relation between outcome and predictors \nchanges over time.\n\n## Split-sample error\n#### Linear regression of COVID deaths on lagged cases\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Getting the predictions for the test set\npred_test <- predict(reg_lagged, newdata = test)\n```\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/plot-test-predictions-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                    MAE     MASE\ntraining     0.05985631 351.4848\nsplit-sample 0.10005007 659.8971\n```\n:::\n:::\n\n\n## Time-series cross-validation (CV) {.smaller}\n#### 1-step ahead predictions\n\n* If we refit in the future once new data are available, a more \nappropriate way to estimate the prediction error is time-series cross-validation.\n\n* To get 1-step ahead predictions (i.e. at time $t$ we forecast for $t+1$) we proceed as follows,\nfor $t = t_0, t_0+1, \\dots$\n\n  1. Fit the model using data up to time $t$\n\n  1. Make a prediction for $t+1$ \n\n  1. Record the prediction error\n\nThe cross-validation MSE is then\n\n$$CVMSE = \\frac{1}{n-t_0} \\sum_{t = t_0}^{n-1} (\\hat y_{t+1|t} - y_{t+1})^2$$\n\nwhere\t$\\hat y_{t+1|t}$ indicates a prediction for $y$ at time $t+1$ that was made \nwith data available up to time $t$.\n\n## Time-series cross-validation (CV) {.smaller}\n#### $h$-step ahead predictions\n\n* In general, if we want to make $h$-step ahead predictions (i.e. at time \n$t$ we forecast for $t+h$), we proceed as follows \nfor $t = t_0, t_0+1, \\dots$\n\n  * Fit the model using data up to time $t$\n\n  * Make a prediction for $t+h$ \n\n  * Record the prediction error\n\n* The cross-validation MSE is then\n\n$$CVMSE = \\frac{1}{n-t_0} \\sum_{t = t_0}^{n-h} (\\hat y_{t+h|t} - y_{t+h})^2$$\n\nwhere\t$\\hat y_{t+h|t}$ indicates a prediction for $y$ at time $t+h$ that was made \nwith data available up to time $t$.\n\n## Time-series cross-validation (CV) \n#### Linear regression of COVID deaths on lagged cases\n\nGetting the predictions requires slightly more code:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn <- nrow(ca)                               #length of time series\nh <- k                                      #number of days ahead for which prediction is wanted\npred_all_past <- rep(NA, length = n-h-t0+1) #initialize vector of predictions\n\nfor (t in t0:(n-h)) {\n  # fit to all past data and make 1-step ahead prediction\n  reg_all_past = lm(deaths ~ lagged_cases, data = ca, subset = (1:n) <= t) \n  pred_all_past[t-t0+1] = predict(reg_all_past, newdata = data.frame(ca[t+h, ]))\n}\n```\n:::\n\n\n::: {.callout-important icon=\"false\"}\n## Note\n\nWith the current model, we can only predict $k$ days ahead (where $k$ = number of days by which predictor is lagged)!\n:::\n\n\n## Time-series cross-validation (CV)\n#### Linear regression of COVID deaths on lagged cases\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/plot-cv-predictions-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                      MAE     MASE\ntraining       0.05985631 351.4848\nsplit-sample   0.10005007 659.8971\ntime series CV 0.08973951 732.5769\n```\n:::\n:::\n\n\n## Regression on a trailing window {.smaller}\n\n* So far, to get $h$-step ahead predictions for time $t+h$, we have fitted the \nmodel on all data available up to time $t$. We can instead use a trailing \nwindow, i.e. fit the model on a window of data of length $w$, starting at \ntime $t-w$ and ending at $t$.\n\n* [Advantage]{.primary}: if the predictors-outcome relation changes over time,\ntraining the forecaster on a window of recent data can better capture the recent \nrelation which might be more relevant to predict the outcome in the near future.\n\n* Window length [$w$]{.primary} considerations: \n\n  * if $w$ is too [big]{.primary}, the model [can't adapt]{.primary} to the \n  recent predictors-outcome relation \n\n  * if $w$ is too [small]{.primary}, the fitted model may be [too volatile]{.primary} \n  (trained on too little data)\n\n## Trailing window\n#### Linear regression of COVID deaths on lagged cases\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Getting the predictions through CV with trailing window\nw <- 200                                    #trailing window size\nh <- k                                      #number of days ahead for which prediction is wanted\npred_trailing <- rep(NA, length = n-h-t0+1) #initialize vector of predictions\n\nfor (t in t0:(n-h)) {\n  # fit to a trailing window of size w and make 1-step ahead prediction\n  reg_trailing = lm(deaths ~ lagged_cases, data = ca, \n                    subset = (1:n) <= t & (1:n) > (t-w)) \n  pred_trailing[t-t0+1] = predict(reg_trailing, newdata = data.frame(ca[t+h, ]))\n}\n```\n:::\n\n\n## Time-series CV: all past vs trailing window\n#### Linear regression of COVID deaths on lagged cases\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/plot-cv-predictions-trailing-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                                 MAE     MASE\ntraining                  0.05985631 351.4848\nsplit-sample              0.10005007 659.8971\ntime series CV            0.08973951 732.5769\ntime series CV + trailing 0.10270064 838.3834\n```\n:::\n:::\n\n\n\n\n\n\n# ARX Models\n\n## Autoregressive (AR) model\n\n* [Idea]{.primary}: predicting the outcome via a linear combination of (some of) its lags \n\n$$\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-1} + \\dots + \\hat\\phi_p y_{t-p}$$\n\n* [Notice]{.primary}: we don't need to include all contiguous lags^[Here we \ndepart from traditional AR models, which do include all contiguous lags.].\n\n* For example, we could fit\n\n$$\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} + \\hat\\phi_2 y_{t-14}$$\n\n\n## AR model for COVID deaths\n\n* Let's disregard cases, and only use COVID deaths to predict deaths 28 days ahead. \n\n* We will fit the model: \n\n$$\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t}$$\n\n* Would this be a good forecaster?\n\n## Preparing the data and checking correlation\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Add column with deaths lagged by 28\nca$lagged_deaths <- dplyr::lag(ca$deaths, n = k)\n\n# Split into train and test (before/after t0_date)\ntrain <- ca %>% filter(time_value <= t0_date)\ntest <- ca %>% filter(time_value > t0_date)\n```\n:::\n\n\n::: flex\n\n::: w-50\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/ar-plot-deaths-and-lagged-cases-1.svg){fig-align='center'}\n:::\n:::\n\n\n:::\n\n::: w-50\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/auto-cor-deaths-1.svg){fig-align='center'}\n:::\n:::\n\n\n:::\n:::\n\n## Fitting the AR model for COVID deaths\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nar_fit = lm(deaths ~ lagged_deaths, data = train)\ncoef(ar_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept) lagged_deaths \n    0.1023887     0.9523213 \n```\n:::\n:::\n\n\n::: {.callout-important icon=\"false\"}\n## Note\n\nThe intercept is close to 0, and the coefficient is close to 1. \nThis means that we are naively predicting the number of deaths in 28 days \nwith (approximately) the number of deaths observed today.\n:::\n\n## Predictions on training and test sets (AR model)\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/ar-plot-train-predictions-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                   MAE      MASE\ntraining     0.1469711  902.8794\nsplit-sample 0.1899489 1252.8397\n```\n:::\n:::\n\n\n\n## Time-Series CV: all past and trailing (AR model)\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/ar-plot-cv-predictions-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                                MAE      MASE\ntraining                  0.1469711  902.8794\nsplit-sample              0.1899489 1252.8397\ntime series CV            0.1242872 1014.6024\ntime series CV + trailing 0.1646065 1343.7439\n```\n:::\n:::\n\n\n## Autoregressive exogenous input (ARX) model\n\n* [Idea]{.primary}: predicting the outcome via a linear combination of its lags and a set of exogenous (i.e. external) input variables\n\n* Example:\n\n$$\\hat y_{t+h} = \\hat\\phi + \\sum_{i=0}^p \\hat\\phi_i y_{t-i} + \\sum_{j=0}^q \\hat\\beta_j x_{t-j}$$\n\n* We can construct more complex ARX models with multiple lags of several exogenous \nvariables\n\n## ARX model for COVID deaths\n\n* To improve our predictions for COVID deaths 28 days ahead, we could merge the two models \nconsidered so far.\n\n* This leads us to the ARX model\n\n$$\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\beta_0 x_{t}$$\n\n* We can fit it on the training set by running\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\narx_fit = lm(deaths ~ lagged_deaths + lagged_cases, data = train)\ncoef(arx_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept) lagged_deaths  lagged_cases \n   0.08133189    0.14010549    0.01030239 \n```\n:::\n:::\n\n\n## Predictions on training and test sets (ARX model)\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/arx-plot-train-test-predictions-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                    MAE     MASE\ntraining     0.06268428 368.0910\nsplit-sample 0.08227714 542.6727\n```\n:::\n:::\n\n\n## Time-Series CV: all past and trailing (ARX model)\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/arx-plot-cv-predictions-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                                 MAE     MASE\ntraining                  0.06268428 368.0910\nsplit-sample              0.08227714 542.6727\ntime series CV            0.06739289 550.1531\ntime series CV + trailing 0.04757330 388.3585\n```\n:::\n:::\n\n\n# Considerations for Different Horizons \n\n## Changing $h$\n\n* So far we focused on COVID deaths prediction 28 days ahead.\n\n* The ARX model we fitted had much better performance than the AR model.\n\n* We will next compare the AR model \n\n$$\\hat y_{t+h} = \\hat\\phi + \\hat\\phi_0 y_t$$\n\nto the ARX model\n\n$$\\hat y_{t+h} = \\hat\\phi + \\hat\\phi_0 y_t + \\hat\\beta_0 x_t$$\n\nfor horizons $h = 7, 14, 21, 28$ (using a trailing window of size 200).\n\n## Predicting 7 days ahead\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/ar-arx-plot-7-1.svg){fig-align='left'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n           MAE     MASE\nAR  0.12989192 934.5696\nARX 0.09713393 698.8765\n```\n:::\n:::\n\n\n## Predicting 14 days ahead\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/ar-arx-plot-14-1.svg){fig-align='left'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n           MAE     MASE\nAR  0.13037989 956.0440\nARX 0.06348795 465.5417\n```\n:::\n:::\n\n\n## Predicting 21 days ahead\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/ar-arx-plot-21-1.svg){fig-align='left'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n          MAE      MASE\nAR  0.1702452 1312.0747\nARX 0.0488983  376.8577\n```\n:::\n:::\n\n\n## Predicting 28 days ahead\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/ar-arx-plot-28-1.svg){fig-align='left'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n          MAE      MASE\nAR  0.1646065 1343.7439\nARX 0.0475733  388.3585\n```\n:::\n:::\n\n\n## Observations\n\n* For each horizon $h$, the ARX model has always smaller error than the AR model.\n\n* The benefit of including cases as a predictor increases with $h$.\n\n* The error of the AR model increases with $h$, while the error of the ARX model\ndecreases with $h$.\n\n# Overfitting and Regularization\n\n## Too many predictors\n\n* What if we try to incorporate past information extensively by fitting a model \nwith a very large number of predictors?\n\n  * The estimated coefficients will be chosen to mimic the observed data very \n  closely on the training set, leading to [small training error]{.primary}\n\n  * The predictive performance on the test set might be very poor, \n  producing [large split-sample and CV error]{.primary}\n\n::: {.callout-important icon=\"false\"}\n## Issue\nOverfitting!\n:::\n\n## ARX model for COVID deaths with many predictors\n\n* When predicting COVID deaths 28 days ahead, we can try to use more past \ninformation by fitting a model that includes the past two months of COVID deaths \nand cases as predictors\n\n$$\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-1} + \\dots + \n\\hat\\phi_{59} y_{t-59} + \n\\hat\\beta_0 x_{t} + \\dots + \\hat\\beta_{t-59} x_{t-59}$$\n\n## Preparing the data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ny <- ca$deaths  #outcome\nlags <- 28:87   #lags used for predictors (deaths and cases)\n\n# Build predictor matrix with 60 columns\nX <- data.frame(matrix(NA, nrow = length(y), ncol = 2*length(lags)))\ncolnames(X) <- paste('X', 1:ncol(X), sep = '')\n\nfor (j in 1:length(lags)) {\n  # first 60 columns contain deaths lagged by 28, 29, ..., 87\n  X[, j] = dplyr::lag(ca$deaths, lags[j])\n  # last 60 columns contain cases lagged by 28, 29, ..., 87\n  X[, length(lags) + j] = dplyr::lag(ca$cases, lags[j])\n}\n```\n:::\n\n\n## Fitting the ARX model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Train/test split\ny_train <- y[1:t0]\nX_train <- X[1:t0, ]\ny_test <- y[(t0+1):length(y)]\nX_test <- X[(t0+1):length(y), ]\n\n# Fitting the ARX model\nreg = lm(y_train ~ ., data = X_train)\ncoef(reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept)            X1            X2            X3            X4 \n 0.2758283711  0.2457314327  0.2225988768 -0.4559613879 -0.4731427507 \n           X5            X6            X7            X8            X9 \n 0.4570192882 -0.0829030158  0.0087610368 -0.1277561418 -0.0930270533 \n          X10           X11           X12           X13           X14 \n 0.2880726732 -0.8396082213  0.5525681932 -0.6656058745 -0.1372663639 \n          X15           X16           X17           X18           X19 \n 0.2441111445 -0.5549887598 -0.1984910609 -0.4381802967  0.9748005886 \n          X20           X21           X22           X23           X24 \n-0.2252872009 -0.3603010052 -0.1484425645 -0.2629114744  0.6481906782 \n          X25           X26           X27           X28           X29 \n-0.4386397760  0.2287881141 -0.4141878941  0.1538387231  0.0016914281 \n          X30           X31           X32           X33           X34 \n-0.1675549452  0.1862035471 -0.7604163647  0.7661301939 -0.3567175136 \n          X35           X36           X37           X38           X39 \n-0.6461899753  0.2820547532  0.3658805915 -0.1036095025  0.3168098103 \n          X40           X41           X42           X43           X44 \n 0.4270049404 -0.3861653324  0.1887767107  0.2446997478  0.0406226039 \n          X45           X46           X47           X48           X49 \n 0.3290951846 -0.4657697117  0.1271299593  0.3931515677  0.2836116580 \n          X50           X51           X52           X53           X54 \n-0.3674019667 -0.4491442210  0.4524243063 -0.3428030503  0.4292019510 \n          X55           X56           X57           X58           X59 \n 0.4096633980 -0.5462527325  0.4501163940 -0.3929646040 -0.2112561496 \n          X60           X61           X62           X63           X64 \n-0.3326657892  0.0175419874 -0.0077855053 -0.0024976868  0.0014263572 \n          X65           X66           X67           X68           X69 \n-0.0048785301  0.0013524131 -0.0022148536  0.0065944994  0.0023437318 \n          X70           X71           X72           X73           X74 \n-0.0040292424  0.0136591034 -0.0086165459 -0.0059687437 -0.0069756592 \n          X75           X76           X77           X78           X79 \n 0.0145125287 -0.0021987656 -0.0018740932  0.0043662687  0.0019855230 \n          X80           X81           X82           X83           X84 \n 0.0005040760 -0.0021147396  0.0030569084 -0.0043404977 -0.0081888972 \n          X85           X86           X87           X88           X89 \n 0.0124142487 -0.0019007422 -0.0091802229  0.0090002190  0.0096226370 \n          X90           X91           X92           X93           X94 \n-0.0033216356 -0.0040088540  0.0006876339 -0.0152565542 -0.0112099615 \n          X95           X96           X97           X98           X99 \n 0.0289012311  0.0084111577 -0.0134474728  0.0083765726 -0.0089290862 \n         X100          X101          X102          X103          X104 \n 0.0069254713 -0.0178761659  0.0191826013  0.0011505708  0.0071752544 \n         X105          X106          X107          X108          X109 \n 0.0127445467 -0.0133315137 -0.0022960536 -0.0031951107  0.0102816246 \n         X110          X111          X112          X113          X114 \n-0.0028098154  0.0092476436 -0.0120237253 -0.0079725070  0.0194764427 \n         X115          X116          X117          X118          X119 \n-0.0170893902  0.0232396558 -0.0175601245  0.0002431107  0.0129597132 \n         X120 \n-0.0196106522 \n```\n:::\n:::\n\n\n## Predictions on training and test set \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npred_train <- predict(reg)                    #get training predictions\npred_test <- predict(reg, newdata = X_test)   #get test predictions\n```\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/overfit-plot-train-test-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                    MAE      MASE\ntraining     0.02888549  146.9367\nsplit-sample 0.35664868 2352.3364\n```\n:::\n:::\n\n\n\n## Regularization\n\n* If we want to consider a large number of predictors, \nhow can we avoid overfitting?\n\n* [Idea]{.primary}: introduce a regularization parameter $\\lambda$ that [shrinks or sets]{.primary} some \nof the estimated coefficients to zero, i.e. some predictors are estimated to \nhave limited or no predictive power\n\n* Most common regularization methods\n\n  * [Ridge]{.primary}: shrinks coefficients to zero\n  \n  * [Lasso]{.primary}: sets some coefficients to zero\n\n## Choosing $\\lambda$\n\n* The regularization parameter $\\lambda$ can be selected by cross-validation:\n\n  1. Select a sequence of $\\lambda$'s\n  \n  1. Fit and predict for each such $\\lambda$\n  \n  1. Select the $\\lambda$ that leads to smaller error\n  \n* The R library `glmnet` implements ridge and lasso regression, \nand can perform step 1. automatically.\n\n\n\n## Fit ARX + ridge/lasso for COVID deaths\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(glmnet) # Implements ridge and lasso\n\n# We'll need to omit NA values explicitly, as otherwise glmnet will complain\nna_obs <- 1:max(lags)\nX_train <- X_train[-na_obs, ]\ny_train <- y_train[-na_obs]\n\n# Ridge regression: set alpha = 0, lambda sequence will be chosen automatically\nridge <- glmnet(X_train, y_train, alpha = 0)\nbeta_ridge <- coef(ridge)       # matrix of estimated coefficients \nlambda_ridge <- ridge$lambda    # sequence of lambdas used to fit ridge \n\n# Lasso regression: set alpha = 1, lambda sequence will be chosen automatically\nlasso <- glmnet(X_train, y_train, alpha = 1)\nbeta_lasso <- coef(lasso)       # matrix of estimated coefficients \nlambda_lasso <- lasso$lambda    # sequence of lambdas used to fit lasso \n\ndim(beta_lasso)      # One row per coefficient, one column per lambda value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 121 100\n```\n:::\n:::\n\n\n\n## Predictions on test set and selection of $\\lambda$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Predict values for second half of the time series\nyhat_ridge <- predict(ridge, newx = as.matrix(X_test))\nyhat_lasso <- predict(lasso, newx = as.matrix(X_test))\n\n# Compute MAE \nmae_ridge <- colMeans(abs(yhat_ridge - y_test))\nmae_lasso <- colMeans(abs(yhat_lasso - y_test))\n\n# Select index of lambda vector which gives lowest MAE\nmin_ridge <- which.min(mae_ridge)\nmin_lasso <- which.min(mae_lasso)\npaste('Best MAE ridge:', round(min(mae_ridge), 3),\n      '; Best MAE lasso:', round(min(mae_lasso), 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Best MAE ridge: 0.196 ; Best MAE lasso: 0.092\"\n```\n:::\n\n```{.r .cell-code}\n# Get predictions for train and test sets\npred_train_ridge <- predict(ridge, newx = as.matrix(X_train))[, min_ridge] \npred_test_ridge <- yhat_ridge[, min_ridge]\npred_train_lasso <- predict(lasso, newx = as.matrix(X_train))[, min_lasso] \npred_test_lasso <- yhat_lasso[, min_lasso]\n```\n:::\n\n\n## Estimated coefficients: shrinkage vs sparsity\n\n::: flex\n::: w-50\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                    ridge         lasso\n(Intercept)  4.112256e-01  0.1027530670\nX1           5.497463e-03  0.0000000000\nX2           5.443749e-03  0.0000000000\nX3           5.385490e-03  0.0000000000\nX4           5.313227e-03  0.0000000000\nX5           5.258979e-03  0.0000000000\nX6           5.188803e-03  0.0000000000\nX7           5.139054e-03  0.0000000000\nX8           5.076501e-03  0.0000000000\nX9           4.981253e-03  0.0000000000\nX10          4.886178e-03  0.0000000000\nX11          4.809706e-03  0.0000000000\nX12          4.729025e-03  0.0000000000\nX13          4.667905e-03  0.0000000000\nX14          4.583550e-03  0.0000000000\nX15          4.499529e-03  0.0000000000\nX16          4.448547e-03  0.0000000000\nX17          4.397032e-03  0.0000000000\nX18          4.368272e-03  0.0000000000\nX19          4.316661e-03  0.0000000000\nX20          4.249886e-03  0.0000000000\nX21          4.183664e-03  0.0000000000\nX22          4.127680e-03  0.0000000000\nX23          4.050602e-03  0.0000000000\nX24          3.988909e-03  0.0000000000\nX25          3.822127e-03  0.0000000000\nX26          3.584918e-03  0.0000000000\nX27          3.283302e-03  0.0000000000\nX28          2.888911e-03  0.0000000000\nX29          2.415738e-03  0.0000000000\nX30          1.824392e-03  0.0000000000\nX31          1.152044e-03  0.0000000000\nX32          3.881764e-04  0.0000000000\nX33         -4.546563e-04  0.0000000000\nX34         -1.293969e-03  0.0000000000\nX35         -2.117525e-03  0.0000000000\nX36         -2.801391e-03  0.0000000000\nX37         -3.394630e-03  0.0000000000\nX38         -4.006729e-03  0.0000000000\nX39         -4.662078e-03  0.0000000000\nX40         -5.354854e-03  0.0000000000\nX41         -6.265590e-03  0.0000000000\nX42         -7.230297e-03  0.0000000000\nX43         -8.508468e-03  0.0000000000\nX44         -9.918750e-03  0.0000000000\nX45         -1.149602e-02  0.0000000000\nX46         -1.319458e-02  0.0000000000\nX47         -1.481247e-02  0.0000000000\nX48         -1.630315e-02  0.0000000000\nX49         -1.753316e-02  0.0000000000\nX50         -1.813929e-02  0.0000000000\nX51         -1.857362e-02  0.0000000000\nX52         -1.893093e-02  0.0000000000\nX53         -1.933053e-02  0.0000000000\nX54         -1.957672e-02  0.0000000000\nX55         -1.975165e-02  0.0000000000\nX56         -2.012127e-02  0.0000000000\nX57         -2.030953e-02  0.0000000000\nX58         -2.037081e-02  0.0000000000\nX59         -2.021378e-02  0.0000000000\nX60         -1.976317e-02 -0.0345707637\nX61          8.242683e-05  0.0095304559\nX62          8.132113e-05  0.0000000000\nX63          8.018020e-05  0.0000000000\nX64          7.901220e-05  0.0000000000\nX65          7.779561e-05  0.0000000000\nX66          7.664052e-05  0.0000000000\nX67          7.551905e-05  0.0000000000\nX68          7.444242e-05  0.0000000000\nX69          7.340449e-05  0.0000000000\nX70          7.236918e-05  0.0000000000\nX71          7.136972e-05  0.0000000000\nX72          7.037117e-05  0.0000000000\nX73          6.943229e-05  0.0000000000\nX74          6.860455e-05  0.0000000000\nX75          6.787924e-05  0.0000000000\nX76          6.722652e-05  0.0015360023\nX77          6.661688e-05  0.0000000000\nX78          6.601493e-05  0.0000000000\nX79          6.545565e-05  0.0000000000\nX80          6.496923e-05  0.0000000000\nX81          6.451692e-05  0.0000000000\nX82          6.407003e-05  0.0000000000\nX83          6.345530e-05  0.0000000000\nX84          6.276881e-05  0.0000000000\nX85          6.192521e-05  0.0000000000\nX86          6.101792e-05  0.0000000000\nX87          6.003796e-05  0.0000000000\nX88          5.900856e-05  0.0000000000\nX89          5.766256e-05  0.0000000000\nX90          5.640154e-05  0.0000000000\nX91          5.521221e-05  0.0000000000\nX92          5.410753e-05  0.0000000000\nX93          5.310748e-05  0.0000000000\nX94          5.191454e-05  0.0000000000\nX95          5.078166e-05  0.0000000000\nX96          4.995013e-05  0.0000000000\nX97          4.934901e-05  0.0000000000\nX98          4.892197e-05  0.0000000000\nX99          4.863106e-05  0.0000000000\nX100         4.829392e-05  0.0000000000\nX101         4.816553e-05  0.0000000000\nX102         4.810093e-05  0.0000000000\nX103         4.841180e-05  0.0000000000\nX104         4.912355e-05  0.0005895771\nX105         4.985320e-05  0.0000000000\nX106         5.066950e-05  0.0000000000\nX107         5.150530e-05  0.0000000000\nX108         5.258211e-05  0.0000000000\nX109         5.387059e-05  0.0000000000\nX110         5.451414e-05  0.0000000000\nX111         5.443739e-05  0.0000000000\nX112         5.410652e-05  0.0000000000\nX113         5.355103e-05  0.0000000000\nX114         5.275985e-05  0.0000000000\nX115         5.111364e-05  0.0000000000\nX116         4.828218e-05  0.0000000000\nX117         4.455698e-05  0.0000000000\nX118         4.029228e-05  0.0000000000\nX119         3.539927e-05  0.0000000000\nX120         3.020232e-05  0.0000000000\n```\n:::\n:::\n\n\n:::\n\n::: w-50\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-ridge-lasso-coeff-1.svg){fig-align='center' height=600px}\n:::\n:::\n\n\n:::\n:::\n\n## Predictions: ARX + ridge/lasso (train and test set)\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/shrinkage-sparsity-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                          MAE      MASE\nridge training     0.25271764 1285.5412\nridge split-sample 0.19616116 1293.8139\nlasso training     0.06984086  355.2712\nlasso split-sample 0.09163079  604.3663\n```\n:::\n:::\n\n\n## Time-series CV for ARX + ridge/lasso (trailing)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nh <- 28  # number of days ahead \nw <- 200 # window length\n\n# Initialize matrices for predictions (one column per lambda value)\nyhat_ridge <- matrix(NA, ncol = length(lambda_ridge), nrow = n-h-t0+1) \nyhat_lasso <- matrix(NA, ncol = length(lambda_lasso), nrow = n-h-t0+1) \n\nfor (t in t0:(n-h)) {\n  # Indices of data within window\n  inds = t-w < 1:n & 1:n <= t\n  # Fit ARX + ridge/lasso\n  ridge_trail = glmnet(X[inds, ], y[inds], alpha = 0, lambda = lambda_ridge)\n  lasso_trail = glmnet(X[inds, ], y[inds], alpha = 1, lambda = lambda_lasso)\n  # Predict\n  yhat_ridge[t-t0+1, ] = predict(ridge_trail, newx = as.matrix(X[(t+h), ]))\n  yhat_lasso[t-t0+1, ] = predict(lasso_trail, newx = as.matrix(X[(t+h), ]))\n}\n\n# MAE values for each lambda\nmae_ridge <- colMeans(abs(yhat_ridge - y_test[-c(1:(k-1))]))\nmae_lasso <- colMeans(abs(yhat_lasso - y_test[-c(1:(k-1))]))\n\n# Select lambda that minimizes MAE and save corresponding predictions\nmin_ridge <- which.min(mae_ridge)\nmin_lasso <- which.min(mae_lasso)\npred_cv_ridge <- yhat_ridge[, min_ridge]\npred_cv_lasso <- yhat_lasso[, min_lasso]\n\npaste('Best MAE ridge:', round(min(mae_ridge), 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Best MAE ridge: 0.12\"\n```\n:::\n\n```{.r .cell-code}\npaste('Best MAE lasso:', round(min(mae_lasso), 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Best MAE lasso: 0.062\"\n```\n:::\n:::\n\n\n\n## Predictions: time-series CV for ARX + ridge/lasso (trailing)\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/plot-regularization-cv-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                           MAE     MASE\nridge CV + trailing 0.11964733 976.7255\nlasso CV + trailing 0.06243937 509.7157\n```\n:::\n:::\n\n\n# Prediction Intervals\n\n## Point predictions vs intervals \n\n* So far, we have only considered [point predictions]{.primary}, i.e. \nwe have fitted models \nto provide our [best guess on the outcome]{.primary} at time $t+h$. \n\n::: {.callout-important icon=\"false\"}\n## \nWhat if we want to provide a [measure of uncertainty]{.primary} around the point \nprediction or a [likely range of values]{.primary} for the outcome at time $t+h$?\n\n:::\n\n* For each target time $t+h$, we can construct [prediction intervals]{.primary}, i.e. provide \nranges of values that are expected to cover the true outcome value a fixed \nfraction of times.\n\n## Prediction intervals for `lm` fits\n\n* To get prediction intervals for the models we previously fitted, \nwe only need to tweak our call to `predict` by adding as an input: \n\n  `interval = \"prediction\", level = p`\n\n  where $p \\in (0, 1)$ is the desired coverage.\n\n* The output from `predict` will then be a matrix with \n\n  * first column a [point estimate]{.primary}\n  \n  * second column the [lower limit]{.primary} of the interval\n  \n  * third column the [upper limit]{.primary} of the interval\n\n## Prediction intervals for ARX (test)\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\npred_test_ci <- predict(arx_fit, \n                        newdata = test, \n                        interval = \"prediction\", \n                        level = 0.95)\n\nhead(pred_test_ci)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        fit       lwr       upr\n1 0.7093207 0.5286159 0.8900255\n2 0.6908382 0.5104118 0.8712647\n3 0.6768019 0.4955346 0.8580692\n4 0.6527938 0.4714708 0.8341169\n5 0.6276180 0.4468436 0.8083924\n6 0.6062234 0.4255984 0.7868483\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-arx-intervals-1.svg){fig-align='center'}\n:::\n:::\n\n\n## Prediction intervals for ARX (CV, trailing window)\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot arx-intervals-cv-trailing-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Quantile regression\n\n* So far we only considered different ways to apply linear regression.\n\n* Quantile regression is a different estimation method, and it directly targets conditional \nquantiles of the outcome over time.\n\n::: {.callout-note}\n## Definition\nConditional quantile = value below which a given percentage (e.g. 25%, 50%, \n75%) of observations fall, given specific values of the predictor variables. \n:::\n\n* [Advantage]{.primary}: it provides a more complete picture of the outcome distribution.\n\n## ARX model for COVID deaths via quantile regression\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#install.packages(\"quantreg\")\nlibrary(quantreg)  #library to perform quantile regression\n\n# Set quantiles of interest: we will focus on 2.5%, 50% (i.e. median), and 97.5% quantiles\nquantiles <- c(0.025, 0.5, 0.975)  \n\n# Fit quantile regression on training set\nq_reg <- rq(deaths ~ lagged_deaths + lagged_cases, data = train, tau = quantiles)\n\n# Estimated coefficients\ncoef(q_reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               tau= 0.025  tau= 0.500 tau= 0.975\n(Intercept)   0.021903320  0.10599167 0.12247490\nlagged_deaths 0.037881788 -0.08804903 0.26866227\nlagged_cases  0.009539598  0.01167695 0.01301036\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## Predictions via quantile regression (CV, trailing)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Initialize matrix to store predictions \n# 3 columns: lower limit, median, and upper limit\npred_trailing <- matrix(NA, nrow = n-h-t0+1, ncol = 3)\ncolnames(pred_trailing) <- c('lower', 'median', 'upper')\n\nfor (t in t0:(n-h)) {\n  # Fit quantile regression\n  rq_trailing = rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles,\n                   data = ca, subset = (1:n) <= t & (1:n) > (t-w)) \n  # Predict\n  pred_trailing[t-t0+1, ] = predict(rq_trailing, newdata = data.frame(ca[t+h, ]))\n}\n```\n:::\n\n\n## Predictions via quantile regression (CV, trailing)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/q-reg-plot-cv-predictions-trailing-1.svg){fig-align='center'}\n:::\n:::\n\n\n## Actual Coverage\n\n* We would expect the ARX model fitted via `lm` and via `rq` to cover the truth\nabout 95\\% of the times. Is this actually true in practice?\n\n* The actual coverage of each predictive interval is  \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n         lm.trailing rq.trailing\nCoverage   0.9749104   0.8566308\n```\n:::\n:::\n\n\n* Notice that the coverage of `lm` is close to 95\\%, while `rq` has lower coverage.\n\n## Evaluation\n\n* Prediction intervals are “good” if they \n\n  * cover the truth most of the time\n  \n  * are not too wide\n  \n* Error metric that captures both desiderata: [Weighted Interval Score (WIS)]{.primary}\n\n* $F$ = forecast composed of predicted quantiles $q_{\\tau}$ for the set \nof quantile levels $\\tau$. The WIS for target variable $Y$ is represented as \n([McDonald et al., 2021](https://www.pnas.org/doi/full/10.1073/pnas.2111453118)):\n\n$$WIS(F, Y) = 2\\sum_{\\tau} \\phi_{\\tau} (Y - q_{\\tau})$$\n\nwhere $\\phi_{\\tau}(x) = \\tau |x|$ for $x \\geq 0$ and \n$\\phi_{\\tau}(x) = (1-\\tau) |x|$ for $x < 0$.\n\n## Computing the WIS \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nWIS <- function(truth, estimates, quantiles) {\n  2 * sum(pmax(\n    quantiles * (truth - estimates),\n    (1 - quantiles) * (estimates - truth),\n    na.rm = TRUE\n  ))\n}\n```\n:::\n\n\n::: {.callout-important icon=\"false\"}\n## Note\nWIS tends to [prioritize sharpness]{.primary} (how wide the interval is) relative to \ncoverage (if the interval contains the truth).\n:::\n\n## WIS for ARX fitted via `lm` and `rq`\n\n* The lowest mean WIS is attained by quantile regression. \n\n* Notice: this method has coverage below 95\\% but is still preferred under WIS \nbecause its intervals are narrower than for linear regression.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n  Mean WIS lm Mean WIS rq\n1  0.06534014  0.05733309\n```\n:::\n:::\n\n\n\n# Forecasting with Versioned Data\n\n## Versioned data\n\n* In our forecasting examples, we have assumed the data are never revised \n(or have simply ignored revisions, and used data `as_of` today)\n\n::: {.callout-important icon=\"false\"}\n## \nHow can we train forecasters when dealing with versioned data?\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_archive\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-04-01 / 2021-12-31\nℹ First/last version with update: 2020-04-02 / 2022-01-01\nℹ Versions end: 2022-01-01\nℹ A preview of the table (93566 rows x 5 columns):\n       geo_value time_value    version case_rate death_rate\n    1:        ak 2020-04-01 2020-04-02  1.797489          0\n    2:        ak 2020-04-01 2020-05-07  1.777061          0\n    3:        ak 2020-04-01 2020-10-28  1.106147          0\n    4:        ak 2020-04-01 2020-10-29  1.797489          0\n    5:        ak 2020-04-01 2020-10-30  1.797489          0\n   ---                                                     \n93562:        wy 2021-12-27 2021-12-28 65.598769          0\n93563:        wy 2021-12-28 2021-12-29 50.315286          0\n93564:        wy 2021-12-29 2021-12-30 55.810471          0\n93565:        wy 2021-12-30 2021-12-31 68.002912          0\n93566:        wy 2021-12-31 2022-01-01  0.000000          0\n```\n:::\n:::\n\n\n## Version-aware forecasting\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# initialize dataframe for predictions\n# 5 columns: forecast date, target date, 2.5%, 50%, and 97.5% quantiles\npred_trailing <- data.frame(matrix(NA, ncol = 5, nrow = 0))\ncolnames(pred_trailing) <- c(\"forecast_date\", \"target_date\", 'tau..0.025', 'tau..0.500', 'tau..0.975')\n\nw <- 200         #trailing window size\nh <- 28          #number of days ahead\n\n# dates when predictions are made (set to be 1 month apart)\nfc_time_values <- seq(from = t0_date, to = as.Date(\"2021-12-31\"), by = \"1 month\")\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data <- epix_as_of(ca_archive, max_version = as.Date(fc_date))\n  # create lagged predictors\n  data$lagged_deaths <- dplyr::lag(data$deaths, h) \n                                                  \n  data$lagged_cases <- dplyr::lag(data$cases, h)\n  # perform quantile regression\n  rq_trailing <- rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles, \n                    # only consider window of data\n                    data = data %>% filter(time_value > (max(time_value) - w))) \n  # construct data.frame with the right predictors for the target date\n  predictors <- data.frame(lagged_deaths = tail(data$deaths, 1), \n                           lagged_cases = tail(data$cases, 1))\n  # make predictions for target date and add them to matrix of predictions\n  pred_trailing <- rbind(pred_trailing, \n                         data.frame('forecast_date' = max(data$time_value),\n                                    'target_date' = max(data$time_value) + h, \n                                    predict(rq_trailing, newdata = predictors)))\n}\n```\n:::\n\n\n\n## Version-aware predictions (CV, trailing)\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-versioned-cv-trailing-1.svg){fig-align='center'}\n:::\n:::\n\n\n# Modeling Multiple Time Series\n\n## Using geo information\n\n* Assume we observe data over time from [multiple locations]{.primary}\n(e.g. states or counties).\n\n* We could\n\n  * Estimate coefficients [separately]{.primary} for each location (as we have done so far).\n  \n  * Fit one model using all locations together at each time point ([geo-pooling]{.primary}). \nEstimated coefficients will not be location specific.\n\n  * Estimate coefficients separately for each location, but include predictors capturing \naverages across locations ([partial geo-pooling]{.primary}).\n\n\n\n## Geo-pooling (trailing window)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nusa_archive <- data_archive$DT %>% \n  as_epi_archive()\n\n# initialize dataframe for predictions\n# 6 columns: geo value, forecast date, target date, 2.5%, 50%, and 97.5% quantiles\npred_trailing <- data.frame(matrix(NA, ncol = 6, nrow = 0))\ncolnames(pred_trailing) <- c('geo_value', 'forecast_date', 'target_date',\n                             'tau..0.025', 'tau..0.500', 'tau..0.975')\n\nw <- 200         #trailing window size\nh <- 28          #number of days ahead\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data <- epix_as_of(usa_archive, max_version = as.Date(fc_date))\n  \n  # create lagged predictors for each state \n  data <- data %>%\n    arrange(geo_value, time_value) %>%  \n    group_by(geo_value) %>%\n    mutate(lagged_deaths = dplyr::lag(deaths, h),\n           lagged_cases = dplyr::lag(cases, h)) %>%\n    ungroup()\n  \n  # perform quantile regression\n  rq_trailing <- rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles, \n                    # only consider window of data\n                    data = data %>% filter(time_value > (max(time_value) - w))) \n  \n  # construct dataframe with the right predictors for the target date\n  new_lagged_deaths <- data %>% \n    filter(time_value == max(time_value)) %>%\n    select(geo_value, deaths)\n  \n  new_lagged_cases <- data %>% \n    filter(time_value == max(time_value)) %>%\n    select(geo_value, cases)\n  \n  predictors <- new_lagged_deaths %>%\n    inner_join(new_lagged_cases, join_by(geo_value)) %>%\n    rename(lagged_deaths = deaths,\n           lagged_cases = cases)\n  \n  # make predictions for target date and add them to matrix of predictions\n  pred_trailing <- rbind(pred_trailing, \n                         data.frame(\n                           'geo_value' = predictors$geo_value,\n                           'forecast_date' = max(data$time_value),\n                           'target_date' = max(data$time_value) + h, \n                           predict(rq_trailing, newdata = predictors)))\n}\n\n# geo-pooled predictions for California\npred_ca <- pred_trailing %>%\n  filter(geo_value == 'ca') %>%\n  rename(median = `tau..0.500`,\n         lower = `tau..0.025`,\n         upper = `tau..0.975`) %>%\n  full_join(ca %>% select(time_value, deaths), join_by(target_date == time_value)) %>%\n  arrange(target_date)\n```\n:::\n\n\n## Geo-pooled predictions for California\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-geo-pooling-1.svg){fig-align='center'}\n:::\n:::\n\n\n## Partial geo-pooling (trailing window)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# initialize dataframe for predictions\n# 6 columns: geo value, forecast date, target date, 2.5%, 50%, and 97.5% quantiles\npred_trailing <- data.frame(matrix(NA, ncol = 6, nrow = 0))\ncolnames(pred_trailing) <- c('geo_value', 'forecast_date', 'target_date',\n                             'tau..0.025', 'tau..0.500', 'tau..0.975')\n\nw <- 200         #trailing window size\nh <- 28          #number of days ahead\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data <- epix_as_of(usa_archive, max_version = as.Date(fc_date))\n  \n  # create lagged predictors \n  data <- data %>%\n    arrange(geo_value, time_value) %>%  \n    group_by(geo_value) %>%\n    mutate(lagged_deaths = dplyr::lag(deaths, h),\n           lagged_cases = dplyr::lag(cases, h)) %>%\n    ungroup() %>%\n    group_by(time_value) %>%\n    mutate(avg_lagged_deaths = mean(lagged_deaths, na.rm = T),\n           avg_lagged_cases = mean(lagged_cases, na.rm = T)) %>%\n    ungroup() \n  \n  # perform quantile regression\n  rq_trailing <- rq(deaths ~ lagged_deaths + lagged_cases + avg_lagged_deaths +\n                      avg_lagged_cases, tau = quantiles, \n                    data = (data %>% filter(geo_value == 'ca'))) \n  \n  # construct data.frame with the right predictors for the target date\n  new_lagged_deaths <- data %>% \n    filter(time_value == max(time_value)) %>%\n    select(geo_value, deaths) %>%\n    mutate(avg_lagged_deaths = mean(deaths, na.rm = T)) %>%\n    filter(geo_value == 'ca')\n  \n  new_lagged_cases <- data %>% \n    filter(time_value == max(time_value)) %>%\n    select(geo_value, cases) %>%\n    mutate(avg_lagged_cases = mean(cases, na.rm = T)) %>%\n    filter(geo_value == 'ca')\n  \n  predictors <- new_lagged_deaths %>%\n    inner_join(new_lagged_cases, join_by(geo_value)) %>%\n    rename(lagged_deaths = deaths,\n           lagged_cases = cases)\n  \n  # make predictions for target date and add them to matrix of predictions\n  pred_trailing <- rbind(pred_trailing, \n                         data.frame(\n                           'geo_value' = predictors$geo_value,\n                           'forecast_date' = max(data$time_value),\n                           'target_date' = max(data$time_value) + h, \n                           predict(rq_trailing, newdata = predictors)))\n}\n\n# partially geo-pooled predictions for California\npred_ca <- pred_trailing %>%\n  filter(geo_value == 'ca') %>%\n  rename(median = `tau..0.500`,\n         lower = `tau..0.025`,\n         upper = `tau..0.975`) %>%\n  full_join(ca %>% select(time_value, deaths), join_by(target_date == time_value)) %>%\n  arrange(target_date)\n```\n:::\n\n\n## Partially geo-pooled predictions for California\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-partial-geo-pooling-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Final slide {.smaller}\n\n### Thanks:\n\n\n\n\n\n- The whole [CMU Delphi Team](https://delphi.cmu.edu/about/team/) (across many institutions)\n- Optum/UnitedHealthcare, Change Healthcare.\n- Google, Facebook, Amazon Web Services.\n- Quidel, SafeGraph, Qualtrics.\n- Centers for Disease Control and Prevention.\n- Council of State and Territorial Epidemiologists\n\n\n::: {layout-row=1 fig-align=\"center\"}\n![](gfx/delphi.jpg){height=\"100px\"}\n![](gfx/berkeley.jpg){height=\"100px\"}\n![](gfx/cmu.jpg){height=\"100px\"}\n![](gfx/ubc.jpg){width=\"250px\"}\n![](gfx/stanford.jpg){width=\"250px\"}\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}