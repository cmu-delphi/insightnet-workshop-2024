{
  "hash": "860d7df77ca709c6f50cd99b80036f5d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntalk-title: \"Forecasting and Time-Series Models\"\ntalk-short-title: \"{{< meta talk-title >}}\"\ntalk-subtitle: \"\"\nauthor: \"\"\nother-authors: \"\"\nrepo-address: \"cmu-delphi/insightnet-workshop-2024\"\ntalk-date: \"Venue -- dd Somemonth yyyy\"\nformat: revealjs\nexecute:\n  cache: true\n---\n\n\n\n<!-- Set any of the above to \"\" to omit them -->\n\n<!-- Or adjust the formatting in _titleslide.qmd -->\n\n\n---\n---\n\n\n\\DeclareMathOperator*{\\minimize}{minimize}\n\n\n\n\n\n\n\n\n\n::: flex\n::: w-20\n\n:::\n::: w-80\n## {{< meta talk-title >}} {background-image=\"gfx/cover-art-1.svg\" background-position=\"bottom\"}\n\n### {{< meta talk-subtitle >}}\n\n<br>\n\n#### {{< meta author >}} \n\n{{< meta other-authors >}}\n\n\n{{< meta talk-date >}}\n\n\n:::\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n## Outline\n\n1. Linear Regression for Time Series Data\n\n1. Evaluation Methods\n\n1. ARX Models\n\n1. Overfitting and Regularization\n\n1. Prediction Intervals\n\n1. Forecasting with Versioned Data\n\n1. Modeling Multiple Time Series\n\n\n# Linear Regression for Time Series Data\n\n## Basics of linear regression \n\n* Assume we observe a predictor $x_i$ and an outcome $y_i$ for $i = 1, \\dots, n$.\n\n* Linear regression seeks coefficients $\\beta_0$ and $\\beta_1$ such that\n\n$$y_i \\approx \\beta_0 + \\beta_1 x_i$$\n\nis a good approximation for every $i = 1, \\dots, n$.\n\n* In R, the coefficients are found by running `lm(y ~ x)`, where `y` is the vector \nof responses and `x` the vector of predictors.\n\n\n## Multiple linear regression \n\n* Given $p$ different predictors, we seek $(p+1)$ coefficients such that\n\n$$y_i \\approx \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip}$$\nis a good approximation for every $i = 1, \\dots, n$.\n\n\n## Linear regression with lagged predictor\n\n* In time series, outcomes and predictors are usually indexed by time $t$. \n\n* [Goal]{.primary}: predicting future $y$, given present $x$. \n\n* [Model]{.primary}: linear regression with lagged predictor\n\n$$\\hat y_t = \\hat \\beta_0 + \\hat \\beta_1 x_{t-k}$$\n\ni.e. regress the outcome $y$ at time $t$ on the predictor $x$ at time $t-k$.\n\n* Equivalent way to write the model: \n\n$$\\hat y_{t+k} = \\hat \\beta_0 + \\hat \\beta_1 x_t$$\n\n\n## Example: predicting COVID deaths  \n\n* During the pandemic, interest in predicting COVID deaths 7, 14, 28 days ahead.\n\n* Can we reasonably predict COVID deaths 28 days ahead by just using cases today?\n\n* If we let\n\n$$y_{t+28} = \\text{deaths at time } t+28 \\quad\\quad x_{t} = \\text{cases at time } t$$\n  is the following a good model?\n\n  $$\\hat y_{t+28} = \\hat\\beta_0 + \\hat\\beta_1 x_{t}$$\n\n\n## Example: COVID cases and deaths in California \n\n* Let's focus on California.\n\n* Cases seem highly correlated with deaths several weeks later.\n\n::: flex\n::: w-50\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-ca-cases-deaths-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n:::\n::: w-50\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(ca)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAn `epi_df` object, 6 x 4 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-10-23 11:07:29.405142\n\n# A tibble: 6 × 4\n  geo_value time_value cases deaths\n* <chr>     <date>     <dbl>  <dbl>\n1 ca        2020-04-01  3.17 0.0734\n2 ca        2020-04-02  3.48 0.0835\n3 ca        2020-04-03  3.44 0.0894\n4 ca        2020-04-04  3.05 0.0778\n5 ca        2020-04-05  3.28 0.0876\n6 ca        2020-04-06  3.37 0.0848\n```\n\n\n:::\n:::\n\n\n:::\n:::\n\n\n## Checking correlation\n\n* Let’s split the data into a training and a test set (before/after 2021-03-01).\n\n* On the training set, the correlation between cases and deaths 28 days ahead is very large (> 0.95).\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/correlation-cases-deaths-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n* Let's use (base) R to prepare the data and fit \n\n$$\\hat y_{t+28} = \\hat\\beta_0 + \\hat\\beta_1 x_{t}$$\n\n\n## Preparing the data\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Add column with cases lagged by k\nca$lagged_cases <- dplyr::lag(ca$cases, n = k)\n\n# Split into train and test (before/after t0_date)\nt0_date <- as.Date('2021-03-01')\ntrain <- ca %>% filter(time_value <= t0_date)\ntest <- ca %>% filter(time_value > t0_date)\n```\n:::\n\n\n\n* Check if `deaths` is approximately linear in `lagged_cases`:\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-lag-cases-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Fitting lagged linear regression in R\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nreg_lagged = lm(deaths ~ lagged_cases, data = train)\ncoef(reg_lagged)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n (Intercept) lagged_cases \n     0.09854      0.01132 \n```\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-linear-fit-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n# Evaluation\n\n## Error metrics\n\n* Assume we have predictions $\\hat y_{new, t}$ for the unseen observations \n$y_{new,t}$ over times $t = 1, \\dots, N$.\n\n* Four commonly used error metrics are:\n\n  * mean squared error (MSE)\n\n  * mean absolute error (MAE)\n\n  * mean absolute percentage error (MAPE)\n\n  * mean absolute scaled error (MASE)\n\n## Error metrics: MSE and MAE\n\n$$MSE = \\frac{1}{N} \\sum_{t=1}^N (y_{new, t}- \\hat y_{new, t})^2$$\n$$MAE = \\frac{1}{N} \\sum_{t=1}^N |y_{new, t}- \\hat y_{new, t}|$$\n\n* MAE gives less importance to extreme errors than MSE.\n\n* [Drawback]{.primary}: both metrics are scale-dependent, so they are not universally \ninterpretable.\n(For example, if $y$ captures height, MSE and MAE will vary depending on whether we measure in feet or meters.)\n\n## Error metrics: MAPE\n\n* Fixing scale-dependence:\n\n$$MAPE = 100 \\times \\frac{1}{N} \\sum_{t=1}^N \n\\left|\\frac{y_{new, t}- \\hat y_{new, t}}{y_{new, t}}\\right|$$\n\n* [Drawbacks]{.primary}:\n\n  * Erratic behavior when $y_{new, t}$ is close to zero\n\n  * It assumes the unit of measurement has a meaningful zero (e.g. using \nFahrenheit or Celsius to measure temperature will lead to different MAPE)\n\n\n## Error metrics: MASE\n\n$$MASE = 100 \\times \\frac{\\frac{1}{N} \\sum_{t=1}^N \n|y_{new, t}- \\hat y_{new, t}|}\n{\\frac{1}{N-1} \\sum_{t=2}^N \n|y_{new, t}- y_{new, t-1}|}$$\n\n* [Advantages]{.primary}:\n\n  * is universally interpretable (not scale dependent)\n\n  * avoids the zero-pitfall\n\n* MASE in words: we normalize the error of our forecasts by that of a naive method \nwhich always predicts the last observation.\n\n\n## Defining the error metrics in R\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nMSE <- function(truth, prediction) {\n  mean((truth - prediction)^2)}\n\nMAE <- function(truth, prediction) {\n  mean(abs(truth - prediction))}\n\nMAPE <- function(truth, prediction) {\n  100 * mean(abs(truth - prediction) / truth)}\n\nMASE <- function(truth, prediction) {\n  100 * MAE(truth, prediction) / mean(abs(diff(truth)))}\n```\n:::\n\n\n\n## Estimating the prediction error\n\n* Given an error metric (e.g. MSE), we want to estimate the prediction error under that metric. \n\n* This can be accomplished in different ways, using the\n\n  * Training error\n\n  * Split-sample error\n\n  * Time series cross-validation error (using all past data or a trailing window)\n\n\n## Training error\n\n* The easiest but [worst]{.primary} approach to estimate the prediction error is \nto use the training error, i.e. the average error on the training set that was \nused to fit the model.\n\n* The training error is\n\n  * generally too optimistic as an estimate of prediction error\n\n  * [more optimistic the more complex the model!]{.primary}^[More on this when we talk about overfitting.]\n\n\n## Training error\n#### Linear regression of COVID deaths on lagged cases\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Getting the predictions for the training set\npred_train <- predict(reg_lagged)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-train-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n          MAE  MASE\ntraining 0.06 351.5\n```\n\n\n:::\n:::\n\n\n\n\n## Split-sample error {.smaller}\n\n* To compute the split-sample error  \n\n  1. Split data into training (up to time $t_0$), and test set (after $t_0$)\n\n  1. Fit the model to the training data only\n\n  1. Make predictions for the test set\n\n  1. Compute the selected error metric on the test set only\n\n* Formally, the split-sample MSE is\n\n$$\\text{SplitMSE} = \\frac{1}{n-t_0} \\sum_{t = t_0 +1}^n (\\hat y_t - y_t)^2$$\n\n* Split-sample estimates of prediction error don't mimic a situation where we \nwould refit the model in the future. \nThey are [pessimistic]{.primary} if the relation between outcome and predictors \nchanges over time.\n\n## Split-sample error\n#### Linear regression of COVID deaths on lagged cases\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Getting the predictions for the test set\npred_test <- predict(reg_lagged, newdata = test)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-test-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n                 MAE  MASE\ntraining     0.05986 351.5\nsplit-sample 0.10005 659.9\n```\n\n\n:::\n:::\n\n\n\n## Time-series cross-validation (CV) {.smaller}\n#### 1-step ahead predictions\n\n* If we refit in the future once new data are available, a more \nappropriate way to estimate the prediction error is time-series cross-validation.\n\n* To get 1-step ahead predictions (i.e. at time $t$ we forecast for $t+1$) we proceed as follows,\nfor $t = t_0, t_0+1, \\dots$\n\n  1. Fit the model using data up to time $t$\n\n  1. Make a prediction for $t+1$ \n\n  1. Record the prediction error\n\nThe cross-validation MSE is then\n\n$$CVMSE = \\frac{1}{n-t_0} \\sum_{t = t_0}^{n-1} (\\hat y_{t+1|t} - y_{t+1})^2$$\n\nwhere\t$\\hat y_{t+1|t}$ indicates a prediction for $y$ at time $t+1$ that was made \nwith data available up to time $t$.\n\n## Time-series cross-validation (CV) {.smaller}\n#### $h$-step ahead predictions\n\n* In general, if we want to make $h$-step ahead predictions (i.e. at time \n$t$ we forecast for $t+h$), we proceed as follows \nfor $t = t_0, t_0+1, \\dots$\n\n  * Fit the model using data up to time $t$\n\n  * Make a prediction for $t+h$ \n\n  * Record the prediction error\n\n* The cross-validation MSE is then\n\n$$CVMSE = \\frac{1}{n-t_0} \\sum_{t = t_0}^{n-h} (\\hat y_{t+h|t} - y_{t+h})^2$$\n\nwhere\t$\\hat y_{t+h|t}$ indicates a prediction for $y$ at time $t+h$ that was made \nwith data available up to time $t$.\n\n## Time-series cross-validation (CV) \n#### Linear regression of COVID deaths on lagged cases\n\nGetting the predictions requires slightly more code:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn <- nrow(ca)                               #length of time series\nh <- k                                      #number of days ahead for which prediction is wanted\npred_all_past <- rep(NA, length = n-h-t0+1) #initialize vector of predictions\n\nfor (t in t0:(n-h)) {\n  # fit to all past data and make 1-step ahead prediction\n  reg_all_past = lm(deaths ~ lagged_cases, data = ca, subset = (1:n) <= t) \n  pred_all_past[t-t0+1] = predict(reg_all_past, newdata = data.frame(ca[t+h, ]))\n}\n```\n:::\n\n\n\n::: {.callout-important icon=\"false\"}\n## Note\n\nWith the current model, we can only predict $k$ days ahead (where $k$ = number of days by which predictor is lagged)!\n:::\n\n\n## Time-series cross-validation (CV)\n#### Linear regression of COVID deaths on lagged cases\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-cv-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n                MAE  MASE\ntraining       0.06 351.5\nsplit-sample   0.10 659.9\ntime series CV 0.09 732.6\n```\n\n\n:::\n:::\n\n\n\n## Time-series CV on a trailing window {.smaller}\n\n* So far, to get $h$-step ahead predictions for time $t+h$, we have fitted the \nmodel on all data available up to time $t$. We can instead use a trailing \nwindow, i.e. fit the model on a window of data of length $w$, starting at \ntime $t-w$ and ending at $t$.\n\n* [Advantage]{.primary}: if the predictors-outcome relation changes over time,\ntraining the forecaster on a window of recent data can better capture the recent \nrelation which might be more relevant to predict the outcome in the near future.\n\n* Window length [$w$]{.primary} considerations: \n\n  * if $w$ is too [big]{.primary}, the model [can't adapt]{.primary} to the \n  recent predictors-outcome relation \n\n  * if $w$ is too [small]{.primary}, the fitted model may be [too volatile]{.primary} \n  (trained on too little data)\n\n## Time-series CV on a trailing window\n#### Linear regression of COVID deaths on lagged cases\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Getting the predictions through CV with trailing window\nw <- 60                                     # trailing window size\nh <- k                                      # number of days ahead for which prediction is wanted\npred_trailing <- rep(NA, length = n-h-t0+1) # initialize space to hold predictions\n\nfor (t in t0:(n - h)) {\n  reg_trailing <- lm(\n    formula = deaths ~ lagged_cases, \n    data = ca, \n    subset = (1:n) <= t & (1:n) > (t - w)   # fit to a trailing window of size w\n  )\n  pred_trailing[t - t0 + 1] <- predict(\n    reg_trailing, \n    newdata = data.frame(ca[t + h, ])       # predict 1 step ahead\n  )\n}\n```\n:::\n\n\n\n## Time-series CV: all past vs trailing window\n#### Linear regression of COVID deaths on lagged cases\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-cv-predictions-trailing-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n                              MAE  MASE\ntraining                  0.05986 351.5\nsplit-sample              0.10005 659.9\ntime series CV            0.08974 732.6\ntime series CV + trailing 0.11305 922.9\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n# ARX Models\n\n## Autoregressive (AR) model\n\n* [Idea]{.primary}: predicting the outcome via a linear combination of (some of) its lags \n\n$$\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-1} + \\dots + \\hat\\phi_p y_{t-p}$$\n\n* [Notice]{.primary}: we don't need to include all contiguous lags^[Here we \ndepart from traditional AR models, which do include all contiguous lags.].\n\n* For example, we could fit\n\n$$\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} + \\hat\\phi_2 y_{t-14}$$\n\n\n## AR model for COVID deaths\n\n* Let's disregard `cases`, and only use past `deaths` to predict future `deaths`. \n\n* For now we use one lag only, the one for which deaths and lagged deaths have largest correlation.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/auto-cor-deaths-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n* We will fit the model: $\\quad y_t \\approx \\beta_0 + \\beta_1 y_{t-1}$\n\n## Preparing the data\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Add column with deaths lagged by 1\nca$lagged_deaths <- dplyr::lag(ca$deaths, n = 1)\n\n# Split into train and test (before/after t0_date)\ntrain <- ca %>% filter(time_value <= t0_date)\ntest <- ca %>% filter(time_value > t0_date)\n```\n:::\n\n\n\nCheck that the relationship between COVID deaths and lagged COVID deaths is approximately linear (on the training set):\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/ar-plot-deaths-and-lagged-cases-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n## Fitting the AR model for COVID deaths\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nar_fit <- lm(deaths ~ lagged_deaths, data = train)\ncoef(ar_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept) lagged_deaths \n     0.002515      1.001278 \n```\n\n\n:::\n:::\n\n\n\n::: {.callout-important icon=\"false\"}\n## Note\n\nThe intercept is $\\approx 0$ and the coefficient is $\\approx 1$. \nThis means that we are naively predicting the number of deaths tomorrow with the\nnumber of deaths observed today.\n:::\n\n## Predictions on training and test sets (AR model)\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npred_train <- predict(ar_fit)                 #get training predictions\npred_test <- predict(ar_fit, newdata = test)  #get test predictions\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/ar-plot-train-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n                 MAE  MASE\ntraining     0.01631 100.2\nsplit-sample 0.01572 103.7\n```\n\n\n:::\n:::\n\n\n\n\n## Time-Series CV: all past and trailing (AR model)\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Getting 1-step ahead predictions through CV \npred_all_past <- rep(NA, length = n - t0)\npred_trailing <- rep(NA, length = n - t0)       # initialize space for predictions\nw <- 30                                         # trailing window size\nh <- 1                                          # number of days ahead for which prediction is wanted\n\nfor (t in (t0 + 1):n) {\n  # fit to all past data \n  ar_all_past <- lm(deaths ~ lagged_deaths, data = ca, subset = (1:n) <= (t-h)) \n  # fit to trailing window of data\n  ar_trailing <- lm(deaths ~ lagged_deaths, data = ca, subset = (1:n) <= (t-h) & (1:n) > (t-h-w)) \n  # make 1-step ahead predictions\n  pred_all_past[t - t0] <- predict(ar_all_past, newdata = data.frame(ca[t, ]))\n  pred_trailing[t - t0] <- predict(ar_trailing, newdata = data.frame(ca[t, ]))\n}\n```\n:::\n\n\n\n::: {.callout-important icon=\"false\"}\n## Reminder\n\nWe can predict at most 1-day ahead in this case, because the predictor is only lagged \nby 1 with respect to the outcome.\n:::\n\n## Time-Series CV: all past and trailing (AR model)\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/ar-plot-cv-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n                              MAE  MASE\ntraining                  0.01631 100.2\nsplit-sample              0.01572 103.7\ntime series CV            0.01532 101.0\ntime series CV + trailing 0.01683 111.0\n```\n\n\n:::\n:::\n\n\n\n## Autoregressive exogenous input (ARX) model\n\n* [Idea]{.primary}: predicting the outcome via a linear combination of its lags and a set of exogenous (i.e. external) input variables\n\n* Example of ARX model \n\n$$y_t \\approx \\sum_{i=1}^p \\phi_i y_{t-i} + \\sum_{j=1}^q \\psi_j x_{t-j}$$\n\n* We can construct more complex ARX models with multiple lags of several exogenous \nvariables\n\n## ARX model for COVID deaths\n\n* To improve our predictions for COVID deaths, we could merge the two models \nconsidered so far (i.e. linear regression on cases lagged by k = 28, and \nlinear regression on deaths lagged by 1).\n\n* This leads us to the ARX model\n\n$$y_t \\approx \\beta_0 + \\beta_1 y_{t-1} + \\beta_2 x_{t-k}$$\n\n* We can fit it on the training set by running\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\narx_fit <- lm(deaths ~ lagged_deaths + lagged_cases, data = train)\ncoef(arx_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept) lagged_deaths  lagged_cases \n    0.0006847     1.0211511    -0.0002334 \n```\n\n\n:::\n:::\n\n\n\n## Predictions on training and test sets (ARX model)\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npred_train <- predict(arx_fit)                  # training predictions\npred_test <- predict(arx_fit, newdata = test)   # test predictions\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/arx-plot-train-test-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n                 MAE  MASE\ntraining     0.01717 100.8\nsplit-sample 0.01595 105.2\n```\n\n\n:::\n:::\n\n\n\n## Time-Series CV: all past and trailing (ARX model)\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Getting 1-step ahead predictions through CV \npred_all_past <- rep(NA, length = n - t0)\npred_trailing <- rep(NA, length = n - t0)      # initialize space for predictions\nw <- 30                                        # trailing window size\nh <- 1                                         # number of days ahead for which prediction is wanted\n\nfor (t in (t0+1):n) {\n  arx_all_past <- lm(\n    deaths ~ lagged_deaths + lagged_cases, data = ca, \n    subset = (1:n) <= (t-h)                    # fit to all past data\n  ) \n  arx_trailing <- lm(\n    deaths ~ lagged_deaths + lagged_cases, data = ca, \n    subset = (1:n) <= (t-h) & (1:n) > (t-h-w)) # fit to trailing window of data\n  # make 1-step ahead prediction\n  pred_all_past[t - t0] <- predict(arx_all_past, newdata = data.frame(ca[t, ]))\n  pred_trailing[t - t0] <- predict(arx_trailing, newdata = data.frame(ca[t, ]))\n}\n```\n:::\n\n\n\n## Time-Series CV: all past and trailing (ARX model)\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/arx-plot-cv-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n                              MAE  MASE\ntraining                  0.01717 100.8\nsplit-sample              0.01595 105.2\ntime series CV            0.01558 102.8\ntime series CV + trailing 0.01841 121.4\n```\n\n\n:::\n:::\n\n\n\n\n\n# Overfitting and Regularization\n\n## Too many predictors\n\n* What if we try to incorporate past information extensively by fitting a model \nwith a very large number of predictors?\n\n  * The estimated coefficients will be chosen to mimic the observed data very \n  closely on the training set, leading to [small training error]{.primary}\n\n  * The predictive performance on the test set might be very poor, \n  producing [large split-sample and CV error]{.primary}\n\n::: {.callout-important icon=\"false\"}\n## Issue\nOverfitting!\n:::\n\n## ARX model for COVID deaths with many predictors\n\n* When predicting COVID deaths at time $t$, we can try to use more past \ninformation by fitting a model that includes the past two months of COVID deaths \nand cases as predictors\n\n$$\n\\begin{aligned}\ny_t &\\approx \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\dots + \\phi_{60} y_{t-60}\\\\\n &\\quad +\\; \\psi_1 x_{t-1} + \\psi_2 x_{t-2} + \\dots + \\psi_{60} x_{t-60}\n\\end{aligned}\n$$\n\n## Preparing the data\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ny <- ca$deaths     # outcome\nnlags <- 60\nlags <- 1:nlags    # lags used for predictors (deaths and cases)\n\n# Build predictor matrix with 120 columns\nX <- data.frame(matrix(NA, nrow = length(y), ncol = 2 * length(lags)))\nnames(X) <- c(t(outer(c(\"Y\", \"X\"), lags, paste0)))\n\nfor (j in 1:length(lags)) {\n  # first 60 columns contain deaths lagged by 1, 2,..., 60\n  X[, j] <- dplyr::lag(ca$deaths, lags[j])\n  # last 60 columns contain cases lagged by 1, 2,..., 60\n  X[, length(lags) + j] <- dplyr::lag(ca$cases, lags[j])\n}\n\nX[1:5, 1:5] # look at first few entries of predictor matrix\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Y1      Y2      Y3     Y4 Y5\n1      NA      NA      NA     NA NA\n2 0.07340      NA      NA     NA NA\n3 0.08352 0.07340      NA     NA NA\n4 0.08942 0.08352 0.07340     NA NA\n5 0.07782 0.08942 0.08352 0.0734 NA\n```\n\n\n:::\n:::\n\n\n\n## Fitting the ARX model\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Train/test split\ny_train <- y[1:t0]\nX_train <- X[1:t0, ]\ny_test <- y[(t0 + 1):length(y)]\nX_test <- X[(t0 + 1):length(y), ]\n\n# Fitting the ARX model\nreg <- lm(y_train ~ ., data = X_train)\ncoef(reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)          Y1          Y2          Y3          Y4          Y5 \n -0.0289752   1.0036479  -0.0697911  -0.0965291   0.1253087  -0.2084338 \n         Y6          Y7          Y8          Y9         Y10         Y11 \n  0.2883024  -0.8537570   0.9078062  -0.1967354   0.0249038   0.1204699 \n        Y12         Y13         Y14         Y15         Y16         Y17 \n -0.5801064   0.5603828  -0.6110256   0.8353451  -0.4524450   0.1033182 \n        Y18         Y19         Y20         Y21         Y22         Y23 \n  0.1245159  -0.3785865   0.6905903  -0.6700784   0.6263187  -0.5753648 \n        Y24         Y25         Y26         Y27         Y28         Y29 \n  0.2775892  -0.0897321  -0.1341106   0.4351487  -0.2602754   0.4725943 \n        Y30         Y31         Y32         Y33         Y34         Y35 \n -0.8007746   0.3937356   0.0128097  -0.1043945   0.5427976  -0.4767253 \n        Y36         Y37         Y38         Y39         Y40         Y41 \n  0.3308457  -0.6875832   0.2761151   0.2558659  -0.1255478   0.1558682 \n        Y42         Y43         Y44         Y45         Y46         Y47 \n -0.4422862   0.6432640  -0.6517865   0.3358910   0.2200145  -0.1375614 \n        Y48         Y49         Y50         Y51         Y52         Y53 \n  0.0672152  -0.3252118   0.2540547  -0.1871311   0.2459381   0.1757874 \n        Y54         Y55         Y56         Y57         Y58         Y59 \n -0.1549375   0.0255017  -0.1832944   0.0593011   0.2009741  -0.3059064 \n        Y60          X1          X2          X3          X4          X5 \n  0.1253185   0.0031164  -0.0018706  -0.0014906   0.0007032  -0.0005235 \n         X6          X7          X8          X9         X10         X11 \n  0.0002075   0.0009498   0.0001458  -0.0018947  -0.0008635   0.0035604 \n        X12         X13         X14         X15         X16         X17 \n -0.0029179   0.0025100   0.0023824   0.0007824  -0.0038704  -0.0050937 \n        X18         X19         X20         X21         X22         X23 \n -0.0011288   0.0052345   0.0043848  -0.0006837  -0.0010784  -0.0013433 \n        X24         X25         X26         X27         X28         X29 \n -0.0064517   0.0092376  -0.0018809  -0.0006133   0.0037939  -0.0031949 \n        X30         X31         X32         X33         X34         X35 \n -0.0039880   0.0019644  -0.0001691   0.0029029  -0.0013386   0.0043478 \n        X36         X37         X38         X39         X40         X41 \n -0.0066887  -0.0027919   0.0085703  -0.0035707   0.0041815  -0.0061790 \n        X42         X43         X44         X45         X46         X47 \n  0.0052011  -0.0080403   0.0016673   0.0079620  -0.0078740   0.0053071 \n        X48         X49         X50         X51         X52         X53 \n -0.0032933   0.0038192  -0.0038973   0.0001300   0.0038706  -0.0074718 \n        X54         X55         X56         X57         X58         X59 \n  0.0056987  -0.0011645  -0.0042329   0.0031769  -0.0002317   0.0025479 \n        X60 \n -0.0033567 \n```\n\n\n:::\n:::\n\n\n\n## Predictions on training and test set \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npred_train <- predict(reg)                    # training predictions\npred_test <- predict(reg, newdata = X_test)   # test predictions\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/overfit-plot-train-test-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n                  MAE   MASE\ntraining     0.008842  47.99\nsplit-sample 0.042037 277.26\n```\n\n\n:::\n:::\n\n\n\n\n## Regularization\n\n* If we want to consider a large number of predictors, \nhow can we avoid overfitting?\n\n* [Idea]{.primary}: introduce a regularization parameter $\\lambda$ that [shrinks or sets]{.primary} some \nof the estimated coefficients to zero, i.e. some predictors are estimated to \nhave limited or no predictive power\n\n* Most common regularization methods\n\n  * [Ridge]{.primary}: shrinks coefficients to zero\n  \n  * [Lasso]{.primary}: sets some coefficients to zero\n\n## Choosing $\\lambda$\n\n* The regularization parameter $\\lambda$ can be selected by cross-validation:\n\n  1. Select a sequence of $\\lambda$'s\n  \n  1. Fit and predict for each such $\\lambda$\n  \n  1. Select the $\\lambda$ that leads to smaller error\n  \n* The R library `glmnet` implements ridge and lasso regression, \nand can perform step 1. automatically.\n\n\n\n## Fit ARX + ridge/lasso for COVID deaths\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(glmnet) # Implements ridge and lasso\n\n# We'll need to omit NA values explicitly, as otherwise glmnet will complain\nna_obs <- 1:max(lags)\nX_train <- X_train[-na_obs, ]\ny_train <- y_train[-na_obs]\n\n# Ridge regression: set alpha = 0, lambda sequence will be chosen automatically\nridge <- glmnet(X_train, y_train, alpha = 0)\nbeta_ridge <- coef(ridge)       # matrix of estimated coefficients \nlambda_ridge <- ridge$lambda    # sequence of lambdas used to fit ridge \n\n# Lasso regression: set alpha = 1, lambda sequence will be chosen automatically\nlasso <- glmnet(X_train, y_train, alpha = 1)\nbeta_lasso <- coef(lasso)       # matrix of estimated coefficients \nlambda_lasso <- lasso$lambda    # sequence of lambdas used to fit lasso \n\ndim(beta_lasso)      # One row per coefficient, one column per lambda value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 121 100\n```\n\n\n:::\n:::\n\n\n\n\n## Predictions on test set and selection of $\\lambda$\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Predict values for second half of the time series\nyhat_ridge <- predict(ridge, newx = as.matrix(X_test))\nyhat_lasso <- predict(lasso, newx = as.matrix(X_test))\n\n# Compute MAE \nmae_ridge <- colMeans(abs(yhat_ridge - y_test))\nmae_lasso <- colMeans(abs(yhat_lasso - y_test))\n\n# Select index of lambda vector which gives lowest MAE\nmin_ridge <- which.min(mae_ridge)\nmin_lasso <- which.min(mae_lasso)\npaste('Best MAE ridge:', round(min(mae_ridge), 3),\n      '; Best MAE lasso:', round(min(mae_lasso), 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Best MAE ridge: 0.046 ; Best MAE lasso: 0.018\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Get predictions for train and test sets\npred_train_ridge <- predict(ridge, newx = as.matrix(X_train))[, min_ridge] \npred_test_ridge <- yhat_ridge[, min_ridge]\npred_train_lasso <- predict(lasso, newx = as.matrix(X_train))[, min_lasso] \npred_test_lasso <- yhat_lasso[, min_lasso]\n```\n:::\n\n\n\n## Estimated coefficients: shrinkage vs sparsity\n\n::: flex\n::: w-50\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n                 ridge     lasso\n(Intercept) -9.939e-03 1.189e-02\nX1           8.873e-02 9.289e-01\nX2           6.783e-02 0.000e+00\nX3           4.946e-02 0.000e+00\nX4           3.515e-02 0.000e+00\nX5           2.419e-02 0.000e+00\nX6           1.128e-02 0.000e+00\nX7           2.613e-03 0.000e+00\nX8           6.824e-03 0.000e+00\nX9           1.148e-02 0.000e+00\nX10          1.400e-02 0.000e+00\nX11          1.450e-02 0.000e+00\nX12          9.402e-03 0.000e+00\nX13          9.216e-03 0.000e+00\nX14          9.760e-03 0.000e+00\nX15          8.211e-03 0.000e+00\nX16          5.431e-03 0.000e+00\nX17          4.833e-03 0.000e+00\nX18          6.671e-03 0.000e+00\nX19          1.199e-02 3.383e-04\nX20          1.276e-02 0.000e+00\nX21          1.441e-02 0.000e+00\nX22          1.841e-02 0.000e+00\nX23          2.384e-02 2.080e-04\nX24          2.761e-02 0.000e+00\nX25          2.543e-02 0.000e+00\nX26          2.420e-02 0.000e+00\nX27          2.434e-02 0.000e+00\nX28          2.450e-02 0.000e+00\nX29          2.022e-02 0.000e+00\nX30          1.338e-02 0.000e+00\nX31          7.529e-03 0.000e+00\nX32          5.901e-03 0.000e+00\nX33          3.727e-03 0.000e+00\nX34          6.463e-03 0.000e+00\nX35          1.674e-03 0.000e+00\nX36         -3.282e-03 0.000e+00\nX37         -7.946e-03 0.000e+00\nX38         -1.192e-02 0.000e+00\nX39         -1.070e-02 0.000e+00\nX40         -8.865e-03 0.000e+00\nX41         -6.464e-03 0.000e+00\nX42          4.276e-03 0.000e+00\nX43          1.920e-02 0.000e+00\nX44          2.980e-02 0.000e+00\nX45          4.787e-02 4.480e-04\nX46          5.325e-02 0.000e+00\nX47          4.887e-02 0.000e+00\nX48          3.629e-02 0.000e+00\nX49          2.581e-02 0.000e+00\nX50          2.677e-02 0.000e+00\nX51          3.226e-02 0.000e+00\nX52          2.766e-02 0.000e+00\nX53          3.046e-02 0.000e+00\nX54          4.403e-02 0.000e+00\nX55          3.935e-02 0.000e+00\nX56          2.178e-02 0.000e+00\nX57         -2.157e-02 0.000e+00\nX58         -6.404e-02 0.000e+00\nX59         -1.144e-01 0.000e+00\nX60         -1.502e-01 0.000e+00\nX61          4.161e-04 0.000e+00\nX62          3.253e-04 0.000e+00\nX63          2.394e-04 0.000e+00\nX64          1.513e-04 0.000e+00\nX65          6.425e-05 0.000e+00\nX66          3.746e-05 0.000e+00\nX67          2.582e-05 0.000e+00\nX68          4.790e-05 0.000e+00\nX69          7.950e-05 0.000e+00\nX70          1.040e-04 0.000e+00\nX71          1.401e-04 8.926e-06\nX72          1.591e-04 2.342e-07\nX73          1.604e-04 0.000e+00\nX74          1.745e-04 1.241e-05\nX75          1.730e-04 0.000e+00\nX76          1.363e-04 0.000e+00\nX77          1.275e-04 0.000e+00\nX78          1.281e-04 0.000e+00\nX79          2.085e-04 0.000e+00\nX80          2.943e-04 6.824e-04\nX81          3.238e-04 0.000e+00\nX82          3.553e-04 0.000e+00\nX83          3.929e-04 0.000e+00\nX84          3.963e-04 0.000e+00\nX85          4.183e-04 0.000e+00\nX86          3.568e-04 0.000e+00\nX87          2.716e-04 0.000e+00\nX88          2.091e-04 0.000e+00\nX89          1.230e-04 0.000e+00\nX90          6.607e-05 0.000e+00\nX91          2.150e-05 0.000e+00\nX92         -4.080e-05 0.000e+00\nX93         -5.814e-05 0.000e+00\nX94         -5.999e-05 0.000e+00\nX95         -4.410e-05 0.000e+00\nX96         -1.835e-05 0.000e+00\nX97         -9.221e-06 0.000e+00\nX98          1.791e-05 0.000e+00\nX99          1.464e-05 0.000e+00\nX100         1.109e-05 0.000e+00\nX101         2.655e-05 0.000e+00\nX102         5.769e-05 0.000e+00\nX103         8.402e-05 0.000e+00\nX104         9.263e-05 0.000e+00\nX105         7.920e-05 0.000e+00\nX106         7.983e-05 0.000e+00\nX107         8.220e-05 0.000e+00\nX108         6.666e-05 0.000e+00\nX109         7.027e-05 0.000e+00\nX110         2.697e-05 0.000e+00\nX111        -1.232e-05 0.000e+00\nX112        -4.742e-05 0.000e+00\nX113        -6.579e-05 0.000e+00\nX114        -7.823e-05 0.000e+00\nX115        -1.490e-04 0.000e+00\nX116        -2.535e-04 0.000e+00\nX117        -3.047e-04 0.000e+00\nX118        -3.284e-04 0.000e+00\nX119        -3.492e-04 0.000e+00\nX120        -3.962e-04 0.000e+00\n```\n\n\n:::\n:::\n\n\n\n:::\n\n::: w-50\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-ridge-lasso-coeff-1.svg){fig-align='center' height=600px}\n:::\n:::\n\n\n\n:::\n:::\n\n## Predictions: ARX + ridge/lasso (train and test set)\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/shrinkage-sparsity-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n                       MAE   MASE\nridge training     0.02556 138.74\nridge split-sample 0.04614 304.32\nlasso training     0.01822  98.92\nlasso split-sample 0.01768 116.58\n```\n\n\n:::\n:::\n\n\n\n## Time-series CV for ARX + ridge/lasso (trailing)\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Initialize matrices for predictions (one column per lambda value)\nyhat_ridge <- matrix(NA, ncol = length(lambda_ridge), nrow = n-t0) \nyhat_lasso <- matrix(NA, ncol = length(lambda_lasso), nrow = n-t0) \n\nh <- 1 #number of days ahead for which prediction is wanted\n\nfor (t in (t0+1):n) {\n  # Indices of data within window\n  inds = t-h-w < 1:n & 1:n <= t-h\n  # Fit ARX + ridge/lasso\n  ridge_trail = glmnet(X[inds, ], y[inds], alpha = 0, lambda = lambda_ridge)\n  lasso_trail = glmnet(X[inds, ], y[inds], alpha = 1, lambda = lambda_lasso)\n  # Predict\n  yhat_ridge[t-t0, ] = predict(ridge_trail, newx = as.matrix(X[t, ]))\n  yhat_lasso[t-t0, ] = predict(lasso_trail, newx = as.matrix(X[t, ]))\n}\n\n# MAE values for each lambda\nmae_ridge <- colMeans(abs(yhat_ridge - y_test))\nmae_lasso <- colMeans(abs(yhat_lasso - y_test))\n\n# Select lambda that minimizes MAE and save corresponding predictions\nmin_ridge <- which.min(mae_ridge)\nmin_lasso <- which.min(mae_lasso)\npred_cv_ridge <- yhat_ridge[, min_ridge]\npred_cv_lasso <- yhat_lasso[, min_lasso]\n\npaste('Best MAE ridge:', round(min(mae_ridge), 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Best MAE ridge: 0.019\"\n```\n\n\n:::\n\n```{.r .cell-code}\npaste('Best MAE lasso:', round(min(mae_lasso), 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Best MAE lasso: 0.02\"\n```\n\n\n:::\n:::\n\n\n\n\n## Predictions: time-series CV for ARX + ridge/lasso (trailing)\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](gfx/plot-regularization-cv-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n                        MAE  MASE\nridge CV + trailing 0.01893 124.9\nlasso CV + trailing 0.02041 134.6\n```\n\n\n:::\n:::\n\n\n\n# Prediction Intervals\n\n## Point predictions vs intervals \n\n* So far, we have only considered [point predictions]{.primary}, i.e. \nwe have fitted models \nto provide our [best guess on the outcome]{.primary} at time $t$. \n\n::: {.callout-important icon=\"false\"}\n## \n* What if we want to provide a [measure of uncertainty]{.primary} around our point \nprediction or a [likely range of values]{.primary} for the outcome at time $t$?\n\n:::\n\n* For each target time $t$, we can construct [prediction intervals]{.primary}, i.e. provide \nranges of values that are expected to cover the true outcome value a fixed \nfraction of times.\n\n## Prediction intervals for `lm` fits\n\n* To get prediction intervals for the models we previously fitted, \nwe only need to tweak our call to `predict` by adding as an input: \n\n  `interval = \"prediction\", level = p`\n\n  where $p \\in (0, 1)$ is the desired coverage.\n\n* The output from `predict` will then be a matrix with \n\n  * first column a point estimate\n  \n  * second column the lower limit of the interval\n  \n  * third column the upper limit of the interval\n\n## Prediction intervals for ARX (test)\n\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\npred_test_ci <- predict(arx_fit, \n                        newdata = test, \n                        interval = \"prediction\", \n                        level = 0.95)\n\nhead(pred_test_ci)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     fit    lwr    upr\n1 1.0916 1.0308 1.1524\n2 1.0686 1.0079 1.1293\n3 0.7745 0.7161 0.8329\n4 0.7407 0.6823 0.7990\n5 0.7071 0.6488 0.7654\n6 0.7533 0.6946 0.8120\n```\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-arx-intervals-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Prediction intervals for ARX (time-series CV)\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Initialize matrices to store predictions \n# 3 columns: point estimate, lower limit, and upper limit\npred_all_past = pred_trailing <- matrix(NA, nrow = n - t0, ncol = 3)\ncolnames(pred_all_past) = colnames(pred_trailing) <- c('prediction', 'lower', 'upper')\n\nfor (t in (t0+1):n) {\n  # Fit ARX \n  arx_all_past = lm(deaths ~ lagged_deaths + lagged_cases, data = ca, \n                    subset = (1:n) <= (t-h)) \n  arx_trailing = lm(deaths ~ lagged_deaths + lagged_cases, data = ca, \n                    subset = (1:n) <= (t-h) & (1:n) > (t-h-w)) \n  # Predict\n  pred_all_past[t-t0, ] = predict(arx_all_past, newdata = data.frame(ca[t, ]),\n                                interval = \"prediction\", level = 0.95)\n  pred_trailing[t-t0, ] = predict(arx_trailing, newdata = data.frame(ca[t, ]),\n                                interval = \"prediction\", level = 0.95)\n}\n\nlm_pred_all_past <- cbind(test, pred_all_past)\nlm_pred_trailing <- cbind(test, pred_trailing)\n```\n:::\n\n\n\n## Prediction intervals for ARX (CV, all past)\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot arx-intervals-cv-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Prediction intervals for ARX (CV, trailing window)\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot arx-intervals-cv-trailing-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n[Note]{.primary}: the width of the prediction intervals varies substantially over time.\n\n\n## Quantile regression\n\n* So far we only considered different ways to apply linear regression.\n\n* Quantile regression is a different estimation method, and it directly targets conditional \nquantiles of the outcome over time.\n\n::: {.callout-note}\n## Definition\nConditional quantile = value below which a given percentage (e.g. 25%, 50%, \n75%) of observations fall, given specific values of the predictor variables. \n:::\n\n* [Advantage]{.primary}: it provides a more complete picture of the outcome distribution.\n\n## ARX model for COVID deaths via quantile regression\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#install.packages(\"quantreg\")\nlibrary(quantreg)  #library to perform quantile regression\n\n# Set quantiles of interest: we will focus on 2.5%, 50% (i.e. median), and 97.5% quantiles\nquantiles <- c(0.025, 0.5, 0.975)  \n\n# Fit quantile regression on training set\nq_reg <- rq(deaths ~ lagged_deaths + lagged_cases, data = train, tau = quantiles)\n\n# Estimated coefficients\ncoef(q_reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              tau= 0.025 tau= 0.500 tau= 0.975\n(Intercept)   -0.0096251  0.0010198   0.005489\nlagged_deaths  0.9266482  1.0133190   1.287609\nlagged_cases   0.0001585 -0.0002417  -0.002423\n```\n\n\n:::\n\n```{.r .cell-code}\n# Predict on test set\npred_test <- predict(q_reg, newdata = test)\n```\n:::\n\n\n\n## Predictions via quantile regression (test)\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/q-reg-training-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Predictions via quantile regression (time-series CV)\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Initialize matrices to store predictions \n# 3 columns: lower limit, median, and upper limit\npred_all_past = pred_trailing <- matrix(NA, nrow = n - t0, ncol = 3)\ncolnames(pred_all_past) = colnames(pred_trailing) <- c('lower', 'median', 'upper')\n\nfor (t in (t0+1):n) {\n  # Fit quantile regression\n  rq_all_past = rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles,\n                   data = ca, subset = (1:n) <= (t-h)) \n  rq_trailing = rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles,\n                   data = ca, subset = (1:n) <= (t-h) & (1:n) > (t-h-w)) \n  # Predict\n  pred_all_past[t-t0, ] = predict(rq_all_past, newdata = data.frame(ca[t, ]))\n  pred_trailing[t-t0, ] = predict(rq_trailing, newdata = data.frame(ca[t, ]))\n}\n\nrq_pred_all_past <- cbind(test, pred_all_past)\nrq_pred_trailing <- cbind(test, pred_trailing)\n```\n:::\n\n\n\n## Predictions via quantile regression (CV, all past)\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/q-reg-plot-cv-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Predictions via quantile regression (CV, trailing)\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/q-reg-plot-cv-predictions-trailing-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Actual Coverage\n\n* We would expect the ARX model fitted via `lm` and via `rq` to cover the truth\nabout 95\\% of the times. Is this actually true in practice?\n\n* The actual coverage of each predictive interval is  \n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n         lm.all.past lm.trailing rq.all.past rq.trailing\nCoverage      0.9673      0.9281      0.8758      0.6699\n```\n\n\n:::\n:::\n\n\n\n* Notice that the coverage of `lm` is close to 95\\%, while `rq` has lower \ncoverage, especially for the trailing window case.\n\n## Evaluation\n\n* Prediction intervals are “good” if they \n\n  * cover the truth most of the time\n  \n  * are not too wide\n  \n* Error metric that captures both desiderata: [Weighted Interval Score (WIS)]{.primary}\n\n* $F$ = forecast composed of predicted quantiles $q_{\\tau}$ for the set \nof quantile levels $\\tau$. The WIS for target variable $Y$ is represented as \n([McDonald et al., 2021](https://www.pnas.org/doi/full/10.1073/pnas.2111453118)):\n\n$$WIS(F, Y) = 2\\sum_{\\tau} \\phi_{\\tau} (Y - q_{\\tau})$$\n\nwhere $\\phi_{\\tau}(x) = \\tau |x|$ for $x \\geq 0$ and \n$\\phi_{\\tau}(x) = (1-\\tau) |x|$ for $x < 0$.\n\n## Computing the WIS \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nWIS <- function(truth, estimates, quantiles) {\n  2 * sum(pmax(\n    quantiles * (truth - estimates),\n    (1 - quantiles) * (estimates - truth),\n    na.rm = TRUE\n  ))\n}\n```\n:::\n\n\n\n::: {.callout-important icon=\"false\"}\n## Note\nWIS tends to prioritize sharpness (how wide the interval is) relative to \ncoverage (if the interval contains the truth).\n:::\n\n## WIS for ARX fitted via `lm` and `rq`\n\n* The lowest mean WIS is attained by quantile regression trained on all past data. \n\n* Notice that this method has coverage below 95\\% but it is still preferred under WIS \nbecause its intervals are narrower than for linear regression.\n\n::: flex\n\n::: w-50\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  method      mean_wis\n  <chr>          <dbl>\n1 lm.all.past   0.0247\n2 lm.trailing   0.0274\n```\n\n\n:::\n:::\n\n\n:::\n\n::: w-50\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  method      mean_wis\n  <chr>          <dbl>\n1 rq.all.past   0.0242\n2 rq.trailing   0.0348\n```\n\n\n:::\n:::\n\n\n\n:::\n:::\n\n# Forecasting with Versioned Data\n\n## Versioned data\n\n* In our forecasting examples, we have assumed the data are never revised \n(or have simply ignored revisions, and used data `as_of` today)\n\n::: {.callout-important icon=\"false\"}\n## \nHow can we train forecasters when dealing with versioned data?\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_archive\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-04-01 / 2021-12-31\nℹ First/last version with update: 2020-04-02 / 2022-01-01\nℹ Versions end: 2022-01-01\nℹ A preview of the table (93566 rows x 5 columns):\nKey: <geo_value, time_value, version>\n       geo_value time_value    version case_rate death_rate\n          <char>     <Date>     <Date>     <num>      <num>\n    1:        ak 2020-04-01 2020-04-02     1.797          0\n    2:        ak 2020-04-01 2020-05-07     1.777          0\n    3:        ak 2020-04-01 2020-10-28     1.106          0\n    4:        ak 2020-04-01 2020-10-29     1.797          0\n    5:        ak 2020-04-01 2020-10-30     1.797          0\n   ---                                                     \n93562:        wy 2021-12-27 2021-12-28    65.599          0\n93563:        wy 2021-12-28 2021-12-29    50.315          0\n93564:        wy 2021-12-29 2021-12-30    55.810          0\n93565:        wy 2021-12-30 2021-12-31    68.003          0\n93566:        wy 2021-12-31 2022-01-01     0.000          0\n```\n\n\n:::\n:::\n\n\n\n## Version-aware forecasting\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# initialize dataframe for predictions\n# 5 columns: forecast date, target date, 2.5%, 50%, and 97.5% quantiles\npred_all_past = pred_trailing <- data.frame(matrix(NA, ncol = 5, nrow = 0))\ncolnames(pred_all_past) = colnames(pred_trailing) <- c(\"forecast_date\", \"target_date\",\n                                                       'tau..0.025', 'tau..0.500', 'tau..0.975')\n\nw <- 30         #trailing window size\nh <- 7          #number of days ahead\n\n# dates when predictions are made (set to be 1 month apart)\nfc_time_values <- seq(from = t0_date, to = as.Date(\"2021-12-31\"), by = \"1 month\")\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data <- epix_as_of(ca_archive, max_version = as.Date(fc_date))\n  # create lagged predictors\n  data$lagged_deaths <- dplyr::lag(data$deaths, h) #since we want to predict h-ahead, \n                                                   #we need to lag deaths by h (at least)\n  data$lagged_cases <- dplyr::lag(data$cases, k)\n  # perform quantile regression\n  rq_all_past <- rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles, data = data) \n  rq_trailing <- rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles, \n                    # only consider window of data\n                    data = data %>% filter(time_value > (max(time_value) - w))) \n  # construct data.frame with the right predictors for the target date\n  predictors <- data.frame(lagged_deaths = tail(data$deaths, 1), \n                           lagged_cases = (data %>% \n                                             filter(time_value == (max(time_value) + h - k)))$cases)\n  # make predictions for target date and add them to matrix of predictions\n  pred_all_past <- rbind(pred_all_past, \n                         data.frame('forecast_date' = max(data$time_value),\n                                    'target_date' = max(data$time_value) + h, \n                                    predict(rq_all_past, newdata = predictors)))\n  pred_trailing <- rbind(pred_trailing, \n                         data.frame('forecast_date' = max(data$time_value),\n                                    'target_date' = max(data$time_value) + h, \n                                    predict(rq_trailing, newdata = predictors)))\n}\n```\n:::\n\n\n\n## Version-aware predictions (CV, all past)\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-versioned-cv-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Version-awere predictions (CV, trailing)\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-versioned-cv-trailing-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n# Geo-pooling\n\n## Using geo information\n\n* Assume we observe data over time from [multiple locations]{.primary}\n(e.g. states or counties).\n\n* We could\n\n  * Estimate coefficients [separately]{.primary} for each location (as we have done so far).\n  \n  * Fit one model using all locations together at each time point ([geo-pooling]{.primary}). \nEstimated coefficients will not be location specific.\n\n  * Estimate coefficients separately for each location, but include predictors capturing \naverages across locations ([partial geo-pooling]{.primary}).\n\n\n\n## Geo-pooling: CV all past\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nusa_archive <- data_archive$DT %>% \n  as_epi_archive()\n\n# initialize dataframe for predictions\n# 6 columns: geo value, forecast date, target date, 2.5%, 50%, and 97.5% quantiles\npred_all_past <- data.frame(matrix(NA, ncol = 6, nrow = 0))\ncolnames(pred_all_past) <- c('geo_value', 'forecast_date', 'target_date',\n                             'tau..0.025', 'tau..0.500', 'tau..0.975')\n\nh <- 7     #number of days ahead\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data <- epix_as_of(usa_archive, max_version = as.Date(fc_date))\n  \n  # create lagged predictors for each state \n  data <- data %>%\n    arrange(geo_value, time_value) %>%  \n    group_by(geo_value) %>%\n    mutate(lagged_deaths = dplyr::lag(deaths, h),\n           lagged_cases = dplyr::lag(cases, k)) %>%\n    ungroup()\n  \n  # perform quantile regression\n  rq_all_past <- rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles, data = data) \n  \n  # construct dataframe with the right predictors for the target date\n  new_lagged_deaths <- data %>% \n    filter(time_value == max(time_value)) %>%\n    select(geo_value, deaths)\n  \n  new_lagged_cases <- data %>% \n    filter(time_value == max(time_value) + h - k) %>%\n    select(geo_value, cases)\n  \n  predictors <- new_lagged_deaths %>%\n    inner_join(new_lagged_cases, join_by(geo_value)) %>%\n    rename(lagged_deaths = deaths,\n           lagged_cases = cases)\n  \n  # make predictions for target date and add them to matrix of predictions\n  pred_all_past <- rbind(pred_all_past, \n                         data.frame(\n                           'geo_value' = predictors$geo_value,\n                           'forecast_date' = max(data$time_value),\n                           'target_date' = max(data$time_value) + h, \n                           predict(rq_all_past, newdata = predictors)))\n}\n\n# geo-pooled predictions for California\npred_ca <- pred_all_past %>%\n  filter(geo_value == 'ca') %>%\n  rename(median = `tau..0.500`,\n         lower = `tau..0.025`,\n         upper = `tau..0.975`) %>%\n  full_join(ca %>% select(time_value, deaths), join_by(target_date == time_value)) %>%\n  arrange(target_date)\n```\n:::\n\n\n\n## Geo-pooled predictions for California\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-geo-pooling-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Partial geo-pooling: CV all past\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# initialize dataframe for predictions\n# 6 columns: geo value, forecast date, target date, 2.5%, 50%, and 97.5% quantiles\npred_all_past <- data.frame(matrix(NA, ncol = 6, nrow = 0))\ncolnames(pred_all_past) <- c('geo_value', 'forecast_date', 'target_date',\n                             'tau..0.025', 'tau..0.500', 'tau..0.975')\n\nh <- 7     #number of days ahead\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data <- epix_as_of(usa_archive, max_version = as.Date(fc_date))\n  \n  # create lagged predictors \n  data <- data %>%\n    arrange(geo_value, time_value) %>%  \n    group_by(geo_value) %>%\n    mutate(lagged_deaths = dplyr::lag(deaths, h),\n           lagged_cases = dplyr::lag(cases, k)) %>%\n    ungroup() %>%\n    group_by(time_value) %>%\n    mutate(avg_lagged_deaths = mean(lagged_deaths, na.rm = T),\n           avg_lagged_cases = mean(lagged_cases, na.rm = T)) %>%\n    ungroup() \n  \n  # perform quantile regression\n  rq_all_past <- rq(deaths ~ lagged_deaths + lagged_cases + avg_lagged_deaths +\n                      avg_lagged_cases, tau = quantiles, \n                    data = (data %>% filter(geo_value == 'ca'))) \n  \n  # construct data.frame with the right predictors for the target date\n  new_lagged_deaths <- data %>% \n    filter(time_value == max(time_value)) %>%\n    select(geo_value, deaths) %>%\n    mutate(avg_lagged_deaths = mean(deaths, na.rm = T)) %>%\n    filter(geo_value == 'ca')\n  \n  new_lagged_cases <- data %>% \n    filter(time_value == max(time_value) + h - k) %>%\n    select(geo_value, cases) %>%\n    mutate(avg_lagged_cases = mean(cases, na.rm = T)) %>%\n    filter(geo_value == 'ca')\n  \n  predictors <- new_lagged_deaths %>%\n    inner_join(new_lagged_cases, join_by(geo_value)) %>%\n    rename(lagged_deaths = deaths,\n           lagged_cases = cases)\n  \n  # make predictions for target date and add them to matrix of predictions\n  pred_all_past <- rbind(pred_all_past, \n                         data.frame(\n                           'geo_value' = predictors$geo_value,\n                           'forecast_date' = max(data$time_value),\n                           'target_date' = max(data$time_value) + h, \n                           predict(rq_all_past, newdata = predictors)))\n}\n\n# partially geo-pooled predictions for California\npred_ca <- pred_all_past %>%\n  filter(geo_value == 'ca') %>%\n  rename(median = `tau..0.500`,\n         lower = `tau..0.025`,\n         upper = `tau..0.975`) %>%\n  full_join(ca %>% select(time_value, deaths), join_by(target_date == time_value)) %>%\n  arrange(target_date)\n```\n:::\n\n\n\n## Partially geo-pooled predictions for California\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](gfx/plot-partial-geo-pooling-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n## Final slide {.smaller}\n\n### Thanks:\n\n\n\n\n\n\n\n- The whole [CMU Delphi Team](https://delphi.cmu.edu/about/team/) (across many institutions)\n- Optum/UnitedHealthcare, Change Healthcare.\n- Google, Facebook, Amazon Web Services.\n- Quidel, SafeGraph, Qualtrics.\n- Centers for Disease Control and Prevention.\n- Council of State and Territorial Epidemiologists\n\n\n::: {layout-row=1 fig-align=\"center\"}\n![](gfx/delphi.jpg){height=\"100px\"}\n![](gfx/berkeley.jpg){height=\"100px\"}\n![](gfx/cmu.jpg){height=\"100px\"}\n![](gfx/ubc.jpg){width=\"250px\"}\n![](gfx/stanford.jpg){width=\"250px\"}\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}