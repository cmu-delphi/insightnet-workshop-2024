{
  "hash": "5129cd32860b2197917e0d894f4cd0d0",
  "result": {
    "markdown": "---\ntalk-title: \"Whirlwind Tour of Forecasting and Time-Series Models\"\ntalk-short-title: \"Time-Series\"\ntalk-subtitle: \"InsightNet Forecasting Workshop 2024\"\ntalk-date: \"12 December -- Morning\"\nformat: revealjs\n---\n---\n---\n\n\\DeclareMathOperator*{\\minimize}{minimize}\n\n\n\n\n\n\n\n::: flex\n::: w-20\n\n:::\n::: w-80\n## {{< meta talk-title >}} {background-image=\"gfx/cover-art-1.svg\" background-position=\"bottom\"}\n\n### {{< meta talk-subtitle >}}\n\n<br>\n\n#### {{< meta author >}} \n[with thanks to Delphi Tooling & Forecasting Team: Logan Brooks, Nat DeFries, Dmitry Shemetov, David Webber]{.fstyle}\n\n{{< meta talk-date >}}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n## Outline\n\n1. Linear Regression for Time Series Data\n\n1. Evaluation Methods\n\n1. ARX Models\n\n1. Overfitting and Regularization\n\n1. Prediction Intervals\n\n1. Forecasting with Versioned Data\n\n1. Other Approaches to Time Series Data\n\n\n# Linear Regression for Time Series Data\n\n## Basics of linear regression \n\n* Assume we observe a predictor $x_i$ and an outcome $y_i$ for $i = 1, \\dots, n$.\n\n* Linear regression seeks coefficients $\\beta_0$ and $\\beta_1$ such that\n\n$$y_i \\approx \\beta_0 + \\beta_1 x_i$$\n\nis a good approximation for every $i = 1, \\dots, n$.\n\n* In R, the coefficients are found by running `lm(y ~ x)`, where `y` is the vector \nof responses and `x` the vector of predictors.\n\n\n## Multiple linear regression \n\n* Given $p$ different predictors, we seek $(p+1)$ coefficients such that\n\n$$y_i \\approx \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip}$$\nis a good approximation for every $i = 1, \\dots, n$.\n\n\n## Linear regression with lagged predictor\n\n\n* In time series, outcomes and predictors are usually indexed by time $t$. \n\n::: {.fragment .fade-in}\n* [Goal]{.primary}: predicting future $y$, given present $x$. \n\n:::\n\n::: {.fragment .fade-in}\n* [Model]{.primary}: linear regression with lagged predictor\n\n$$\\hat y_t = \\hat \\beta + \\hat \\beta_0 x_{t-k}$$\n\ni.e. regress the outcome $y$ at time $t$ on the predictor $x$ at time $t-k$.\n\n:::\n\n::: {.fragment .fade-in}\n* [Equivalent]{.primary} way to write the model: \n\n$$\\hat y_{t+k} = \\hat \\beta + \\hat \\beta_0 x_t$$\n\n:::\n\n## Example: predicting COVID deaths  \n\n* During the pandemic, interest in predicting COVID deaths 7, 14, 21, 28 days ahead.\n\n* Can we reasonably [predict COVID deaths 28 days ahead]{.primary} by just using cases today?\n\n\n::: {.fragment .fade-in}\n* If we let\n\n$$y_{t+28} = \\text{deaths at time } t+28 \\quad\\quad x_{t} = \\text{cases at time } t$$\n  is the following a good model?\n\n  $$\\hat y_{t+28} = \\hat\\beta_0 + \\hat\\beta_1 x_{t}$$\n\n:::\n\n## Example: COVID cases and deaths in California \n\n::: flex\n\n::: w-65\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-ca-cases-deaths_991a45b452001009ef7300966866c9f4'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-ca-cases-deaths-1.svg){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n::: w-35\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/ca data_d58c0b46dc30f17ef16918a6be1c2787'}\n\n```{.r .cell-code}\nhead(ca)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn `epi_df` object, 6 x 4 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-11-06 08:50:44.00687\n\n# A tibble: 6 × 4\n# Groups:   geo_value [1]\n  geo_value time_value cases deaths\n* <chr>     <date>     <dbl>  <dbl>\n1 ca        2020-04-01  3.17 0.0734\n2 ca        2020-04-02  3.48 0.0835\n3 ca        2020-04-03  3.44 0.0894\n4 ca        2020-04-04  3.05 0.0778\n5 ca        2020-04-05  3.28 0.0876\n6 ca        2020-04-06  3.37 0.0848\n```\n:::\n:::\n\n\n:::\n\n:::\n\n::: {.callout-important icon=\"false\"}\n## Note\n\n[Cases]{.primary} seem [highly correlated]{.primary} with [deaths]{.primary}\nseveral weeks later (but [relation]{.primary} cases-deaths [changes]{.primary} over time).\n:::\n\n## Checking correlation\n\n\n* Let’s split the data into a training and a test set (before/after 2021-04-01).\n\n* On training set: [large correlation]{.primary}\nbetween cases and deaths 28 days ahead (> 0.95).\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/correlation-cases-deaths_870e39fb3506cff6e5008181e22819f0'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/correlation-cases-deaths-1.svg){fig-align='center'}\n:::\n:::\n\n\n::: {.fragment .fade-in}\n* Let's use (base) R to prepare the data and fit \n\n$$\\hat y_{t+28} = \\hat\\beta + \\hat\\beta_0 x_{t}$$\n\n:::\n\n## Preparing the data\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/lag-cases_43342f50a070b75be55440ad1b8ab57f'}\n\n```{.r .cell-code}\nca$lagged_cases <- dplyr::lag(ca$cases, n = k)     # Add column with cases lagged by k\nt0_date <- as.Date('2021-04-01')                   # Split into train and test (before/after t0_date)\ntrain <- ca |> filter(time_value <= t0_date)\ntest <- ca |> filter(time_value > t0_date)\n```\n:::\n\n\nCheck if `deaths` is approximately linear in `lagged_cases`:\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-lag-cases_7873c5e036821f5e0f30f5ab3024213c'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-lag-cases-1.svg){fig-align='center'}\n:::\n:::\n\n\n## Fitting lagged linear regression in R\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/lagged-lm_2d30155983f6626cb7f3300a6672b590'}\n\n```{.r .cell-code}\nreg_lagged = lm(deaths ~ lagged_cases, data = train)\ncoef(reg_lagged)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept) lagged_cases \n   0.1171839    0.0112714 \n```\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-linear-fit_a32586516e39a2f5b3704388af20858d'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-linear-fit-1.svg){fig-align='center'}\n:::\n:::\n\n\n# Evaluation\n\n## Error metrics\n\n* Assume we have predictions $\\hat y_{new, t}$ for the unseen observations \n$y_{new,t}$ over times $t = 1, \\dots, N$.\n\n* Four commonly used error metrics are:\n\n  * mean squared error (MSE)\n\n  * mean absolute error (MAE)\n\n  * mean absolute percentage error (MAPE)\n\n  * mean absolute scaled error (MASE)\n\n## Error metrics: MSE and MAE\n\n$$MSE = \\frac{1}{N} \\sum_{t=1}^N (y_{new, t}- \\hat y_{new, t})^2$$\n$$MAE = \\frac{1}{N} \\sum_{t=1}^N |y_{new, t}- \\hat y_{new, t}|$$\n\n* MAE gives less importance to extreme errors than MSE.\n\n* [Drawback]{.primary}: both metrics are scale-dependent, so they are not universally \ninterpretable.\n(For example, if $y$ captures height, MSE and MAE will vary depending on whether we measure in feet or meters.)\n\n## Error metrics: MAPE\n\n* Fixing scale-dependence:\n\n$$MAPE = 100 \\times \\frac{1}{N} \\sum_{t=1}^N \n\\left|\\frac{y_{new, t}- \\hat y_{new, t}}{y_{new, t}}\\right|$$\n\n* [Drawbacks]{.primary}:\n\n  * Erratic behavior when $y_{new, t}$ is close to zero\n\n  * It assumes the unit of measurement has a meaningful zero (e.g. using \nFahrenheit or Celsius to measure temperature will lead to different MAPE)\n\n## Comparing MAE and MAPE\n\n::: {.callout-important}\nThere are situations when MAPE is problematic!\n:::\n\n::: flex\n::: w-70\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/mae-mape-example_9e6a879e589e1ca53a9a3ec4dafd000c'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/mae-mape-example-1.svg){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n::: {.w-30}\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/mae-mape-error_deae2b54445c79955f5558c0ad715db4'}\n::: {.cell-output-display}\n|      |   MAE|   MAPE|\n|:-----|-----:|------:|\n|yhat1 | 2.873| 43.140|\n|yhat2 | 5.382| 36.083|\n:::\n:::\n\n\n:::\n:::\n\n\n## Error metrics: MASE\n\n$$MASE = 100 \\times \\frac{\\frac{1}{N} \\sum_{t=1}^N \n|y_{new, t}- \\hat y_{new, t}|}\n{\\frac{1}{N-1} \\sum_{t=2}^N \n|y_{new, t}- y_{new, t-1}|}$$\n\n* [Advantages]{.primary}:\n\n  * is universally interpretable (not scale dependent)\n\n  * avoids the zero-pitfall\n\n* MASE in words: we normalize the error of our forecasts by that of a naive method \nwhich always predicts the last observation.\n\n\n## Comparing MAE, MAPE and MASE\n\n::: flex\n::: w-70\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/mae-mape-mase-example_162f4dc7ea838bc5af6e2e91c9a291e8'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/mae-mape-mase-example-1.svg){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::: w-35\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/mae-mape-mase-error_006366a7cf6f1eca6e820299fae75339'}\n::: {.cell-output-display}\n|      |   MAE|   MAPE|    MASE|\n|:-----|-----:|------:|-------:|\n|yhat1 | 2.873| 43.140|  66.100|\n|yhat2 | 5.382| 36.083| 123.817|\n:::\n:::\n\n\n:::\n:::\n\n## Defining the error metrics in R\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/error functions_f9ba612b26f03abc7c1c9e7cbd74fd67'}\n\n```{.r .cell-code}\nMSE <- function(truth, prediction) {\n  mean((truth - prediction)^2)}\n\nMAE <- function(truth, prediction) {\n  mean(abs(truth - prediction))}\n\nMAPE <- function(truth, prediction) {\n  100 * mean(abs(truth - prediction) / truth)}\n\nMASE <- function(truth, prediction) {\n  100 * MAE(truth, prediction) / mean(abs(diff(truth)))}\n```\n:::\n\n\n## Estimating the prediction error\n\n* Given an error metric, we want to estimate the prediction error under that metric. \n\n* This can be accomplished in different ways, using the\n\n  * Training error\n\n  * Split-sample error\n\n  * Time series cross-validation error (using all past data or a trailing window)\n\n\n## Training error\n\n* The easiest but [worst]{.primary} approach to estimate the prediction error is \nto use the training error, i.e. the average error on the training set that was \nused to fit the model.\n\n* The training error is\n\n  * generally too optimistic as an estimate of prediction error\n\n  * [more optimistic the more complex the model!]{.primary}^[More on this when we talk about overfitting.]\n\n\n## Training error \n#### Linear regression of COVID deaths on lagged cases\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/pred-train_d09534d0ab2730714b382752c8a8f59a'}\n\n```{.r .cell-code}\n# Getting the predictions for the training set\npred_train <- predict(reg_lagged)\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-train-predictions_f31d06818129102ab681da0faf4cf943'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-train-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/function errors_f64bf23acd9a3854df763c39abe1d361'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/training-error_3ce06b4bb3245dee01bb231638f2aa6e'}\n::: {.cell-output .cell-output-stdout}\n```\n               MAE     MASE\ntraining 0.0740177 380.9996\n```\n:::\n:::\n\n\n\n\n## Split-sample error \n\nTo compute the split-sample error  \n\n  1. [Split]{.primary} data into training (up to time $t_0$), and test set (after $t_0$)\n\n  1. [Fit]{.primary} the model to the [training]{.primary} data only\n\n  1. Make [predictions]{.primary} for the [test]{.primary} set\n\n  1. Compute the selected [error]{.primary} metric on the [test]{.primary} set only\n\n\n::: {.callout-important icon=\"false\"}\n## Note\n\nSplit-sample estimates of prediction error don't mimic a situation where we \nwould refit the model in the future. \nThey are [pessimistic]{.primary} if the relation between outcome and predictors \nchanges over time.\n:::\n\n## Split-sample MSE \n\nAssume we want to make $h$-step ahead predictions, i.e. at time $t$ we want to \nmake a forecast for $t+h$. Then, the split-sample MSE is\n\n$$\\text{SplitMSE} = \\frac{1}{n-h-t_0} \\sum_{t = t_0}^{n-h} (\\hat y_{t+h|t_0} - y_{t+h})^2$$\n\nwhere\t$\\hat y_{t+h|t_0}$ indicates a prediction for $y$ at time $t+h$ that was made \nwith a model that was fit on data up to time $t_0$.\n\n\n\n## Split-sample error\n#### Linear regression of COVID deaths on lagged cases\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/test-pred_f3959e07fba7133d1d162ed09b11c3e1'}\n\n```{.r .cell-code}\n# Getting h-step ahead predictions for the test set\nh <- k\ntest_h <- test[-(1:h-1), ] # drop first h-1 rows to avoid data leakage\npred_test <- predict(reg_lagged, newdata = test_h)\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-test-predictions_b584914b719ea3c692ddc0042462f95f'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-test-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/test-error_2d4266d1f023b6291008d0a11ab9bcd9'}\n::: {.cell-output .cell-output-stdout}\n```\n                   MAE      MASE\ntraining     0.0740177  380.9996\nsplit-sample 0.3116854 2914.4575\n```\n:::\n:::\n\n\n::: {.notes}\nNote that we are overestimating the peak due to the changed relationship \nbetween cases - deaths over time.\n\nTalk about data leakage.\n:::\n\n## Warning!\n\n* [Predictions]{.primary} are [overshooting]{.primary} the target, \nespecially in early 2022 ([Omicron]{.primary} phase).\n\n* This is because we are predicting [deaths]{.primary} using [lagged cases]{.primary}, \nbut the [relation]{.primary} between \nthe two [changes]{.primary} over time.\n\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-ca-cases-deaths-again_de6739bbbdf8fa072e08c1082ffa4191'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-ca-cases-deaths-again-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n## Time-series cross-validation (CV)\n#### $h$-step ahead predictions\n\n* If we [refit]{.primary} in the future once new data are available, a more \nappropriate way to estimate the prediction error is time-series cross-validation.\n\n* To get $h$-step ahead predictions, for each time $t = t_0, t_0+1, \\dots$,\n\n  * [Fit]{.primary} the model using data [up to time $t$]{.primary}\n\n  * Make a [prediction for $t+h$]{.primary} \n\n  * Record the [prediction error]{.primary}\n\n* The cross-validation MSE is then\n\n$$CVMSE = \\frac{1}{n-h-t_0} \\sum_{t = t_0}^{n-h} (\\hat y_{t+h|t} - y_{t+h})^2$$\n\nwhere\t$\\hat y_{t+h|t}$ indicates a prediction for $y$ at time $t+h$ that was made \nwith data available up to time $t$.\n\n## Time-series cross-validation (CV) \n#### Linear regression of COVID deaths on lagged cases\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/time-series-cv_c1ad0b9ba9d94aaf29782393034ea165'}\n\n```{.r .cell-code}\nn <- nrow(ca)                               #length of time series\nh <- k                                      #number of days ahead for which prediction is wanted\npred_all_past <- rep(NA, length = n)        #initialize vector of predictions\n\nfor (t in t0:(n-h)) {\n  # fit to all past data and make h-step ahead prediction\n  reg_all_past = lm(deaths ~ lagged_cases, data = ca, subset = (1:n) <= t) \n  pred_all_past[t+h] = predict(reg_all_past, newdata = data.frame(ca[t+h, ]))\n}\n```\n:::\n\n\n::: {.callout-important icon=\"false\"}\n## Note\n\nWith the current model, we can only predict $k$ days ahead (where $k$ = number of days by which predictor is lagged)!\n:::\n\n\n## Time-series cross-validation (CV)\n#### Linear regression of COVID deaths on lagged cases\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-cv-predictions_66efa74786f2f6dc7f2b88a2fd4c1232'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-cv-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/cv-error_f1ea8db5ff09a13cda0429bc6085c8fc'}\n::: {.cell-output .cell-output-stdout}\n```\n                     MAE      MASE\ntraining       0.0740177  380.9996\nsplit-sample   0.3116854 2914.4575\ntime series CV 0.2374931 2212.5992\n```\n:::\n:::\n\n\n::: {.notes}\nSome improvement wrt split-sample, but still overestimating peak. \n:::\n\n## Warning!\n\n* [Predictions]{.primary} are still [overshooting]{.primary} the target, \nbut [error]{.primary} is [smaller]{.primary} than split-sample.\n\n* Why?\n\n  * <span class=\"inner-list\"> 👍 Forecaster is partially learning the change in cases-deaths relation \n(especially in late 2022)</span>\n\n  * <span class=\"inner-list\">👎 We refit on all past data, so predictions are still influenced by \n    old cases-deaths relation</span>\n\n\n::: {.callout-important icon=\"false\"}\n## Idea 💡\n\n**Ignore old data when refitting?**\n:::\n\n## Regression on a trailing window\n\n* [Fit the model on a window of data of length $w$]{.primary}, \nstarting at $t-w$ and ending at $t$.\n\n* [Advantage]{.primary}: if the predictors-outcome relation changes over time,\ntraining the forecaster on a window of recent data can better capture the recent \nrelation which might be more relevant to predict the outcome in the near future.\n\n* Window length [$w$]{.primary} considerations: \n\n  * <span class=\"inner-list\">if $w$ is too [big]{.primary}, \n  the model [can't adapt]{.primary} to the \n  recent predictors-outcome relation </span>\n  \n\n  * <span class=\"inner-list\">if $w$ is too [small]{.primary}, \n  the fitted model may be [too volatile]{.primary} \n  (trained on too little data)</span>\n  \n\n## Trailing window\n#### Linear regression of COVID deaths on lagged cases\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/time-series-cv-trailing_c7ca1e634e62a116bf6794c8b340951e'}\n\n```{.r .cell-code}\n# Getting the predictions through CV with trailing window\nw <- 120                                    #trailing window size\nh <- k                                      #number of days ahead for which prediction is wanted\npred_trailing <- rep(NA, length = n)        #initialize vector of predictions\n\nfor (t in t0:(n-h)) {\n  # fit to a trailing window of size w and make h-step ahead prediction\n  reg_trailing = lm(deaths ~ lagged_cases, data = ca, \n                    subset = (1:n) <= t & (1:n) > (t-w)) \n  pred_trailing[t+h] = predict(reg_trailing, newdata = data.frame(ca[t+h, ]))\n}\n```\n:::\n\n\n\n## Time-series CV: all past vs trailing window\n#### Linear regression of COVID deaths on lagged cases\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-cv-predictions-trailing_6f5e12c2a58bd2dcf142f4726dbfef2d'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-cv-predictions-trailing-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/cv-trailing-error_c6a50b47b17fd008e0115f3e9142e197'}\n::: {.cell-output .cell-output-stdout}\n```\n                                 MAE      MASE\ntraining                  0.07401770  380.9996\nsplit-sample              0.31168536 2914.4575\ntime series CV            0.23749306 2212.5992\ntime series CV + trailing 0.09932651  925.3734\n```\n:::\n:::\n\n\n::: {.notes}\nA lot of improvement: trailing window allows to adapt to the change in relationship \nbetween cases and deaths over time.\n:::\n\n\n# ARX models\n\n## Autoregressive exogenous input (ARX) model\n\n* [Idea]{.primary}: predicting the outcome via a linear combination of its lags \nand a set of exogenous (i.e. external) input variables\n\n* Example:\n\n$$\\hat y_{t+h} = \\hat\\phi + \\sum_{i=0}^p \\hat\\phi_i y_{t-i} + \\sum_{j=0}^q \\hat\\beta_j x_{t-j}$$\n\n* [Notice]{.primary}: we don't need to include all contiguous lags, and we could fit e.g.\n\n$$\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} + \\hat\\phi_2 y_{t-14} +\n\\hat\\beta_0 x_{t} + \\hat\\beta_1 x_{t-7} + \\hat\\beta_2 x_{t-14}$$\n\n\n## ARX model for COVID deaths\n\n* Let's add lagged deaths as a predictor to our previous forecaster: \n\n$$\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\beta_0 x_{t}$$\n\n* We will refer to this model as [ARX(1)]{.primary}, as it only includes one lag for each predictor.\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/arx-lm_9071eb8bb25ff7ae5724738710e54d44'}\n\n```{.r .cell-code}\n# Prepare data: add column with deaths lagged by 28\nca$lagged_deaths <- dplyr::lag(ca$deaths, n = k)\n```\n:::\n\n\n* How does it compare to the previous model in terms of time-series CV?\n\n::: {.callout-important icon=\"false\"}\n## Note\n\nFrom now on, we will only consider regression on a [trailing window]{.primary},\nsince regression on all past data leads to overshooting during Omicron.\n:::\n\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/arx-training-error_057ad98cd4250bcd274196ffea75df9a'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/arx-plot-train-test-predictions_ba249159434dd3924344ed8b0239a2fe'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/arx-train-test-errors_47b3653de2143675a556fb4cd29f5de6'}\n\n:::\n\n\n\n\n## Time-Series CV (trailing): ARX(1) vs `lm` on lagged cases\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/arx-time-series-cv_eb51902b098bf3ef0a47f5e6826f925f'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/arx-lm-plot-cv-predictions_d4767d76f5550546c6c46a10273039e2'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/arx-lm-plot-cv-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/arx-cv-error_e635b019216a01e14a0d20f7bcca3a67'}\n::: {.cell-output .cell-output-stdout}\n```\n                          MAE     MASE\nARX(1)             0.07852942 731.6178\nlm on lagged cases 0.09932651 925.3734\n```\n:::\n:::\n\n\n::: {.notes}\nErrors under both metrics are smaller than with previous model.\n:::\n\n## Warning!\n\nRegression on a trailing window can be quite sensitive to data issues.\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/warning-cv-predictions_2d184d32d4407cf6336689a498edf4f7'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/warning-cv-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n\n## Warning!\n\n* At the [forecast date]{.primary} when the downward dip in deaths is predicted, \nthe coefficients estimated by [ARX(1)]{.primary} are\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/check-issue-trailing_1478d795993ed36966b4dd60d3a38f98'}\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept) lagged_deaths  lagged_cases \n  0.067259206   0.304075294  -0.004285251 \n```\n:::\n:::\n\n\n\n* The downward dip is explained by the [negative coefficient on `lagged_cases`]{.primary}, \nand by the fact that at the forecast date\n\n  * observed deaths are exactly equal to 0 (data issue)\n\n  * observed cases are increasing\n\n\n\n## Predictions for different $h$\n\n* So far we only focused on COVID death predictions 28 days ahead.\n\n* We will now compare the model with lagged cases as predictor\n\n$$\\hat y_{t+h} = \\hat\\beta + \\hat\\beta_0 x_t$$\n\nto the ARX(1) model\n\n$$\\hat y_{t+h} = \\hat\\phi + \\hat\\phi_0 y_t + \\hat\\beta_0 x_t$$\n\nfor [horizons $h = 7, 14, 21, 28$]{.primary}.\n\n* We will only make forecasts on the $1^{st}$ day of each month, and use a trailing window with $w = 120$.\n\n\n## Predictions for different $h$\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/different-h-pred_13c88138f4e1c5559412358913082f17'}\n\n```{.r .cell-code}\nh_vals <- c(7, 14, 21, 28)  #horizons \npred_m1 = pred_m2 <- data.frame(matrix(NA, nrow = 0, ncol = 3))  #initialize df for predictions\ncolnames(pred_m1) = colnames(pred_m2) = c(\"forecast_date\", \"target_date\", \"prediction\")\nw <- 120    #trailing window size\n\nca_lags <- ca |> select(!c(lagged_cases, lagged_deaths))\n\n# Create lagged predictors \nfor (i in seq_along(h_vals)) {\n  ca_lags[[paste0(\"lagged_deaths_\", h_vals[i])]] <- dplyr::lag(ca_lags$deaths, n = h_vals[i])\n  ca_lags[[paste0(\"lagged_cases_\", h_vals[i])]] <- dplyr::lag(ca_lags$cases, n = h_vals[i])\n}\n\n# Only forecast on 1st day of the months\nforecast_time <- which(ca_lags$time_value >= t0_date & \n                         ca_lags$time_value < ca_lags$time_value[n-max(h_vals)] &\n                         day(ca_lags$time_value) == 1)\n\nfor (t in forecast_time) {\n  for (i in seq_along(h_vals)) {\n    h = h_vals[i]\n    # formulas including h-lagged variables\n    m1_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h))\n    m2_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h, \" + lagged_deaths_\", h))\n    # fit to trailing window of data\n    m1_fit = lm(m1_formula, data = ca_lags, subset = (1:n) <= t & (1:n) > (t-w)) \n    m2_fit = lm(m2_formula, data = ca_lags, subset = (1:n) <= t & (1:n) > (t-w)) \n    # make h-step ahead predictions\n    pred_m1 = rbind(pred_m1, \n                    data.frame(forecast_date = ca_lags$time_value[t],\n                               target_date = ca_lags$time_value[t+h],\n                               prediction = predict(m1_fit, newdata = data.frame(ca_lags[t+h, ]))))\n    pred_m2 = rbind(pred_m2, \n                    data.frame(forecast_date = ca_lags$time_value[t],\n                               target_date = ca_lags$time_value[t+h],\n                               prediction = predict(m2_fit, newdata = data.frame(ca_lags[t+h, ]))))\n    }\n}\n```\n:::\n\n\n## Predictions for different $h$, `lm` on lagged cases\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-m1_5ff45367c04a700c21bceca32ba76443'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-m1-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/m1-error_b3cb4463eedaa8c1231f009d7591ea2b'}\n::: {.cell-output .cell-output-stdout}\n```\n                         MAE    MASE\nlm on lagged cases 0.1049742 304.007\n```\n:::\n:::\n\n\n## Predictions for different $h$, ARX(1)\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-m2_f8312f47797ef70ce3f562add02e9a10'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-m2-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/m2-error_b121b6ee98b64c588a62bf9e1a654626'}\n::: {.cell-output .cell-output-stdout}\n```\n              MAE     MASE\nARX(1) 0.04463132 129.2531\n```\n:::\n:::\n\n\n\n## Visualizing predictions for multiple horizons\n\nDifferent ways to visualize predictions for multiple $h$\n\n* Last slides: [group by forecast date]{.primary}, and show prediction \"trajectories\"\n\n* Other approach: [one line and color per horizon]{.primary} $h$\n\n## Predictions by horizon, ARX(1)\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/weekly-predictions_68211dc461e5a7a66d025bc0f8ae8a40'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-by-h_007fa791747e78190ee2687655a02dff'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-by-h-1.svg){fig-align='center'}\n:::\n:::\n\n\n# Overfitting and Regularization\n\n## ARX models with 2 and 3 lags\n\n* The [ARX(1)]{.primary} model \n$\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\beta_0 x_{t}$ \nhas good predictive performance\n\n* We will now try to improve the ARX(1) model by including [more lags]{.primary} in the set of predictors\n\n* Let's consider two extensions: the [ARX(2)]{.primary} model\n\n$$\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} + \n\\hat\\beta_0 x_{t} + \\hat\\beta_1 x_{t-7}$$\n\nand the [ARX(3)]{.primary} model\n\n$$\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} + \\hat\\phi_2 y_{t-14} +\n\\hat\\beta_0 x_{t} + \\hat\\beta_1 x_{t-7} + \\hat\\beta_2 x_{t-14}$$\n\nand fit them using a trailing window with $w = 120$.\n\n## Fit ARX(2) and ARX(3) on trailing window\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/arx-2-and-3_64a51843b4fc50ad7b7cf73286c2531e'}\n\n```{.r .cell-code}\npred_arx2 = pred_arx3 <- rep(NA, length = n)  \nw <- 120     #trailing window size\nh <- 28      #number of days ahead\n\n# create lagged predictors\nca_lags$lagged_deaths_35 <- dplyr::lag(ca_lags$deaths, n = 35)\nca_lags$lagged_deaths_42 <- dplyr::lag(ca_lags$deaths, n = 42)\nca_lags$lagged_cases_35 <- dplyr::lag(ca_lags$cases, n = 35)\nca_lags$lagged_cases_42 <- dplyr::lag(ca_lags$cases, n = 42)\n\nfor (t in t0:(n-h)) {\n  arx2_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h, \" + lagged_deaths_\", h,\n                                  \" + lagged_cases_\", h+7, \" + lagged_deaths_\", h+7))\n  arx3_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h, \" + lagged_deaths_\", h,\n                                  \" + lagged_cases_\", h+7, \" + lagged_deaths_\", h+7,\n                                  \" + lagged_cases_\", h+14, \" + lagged_deaths_\", h+14))\n  # fit to trailing window of data\n  arx2_fit = lm(arx2_formula, data = ca_lags, subset = (1:n) <= t & (1:n) > (t-w-7)) \n  arx3_fit = lm(arx3_formula, data = ca_lags, subset = (1:n) <= t & (1:n) > (t-w-14)) \n  # make h-step ahead predictions\n  pred_arx2[t+h] <- max(0, predict(arx2_fit, newdata = data.frame(ca_lags[t+h, ])))\n  pred_arx3[t+h] <- max(0, predict(arx3_fit, newdata = data.frame(ca_lags[t+h, ])))\n}\n```\n:::\n\n\n## Time-Series CV (trailing): ARX(1), ARX(2), and ARX(3) \n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/arx-2-and-3-plot-cv-predictions_2612e0acf7f3fd650b532163e7fdcbe7'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/arx-2-and-3-plot-cv-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/arx-1-arx-2-and-3-cv-error_4c67e7ee8de8d8f2bf2c9e9f895f6de4'}\n::: {.cell-output .cell-output-stdout}\n```\n              MAE      MASE\nARX(1) 0.07852942  731.6178\nARX(2) 0.08716160  812.0393\nARX(3) 0.12487694 1163.4135\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/arx-1-arx-2-and-3-no-omicron_d27b093f19d868d21f186f12a6634d34'}\n\n:::\n\n\n\n## Warning!\n\nAs we add more predictors, [forecasts]{.primary} seem more [volatile]{.primary} and errors increase.\n\n::: {.callout-important icon=\"false\"}\n## **Overfitting**\n:::\n\n## Overfitting\n\nWhen we introduce [too many predictors]{.primary} in the model\n\n* The estimated coefficients will be chosen to mimic the observed data very \n  closely on the training set, leading to [small training error]{.primary}\n\n* The predictive performance on the test set might be very poor, \n  producing [large split-sample and CV error]{.primary}\n\n\n\n## Extreme case: ARX model with 120 predictors\n\n* What happens if we increase the number of predictors to 120? \n\n* Let's fit\n\n$$\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-1} + \\dots + \n\\hat\\phi_{59} y_{t-59} + \n\\hat\\beta_0 x_{t} + \\dots + \\hat\\beta_{t-59} x_{t-59}$$\n\nand compare [training vs split-sample errors]{.primary}\n\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/overfit-data_1cdb67f94e26771c8bd8d82ed643aaf3'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/overfit-lm_453ba61943074a35b306bec85f82d44c'}\n\n:::\n\n\n## Extreme case: predictions on training and test set \n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/overfit-pred_40355608d6f9e34126be2910cc0c4e65'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/overfit-plot-train-test_d34c79f617f9aad65af3415020e978f9'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/overfit-train-test-error_f142f21882160c3494fc948c4cfde81b'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/overfit-plot-train-test-trunc_34da73b9bcb425142a1b6bfe97eb0b43'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/overfit-plot-train-test-trunc-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/overfit-train-test-error-trunc_d9d8db79d479476b8a7f86009af827e0'}\n::: {.cell-output .cell-output-stdout}\n```\n                   MAE    MASE\nsplit-sample 0.3978198 3706.28\n```\n:::\n:::\n\n\n\n::: {.callout-important icon=\"false\"}\n## Note\n\nSome predictions were negative, which doesn't make sense for count data, so we truncated them at 0.\n:::\n\n\n## Back to ARX(1), ARX(2), and ARX(3)\n\nHow can we \n\n* select the \"right\" number of lags to include? \n\n* avoid overfitting, while considering a large number of predictors? \n\n\n## Regularization\n\n* [Idea]{.primary}: introduce a regularization parameter $\\lambda$ that [shrinks or sets]{.primary} some \nof the estimated coefficients to zero, i.e. some predictors are estimated to \nhave limited or no predictive power\n\n* Most common regularization methods\n\n  * [Ridge]{.primary}: shrinks coefficients to zero\n  \n  * [Lasso]{.primary}: sets some coefficients to zero\n\n\n* Let's predict $h=28$ days ahead by regularizing\n\n  * ARX(1)\n  * ARX(2)\n  * ARX(3)\n\n\n## Fit ARX(3) + ridge/lasso for COVID deaths\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/ridge-lasso-fit_105d92cfe8b28f972f0725f1f0f7f32f'}\n\n```{.r .cell-code}\nlibrary(glmnet) # Implements ridge and lasso\n\nh <- 28\nX <- as_tibble(ca_lags) |> select(ends_with(\"_28\"), ends_with(\"_35\"), ends_with(\"_42\"))\ny <- ca_lags$deaths\n\n# We'll need to omit NA values explicitly, as otherwise glmnet will complain\nX_train <- X[43:t0, ]\ny_train <- y[43:t0]\n\n# Ridge regression: set alpha = 0, lambda sequence will be chosen automatically\nridge <- glmnet(X_train, y_train, alpha = 0)\nbeta_ridge <- coef(ridge)       # matrix of estimated coefficients \nlambda_ridge <- ridge$lambda    # sequence of lambdas used to fit ridge \n\n# Lasso regression: set alpha = 1, lambda sequence will be chosen automatically\nlasso <- glmnet(X_train, y_train, alpha = 1)\nbeta_lasso <- coef(lasso)       # matrix of estimated coefficients \nlambda_lasso <- lasso$lambda    # sequence of lambdas used to fit lasso \n\ndim(beta_lasso)                 # One row per coefficient, one column per lambda value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  7 85\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/lasso-ridge-predictions_9add45d6cb66b2f7fe65bd8d989847a5'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/lasso-ridge-coeff_71f4c1951048c0629fb9506ced3a111c'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-ridge-lasso-coeff_e49e6ac5b440e0ec60eb29b5ab33195c'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/shrinkage-sparsity_92965313ab6108db42fbd1217c92f0ef'}\n\n:::\n\n\n\n\n## Time-series CV (trailing) for ARX(3) + ridge/lasso \n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/regularization-cv_9ebf52f6788e81b2a0de1f5fb9e78b13'}\n\n```{.r .cell-code}\nh <- 28  # number of days ahead \nw <- 120 # window length\n\n# Initialize matrices for predictions (one column per lambda value)\nyhat_ridge_mat <- matrix(NA, nrow = n, ncol = length(lambda_ridge))\nyhat_lasso_mat <- matrix(NA, nrow = n, ncol = length(lambda_lasso)) \nyhat_ridge = yhat_lasso <- rep(NA, length = n)\n\n# Select index of best lambda value on training set\nridge_index = cv.glmnet(as.matrix(X_train), y_train, alpha = 0, lambda = lambda_ridge)$index[1]\nlasso_index = cv.glmnet(as.matrix(X_train), y_train, alpha = 1, lambda = lambda_lasso)$index[1]\n\nfor (t in t0:(n-h)) {\n  # Indices of data within window\n  inds = t-w < 1:n & 1:n <= t\n  # Fit ARX + ridge/lasso for each lambda value\n  ridge_trail = glmnet(X[inds, ], y[inds], alpha = 0, lambda = lambda_ridge)\n  lasso_trail = glmnet(X[inds, ], y[inds], alpha = 1, lambda = lambda_lasso)\n  # Predict for each lambda value\n  yhat_ridge_mat[t+h, ] = predict(ridge_trail, newx = as.matrix(X[(t+h), ]))\n  yhat_lasso_mat[t+h, ] = predict(lasso_trail, newx = as.matrix(X[(t+h), ]))\n  # Save prediction corresponding to best lambda so far\n  yhat_ridge[t+h] = max(0, yhat_ridge_mat[t+h, ridge_index])\n  yhat_lasso[t+h] = max(0, yhat_lasso_mat[t+h, lasso_index])\n  if (t >= t0+h) {\n    # Prediction error\n    mae_ridge = colMeans(abs(yhat_ridge_mat[1:(t+1), ] - y[1:(t+1)]), na.rm = T)\n    mae_lasso = colMeans(abs(yhat_lasso_mat[1:(t+1), ] - y[1:(t+1)]), na.rm = T)\n    # Select index of lambda vector which gives lowest MAE so far\n    ridge_index <- which.min(mae_ridge)\n    lasso_index <- which.min(mae_lasso)\n  }\n}\n```\n:::\n\n\n\n## Predictions: time-series CV (trailing) for ARX(1) + ridge/lasso \n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/regularize-arx-1_401bb55230c81d4c4f2fc2b53194287d'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/regularize-arx-1-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/errors-arx1-regularized_39a5652547278432cd227d542bc80b6a'}\n::: {.cell-output .cell-output-stdout}\n```\n                      MAE     MASE\nARX(1)         0.07852942 731.6178\nARX(1) + ridge 0.07004585 652.5808\nARX(1) + lasso 0.07887651 734.8514\n```\n:::\n:::\n\n\n\n## Predictions: time-series CV (trailing) for ARX(2) + ridge/lasso \n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/regularize-arx-2_9214cea9dc8da12f24136299ada8fd96'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/regularize-arx-2-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/errors-arx2-regularized_f36e1c5a8b9fb61a3af5b228c8305988'}\n::: {.cell-output .cell-output-stdout}\n```\n                      MAE     MASE\nARX(2)         0.08716160 812.0393\nARX(2) + ridge 0.08143228 758.6622\nARX(2) + lasso 0.07807801 727.4122\n```\n:::\n:::\n\n\n\n\n## Predictions: time-series CV (trailing) for ARX(3) + ridge/lasso \n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-arx3-regularization-cv_8dda178f8f8a22c2bc4a988f3c650dce'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-arx3-regularization-cv-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/arx3-regularization-cv-errors_70c28f80795f7f94fa4974eaf5408f82'}\n::: {.cell-output .cell-output-stdout}\n```\n                      MAE      MASE\nARX(3)         0.12487694 1163.4135\nARX(3) + ridge 0.08555066  797.0310\nARX(3) + lasso 0.07633053  711.1318\n```\n:::\n:::\n\n\n## Comparison of regularized ARX(1), ARX(2), and ARX(3)\n\n* Best model: ARX(1) + ridge\n\n* Second best: ARX(3) + lasso\n\n* Ridge worsens as more predictors are included\n\n* Lasso improves as more predictors are included\n\n\n# Prediction Intervals\n\n## Point predictions vs intervals \n\n* So far, we have only considered [point predictions]{.primary}, i.e. \nwe have fitted models \nto provide our [best guess on the outcome]{.primary} at time $t+h$. \n\n::: {.callout-important icon=\"false\"}\n## \nWhat if we want to provide a [measure of uncertainty]{.primary} around the point \nprediction or a [likely range of values]{.primary} for the outcome at time $t+h$?\n\n:::\n\n* For each target time $t+h$, we can construct [prediction intervals]{.primary}, i.e. provide \nranges of values that are expected to cover the true outcome value a fixed \nfraction of times.\n\n## Prediction intervals for `lm` fits\n\n* To get prediction intervals for the models we previously fitted, \nwe only need to tweak our call to `predict` by adding as an input: \n\n  `interval = \"prediction\", level = p`\n\n  where $p \\in (0, 1)$ is the desired coverage.\n\n* The output from `predict` will then be a matrix with \n\n  * first column a [point estimate]{.primary}\n  \n  * second column the [lower limit]{.primary} of the interval\n  \n  * third column the [upper limit]{.primary} of the interval\n\n\n## Prediction intervals for ARX (CV, trailing window)\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/arx-intervals-time-series-cv_547cce04a07079cf93be49849e4cf53a'}\n\n```{.r .cell-code}\n# Initialize matrices to store predictions \n# 3 columns: point estimate, lower limit, and upper limit\npred_interval_lm <- matrix(NA, nrow = n, ncol = 3)\ncolnames(pred_interval_lm) <- c('prediction', 'lower', 'upper')\n\nfor (t in t0:(n-h)) {\n  # Fit ARX and predict\n  arx_trailing = lm(deaths ~ lagged_deaths + lagged_cases, data = ca, \n                    subset = (1:n) <= t & (1:n) > (t-w)) \n  pred_interval_lm[t+h, ] = pmax(0, \n                              predict(arx_trailing, newdata = data.frame(ca[t+h, ]),\n                                      interval = \"prediction\", level = 0.8))\n}\n```\n:::\n\n\n## Prediction intervals for ARX (CV, trailing window)\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot arx-intervals-cv-trailing_11e9102f78319dd93bed24e0137ee3f4'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot arx-intervals-cv-trailing-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/lm-errors-arx_bd9ad819218604a91dc8fd0892372709'}\n::: {.cell-output .cell-output-stdout}\n```\n                   MAE     MASE\nlm.trailing 0.08932857 832.2278\n```\n:::\n:::\n\n\n## Quantile regression\n\n* So far we only considered different ways to apply linear regression.\n\n* Quantile regression is a different estimation method, and it directly targets conditional \nquantiles of the outcome over time.\n\n::: {.callout-note}\n## Definition\nConditional quantile = value below which a given percentage (e.g. 25%, 50%, \n75%) of observations fall, given specific values of the predictor variables. \n:::\n\n* [Advantage]{.primary}: it provides a more complete picture of the outcome distribution.\n\n## ARX model for COVID deaths via quantile regression\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/q-reg_bf9930f12b71e289835430a77f8a16c9'}\n\n```{.r .cell-code}\n#install.packages(\"quantreg\")\nlibrary(quantreg)  #library to perform quantile regression\n\n# Set quantiles of interest: we will focus on 10%, 50% (i.e. median), and 90% quantiles\nquantiles <- c(0.1, 0.5, 0.9)  \n\n# Fit quantile regression to training set\nq_reg <- rq(deaths ~ lagged_deaths + lagged_cases, data = train, tau = quantiles)\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/q-reg-training_c68f0af2f3a06567f69aed6151f69fc6'}\n\n:::\n\n\n## Predictions via quantile regression (CV, trailing)\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/q-reg-time-series-cv_cf655b492c7616b9d62fc4141c08773f'}\n\n```{.r .cell-code}\n# Initialize matrix to store predictions \n# 3 columns: lower limit, median, and upper limit\npred_interval_rq <- matrix(NA, nrow = n, ncol = 3)\ncolnames(pred_interval_rq) <- c('lower', 'median', 'upper')\n\nfor (t in t0:(n-h)) {\n  # Fit quantile regression\n  rq_trailing = rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles,\n                   data = ca, subset = (1:n) <= t & (1:n) > (t-w)) \n  \n  # Sort estimated coefficients \n  #coefs_sorted <- t(apply(coef(rq_trailing), 1, sort))\n  #rq_trailing$coefficients <- coefs_sorted\n  \n  # Predict\n  #pred_interval_rq[t+h, ] = pmax(0, predict(rq_trailing, newdata = data.frame(ca[t+h, ])))\n  pred_interval_rq[t+h, ] = sort(pmax(0, predict(rq_trailing, newdata = data.frame(ca[t+h, ]))))\n}\n```\n:::\n\n\n## Predictions via quantile regression (CV, trailing)\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/q-reg-plot-cv-predictions-trailing_9145327964ec3ee882bd193c6669e7e1'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/q-reg-plot-cv-predictions-trailing-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/qr-errors-arx_03e0ccfc833bbecb06e67f7bd4ca6047'}\n::: {.cell-output .cell-output-stdout}\n```\n                   MAE     MASE\nrq.trailing 0.08379408 780.6659\n```\n:::\n:::\n\n\n## Actual Coverage\n\n* We would [expect]{.primary} the ARX model fitted via `lm` and via `rq` to [cover]{.primary} the truth\nabout [80\\%]{.primary} of the times. Is this actually true in practice?\n\n* The actual coverage of each predictive interval is [lower]{.primary}:\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/lm-coverage-all-past_fc73464e0d70890ff9f6a0f0d2dc8f27'}\n::: {.cell-output .cell-output-stdout}\n```\n         lm.trailing rq.trailing\nCoverage   0.6029412   0.4367647\n```\n:::\n:::\n\n\n* We can use [calibration]{.primary} to handle under-covering (more on this in the afternoon)\n\n## Evaluation {.smaller}\n\n* Prediction intervals are “good” if they \n\n  * cover the truth most of the time\n  \n  * are not too wide\n  \n* Error metric that captures both desiderata: [Weighted Interval Score (WIS)]{.primary}\n\n* $F$ = forecast composed of predicted quantiles $q_{\\tau}$ for the set \nof quantile levels $\\tau$. The WIS for target variable $Y$ is represented as:\n\n$$WIS(F, Y) = 2\\sum_{\\tau} \\phi_{\\tau} (Y - q_{\\tau})$$\n\nwhere $\\phi_{\\tau}(x) = \\tau |x|$ for $x \\geq 0$ and \n$\\phi_{\\tau}(x) = (1-\\tau) |x|$ for $x < 0$.\n\n* If [quantile levels]{.primary} are [symmetric]{.primar}, alternative expression:\n\n$$WIS(F, Y) = \\sum_{\\alpha} \\{(u_\\alpha - l_\\alpha) + 2 \\cdot \\text{dist}(Y, [l_\\alpha, u_\\alpha])\\}$$\nwhere $[l_\\alpha, u_\\alpha]$ are central prediction intervals parametrized by\nthe exclusion probability $\\alpha$, and $\\text{dist}(a, S)$ = smallest distance \nbetween point $a$ and an element of set $S$.\n\n## Computing the WIS \n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/wis-function_f9777239a2900a70030d179a61d6796e'}\n\n```{.r .cell-code}\nWIS <- function(truth, estimates, quantiles) {\n  2 * sum(pmax(\n    quantiles * (truth - estimates),\n    (1 - quantiles) * (estimates - truth),\n    na.rm = TRUE\n  ))\n}\n```\n:::\n\n\n::: {.callout-important icon=\"false\"}\n## Note\nWIS tends to [prioritize sharpness]{.primary} (how wide the interval is) relative to \ncoverage (if the interval contains the truth).\n:::\n\n## WIS for ARX fitted via `lm` and `rq`\n\nThe lowest mean WIS is attained by quantile regression. \n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/wis-lm_e1967262d61a14968734dd3959a7fb90'}\n::: {.cell-output .cell-output-stdout}\n```\n  Mean WIS lm Mean WIS rq\n1   0.1670436   0.1628808\n```\n:::\n:::\n\n\n\n## Multiple quantiles\n\n* In practice, one might want to include more quantiles \n(Forecast Hub asks for 23 quantiles)\n\n* To reliably estimate more quantiles, we [need more data]{.primary}. \nThis can be achieved by:\n\n  * using a [longer trailing window]{.primary} \n  (but [trade-off]{.primary} with ability to adapt to changes in predictors-outcome relation)\n\n  * using [multiple time series]{.primary} (e.g. data from multiple states, more on this in the afternoon)\n\n## Quantile regression with Forecast Hub quantiles \n\n### No sorting\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/q-reg-more-quantiles_0a3398f77077f82ef7b6b381dc22e901'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/q-reg-plot-more-quantiles_c183c5d8c7270494b4eb54323a26680e'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/q-reg-plot-more-quantiles-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Quantile regression with Forecast Hub quantiles \n\n### Sorted predictions \n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/q-reg-more-quantiles-sort_e955a8504c9c041973573c22ca4e735f'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/q-reg-more-quantiles-sort-1.svg){fig-align='center'}\n:::\n:::\n\n\n# Forecasting with Versioned Data\n\n## Versioned data\n\nSo far: data never revised \n(or simply ignored revisions, `as_of` today)\n\n::: {.callout-important icon=\"false\"}\n## \nHow can we [train forecasters]{.primary} when dealing with [versioned data]{.primary}?\n:::\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/get-versioned-data_cafc7a116a6e0ecee94ae043e5a05009'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/versioned-data_b2c330ffc99a05aeb303ef403c610610'}\n\n```{.r .cell-code}\nca_archive\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-04-01 / 2023-03-09\nℹ First/last version with update: 2020-04-02 / 2023-03-10\nℹ Versions end: 2023-03-10\nℹ A preview of the table (24953 rows x 5 columns):\n       geo_value time_value    version case_rate death_rate\n    1:        ca 2020-04-01 2020-04-02  3.009195 0.06580240\n    2:        ca 2020-04-01 2020-05-07  3.009195 0.06327156\n    3:        ca 2020-04-01 2020-06-21  3.009195 0.06580242\n    4:        ca 2020-04-01 2020-07-02  2.978825 0.06580242\n    5:        ca 2020-04-01 2020-07-03  2.978825 0.06580242\n   ---                                                     \n24949:        ca 2023-03-07 2023-03-08  0.000000 0.00000000\n24950:        ca 2023-03-07 2023-03-10 27.397832 0.00000000\n24951:        ca 2023-03-08 2023-03-09 21.083071 0.00000000\n24952:        ca 2023-03-08 2023-03-10  0.000000 0.00000000\n24953:        ca 2023-03-09 2023-03-10 22.185487 0.52072650\n```\n:::\n:::\n\n\n## Version aware-forecasting\n\n[Important]{.primary}: when fitting and predicting, only use data in the latest \nversion available at the forecast date!\n\n## Version-aware forecasting\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/versioned-weekly-avg_5c98e006f5452a3eb540fcdca8b46534'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/versioned-quantile-reg_ed726980cff0e74cfc4e78b16de09462'}\n\n```{.r .cell-code}\n# initialize dataframe for predictions\n# 5 columns: forecast date, target date, 10%, 50%, and 90% quantiles\npred_aware <- data.frame(matrix(NA, ncol = 5, nrow = 0))\n\nw <- 120         #trailing window size\nh <- 28          #number of days ahead\n\n# dates when predictions are made \nfc_time_values <- seq(from = t0_date, to = as.Date(\"2023-02-01\"), by = \"1 day\")\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data <- epix_as_of(ca_archive, max_version = as.Date(fc_date))\n  # create lagged predictors\n  data$lagged_deaths <- dplyr::lag(data$deaths, h) \n  data$lagged_cases <- dplyr::lag(data$cases, h)\n  # perform quantile regression\n  rq_trailing <- rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles, \n                    # only consider window of data\n                    data = data |> filter(time_value > (max(time_value) - w))) \n  # sort estimated coefficients \n  #coefs_sorted <- t(apply(coef(rq_trailing), 1, sort))\n  #colnames(coefs_sorted) <- c('tau..0.1', 'tau..0.5', 'tau..0.9')\n  #rq_trailing$coefficients <- coefs_sorted\n  # construct data.frame with the right predictors for the target date\n  predictors <- data.frame(lagged_deaths = tail(data$deaths, 1), \n                           lagged_cases = tail(data$cases, 1))\n  # make predictions for target date and add them to matrix of predictions\n  pred_aware <- rbind(pred_aware, \n                      data.frame('forecast_date' = max(data$time_value),\n                                 'target_date' = max(data$time_value) + h, \n                                 t(pmax(0, sort(predict(rq_trailing, newdata = predictors))))))\n}\n```\n:::\n\n\n\n## Version-aware predictions (CV, trailing)\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/clean-data-output_9d8d26be845226606a91ead6df7f4517'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-versioned-cv-trailing_aff2aea3071cf43d4352795ed4487c3f'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-versioned-cv-trailing-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/versioned-cv-errors_0908bb9ae24cc449b34d58d9a3f0caa4'}\n::: {.cell-output .cell-output-stdout}\n```\n                     MAE     MASE\nversion-aware 0.07130073 672.6971\n```\n:::\n:::\n\n\n## Version-unaware predictions (CV, trailing)\n\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/plot-version-unaware-cv-trailing_5356ed39c87c0918ec62f662dc81df42'}\n::: {.cell-output-display}\n![](day2-morning_files/figure-revealjs/plot-version-unaware-cv-trailing-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-morning_cache/revealjs/qr-errors-unaware_a725e8e5511f5c95886e999003a875d3'}\n::: {.cell-output .cell-output-stdout}\n```\n                      MAE     MASE\nversion-unaware 0.0694222 646.7705\n```\n:::\n:::\n\n\n# Other Approaches to Time Series Data\n\n## Traditional Time Series Forecasting\n\nTwo popular frameworks:\n\n* Exponential Smoothing with Trend and Seasonality ([ETS]{.primary})\n\n* Autoregressive Integrated Moving Average ([ARIMA]{.primary})\n\n\n## ETS\n\n### Simple Exponential Smoothing (SES)\n\n* The $h$-step ahead prediction is a weighted average of the current \nobservation $y_t$ and the forecast $\\hat y_{t|t-1}$:\n\n$$\\hat y_{t+h|t} = \\alpha y_t + (1- \\alpha) \\hat y_{t|t-1}$$\n\nwhere $\\alpha \\in [0,1]$\n\n* [Forecasts are flat]{.primary}, i.e. do not depend on $h$\n\n* If $\\alpha = 1$, we retrieve the [naive flatline]{.primary} forecaster\n\n$$ y_{t+h|t} = y_t$$\n\n\n## ETS\n\n### Simple Exponential Smoothing (SES)\n\n* The SES forecast can be re-expressed as\n\n$$\\hat y_{t+h|t} = \\alpha y_t + \\alpha (1- \\alpha) y_{t-1}  + \\alpha (1- \\alpha)^2 y_{t-2} + \\dots$$\n\ni.e. observations [$y_{t-k}$]{.primary}  that are $k$ steps into the past are [exponentially \ndown-weighted]{.primary}, with weight $(1- \\alpha)^2$. Hence the name exponential smoothing.\n\n* [Component form]{.primary} of the SES forecast\n\n\\begin{align*}\n\\hat y_{t+h | t} & = l_t \\\\\nl_t & = \\alpha y_t + (1- \\alpha) l_{t-1}\n\\end{align*}\n\n## ETS\n\n### Holt's linear trend method\n\n* Expands SES component form by introducing a [trend]{.primary} $b_t$\n\n\\begin{align*}\n\\hat y_{t+h | t} &= l_t + b_t h\\\\\nl_t &= \\alpha y_t + (1- \\alpha) (l_{t-1} + b_{t-1}) \\\\\nb_t & = \\beta (l_{t} - l_{t-1}) + (1-\\beta) b_{t-1}\n\\end{align*}\n\nwhere $\\alpha, \\beta \\in [0,1]$.\n\n* [Forecasts are linear]{.primary} in $h$, with slope $b_t$.\n\n::: {.callout-important icon=\"false\"}\n## Note\n\nLinear trend forecasts can be erratic for large $h$!\n:::\n\n\n## ETS\n\n### Damped Holt's method\n\n* Introduces a parameter $\\phi$ to [dampen the forecast trajectory]{.primary} \n\n\\begin{align*}\n\\hat y_{t+h | t} &= l_t + b_t (\\phi +\\phi^2 + \\dots + \\phi^h)\\\\\nl_t &= \\alpha y_t + (1- \\alpha) (l_{t-1} + b_{t-1}\\phi) \\\\\nb_t & = \\beta (l_{t} - l_{t-1}) + (1-\\beta) b_{t-1}\\phi\n\\end{align*}\n\nwhere $\\alpha, \\beta, \\phi \\in [0,1]$\n\n* Contribution of slope $b_t$ to a forecast diminishes at each step into the \nfuture, by a multiplicative factor $\\phi$\n\n* As $h\\to \\infty$, forecasts approach a constant level\n\n$$ y_{t+h | t} \\to l_t + b_t \\sum_{j=1}^\\infty \\phi^j = l_t + b_t \\frac{\\phi}{1-\\phi}$$\n\n## ARIMA\n\n### AR(p)\n\nAuto-regressive model of order $p$\n\n$$y_t = \\sum_{j=1}^p \\phi_j y_{t-j} + w_t$$\n\n### MA(q)\n\nMoving average model of order $q$\n\n$$y_t = w_t + \\sum_{j=1}^q \\theta_j w_{t-j} $$\n\nwhere $w_t$ is a white noise sequence, i.e. \n$\\mathbb{E}(w_t)=0$ and $\\text{Var}(w_t)=\\sigma^2$ for all $t$, and \n$\\text{Cov}(w_s, w_t)=0$ for all $s \\neq t$\n\n\n## ARIMA\n\n### ARMA(p, q)\n\n$$y_t = \\sum_{j=1}^p \\phi_j y_{t-j} + \\sum_{j=0}^q \\theta_j w_{t-j} $$\n\nwith $\\theta_0 = 1$\n\n### ARIMA(p, d, q)\n\nAssumes an $ARMA(p, q)$ model on the \n$d^{th}$-order differences of $y_t$\n\n## Mechanistic Models\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}