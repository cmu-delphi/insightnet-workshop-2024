{
  "hash": "f9a7e0aee9cc910cd1aaa2c6cd6db207",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntalk-title: \"Forecasting and Time-Series Models\"\ntalk-short-title: \"{{< meta talk-title >}}\"\ntalk-subtitle: \"\"\nauthor: \"\"\nother-authors: \"\"\nrepo-address: \"cmu-delphi/insightnet-workshop-2024\"\ntalk-date: \"Venue -- dd Somemonth yyyy\"\nformat: revealjs\n---\n\n\n\n<!-- Set any of the above to \"\" to omit them -->\n\n<!-- Or adjust the formatting in _titleslide.qmd -->\n\n\n---\n---\n\n\n\\DeclareMathOperator*{\\minimize}{minimize}\n\n\n\n\n\n\n\n\n\n::: flex\n::: w-20\n\n:::\n::: w-80\n## {{< meta talk-title >}} {background-image=\"gfx/cover-art-1.svg\" background-position=\"bottom\"}\n\n### {{< meta talk-subtitle >}}\n\n<br>\n\n#### {{< meta author >}} \n\n{{< meta other-authors >}}\n\n\n{{< meta talk-date >}}\n\n\n:::\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n## Basics of linear regression \n\n* Assume we observe a predictor $x_i$ and an outcome $y_i$ for $i = 1, \\dots, n$.\n\n* Linear regression seeks coefficients $\\beta_0$ and $\\beta_1$ such that\n\n$$y_i \\approx \\beta_0 + \\beta_1 x_i$$\n\nis a good approximation for every $i = 1, \\dots, n$.\n\n* In R, the coefficients are found by running `lm(y ~ x)`, where `y` is the vector \nof responses and `x` the vector of predictors.\n\n\n## Multiple linear regression \n\nGiven $p$ different predictors, we seek $(p+1)$ coefficients such that\n\n$$y_i \\approx \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip}$$\nis a good approximation for every $i = 1, \\dots, n$.\n\n\n## Linear regression with lagged predictor\n\n* In time series models, the outcomes and predictors are usually indexed by time \n$t$. \n\n* Often we want to predict a future value of $y$, given present and past \nvalues of $x$. \n\n* For this purpose, we introduce linear regression with lagged \npredictors \n\n$$y_t \\approx \\beta_0 + \\beta_1 x_{t-k}$$\n\ni.e. we regress the outcome $y$ at time $t$ on the predictor $x$ at time $t-k$.\n\n## Example: COVID cases and deaths\n\n- Cases seem to be highly correlated with deaths several weeks later\n\n- What is the lag $k$ for which the correlation between cases at $t-k$ and \ndeaths at $t$ is maximized?\n\n- Given that lag, we can fit linear regression with a lagged predictor where\n\n$$y_t = \\text{deaths at time } t$$\n$$x_{t-k} = \\text{cases at time } t-k$$\n\n## Choosing the lag $k$\n\n* Let’s split the data into a training set (before 2021-03-01), and a test set\n(after 2021-03-01).\n\n* The lag leading to largest correlation between lagged cases and deaths is \n$k = 26$.\n\n\n## Fitting lagged linear regression in R\n\n# Evaluation\n\n## Error metrics\n\n* Assume we have predictions $\\hat y_{new, t}$ for the unseen observations \n$y_{new,t}$ over times $t = 1, \\dots, N$.\n\n* Four commonly used error metrics are:\n\n  * mean squared error (MSE)\n\n  * mean absolute error (MAE)\n\n  * mean absolute percentage error (MAPE)\n\n  * mean absolute scaled error (MASE)\n\n## Error metrics: MSE and MAE\n\n$$MSE = \\frac{1}{N} \\sum_{t=1}^N (y_{new, t}- \\hat y_{new, t})^2$$\n$$MAE = \\frac{1}{N} \\sum_{t=1}^N |y_{new, t}- \\hat y_{new, t}|$$\n\n* MAE gives less importance to extreme errors than MSE.\n\n* [Drawback]{.primary}: both metrics are scale-dependent, so they are not universally \ninterpretable.\n(For example, if $y$ captures height, MSE and MAE will vary depending on whether we measure in feet or meters.)\n\n## Error metrics: MAPE\n\n* Fixing scale-dependence:\n\n$$MAPE = 100 \\times \\frac{1}{N} \\sum_{t=1}^N \n\\left|\\frac{y_{new, t}- \\hat y_{new, t}}{y_{new, t}}\\right|$$\n\n* [Drawbacks]{.primary}:\n\n  * Erratic behavior when $y_{new, t}$ is close to zero\n\n  * It assumes the unit of measurement has a meaningful zero (e.g. using \nFahrenheit or Celsius to measure temperature will lead to different MAPE)\n\n\n## Error metrics: MASE\n\n$$MASE = 100 \\times \\frac{\\frac{1}{N} \\sum_{t=1}^N \n|y_{new, t}- \\hat y_{new, t}|}\n{\\frac{1}{N-1} \\sum_{t=2}^N \n|y_{new, t}- y_{new, t-1}|}$$\n\n* [Advantages]{.primary}:\n\n  * is universally interpretable (not scale dependent)\n\n  * avoids the zero-pitfall\n\n* MASE in words: we normalize the error of our forecasts by that of a naive method \nwhich always predicts the last observation.\n\n\n## Estimating the prediction error\n\n* After choosing the error metric (e.g. MSE), we need to estimate the prediction \nerror. \n\n* This can be accomplished in different ways, using the\n\n  * Training error\n\n  * Split-sample error\n\n  * Time series cross-validation error (using all past data or a trailing window)\n\n\n## Training error\n\n* The easiest but [worst]{.primary} approach to estimate the prediction error is \nto use the training error, i.e. the average error on the training set that was \nused to fit the model.\n\n* The training error is\n\n  * generally too optimistic as an estimate of prediction error\n\n  * [more optimistic the more complex the model!]{.primary}\n\n\n## Training error\n### Linear regression of COVID deaths on lagged cases\n\n\n## Split-sample error {.smaller}\n\n* To compute the split-sample error  \n\n  1. Split the data into training (up to time $t_0$), and test set (after $t_0$)\n\n  1. Fit the model to the training data only\n\n  1. Make predictions for the test set\n\n  1. Compute the selected error metric on the test set only\n\n* Formally, the split-sample MSE is\n\n$$\\text{SplitMSE} = \\frac{1}{n-t_0} \\sum_{t = t_0 +1}^n (\\hat y_t - y_t)^2$$\n\n* In practice, split-sample estimates of prediction error are generally \n[pessimistic]{.primary}, as they mimic a situation where we would never refit\nthe model in the future. \n\n## Split-sample error\n### Linear regression of COVID deaths on lagged cases\n\n## Time-series cross-validation (CV) {.smaller}\n### 1-step ahead predictions\n\n* If we will refit the model in the future once new data become available, a more \nappropriate way to estimate the prediction error is time-series cross-validation.\n\n* Assume we want to make 1-step ahead predictions (i.e. at time $t-1$ we want to \nmake a forecast for time $t$). Then, for $t = t_0+1, t_0+2, \\dots$, we proceed\nas follows:\n\n  1. Fit the model using data up to time $t-1$\n\n  1. Make a prediction for $t$ \n\n  1. Record the prediction error\n\nThe cross-validation MSE is then\n\n$$CVMSE = \\frac{1}{n-t_0} \\sum_{t = t_0+1}^n (\\hat y_{t|t-1} - y_t)^2$$\n\nwhere\t$\\hat y_{t|t-1}$ indicates a prediction for $y$ at time $t$ that was made \nwith data available up to time $t-1$.\n\n## Time-series cross-validation (CV) {.smaller}\n### $h$-step ahead predictions\n\n* More in general, if we want to make $h$-step ahead predictions (i.e. at time \n$t-h$ we want to make a forecast for time $t$), we proceed as follows \nfor $t = t_0+1, t_0+2, \\dots$\n\n  * Fit the model using data up to time $t-h$\n\n  * Make a prediction for $t$ \n\n  * Record the prediction error\n\n* The cross-validation MSE is then\n\n$$CVMSE = \\frac{1}{n-t_0} \\sum_{t = t_0+1}^n (\\hat y_{t|t-h} - y_t)^2$$\n\nwhere\t$\\hat y_{t|t-h}$ indicates a prediction for $y$ at time $t$ that was made \nwith data available up to time $t-h$.\n\n## Time-series CV on a trailing window\n\n* So far, when making $h$-step ahead predictions for time $t$, we have fitted the \nmodel on all the data available up to time $t-h$. We can instead use a trailing \nwindow, i.e. fit the model on only a window of data of length $w$, starting at \ntime $t-h-w$ and ending at time $t-h$.\n\n* [Advantage]{.primary}: if the relationship between predictors and outcome changes over time,\ntraining the forecaster on a window of recent data can better capture the \nrecent relationship.\n\n* Window length $w$ considerations: \n\n  * if $w$ is too large, the model cannot adapt to the recent predictors-outcome \nrelation \n\n  * if $w$ is too small, the fitted model may be too volatile (trained on too \nlittle data)\n\n\n## Time-series CV: all past vs trailing window\n### Linear regression of COVID deaths on lagged cases\n\n\n# ARX Models\n\n## Autoregressive (AR) model\n\n* [Idea]{.primary}: predicting the outcome via a linear combination of its lags \n\n$$y_t \\approx \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\dots + \\phi_p y_{t-p}$$\n\n* In R, the coefficients $\\phi_1, \\phi_2, \\dots, \\phi_p$ can be estimated using `lm`.\n\n## AR model for COVID deaths\n\n## Autoregressive exogenous input (ARX) model\n\n* [Idea]{.primary}: predicting the outcome via a linear combination of its lags and a set of exogenous (i.e. external) input variables\n\n* Example of ARX model \n\n$$y_t \\approx \\sum_{i=1}^p \\phi_i y_{t-i} + \\sum_{j=1}^q \\psi_j x_{t-j}$$\n\n* We can construct more complex ARX models with multiple lags of several exogenous \nvariables\n\n## ARX model for COVID deaths\n\n\n# Overfitting and Regularization\n\n## Too many predictors\n\n* What if we fit a model with a very large number of predictors?\n\n* The estimated coefficients will be chosen to mimic the observed data very \nclosely on the training set, leading to small training error\n\n* The predictive performance on the test set might be very poor, \nproducing large split-sample and CV error\n\n\nOVERFITTING\n\n\n\n# Prediction Intervals\n\n## Point predictions vs intervals \n\n* So far, we have only considered point predictions, i.e. we have fitted models \nto provide our best guess on the outcome at time $t$. \n\n\n* What if we want to provide a measure of uncertainty around our point \nprediction or a likely range of values for the outcome at time $t$?\n\n\n* For each target time $t$, we can construct prediction intervals, i.e. provide \nranges of values that are expected to cover the true outcome value a fixed \npercentage of times.\n\n## Prediction intervals via residuals\n\n## Prediction intervals via residuals\n### ARX model for COVID deaths\n\n## Quantile regression\n\n* Different approach: method that directly targets conditional quantiles of the \noutcome.\n\n* Conditional quantile = value below which a given percentage (e.g., 25%, 50%, \n75%) of observations fall, given specific values of the predictor variables. \n\n* [Advantage]{.primary}: it provides a more complete picture of the outcome distribution.\n\n## Quantile regression\n### ARX model for COVID deaths\n\n\n## Evaluation\n\n* Prediction intervals are “good” if they \n\n  * cover the truth most of the time\n  \n  * are not too wide\n  \n* Error metric that captures both desiderata: Weighted Interval Score (WIS)\n\n* $F$ = forecast composed of predicted quantiles $q_{\\tau}$ for the set \nof quantile levels $\\tau$. The WIS for target variable $Y$ is represented as \n([McDonald et al., 2021](https://www.pnas.org/doi/full/10.1073/pnas.2111453118)):\n\n$$WIS(F, Y) = 2\\sum_{\\tau} \\phi_{\\tau} (Y - q_{\\tau})$$\n\nwhere $\\phi_{\\tau}(x) = \\tau |x|$ for $x \\geq 0$ and \n$\\phi_{\\tau}(x) = (1-\\tau) |x|$ for $x < 0$.\n\n# Forecasting with Versioned Data\n# Geo-pooling\n\n## Callouts\n\n::: {.callout-note}\nYou can use these. See <https://quarto.org/docs/authoring/callouts.html>\n:::\n\n## Final slide {.smaller}\n\n### Thanks:\n\n\n\n\n\n\n\n- The whole [CMU Delphi Team](https://delphi.cmu.edu/about/team/) (across many institutions)\n- Optum/UnitedHealthcare, Change Healthcare.\n- Google, Facebook, Amazon Web Services.\n- Quidel, SafeGraph, Qualtrics.\n- Centers for Disease Control and Prevention.\n- Council of State and Territorial Epidemiologists\n\n\n::: {layout-row=1 fig-align=\"center\"}\n![](gfx/delphi.jpg){height=\"100px\"}\n![](gfx/berkeley.jpg){height=\"100px\"}\n![](gfx/cmu.jpg){height=\"100px\"}\n![](gfx/ubc.jpg){width=\"250px\"}\n![](gfx/stanford.jpg){width=\"250px\"}\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}