{
  "hash": "73e67b3abcdd0810bb06ae1652674929",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntalk-title: \"Forecasting with `{epipredict}`\"\ntalk-short-title: \"Forecasting\"\ntalk-subtitle: \"InsightNet Forecasting Workshop 2024\"\ntalk-date: \"12 December -- Afternoon\"\nformat: revealjs\n---\n\n---\n---\n\n\n\\DeclareMathOperator*{\\minimize}{minimize}\n\n\n\n\n\n\n\n\n\n::: flex\n::: w-20\n\n:::\n::: w-80\n## {{< meta talk-title >}} {background-image=\"gfx/cover-art-1.svg\" background-position=\"bottom\"}\n\n### {{< meta talk-subtitle >}}\n\n<br>\n\n#### {{< meta author >}} \n[with thanks to Delphi Tooling & Forecasting Team: Logan Brooks, Nat DeFries, Dmitry Shemetov, David Webber]{.fstyle}\n\n\n{{< meta talk-date >}}\n\n\n:::\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n## Outline\n\n1. `{epipredict}`\n\n1. Customizing `arx_forecaster()`\n\n1. Advanced Customizations\n\n1. Building a Forecaster\n\n1. A Flu Forecaster\n\n1. Advanced Topics\n\n# `{epipredict}` \n\n## `{epipredict}` \n\n<https://cmu-delphi.github.io/epipredict>\n\n#### Installation \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Stable version\npak::pkg_install(\"cmu-delphi/epipredict@main\")\n# Development version\n# pak::pkg_install(\"cmu-delphi/epipredict@dev\")\n```\n:::\n\n\n\n\n## What `{epipredict}` provides (i)\n\nBasic and easy to use [\"canned\" forecasters]{.primary}: \n\n  * Baseline flat forecaster\n  \n  * Autoregressive forecaster (ARX)\n  \n  * Autoregressive classifier\n  \n  * CDC FluSight flatline forecaster\n  \n## What `{epipredict}` provides (ii)\n\n* A framework for creating [custom forecasters]{.primary} out of [modular]{.primary} components. \n\n* There are four types of components:\n\n  1. [Preprocessor]{.primary}: do things to the data before model training\n  \n  1. [Trainer]{.primary}: train a model on data, resulting in a fitted model object\n\n  1. [Predictor]{.primary}: make predictions, using a fitted model object\n\n  1. [Postprocessor]{.primary}: do things to the predictions before returning\n  \n  \n\n\n## Examples of pre-processing\n\n::: {.fragment .fade-in-then-semi-out}\n\n### EDA type stuff\n\n1. Making locations/signals commensurate (scaling)\n1. Dealing with revisions \n1. Detecting and removing outliers\n1. Imputing or removing missing data\n\n:::\n\n::: {.fragment .fade-in-then-semi-out}\n\n### Feature engineering\n\n1. Creating lagged predictors\n1. Day of Week effects\n1. Rolling averages for smoothing \n1. Lagged differences\n1. Growth rates instead of raw signals\n1. The sky's the limit\n\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n## Get the data\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(epidatr)\nlibrary(epiprocess)\nlibrary(epipredict)\n\ncases <- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_incidence_num\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20200401, 20230401),\n  geo_values = \"*\") |>\n  select(geo_value, time_value, cases = value)\n\ndeaths <- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"deaths_incidence_num\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20200401, 20230401),\n  geo_values = \"*\") |>\n  select(geo_value, time_value, deaths = value)\n```\n:::\n\n\n\n\n## Create an `epi_df`\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- left_join(cases, deaths, by = c(\"time_value\", \"geo_value\")) |>\n  as_epi_df()\n\ndf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAn `epi_df` object, 60,036 x 4 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-11-21 13:40:43.941989\n\n# A tibble: 60,036 × 4\n   geo_value time_value cases deaths\n * <chr>     <date>     <dbl>  <dbl>\n 1 ak        2020-04-01    13      0\n 2 al        2020-04-01   112      4\n 3 ar        2020-04-01    61      2\n 4 as        2020-04-01     0      0\n 5 az        2020-04-01   124      7\n 6 ca        2020-04-01  1254     29\n 7 co        2020-04-01  4655    388\n 8 ct        2020-04-01   429     16\n 9 dc        2020-04-01    91      0\n10 de        2020-04-01    49     10\n# ℹ 60,026 more rows\n```\n\n\n:::\n:::\n\n\n\n## Pre-processing: data scaling\n\nScale cases and deaths by population and multiply by 100K\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- left_join(\n  x = df,\n  y = state_census |> select(pop, abbr),   # state_census is available in epipredict\n  by = c(\"geo_value\" = \"abbr\")) |>\n    mutate(cases = cases / pop * 1e5, \n           deaths = deaths / pop * 1e5) |> \n    select(-pop)\n```\n:::\n\n\n\n\n## Scaled COVID cases and deaths \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ndf |> \n  filter(geo_value %in% c(\"ca\", \"ma\", \"ny\", \"tx\")) |>\n  autoplot(cases, deaths) \n```\n\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/autoplot-deaths-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Pre-processing: smoothing\n\nSmooth the data by computing 7-day averages of cases and deaths for each state\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- df |>\n  group_by(geo_value) |>\n  epi_slide(cases_7dav = mean(cases, na.rm = T),\n            deaths_7dav = mean(deaths, na.rm = T),\n            .window_size = 7) |>\n  ungroup() |>\n  select(!c(cases, deaths)) |>\n  rename(cases = cases_7dav, \n         deaths = deaths_7dav)\n```\n:::\n\n\n\n## Scaled and smoothed COVID cases deaths \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ndf |> \n  filter(geo_value %in% c(\"ca\", \"ma\", \"ny\", \"tx\")) |>\n  autoplot(cases, deaths) \n```\n\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/autoplot-7dav-deaths-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Pre-processing: fix outliers and negative values\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ndetection_methods <- dplyr::bind_rows(\n  dplyr::tibble(method = \"rm\", args = list(list(detect_negatives = TRUE)), abbr = \"rm\")#,\n  #dplyr::tibble(method = \"stl\", args = list(list(detect_negatives = TRUE, seasonal_period = 7)),\n  #              abbr = \"stl_seasonal\")\n  )\n\ndeaths_outlr <- df |> \n  group_by(geo_value) |>\n  mutate(outlier_info = detect_outlr(x = time_value, \n                                     y = deaths, \n                                     methods = detection_methods, \n                                     combiner = \"median\"\n                                     )) |>\n  ungroup() |>\n  unnest(outlier_info)\n\ndeaths_outlr |>\n  filter(geo_value %in% c(\"ca\", \"ma\", \"ny\", \"tx\")) |> \n  ggplot(aes(x = time_value)) +\n  geom_line(aes(y = deaths), linetype = 2) +\n  geom_line(aes(y = combined_replacement, col = geo_value)) +\n  geom_hline(yintercept = 0, linetype = 3) +\n  facet_wrap(vars(geo_value), scales = \"free_y\") +\n  scale_color_viridis_d() +\n  labs(x = \"\", y = \"Covid-19 deaths per 100k people\")\n```\n\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/outliers-deaths-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n## Fit `arx_forecaster` on training set\n\n* Back to the [ARX(1)]{.primary} model for COVID deaths:\n$\\quad \\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\beta_0 x_{t}$\n\n* Only focus on California (for now)\n\n* Using `{epipredict}`\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|7-13\"}\n# split into train and test \nca <- df |> filter(geo_value == \"ca\")\nt0_date <- as.Date('2021-04-01')\ntrain <- ca |> filter(time_value <= t0_date)\ntest <- ca |> filter(time_value > t0_date)\n\n# fit ARX\nepi_arx <- arx_forecaster(epi_data = train |> as_epi_df(), \n                          outcome = \"deaths\", \n                          predictors = c(\"cases\", \"deaths\"),\n                          trainer = linear_reg() |> set_engine(\"lm\"),\n                          args_list = arx_args_list(lags = 0, ahead = 28,\n                                                    quantile_levels = c(0.1, 0.9)))\n```\n:::\n\n\n\n## `arx_forecaster` output\n\n* A [fitted model]{.primary} object which can be used any time in the future to create forecasts (`$epi_workflow`).\n\n* A [forecast]{.primary} (point prediction + interval) \nfor 28 days after the last available time value in the data (`$predictions`).\n\n\n## `arx_forecaster` output\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nepi_arx \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n══ A basic forecaster of type ARX Forecaster ═══════════════════════════════════\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThis forecaster was fit on 2024-11-21 13:41:47.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTraining data was an <epi_df> with:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Geography: state,\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Other keys: ,\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Time type: day,\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Using data up-to-date as of: 2024-11-21 13:40:43.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Predictions ─────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nA total of 1 prediction is available for\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• 1 unique geographic region,\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• At forecast date: 2021-04-01,\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• For target date: 2021-04-29.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n:::\n\n\n\n\n## Extract fitted object\n\n<div class=\"scrollable-output\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nepi_arx$epi_workflow\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n══ Epi Workflow [trained] ══════════════════════════════════════════════════════\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nPreprocessor: Recipe\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nModel: linear_reg()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nPostprocessor: Frosting\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Preprocessor ────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n6 Recipe steps.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n1. step_epi_lag()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n2. step_epi_lag()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n3. step_epi_ahead()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n4. step_naomit()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n5. step_naomit()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n6. step_training_window()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Model ───────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n (Intercept)   lag_0_cases  lag_0_deaths  \n    0.037694      0.009953      0.201329  \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Postprocessor ───────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n5 Frosting layers.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n1. layer_predict()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n2. layer_residual_quantiles()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n3. layer_add_forecast_date()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n4. layer_add_target_date()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n5. layer_threshold()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n:::\n\n\n\n</div>\n\n## `$epi_workflow`\n\nContains information on \n\n* [Pre-processing]{.primary} steps automatically performed by `arx_forecaster` (e.g. compute lags of the predictors)\n\n* [Fitted model]{.primary} \n\n* [Post-processing]{.primary} steps automatically performed by `arx_forecaster` (e.g. compute quantiles)\n\n## Extract predictions\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nepi_arx$predictions\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n  geo_value .pred        .pred_distn forecast_date target_date\n  <chr>     <dbl>             <dist> <date>        <date>     \n1 ca        0.109 quantiles(0.11)[2] 2021-04-01    2021-04-29 \n```\n\n\n:::\n:::\n\n\n\n::: {.callout-important icon=\"false\"}\n## Note \n\n`.pred_dstn` is actually a “distribution”, parameterized by its quantiles. \n:::\n\n\n## Extract predictions\n\nWe can extract the distribution into a “long” `epi_df`\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nepi_arx$predictions |>\n  pivot_quantiles_longer(.pred_distn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  geo_value .pred values quantile_levels forecast_date target_date\n  <chr>     <dbl>  <dbl>           <dbl> <date>        <date>     \n1 ca        0.109 0.0684             0.1 2021-04-01    2021-04-29 \n2 ca        0.109 0.150              0.9 2021-04-01    2021-04-29 \n```\n\n\n:::\n:::\n\n\n\nor into a \"wide\" `epi_df`\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nepi_arx$predictions |>\n  pivot_quantiles_wider(.pred_distn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n  geo_value .pred forecast_date target_date  `0.1` `0.9`\n  <chr>     <dbl> <date>        <date>       <dbl> <dbl>\n1 ca        0.109 2021-04-01    2021-04-29  0.0684 0.150\n```\n\n\n:::\n:::\n\n\n\n\n## Predict with fitted ARX (split-sample)\n\n* `arx_forecaster` fits a model to the training set, and outputs only one prediction (for time $t_0+h$).\n\n* To get [predictions]{.primary} for the [test]{.primary} set:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(epi_arx$epi_workflow, test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAn `epi_df` object, 707 x 6 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-11-21 13:40:43.941989\n\n# A tibble: 707 × 6\n   geo_value time_value  .pred        .pred_distn forecast_date target_date\n * <chr>     <date>      <dbl>             <dist> <date>        <date>     \n 1 ca        2021-04-02 0.106  quantiles(0.11)[2] 2021-04-01    2021-04-29 \n 2 ca        2021-04-03 0.101   quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 3 ca        2021-04-04 0.0984  quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 4 ca        2021-04-05 0.100   quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 5 ca        2021-04-06 0.0993  quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 6 ca        2021-04-07 0.0976  quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 7 ca        2021-04-08 0.0975  quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 8 ca        2021-04-09 0.0979  quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 9 ca        2021-04-10 0.104   quantiles(0.1)[2] 2021-04-01    2021-04-29 \n10 ca        2021-04-11 0.106  quantiles(0.11)[2] 2021-04-01    2021-04-29 \n# ℹ 697 more rows\n```\n\n\n:::\n:::\n\n\n\n## Predict with ARX (when re-fitting)\n\n* In practice, if we want to [re-train]{.primary} the forecasters as [new data]{.primary} arrive,\nwe fit and predict combining `arx_forecaster` with `epix_slide`\n\n* From now on, we will only used [versioned data]{.primary}, and make predictions once a week\n\n## Predict with ARX (re-fitting on trailing window)\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nh <- 28         #horizon\nw <- 120 + h    #trailing window length\n\n# Specify the forecast dates\nfc_time_values <- seq(from = t0_date, to = as.Date(\"2023-02-09\"), by = \"1 week\")\n\n# Slide the arx_forecaster over the epi_archive\npred_arx <- ca_archive |>\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"cases\", \"deaths\"), \n                     trainer = linear_reg() |> set_engine(\"lm\"),\n                     args_list = arx_args_list(lags = 0, ahead = h,\n                                               quantile_levels = c(0.1, 0.9))\n                     )$predictions |>\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)\n```\n:::\n\n\n\n## Predict with ARX \n\n::: {.callout-important icon=\"false\"}\n## Note (window length)\n\nWe set $w = 120 + h$ to match the window size of the ARX model we fitted manually.\nPreviously, when considering a window from $t-w$ to $t$, \nwe had access to all outcomes in that window, and to all predictors between \n$t-w-h$ and $t-h$. \n(That's because we lagged $x$ before applying the window.) \nSo we were \"cheating\" by saying that \nthe trailing window had length $w=120$, as its actual size was $120+h$! \n:::\n  \n::: {.callout-important icon=\"false\"}\n## Note (all past)\n\nThe method [fitting on all past data]{.primary} up to the forecasting date can be \nimplemented by setting:\n\n`.window_size = Inf` in `epi_slide`.\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n## Predict with ARX (re-fitting on trailing window)\n\n<div class=\"large-output\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npred_arx \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAn `epi_df` object, 680 x 9 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-11-21 13:40:43.941989\n\n# A tibble: 680 × 9\n# Groups:   geo_value [1]\n   geo_value time_value cases deaths .pred forecast_date target_date  `0.1`\n * <chr>     <date>     <dbl>  <dbl> <dbl> <date>        <date>       <dbl>\n 1 ca        2021-04-01  3.39  0.187 0.166 2021-04-01    2021-04-29  0.109 \n 2 ca        2021-04-02  3.46  0.170 0.166 2021-04-02    2021-04-30  0.110 \n 3 ca        2021-04-03  3.40  0.146 0.162 2021-04-03    2021-05-01  0.108 \n 4 ca        2021-04-04  3.25  0.141 0.161 2021-04-04    2021-05-02  0.103 \n 5 ca        2021-04-05  3.44  0.142 0.162 2021-04-05    2021-05-03  0.0992\n 6 ca        2021-04-06  3.49  0.134 0.161 2021-04-06    2021-05-04  0.0988\n 7 ca        2021-04-07  3.46  0.126 0.160 2021-04-07    2021-05-05  0.0962\n 8 ca        2021-04-08  3.49  0.125 0.159 2021-04-08    2021-05-06  0.0952\n 9 ca        2021-04-09  3.53  0.124 0.158 2021-04-09    2021-05-07  0.0948\n10 ca        2021-04-10  4.17  0.123 0.163 2021-04-10    2021-05-08  0.100 \n# ℹ 670 more rows\n# ℹ 1 more variable: `0.9` <dbl>\n```\n\n\n:::\n:::\n\n\n\n</div>\n\n## Predict with ARX (re-fitting on trailing window)\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-plot-cv-predictions-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n                                MAE     MASE\ntime series CV + trailing 0.1077706 722.6583\n```\n\n\n:::\n:::\n\n\n\n\n## Customizing `arx_forecaster`\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|3\"}\narx_forecaster(epi_data = train |> as_epi_df(), \n               outcome = \"deaths\", \n               predictors = c(\"cases\", \"deaths\"),\n               trainer = linear_reg() |> set_engine(\"lm\"),\n               args_list = arx_args_list(lags = 0, ahead = 28,\n                                         quantile_levels = c(0.1, 0.9)))\n```\n:::\n\n\n\n::: {.fragment .fade-in}\n* Modify `predictors` to add/drop predictors \n\n  * <span class=\"inner-list\">e.g. drop `deaths` for regression with a \n  lagged predictor, or drop `cases` to get AR model</span>\n\n  * <span class=\"inner-list\">default: `predictors = outcome`</span>\n\n:::  \n  \n\n## Customizing `arx_forecaster`\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"5-6\"}\narx_forecaster(epi_data = train |> as_epi_df(), \n               outcome = \"deaths\", \n               predictors = c(\"cases\", \"deaths\"),\n               trainer = linear_reg() |> set_engine(\"lm\"),\n               args_list = arx_args_list(lags = 0, ahead = 28,\n                                         quantile_levels = c(0.1, 0.9)))\n```\n:::\n\n\n\n* Modify `arx_args_list` to change lags, horizon, quantile levels, ...\n\n::: {.fragment .fade-in}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\narx_args_list(\n  lags = c(0L, 7L, 14L),\n  ahead = 7L,\n  n_training = Inf,\n  forecast_date = NULL,\n  target_date = NULL,\n  adjust_latency = c(\"none\", \"extend_ahead\", \"extend_lags\", \"locf\"),\n  warn_latency = TRUE,\n  quantile_levels = c(0.05, 0.95),\n  symmetrize = TRUE,\n  nonneg = TRUE,\n  quantile_by_key = character(0L),\n  check_enough_data_n = NULL,\n  check_enough_data_epi_keys = NULL,\n  ...\n)\n```\n:::\n\n\n:::\n\n## Customizing `arx_forecaster`\n\n### Change predictors: doctor visits instead of cases\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndv_archive <- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20200401, 20230401),\n  geo_values = \"*\",\n  issues = epirange(20200401, 20230401)) %>%\n  select(geo_value, time_value, version = issue, doctor_visits = value) %>%\n  arrange(geo_value, time_value) %>%\n  as_epi_archive(compactify = FALSE)\n```\n:::\n\n\n\n## Customizing `arx_forecaster`\n\n### Change predictors: doctor visits instead of cases\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"5\"}\npred_arx_hosp <- ca_archive_dv |>\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"doctor_visits\"), \n                     trainer = linear_reg() |> set_engine(\"lm\"),\n                     args_list = arx_args_list(lags = 0, ahead = 28,\n                                               quantile_levels = c(0.1, 0.9))\n                     )$predictions |>\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)\n```\n:::\n\n\n\n## Predictions (doctor visits instead of cases in predictor set)\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-with-dv-plot-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n        MAE     MASE\n 0.09661133 647.8296\n```\n\n\n:::\n:::\n\n\n\n\n## Customizing `arx_forecaster`\n\n### Add more lags\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"8\"}\npred_arx_more_lags <- ca_archive |>\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"cases\"), \n                     trainer = linear_reg() |> set_engine(\"lm\"),\n                     args_list = arx_args_list(\n                       lags = c(0, 7, 14),\n                       ahead = 28,\n                       quantile_levels = c(0.1, 0.9))\n                     )$predictions |>\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)\n```\n:::\n\n\n\n## Predictions (more lags)\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-with-more-lags-plot-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n       MAE     MASE\n 0.1741004 1167.435\n```\n\n\n:::\n:::\n\n\n\n\n\n## Customizing `arx_forecaster`\n\n### Multiple horizons\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"1-2,11,18|19-20\"}\nforecast_times <- seq(from = t0_date, to = as.Date(\"2023-02-23\"), by = \"1 month\")\npred_h_days_ahead <- function(epi_archive, ahead = 7) {\n  epi_archive |>\n    epix_slide(\n      ~ arx_forecaster(epi_data = .x,\n                       outcome = \"deaths\", \n                       predictors = c(\"deaths\", \"cases\"), \n                       trainer = linear_reg() |> set_engine(\"lm\"),\n                       args_list = arx_args_list(\n                         lags = 0,  \n                         ahead = ahead,\n                         quantile_levels = c(0.1, 0.9))\n      )$predictions |> \n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = forecast_times\n  )\n}\nh <- c(7, 14, 21, 28)\nforecasts <- bind_rows(map(h, ~ pred_h_days_ahead(ca_archive, ahead = .x)))\n```\n:::\n\n\n\n## Predictions (multiple horizons)\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-multiple-h-plot-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n# Advanced Customizations\n\n## Changing trainer\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"4\"}\narx_forecaster(epi_data = train |> as_epi_df(), \n               outcome = \"deaths\", \n               predictors = c(\"cases\", \"deaths\"),\n               trainer = linear_reg() |> set_engine(\"lm\"),\n               args_list = arx_args_list(lags = 0, ahead = 28,\n                                         quantile_levels = c(0.1, 0.9)))\n```\n:::\n\n\n\n* Modify `trainer` to use a model that is not `lm` (default)\n\n  * <span class=\"inner-list\"> e.g. `trainer = quantile_reg()`</span>\n  \n  * <span class=\"inner-list\">can use any `{parsnip}` models, \n  see [list](https://www.tidymodels.org/find/parsnip/)</span>\n  \n  \n\n## Changing trainer\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"6\"}\npred_arx_rf <- ca_archive |>\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"cases\"), \n                     trainer = parsnip::rand_forest(mode = \"regression\"), # defaults to ranger\n                     args_list = arx_args_list(\n                       lags = 0,  \n                       ahead = 28,\n                       quantile_levels = c(0.1, 0.9))\n                     )$predictions |>\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)\n```\n:::\n\n\n\n## Predictions (trained using random forest)\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-with-random-forests-plot-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n        MAE     MASE\n 0.09557336 640.8694\n```\n\n\n:::\n:::\n\n\n\n## Warning!\n\nRandom forests have really [poor coverage]{.primary} here. \nCan [change engine]{.primary} to get better coverage: \n\nspecify `engine = \"grf_quantiles\"` in the `rand_forest` call\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n## Geo-pooling\n\n* Assume we observe data over time from [multiple locations]{.primary}\n(e.g. states or counties).\n\n* We could\n\n  * Estimate coefficients [separately]{.primary} for each location (as we have done so far), or\n\n  * Fit one model using all locations together at each time point ([geo-pooling]{.primary}).\nEstimated coefficients will not be location specific.\n\n\n## Geo-pooling\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"1\"}\npred_arx_geo_pool <- usa_archive |>\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"cases\"), \n                     trainer = linear_reg() |> set_engine(\"lm\"),\n                     args_list = arx_args_list(\n                       lags = 0,\n                       ahead = 28,\n                       quantile_levels = c(0.1, 0.9))\n                     )$predictions |>\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)\n```\n:::\n\n\n\n## Predictions (geo-pooling): California\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-geo-pooling-plot-ca-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n       MAE     MASE\n 0.1815427 1217.339\n```\n\n\n:::\n:::\n\n\n\n\n## Predictions (geo-pooling)\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-geo-pooling-plot-1.svg){fig-align='left'}\n:::\n:::\n\n\n\n# Building a forecaster\n\n## Philosophy of forecasting\n\n::: {.fragment .fade-in-then-semi-out}\n\nWe should build up modular components\n\nBe able to add/remove layers of complexity sequentially\n\n:::\n\n::: {.fragment .fade-in-then-semi-out}\n\n  1. [Preprocessor]{.primary}: do things to the data before model training\n  \n  1. [Trainer]{.primary}: train a model on data, resulting in a fitted model object\n\n  1. [Predictor]{.primary}: make predictions, using a fitted model object\n\n  1. [Postprocessor]{.primary}: do things to the predictions before returning\n  \n:::\n\n## Fit a forecaster from scratch\n\nSo far, we performed some [manual pre-processing]{.primary}, and then relied on \na [canned forecaster]{.primary}\nto automatically perform [more pre-processing]{.primary}, [training]{.primary}, [predicting]{.primary}, and [post-processing]{.primary}.\n\n\n::: {.callout-important icon=\"false\"}\n## What if we want more direct control on each single step?\n\n:::\n\n## Fit a forecaster from scratch\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"1-6|8-9|11-16|18-20|21-29\"}\n# A preprocessing \"recipe\" that turns raw data into features / response\nr <- epi_recipe(ca) |>\n  step_epi_lag(cases, lag = c(0, 7, 14)) |>\n  step_epi_lag(deaths, lag = c(0, 7, 14)) |>\n  step_epi_ahead(deaths, ahead = 28) |>\n  step_epi_naomit()\n\n# Training engine\ne <- quantile_reg(quantile_levels = c(.1, .5, .9))\n\n# A post-processing routine describing what to do to the predictions\nf <- frosting() |>\n  layer_predict() |>\n  layer_threshold(.pred, lower = 0) |> # predictions / intervals should be non-negative\n  layer_add_target_date() |>\n  layer_add_forecast_date()\n\n# Bundle up the preprocessor, training engine, and postprocessor\n# We use quantile regression\newf <- epi_workflow(r, e, f)\n\n# Fit it to data (we could fit this to ANY data that has the same format)\ntrained_ewf <- ewf |> fit(ca)\n\n# examines the recipe to determine what we need to make the prediction\nlatest <- get_test_data(r, ca)\n\n# we could make predictions using the same model on ANY test data\npreds <- trained_ewf |> predict(new_data = latest)\n```\n:::\n\n\n\n\n# A Flu Forecaster\n\n## Flu data archive\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-01-01 / 2024-03-20\nℹ First/last version with update: 2023-10-04 / 2024-03-27\nℹ Versions end: 2024-03-27\nℹ A preview of the table (14420 rows x 4 columns):\nKey: <geo_value, time_value, version>\n          version geo_value time_value   hhs\n           <Date>    <char>     <Date> <num>\n    1: 2023-10-04        ak 2020-07-15    67\n    2: 2023-10-04        ak 2020-07-22   120\n    3: 2023-10-04        ak 2020-07-29    99\n    4: 2023-10-04        ak 2020-08-05   108\n    5: 2023-10-04        ak 2020-08-12    76\n   ---                                      \n14416: 2024-03-20        wy 2024-03-06    51\n14417: 2024-03-27        wy 2024-03-06    47\n14418: 2024-03-20        wy 2024-03-13    58\n14419: 2024-03-27        wy 2024-03-13    43\n14420: 2024-03-27        wy 2024-03-20    39\n```\n\n\n:::\n:::\n\n\n\n## Build forecaster\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# A preprocessing \"recipe\" that turns raw data into features / response\nr <- epi_recipe(flu) |>\n  #drop_non_seasons() |>\n  step_population_scaling(\n    hhs,\n    df = epidatasets::state_census,\n    df_pop_col = \"pop\",\n    create_new = FALSE,\n    rate_rescaling = 1e5,\n    by = c(\"geo_value\" = \"abbr\")) |>\n  step_epi_lag(hhs, lag = c(0, 7, 14)) |>\n  step_epi_ahead(hhs, ahead = 14) |>\n  step_epi_naomit()\n\n# Training engine\ne <- quantile_reg(quantile_levels = c(0.01, 0.025, 1:19 / 20, 0.975, 0.99)) # 23 ForecastHub quantiles\n\n# A post-processing routine describing what to do to the predictions\nf <- frosting() |>\n  layer_predict() |>\n  layer_threshold(.pred, lower = 0) |> # predictions / intervals should be non-negative\n  layer_population_scaling(\n    .pred, \n    df = epidatasets::state_census,\n    df_pop_col = \"pop\",\n    create_new = FALSE,\n    rate_rescaling = 1e5,\n    by = c(\"geo_value\" = \"abbr\")) |>\n  layer_add_target_date() |>\n  layer_add_forecast_date()\n\n# Bundle up the preprocessor, training engine, and postprocessor\n# We use quantile regression\newf <- epi_workflow(r, e, f)\n\n# Fit it to data (we could fit this to ANY data that has the same format)\ntrained_ewf <- ewf |> fit(flu)\n\n# examines the recipe to determine what we need to make the prediction\nlatest <- get_test_data(r, flu)\n\n# we could make predictions using the same model on ANY test data\npreds <- trained_ewf |> predict(new_data = latest)\n```\n:::\n\n\n\n## Predictions at one forecast date\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 21 × 27\n   geo_value time_value target_date forecast_date `0.01` `0.025` `0.05` `0.1`\n   <chr>     <date>     <date>      <date>         <dbl>   <dbl>  <dbl> <dbl>\n 1 al        2023-11-08 2023-11-22  2023-11-08      218.    218.   228.  242.\n 2 az        2023-11-08 2023-11-22  2023-11-08      706.    706.   741.  837.\n 3 ca        2023-11-08 2023-11-22  2023-11-08     1823.   1823.  1917. 2019.\n 4 ga        2023-11-08 2023-11-22  2023-11-08      527.    527.   563.  596.\n 5 hi        2023-11-08 2023-11-22  2023-11-08      138.    138.   152.  161.\n 6 il        2023-11-08 2023-11-22  2023-11-08      939.    939.  1015. 1109.\n 7 in        2023-11-08 2023-11-22  2023-11-08      298.    298.   316.  333.\n 8 ks        2023-11-08 2023-11-22  2023-11-08      169.    169.   175.  192.\n 9 ky        2023-11-08 2023-11-22  2023-11-08      281.    281.   304.  328.\n10 mi        2023-11-08 2023-11-22  2023-11-08      435.    435.   457.  481.\n# ℹ 11 more rows\n# ℹ 19 more variables: `0.15` <dbl>, `0.2` <dbl>, `0.25` <dbl>, `0.3` <dbl>,\n#   `0.35` <dbl>, `0.4` <dbl>, `0.45` <dbl>, `0.5` <dbl>, `0.55` <dbl>,\n#   `0.6` <dbl>, `0.65` <dbl>, `0.7` <dbl>, `0.75` <dbl>, `0.8` <dbl>,\n#   `0.85` <dbl>, `0.9` <dbl>, `0.95` <dbl>, `0.975` <dbl>, `0.99` <dbl>\n```\n\n\n:::\n:::\n\n\n\n## Slide forecaster\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nflu_forecast <- function(epi_archive, forecast_date, ahead = 14) {\n  flu <- epi_archive$DT |> \n    filter(version == forecast_date) |>\n    as_epi_df()\n\n  r <- epi_recipe(flu) |>\n    #drop_non_seasons() |>\n    step_population_scaling(\n      hhs,\n      df = epidatasets::state_census,\n      df_pop_col = \"pop\",\n      create_new = FALSE,\n      rate_rescaling = 1e5,\n      by = c(\"geo_value\" = \"abbr\")) |>\n    step_epi_lag(hhs, lag = c(0, 7, 14)) |>\n    step_epi_ahead(hhs, ahead = ahead) |>\n    step_epi_naomit()\n  \n  ewf <- epi_workflow(r, e, f)\n  trained_ewf <- ewf |> fit(flu)\n  latest <- get_test_data(r, flu)\n  preds <- trained_ewf |> predict(new_data = latest)\n  return(preds)\n}\n\nforecast_dates <- seq.Date(as.Date(\"2023-10-04\"), as.Date(\"2024-03-27\"), by = 7L)\nforecasts <- bind_rows(map(forecast_dates, \n                           ~ flu_forecast(weekly_archive, forecast_date = .x, ahead = 14)))\n```\n:::\n\n\n\n## Version-aware predictions\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/plot-flu-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n# Advanced Topics\n\n## Ensembling\n\n* Instead of choosing one model, [combine]{.primary} the predictions from multiple constituent models\n\n* Ensemble types\n\n  * [untrained]{.primary}: combines multiple constituent models without considering their past performance \n  \n  * [trained]{.primary}: weights different constituent models based on their accuracy\n  \n* Goals\n\n  * [compete-with-best]{.primary}: ensemble should have accuracy competitive with best individual constituent model\n  \n  * [robustness-over-all]{.primary}: ensemble should have greater robustness than any individual constituent model\n\n* Typically: untrained ensembles are robust but less accurate, \nand trained ensembles are accurate but less robust.\n\n## Calibration\n\n* We have seen that prediction intervals often have [nominal coverage << actual empirical coverage]{.primary},\ne.g. 80% predictive intervals that in practice cover the truth $\\approx$ 60% of the times\n\n* Calibration aims at adjusting the intervals so that \nnominal coverage $\\approx$ empirical coverage\n\n\n## Calibration\n\n### Quantile tracking\n\n* Let $\\hat q_{t}^{1-\\alpha}$ = predicted level $1-\\alpha$ quantile of the \ndistribution of $e_t$, the absolute forecast error at time $t$:\n\n$$e_t = |y_t - \\hat y_{t|t-1}|.$$\n\n* Given a learning rate $\\eta>0$, update the quantiles as\n\n$$\\hat q_{t+1}^{1-\\alpha} = \\begin{cases} \n\\hat q_{t}^{1-\\alpha} + \\eta(1-\\alpha) \\quad \\text{if } x_t\\notin I_{t|t-1}^{1-\\alpha} \\\\\n\\hat q_{t}^{1-\\alpha} - \\eta\\alpha \\quad \\quad \\quad \\,\\,\\, \\text{if } x_t\\in I_{t|t-1}^{1-\\alpha}\n\\end{cases}$$\n\nwhere $I_{t|t-1}^{1-\\alpha}$ is the \n$1-\\alpha$ prediction interval made by a forecaster at time $t$ for time $t+1$.\n\n* Quantile tracking in words: if the latest interval does not cover, increase the quantile by \n$\\eta(1-\\alpha)$ (make the next interval wider), otherwise decrease the quantile by $\\eta\\alpha$\n(make the next interval narrower).\n\n## Multi-horizon smoothing\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}