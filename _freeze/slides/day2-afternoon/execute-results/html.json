{
  "hash": "f397c14ba5305990d45caa75b08dc380",
  "result": {
    "markdown": "---\ntalk-title: \"Forecasting With `{epipredict}` and Other Advanced Topics\"\ntalk-short-title: \"Forecasting\"\ntalk-subtitle: \"InsightNet Forecasting Workshop 2024\"\ntalk-date: \"12 December -- Afternoon\"\nformat: revealjs\n---\n---\n---\n\n\\DeclareMathOperator*{\\minimize}{minimize}\n\n\n\n\n\n\n\n::: flex\n::: w-20\n\n:::\n::: w-80\n## {{< meta talk-title >}} {background-image=\"gfx/cover-art-1.svg\" background-position=\"bottom\"}\n\n### {{< meta talk-subtitle >}}\n\n<br>\n\n#### {{< meta author >}} \n[with huge thanks to Logan Brooks, and also Xueda Shen, Nat DeFries, Dmitry Shemetov, and David Weber]{.fstyle}\n\n{{< meta talk-date >}}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n## Outline\n\n1. `{epipredict}`\n\n1. Customizing `arx_forecaster()`\n\n1. Advanced Customizations\n\n1. Building a Forecaster\n\n1. A Flu Forecaster\n\n1. Advanced Topics\n\n# `{epipredict}` \n\n## `{epipredict}` \n\n<https://cmu-delphi.github.io/epipredict>\n\n#### Installation \n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/install_4d1dd80ae86a1588c064a1c9170f70e4'}\n\n```{.r .cell-code}\n# Stable version\n# pak::pkg_install(\"cmu-delphi/epipredict@main\")\n# Development version\npak::pkg_install(\"cmu-delphi/epipredict@dev\")\n```\n:::\n\n\n\n## What `{epipredict}` provides (i)\n\nBasic and easy to use [\"canned\" forecasters]{.primary}: \n\n  * Baseline flat forecaster\n  \n  * Autoregressive forecaster (ARX)\n  \n  * Autoregressive classifier\n  \n  * CDC FluSight flatline forecaster\n  \n## What `{epipredict}` provides (ii)\n\n* A framework for creating [custom forecasters]{.primary} out of [modular]{.primary} components. \n\n* There are four types of components:\n\n  1. [Preprocessor]{.primary}: do things to the data before model training\n  \n  1. [Trainer]{.primary}: train a model on data, resulting in a fitted model object\n\n  1. [Predictor]{.primary}: make predictions, using a fitted model object\n\n  1. [Postprocessor]{.primary}: do things to the predictions before returning\n  \n  \n\n\n## Examples of pre-processing\n\n::: {.fragment .fade-in-then-semi-out}\n\n### EDA type stuff\n\n1. Making locations/signals commensurate (scaling)\n1. Dealing with revisions \n1. Detecting and removing outliers\n1. Imputing or removing missing data\n\n:::\n\n::: {.fragment .fade-in-then-semi-out}\n\n### Feature engineering\n\n1. Creating lagged predictors\n1. Day of Week effects\n1. Rolling averages for smoothing \n1. Lagged differences\n1. Growth rates instead of raw signals\n1. The sky's the limit\n\n:::\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/load-data_c8a70a8bd0e93c222079395e5b3b41c5'}\n\n:::\n\n\n## Get the data\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/get-data_2ee8b154a762e13e21ec1e50ec025e1d'}\n\n```{.r .cell-code}\nlibrary(epidatr)\nlibrary(epiprocess)\nlibrary(epipredict)\n\ncases <- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_incidence_num\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20200401, 20230401),\n  geo_values = \"*\") |>\n  select(geo_value, time_value, cases = value)\n\ndeaths <- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"deaths_incidence_num\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20200401, 20230401),\n  geo_values = \"*\") |>\n  select(geo_value, time_value, deaths = value)\n```\n:::\n\n\n\n## Create an `epi_df`\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/epi-df_5e213ae066ab58eec5875ac95003a85f'}\n\n```{.r .cell-code}\ndf <- left_join(cases, deaths, by = c(\"time_value\", \"geo_value\")) |>\n  as_epi_df()\n\ndf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn `epi_df` object, 60,036 x 4 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-12-07 01:02:42.021018\n\n# A tibble: 60,036 × 4\n   geo_value time_value cases deaths\n * <chr>     <date>     <dbl>  <dbl>\n 1 ak        2020-04-01    13      0\n 2 al        2020-04-01   112      4\n 3 ar        2020-04-01    61      2\n 4 as        2020-04-01     0      0\n 5 az        2020-04-01   124      7\n 6 ca        2020-04-01  1254     29\n 7 co        2020-04-01  4655    388\n 8 ct        2020-04-01   429     16\n 9 dc        2020-04-01    91      0\n10 de        2020-04-01    49     10\n# ℹ 60,026 more rows\n```\n:::\n:::\n\n\n## Pre-processing: data scaling\n\nScale cases and deaths by population and multiply by 100K\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/scale-data_5544beaef4bd8641f7a2b78ee05c6629'}\n\n```{.r .cell-code}\ndf <- left_join(\n  x = df,\n  y = state_census |> select(pop, abbr),   # state_census is available in epipredict\n  by = c(\"geo_value\" = \"abbr\")) |>\n    mutate(cases = cases / pop * 1e5, \n           deaths = deaths / pop * 1e5) |> \n    select(-pop)\n```\n:::\n\n\n\n## Scaled COVID cases and deaths \n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/autoplot-deaths_790a8eb4e9b4b6b099f3d314fbccfe05'}\n\n```{.r .cell-code  code-fold=\"true\"}\ndf |> \n  filter(geo_value %in% c(\"ca\", \"ma\", \"ny\", \"tx\")) |>\n  autoplot(cases, deaths) \n```\n\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/autoplot-deaths-1.svg){fig-align='center'}\n:::\n:::\n\n\n## Pre-processing: smoothing\n\nSmooth the data by computing 7-day averages of cases and deaths for each state\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/7dav-data_9ee54b56ba60bd3923db9ac09f5d02bd'}\n\n```{.r .cell-code}\ndf <- df |>\n  group_by(geo_value) |>\n  epi_slide(cases_7dav = mean(cases, na.rm = T),\n            deaths_7dav = mean(deaths, na.rm = T),\n            .window_size = 7) |>\n  ungroup() |>\n  select(!c(cases, deaths)) |>\n  rename(cases = cases_7dav, \n         deaths = deaths_7dav)\n```\n:::\n\n\n## Scaled and smoothed COVID cases deaths \n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/autoplot-7dav-deaths_3dff9be8ecafdb9380f414c51a951bcc'}\n\n```{.r .cell-code  code-fold=\"true\"}\ndf |> \n  filter(geo_value %in% c(\"ca\", \"ma\", \"ny\", \"tx\")) |>\n  autoplot(cases, deaths) \n```\n\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/autoplot-7dav-deaths-1.svg){fig-align='center'}\n:::\n:::\n\n\n## Pre-processing: fix outliers and negative values\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/outliers-deaths_6700328ae13e4e525bc2e9d081800cb4'}\n\n```{.r .cell-code  code-fold=\"true\"}\ndetection_methods <- dplyr::bind_rows(\n  dplyr::tibble(method = \"rm\", args = list(list(detect_negatives = TRUE)), abbr = \"rm\")#,\n  #dplyr::tibble(method = \"stl\", args = list(list(detect_negatives = TRUE, seasonal_period = 7)),\n  #              abbr = \"stl_seasonal\")\n  )\n\ndeaths_outlr <- df |> \n  group_by(geo_value) |>\n  mutate(outlier_info = detect_outlr(x = time_value, \n                                     y = deaths, \n                                     methods = detection_methods, \n                                     combiner = \"median\"\n                                     )) |>\n  ungroup() |>\n  unnest(outlier_info)\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/outliers-fig_76e57edc9532c1d7b88b87af8daaaaae'}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/outliers-fig-1.svg){fig-align='center'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/outlier-cases_0111dd0867824ac84b814e70a8960f85'}\n\n:::\n\n\n## Fit `arx_forecaster` on training set\n\n* Back to the [ARX(1)]{.primary} model for COVID deaths:\n$\\quad \\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\beta_0 x_{t}$\n\n* Only focus on California (for now)\n\n* Using `{epipredict}`\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/epipredict-arx_a929a68cc68b97bb4d4c438527bc004e'}\n\n```{.r .cell-code  code-line-numbers=\"|7-13\"}\n# split into train and test \nca <- df |> filter(geo_value == \"ca\")\nt0_date <- as.Date('2021-04-01')\ntrain <- ca |> filter(time_value <= t0_date)\ntest <- ca |> filter(time_value > t0_date)\n\n# fit ARX\nepi_arx <- arx_forecaster(epi_data = train |> as_epi_df(), \n                          outcome = \"deaths\", \n                          predictors = c(\"cases\", \"deaths\"),\n                          trainer = linear_reg() |> set_engine(\"lm\"),\n                          args_list = arx_args_list(lags = 0, ahead = 28,\n                                                    quantile_levels = c(0.1, 0.9)))\n```\n:::\n\n\n## `arx_forecaster` output\n\n* A [fitted model]{.primary} object which can be used any time in the future to create forecasts (`$epi_workflow`).\n\n* A [forecast]{.primary} (point prediction + interval) \nfor 28 days after the last available time value in the data (`$predictions`).\n\n\n## `arx_forecaster` output\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/output-arx_b311982f813644d002e71ff04d223acb'}\n\n```{.r .cell-code}\nepi_arx \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n══ A basic forecaster of type ARX Forecaster ═══════════════════════════════════\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThis forecaster was fit on 2024-12-07 01:07:18.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nTraining data was an <epi_df> with:\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n• Geography: state,\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n• Other keys: ,\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n• Time type: day,\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n• Using data up-to-date as of: 2024-12-07 01:02:42.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Predictions ─────────────────────────────────────────────────────────────────\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nA total of 1 prediction is available for\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n• 1 unique geographic region,\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n• At forecast date: 2021-04-01,\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n• For target date: 2021-04-29.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n:::\n\n\n\n## Extract fitted object\n\n<div class=\"scrollable-output\">\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/epi-workflow-arx_e507248819bdd7c55d84f0df28fe9e86'}\n\n```{.r .cell-code}\nepi_arx$epi_workflow\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n══ Epi Workflow [trained] ══════════════════════════════════════════════════════\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nPreprocessor: Recipe\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nModel: linear_reg()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nPostprocessor: Frosting\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Preprocessor ────────────────────────────────────────────────────────────────\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n6 Recipe steps.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n1. step_epi_lag()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n2. step_epi_lag()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n3. step_epi_ahead()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n4. step_naomit()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n5. step_naomit()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n6. step_training_window()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Model ───────────────────────────────────────────────────────────────────────\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n (Intercept)   lag_0_cases  lag_0_deaths  \n    0.037694      0.009953      0.201329  \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Postprocessor ───────────────────────────────────────────────────────────────\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n5 Frosting layers.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n1. layer_predict()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n2. layer_residual_quantiles()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n3. layer_add_forecast_date()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n4. layer_add_target_date()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n5. layer_threshold()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n:::\n\n\n</div>\n\n## `$epi_workflow`\n\nContains information on \n\n* [Pre-processing]{.primary} steps automatically performed by `arx_forecaster` (e.g. compute lags of the predictors)\n\n* [Fitted model]{.primary} \n\n* [Post-processing]{.primary} steps automatically performed by `arx_forecaster` (e.g. compute quantiles)\n\n## Extract predictions\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/epi-pred-arx_43331ea99d1bd2a1364e1cb26a52cc55'}\n\n```{.r .cell-code}\nepi_arx$predictions\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 5\n  geo_value .pred        .pred_distn forecast_date target_date\n  <chr>     <dbl>             <dist> <date>        <date>     \n1 ca        0.109 quantiles(0.11)[2] 2021-04-01    2021-04-29 \n```\n:::\n:::\n\n\n::: {.callout-important icon=\"false\"}\n## Note \n\n* `.pred_distn` is actually a “distribution”, parameterized by its quantiles\n\n* `arx_forecaster` estimates the quantiles in a different way than `lm` \n:::\n\n\n## Extract predictions\n\nWe can extract the distribution into a “long” `epi_df`\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/epi-pred-quantile-longer_f628bb30fc3b57251f01761b529f328c'}\n\n```{.r .cell-code}\nepi_arx$predictions |>\n  pivot_quantiles_longer(.pred_distn)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  geo_value .pred values quantile_levels forecast_date target_date\n  <chr>     <dbl>  <dbl>           <dbl> <date>        <date>     \n1 ca        0.109 0.0684             0.1 2021-04-01    2021-04-29 \n2 ca        0.109 0.150              0.9 2021-04-01    2021-04-29 \n```\n:::\n:::\n\n\nor into a \"wide\" `epi_df`\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/epi-pred-quantile-wider_cda477ca0d0b1a4c6bd20fa7be18e2e2'}\n\n```{.r .cell-code}\nepi_arx$predictions |>\n  pivot_quantiles_wider(.pred_distn)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 6\n  geo_value .pred forecast_date target_date  `0.1` `0.9`\n  <chr>     <dbl> <date>        <date>       <dbl> <dbl>\n1 ca        0.109 2021-04-01    2021-04-29  0.0684 0.150\n```\n:::\n:::\n\n\n\n## Predict with fitted ARX (split-sample)\n\n* `arx_forecaster` fits a model to the training set, and outputs only one prediction (for time $t_0+h$).\n\n* To get [predictions]{.primary} for the [test]{.primary} set:\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/arx-test-predict_72ce8500b03398a5db44ed3744123776'}\n\n```{.r .cell-code}\npredict(epi_arx$epi_workflow, test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn `epi_df` object, 707 x 6 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-12-07 01:02:42.021018\n\n# A tibble: 707 × 6\n   geo_value time_value  .pred        .pred_distn forecast_date target_date\n * <chr>     <date>      <dbl>             <dist> <date>        <date>     \n 1 ca        2021-04-02 0.106  quantiles(0.11)[2] 2021-04-01    2021-04-29 \n 2 ca        2021-04-03 0.101   quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 3 ca        2021-04-04 0.0984  quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 4 ca        2021-04-05 0.100   quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 5 ca        2021-04-06 0.0993  quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 6 ca        2021-04-07 0.0976  quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 7 ca        2021-04-08 0.0975  quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 8 ca        2021-04-09 0.0979  quantiles(0.1)[2] 2021-04-01    2021-04-29 \n 9 ca        2021-04-10 0.104   quantiles(0.1)[2] 2021-04-01    2021-04-29 \n10 ca        2021-04-11 0.106  quantiles(0.11)[2] 2021-04-01    2021-04-29 \n# ℹ 697 more rows\n```\n:::\n:::\n\n\n## Predict with ARX (when re-fitting)\n\n* In practice, if we want to [re-train]{.primary} the forecasters as [new data]{.primary} arrive,\nwe fit and predict combining `arx_forecaster` with `epix_slide`\n\n* From now on, we will only used [versioned data]{.primary}, and make predictions once a week\n\n## Predict with ARX (re-fitting on trailing window)\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/source-versioned-data_483b79367ce5025382ce6c4c39c75466'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/ca-archive_b8f1ede5d5bb3da94301edec52af7e86'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/epipredict-cv-trailing_faa082cd6f348e2c834394770cdc6cad'}\n\n```{.r .cell-code}\nh <- 28         #horizon\nw <- 120 + h    #trailing window length\n\n# Specify the forecast dates\nfc_time_values <- seq(from = t0_date, to = as.Date(\"2023-02-09\"), by = \"1 week\")\n\n# Slide the arx_forecaster over the epi_archive\npred_arx <- ca_archive |>\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"cases\", \"deaths\"), \n                     trainer = linear_reg() |> set_engine(\"lm\"),\n                     args_list = arx_args_list(lags = 0, ahead = h,\n                                               quantile_levels = c(0.1, 0.9))\n                     )$predictions |>\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)\n```\n:::\n\n\n## Predict with ARX \n\n::: {.callout-important icon=\"false\"}\n## Note (window length)\n\nWe set $w = 120 + h$ to match the window size of the ARX model we fitted manually.\nPreviously, when considering a window from $t-w$ to $t$, \nwe had access to all outcomes in that window, and to all predictors between \n$t-w-h$ and $t-h$. \n(That's because we lagged $x$ before applying the window.) \nSo we were \"cheating\" by saying that \nthe trailing window had length $w=120$, as its actual size was $120+h$! \n:::\n  \n::: {.callout-important icon=\"false\"}\n## Note (all past)\n\nThe method [fitting on all past data]{.primary} up to the forecasting date can be \nimplemented by setting:\n\n`.window_size = Inf` in `epi_slide`.\n:::\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/epipredict-cv_1cd4dc025b9c848bd01ed0f3e42abee5'}\n\n:::\n\n\n\n## Predict with ARX (re-fitting on trailing window)\n\n<div class=\"large-output\">\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/epipredict-cv-trailing-head_5553304af7577800a52da081d0f99900'}\n\n```{.r .cell-code}\npred_arx \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 98 × 7\n   version    geo_value  .pred forecast_date target_date  `0.1` `0.9`\n * <date>     <chr>      <dbl> <date>        <date>       <dbl> <dbl>\n 1 2021-04-01 ca        0.396  2021-03-31    2021-04-28  0.192  0.599\n 2 2021-04-08 ca        0.395  2021-04-07    2021-05-05  0.197  0.594\n 3 2021-04-15 ca        0.403  2021-04-14    2021-05-12  0.211  0.595\n 4 2021-04-22 ca        0.312  2021-04-21    2021-05-19  0.142  0.482\n 5 2021-04-29 ca        0.261  2021-04-28    2021-05-26  0.0879 0.433\n 6 2021-05-06 ca        0.209  2021-05-05    2021-06-02  0.0238 0.394\n 7 2021-05-13 ca        0.158  2021-05-12    2021-06-09  0      0.345\n 8 2021-05-20 ca        0.118  2021-05-19    2021-06-16  0      0.296\n 9 2021-05-27 ca        0.0775 2021-05-26    2021-06-23  0      0.239\n10 2021-06-03 ca        0.0552 2021-06-02    2021-06-30  0      0.137\n# ℹ 88 more rows\n```\n:::\n:::\n\n\n</div>\n\n## Predict with ARX (re-fitting on trailing window)\n\n\n::: {.cell layout-align=\"left\" hash='day2-afternoon_cache/revealjs/arx-plot-cv-predictions_c6f0e282e1b44daa50abd4194b1756c9'}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-plot-cv-predictions-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/function errors_59648a4d2eba45be4c8fcbf31d04e11a'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/error-arx_afa530cfefcd4a91414d5d15d0ab4e38'}\n::: {.cell-output .cell-output-stdout}\n```\n       MAE     MASE  Coverage\n 0.1077706 722.6583 0.3367347\n```\n:::\n:::\n\n\n\n## Customizing `arx_forecaster`\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/print-model-1_abeb57edd69194abedf82273b69f00c9'}\n\n```{.r .cell-code  code-line-numbers=\"|3\"}\narx_forecaster(epi_data = train |> as_epi_df(), \n               outcome = \"deaths\", \n               predictors = c(\"cases\", \"deaths\"),\n               trainer = linear_reg() |> set_engine(\"lm\"),\n               args_list = arx_args_list(lags = 0, ahead = 28,\n                                         quantile_levels = c(0.1, 0.9)))\n```\n:::\n\n\n::: {.fragment .fade-in}\n* Modify `predictors` to add/drop predictors \n\n  * <span class=\"inner-list\">e.g. drop `deaths` for regression with a \n  lagged predictor, or drop `cases` to get AR model</span>\n\n  * <span class=\"inner-list\">default: `predictors = outcome`</span>\n\n:::  \n  \n\n## Customizing `arx_forecaster`\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/print-model-3_ff7ab81b8e82e06ec8a52e817af5b02f'}\n\n```{.r .cell-code  code-line-numbers=\"5-6\"}\narx_forecaster(epi_data = train |> as_epi_df(), \n               outcome = \"deaths\", \n               predictors = c(\"cases\", \"deaths\"),\n               trainer = linear_reg() |> set_engine(\"lm\"),\n               args_list = arx_args_list(lags = 0, ahead = 28,\n                                         quantile_levels = c(0.1, 0.9)))\n```\n:::\n\n\n* Modify `arx_args_list` to change lags, horizon, quantile levels, ...\n\n::: {.fragment .fade-in}\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/arx_args_list_3b91e8e47c679d5b3956ee03bf5eaadc'}\n\n```{.r .cell-code}\narx_args_list(\n  lags = c(0L, 7L, 14L),\n  ahead = 7L,\n  n_training = Inf,\n  forecast_date = NULL,\n  target_date = NULL,\n  adjust_latency = c(\"none\", \"extend_ahead\", \"extend_lags\", \"locf\"),\n  warn_latency = TRUE,\n  quantile_levels = c(0.05, 0.95),\n  symmetrize = TRUE,\n  nonneg = TRUE,\n  quantile_by_key = character(0L),\n  check_enough_data_n = NULL,\n  check_enough_data_epi_keys = NULL,\n  ...\n)\n```\n:::\n\n:::\n\n## Customizing `arx_forecaster`\n\n### Change predictors: doctor visits instead of cases\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/get-doctor-visits-data_9ac6bfa96b0aafa4da07d05de2c3b5f9'}\n\n```{.r .cell-code}\ndv_archive <- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20200401, 20230401),\n  geo_values = \"*\",\n  issues = epirange(20200401, 20230401)) |>\n  select(geo_value, time_value, version = issue, doctor_visits = value) |>\n  arrange(geo_value, time_value) |>\n  as_epi_archive(compactify = FALSE)\n```\n:::\n\n\n## Customizing `arx_forecaster`\n\n### Change predictors: doctor visits instead of cases\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/get-archives_2fdd9d1457792c92b4786a4f51c3c438'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/arx-with-dv_95990f7a7f2f735f97972a23ff4d7adb'}\n\n```{.r .cell-code  code-line-numbers=\"5\"}\npred_arx_hosp <- ca_archive_dv |>\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"doctor_visits\"), \n                     trainer = linear_reg() |> set_engine(\"lm\"),\n                     args_list = arx_args_list(lags = 0, ahead = 28,\n                                               quantile_levels = c(0.1, 0.9))\n                     )$predictions |>\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)\n```\n:::\n\n\n## Predictions (doctor visits instead of cases in predictor set)\n\n\n::: {.cell layout-align=\"left\" hash='day2-afternoon_cache/revealjs/arx-with-dv-plot_f8c570d1af3e1e38390863a63b15a972'}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-with-dv-plot-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/error-arx-with-dv_efeef137e7b6f00a20f51e2565d3fe7b'}\n::: {.cell-output .cell-output-stdout}\n```\n        MAE     MASE  Coverage\n 0.09661133 647.8296 0.4081633\n```\n:::\n:::\n\n\n\n## Customizing `arx_forecaster`\n\n### Add more lags\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/arx-with-more-lags_d1cb647041397eb7afdd8c46eee40c6b'}\n\n```{.r .cell-code  code-line-numbers=\"8\"}\npred_arx_more_lags <- ca_archive_dv |>\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"doctor_visits\"), \n                     trainer = linear_reg() |> set_engine(\"lm\"),\n                     args_list = arx_args_list(\n                       lags = c(0, 7, 14),\n                       ahead = 28,\n                       quantile_levels = c(0.1, 0.9))\n                     )$predictions |>\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)\n```\n:::\n\n\n## Predictions (more lags)\n\n\n::: {.cell layout-align=\"left\" hash='day2-afternoon_cache/revealjs/arx-with-more-lags-plot_eecc930655613fc3edf180a7ad8bf0fb'}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-with-more-lags-plot-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/error-arx-more-lags_e6c3b8ba0041f1730b5f8f53d55cda8b'}\n::: {.cell-output .cell-output-stdout}\n```\n       MAE     MASE  Coverage\n 0.1022146 685.4021 0.2755102\n```\n:::\n:::\n\n\n\n\n## Customizing `arx_forecaster`\n\n### Multiple horizons\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/arx-multiple-h_1ebf59bebbe80ecb968294e677f53a27'}\n\n```{.r .cell-code  code-line-numbers=\"1-2,11,18|19-20\"}\nforecast_times <- seq(from = t0_date, to = as.Date(\"2023-02-23\"), by = \"1 month\")\npred_h_days_ahead <- function(epi_archive, ahead = 7) {\n  epi_archive |>\n    epix_slide(\n      ~ arx_forecaster(epi_data = .x,\n                       outcome = \"deaths\", \n                       predictors = c(\"deaths\", \"doctor_visits\"), \n                       trainer = linear_reg() |> set_engine(\"lm\"),\n                       args_list = arx_args_list(\n                         lags = 0,  \n                         ahead = ahead,\n                         quantile_levels = c(0.1, 0.9))\n      )$predictions |> \n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = forecast_times\n  )\n}\nh <- c(7, 14, 21, 28)\nforecasts <- bind_rows(map(h, ~ pred_h_days_ahead(ca_archive_dv, ahead = .x)))\n```\n:::\n\n\n## Predictions (multiple horizons)\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/arx-multiple-h-plot_65f6b77bd29061c37b1ef8b498baaa07'}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-multiple-h-plot-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n# Advanced Customizations\n\n## Changing trainer\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/print-model-2_d0e361880216e3c778de51f90a1e86a4'}\n\n```{.r .cell-code  code-line-numbers=\"4\"}\narx_forecaster(epi_data = train |> as_epi_df(), \n               outcome = \"deaths\", \n               predictors = c(\"cases\", \"deaths\"),\n               trainer = linear_reg() |> set_engine(\"lm\"),\n               args_list = arx_args_list(lags = 0, ahead = 28,\n                                         quantile_levels = c(0.1, 0.9)))\n```\n:::\n\n\n* Modify `trainer` to use a model that is not `lm` (default)\n\n  * <span class=\"inner-list\"> e.g. `trainer = rand_forest()`</span>\n  \n  * <span class=\"inner-list\">can use any `{parsnip}` models, \n  see [list](https://www.tidymodels.org/find/parsnip/)</span>\n  \n  \n\n## Changing trainer\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/arx-with-random-forests_66979b79fb75952d427c447bc193c37e'}\n\n```{.r .cell-code  code-line-numbers=\"6\"}\npred_arx_rf <- ca_archive_dv |>\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"doctor_visits\"), \n                     trainer = parsnip::rand_forest(mode = \"regression\"), # defaults to ranger\n                     args_list = arx_args_list(\n                       lags = 0,\n                       ahead = 28,\n                       quantile_levels = c(0.1, 0.9))\n                     )$predictions |>\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)\n```\n:::\n\n\n## Predictions (trained using random forest)\n\n\n::: {.cell layout-align=\"left\" hash='day2-afternoon_cache/revealjs/arx-with-random-forests-plot_1b0b256440c62d43e3b2ddb728ad05b2'}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-with-random-forests-plot-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/error-arx-random-forests_cb52b493821fbf1602d91786d5a3f5b8'}\n::: {.cell-output .cell-output-stdout}\n```\n        MAE     MASE   Coverage\n 0.09422738 631.8439 0.08163265\n```\n:::\n:::\n\n\n## Warning!\n\nRandom forests has really [poor coverage]{.primary} here. \nCan [change engine]{.primary} to get better coverage: \n\nspecify `engine = \"grf_quantiles\"` in the `rand_forest` call\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/arx-with-grf_7eaffedf34a85e72b33257e84734aa0b'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/error-arx-grf_a2d5a78feabcac30cf2f9ebcf4730a5b'}\n\n:::\n\n\n\n## Geo-pooling\n\n* Assume we observe data over time from [multiple locations]{.primary}\n(e.g. states or counties).\n\n* We could\n\n  * Estimate coefficients [separately]{.primary} for each location (as we have done so far), or\n\n  * Fit one model using all locations together at each time point ([geo-pooling]{.primary}).\nEstimated coefficients will not be location specific.\n\n* We will now pool data from [all US states]{.primary} to make predictions.\n\n## Geo-pooling\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/arx-geo-pooling_1a33d4838323f4fc4eafaaff356de0e8'}\n\n```{.r .cell-code  code-line-numbers=\"1\"}\npred_arx_geo_pool <- usa_archive_dv |>\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"doctor_visits\"), \n                     trainer = linear_reg() |> set_engine(\"lm\"),\n                     args_list = arx_args_list(\n                       lags = 0, #c(0, 7, 14),\n                       ahead = 28,\n                       quantile_levels = c(0.1, 0.9))\n                     )$predictions |>\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)\n```\n:::\n\n\n## Predictions (geo-pooling): California\n\n[Error is worse]{.primary} than without geo-pooling, \nbut much [better coverage]{.primary} (close to nominal 80%)\n\n\n::: {.cell layout-align=\"left\" hash='day2-afternoon_cache/revealjs/arx-geo-pooling-plot-ca_7860d9fa1a109b24239f6e90d6a08207'}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-geo-pooling-plot-ca-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/error-arx-geo-pooling_57e3355c8abc451c92988c0671fa779d'}\n::: {.cell-output .cell-output-stdout}\n```\n         MAE     MASE  Coverage\nCA 0.2119066 1420.945 0.6632653\n```\n:::\n:::\n\n\n\n## Predictions (geo-pooling)\n\n\n::: {.cell layout-align=\"left\" hash='day2-afternoon_cache/revealjs/arx-geo-pooling-plot_6530d5088f126fe403a8877e25c696d0'}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/arx-geo-pooling-plot-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/error-geo-pooling-all-states_e6364704b31ad4b0e6165f0f3a66abcb'}\n::: {.cell-output .cell-output-stdout}\n```\n         MAE     MASE  Coverage\nMA 0.1244185 256.5266 0.7894737\nNY 0.1352486 276.1753 0.8631579\nTX 0.1662284 330.8706 0.8315789\n```\n:::\n:::\n\n\n\n## Quantile regression\n\n* Quantile regression is a different estimation method, which directly targets conditional \nquantiles of the outcome over time\n\n* It [needs more data]{.primary} to estimate quantiles appropriately, so\n\n  * unsuitable for settings with small training set (e.g. trailing window on one state)\n  \n  * can benefit by combination with geo-pooling (much more data to train on)\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/qr-geo-pooling_3f9d7c2af8b6dc621be1b1888d3e3d9f'}\n\n```{.r .cell-code  code-line-numbers=\"|8\"}\nlibrary(quantreg)\n\npred_qr_geo_pool <- usa_archive_dv |>\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"doctor_visits\"), \n                     trainer = quantile_reg(),\n                     args_list = arx_args_list(\n                       lags = 0, #c(0, 7, 14),\n                       ahead = 28,\n                       quantile_levels = c(0.1, 0.9))\n                     )$predictions |>\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)\n```\n:::\n\n\n## Predictions (geo-pooling + quantile regression): California\n\n\n::: {.cell layout-align=\"left\" hash='day2-afternoon_cache/revealjs/qr-geo-pooling-plot-ca_783898f459f6db9e731ad24966d1a5d9'}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/qr-geo-pooling-plot-ca-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/error-qr-geo-pooling_06be7b7401f63eb7fb5a60ace0313181'}\n::: {.cell-output .cell-output-stdout}\n```\n         MAE     MASE  Coverage\nCA 0.2266103 1519.541 0.5408163\n```\n:::\n:::\n\n\n\n## Predictions (geo-pooling + quantile regression)\n\n\n::: {.cell layout-align=\"left\" hash='day2-afternoon_cache/revealjs/qr-geo-pooling-plot_eff029b881b12a384dee51c560ff6880'}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/qr-geo-pooling-plot-1.svg){fig-align='left'}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/error-qr-geo-pooling-all-states_d86d5f93ab98cf8dc77c6fd688c5a9d5'}\n::: {.cell-output .cell-output-stdout}\n```\n         MAE     MASE  Coverage\nMA 0.1260110 259.8102 0.7052632\nNY 0.1397487 285.3646 0.7684211\nTX 0.1639215 326.2788 0.7578947\n```\n:::\n:::\n\n\n\n# Building a forecaster\n\n## Philosophy of forecasting\n\n::: {.fragment .fade-in-then-semi-out}\n\nWe should build up modular components\n\nBe able to add/remove layers of complexity sequentially\n\n:::\n\n::: {.fragment .fade-in-then-semi-out}\n\n  1. [Preprocessor]{.primary}: do things to the data before model training\n  \n  1. [Trainer]{.primary}: train a model on data, resulting in a fitted model object\n\n  1. [Predictor]{.primary}: make predictions, using a fitted model object\n\n  1. [Postprocessor]{.primary}: do things to the predictions before returning\n  \n:::\n\n## Fit a forecaster from scratch\n\nSo far, we performed some [manual pre-processing]{.primary}, and then relied on \na [canned forecaster]{.primary}\nto automatically perform [more pre-processing]{.primary}, [training]{.primary}, [predicting]{.primary}, and [post-processing]{.primary}.\n\n\n::: {.callout-important icon=\"false\"}\n## What if we want more direct control on each single step?\n\n:::\n\n## Fit a forecaster from scratch\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/forecaster-from-scratch_39bcb8591faa8aec266bdc61dd260e43'}\n\n```{.r .cell-code  code-line-numbers=\"1-6|8-9|11-16|18-20|21-29\"}\n# A preprocessing \"recipe\" that turns raw data into features / response\nr <- epi_recipe(ca) |>\n  step_epi_lag(cases, lag = c(0, 7, 14)) |>\n  step_epi_lag(deaths, lag = c(0, 7, 14)) |>\n  step_epi_ahead(deaths, ahead = 28) |>\n  step_epi_naomit()\n\n# Training engine\ne <- quantile_reg(quantile_levels = c(.1, .5, .9))\n\n# A post-processing routine describing what to do to the predictions\nf <- frosting() |>\n  layer_predict() |>\n  layer_threshold(.pred, lower = 0) |> # predictions / intervals should be non-negative\n  layer_add_target_date() |>\n  layer_add_forecast_date()\n\n# Bundle up the preprocessor, training engine, and postprocessor\n# We use quantile regression\newf <- epi_workflow(r, e, f)\n\n# Fit it to data (we could fit this to ANY data that has the same format)\ntrained_ewf <- ewf |> fit(ca)\n\n# examines the recipe to determine what we need to make the prediction\nlatest <- get_test_data(r, ca)\n\n# we could make predictions using the same model on ANY test data\npreds <- trained_ewf |> predict(new_data = latest)\n```\n:::\n\n\n\n# A Flu Forecaster\n\n## Flu data archive\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/load-flu-data_95dae3fc415501e71af4c4b00c9ee9bd'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/show-flu-data_25d504f5f45655d0a12a04c01943fa1c'}\n::: {.cell-output .cell-output-stdout}\n```\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-01-01 / 2024-03-20\nℹ First/last version with update: 2023-10-04 / 2024-03-27\nℹ Versions end: 2024-03-27\nℹ A preview of the table (14420 rows x 4 columns):\nKey: <geo_value, time_value, version>\n          version geo_value time_value   hhs\n           <Date>    <char>     <Date> <num>\n    1: 2023-10-04        ak 2020-07-15    67\n    2: 2023-10-04        ak 2020-07-22   120\n    3: 2023-10-04        ak 2020-07-29    99\n    4: 2023-10-04        ak 2020-08-05   108\n    5: 2023-10-04        ak 2020-08-12    76\n   ---                                      \n14416: 2024-03-20        wy 2024-03-06    51\n14417: 2024-03-27        wy 2024-03-06    47\n14418: 2024-03-20        wy 2024-03-13    58\n14419: 2024-03-27        wy 2024-03-13    43\n14420: 2024-03-27        wy 2024-03-20    39\n```\n:::\n:::\n\n\n## Build forecaster\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/forecaster-flu_4065541317ea98de976f2b90d284b7b1'}\n\n```{.r .cell-code}\n# A preprocessing \"recipe\" that turns raw data into features / response\nr <- epi_recipe(flu) |>\n  #drop_non_seasons() |>\n  step_population_scaling(\n    hhs,\n    df = epidatasets::state_census,\n    df_pop_col = \"pop\",\n    create_new = FALSE,\n    rate_rescaling = 1e5,\n    by = c(\"geo_value\" = \"abbr\")) |>\n  step_epi_lag(hhs, lag = c(0, 7, 14)) |>\n  step_epi_ahead(hhs, ahead = 14) |>\n  step_epi_naomit()\n\n# Training engine\ne <- quantile_reg(quantile_levels = c(0.01, 0.025, 1:19 / 20, 0.975, 0.99)) # 23 ForecastHub quantiles\n\n# A post-processing routine describing what to do to the predictions\nf <- frosting() |>\n  layer_predict() |>\n  layer_threshold(.pred, lower = 0) |> # predictions / intervals should be non-negative\n  layer_population_scaling(\n    .pred, \n    df = epidatasets::state_census,\n    df_pop_col = \"pop\",\n    create_new = FALSE,\n    rate_rescaling = 1e5,\n    by = c(\"geo_value\" = \"abbr\")) |>\n  layer_add_target_date() |>\n  layer_add_forecast_date()\n\n# Bundle up the preprocessor, training engine, and postprocessor\n# We use quantile regression\newf <- epi_workflow(r, e, f)\n\n# Fit it to data (we could fit this to ANY data that has the same format)\ntrained_ewf <- ewf |> fit(flu)\n\n# examines the recipe to determine what we need to make the prediction\nlatest <- get_test_data(r, flu)\n\n# we could make predictions using the same model on ANY test data\npreds <- trained_ewf |> predict(new_data = latest)\n```\n:::\n\n\n## Predictions at one forecast date\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/pred-one-forecast-date_696193871c574c3fcc2c30d08384ae5b'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 21 × 27\n   geo_value time_value target_date forecast_date `0.01` `0.025` `0.05` `0.1`\n   <chr>     <date>     <date>      <date>         <dbl>   <dbl>  <dbl> <dbl>\n 1 al        2023-11-08 2023-11-22  2023-11-08      218.    218.   228.  242.\n 2 az        2023-11-08 2023-11-22  2023-11-08      706.    706.   741.  837.\n 3 ca        2023-11-08 2023-11-22  2023-11-08     1823.   1823.  1917. 2019.\n 4 ga        2023-11-08 2023-11-22  2023-11-08      527.    527.   563.  596.\n 5 hi        2023-11-08 2023-11-22  2023-11-08      138.    138.   152.  161.\n 6 il        2023-11-08 2023-11-22  2023-11-08      939.    939.  1015. 1109.\n 7 in        2023-11-08 2023-11-22  2023-11-08      298.    298.   316.  333.\n 8 ks        2023-11-08 2023-11-22  2023-11-08      169.    169.   175.  192.\n 9 ky        2023-11-08 2023-11-22  2023-11-08      281.    281.   304.  328.\n10 mi        2023-11-08 2023-11-22  2023-11-08      435.    435.   457.  481.\n# ℹ 11 more rows\n# ℹ 19 more variables: `0.15` <dbl>, `0.2` <dbl>, `0.25` <dbl>, `0.3` <dbl>,\n#   `0.35` <dbl>, `0.4` <dbl>, `0.45` <dbl>, `0.5` <dbl>, `0.55` <dbl>,\n#   `0.6` <dbl>, `0.65` <dbl>, `0.7` <dbl>, `0.75` <dbl>, `0.8` <dbl>,\n#   `0.85` <dbl>, `0.9` <dbl>, `0.95` <dbl>, `0.975` <dbl>, `0.99` <dbl>\n```\n:::\n:::\n\n\n## Slide forecaster\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/slide-flu-forecaster_2c5c27911935326eec6c07eb9f5c7e92'}\n\n```{.r .cell-code}\nflu_forecast <- function(epi_archive, forecast_date, ahead = 14) {\n  flu <- epi_archive$DT |> \n    filter(version == forecast_date) |>\n    as_epi_df()\n\n  r <- epi_recipe(flu) |>\n    #drop_non_seasons() |>\n    step_population_scaling(\n      hhs,\n      df = epidatasets::state_census,\n      df_pop_col = \"pop\",\n      create_new = FALSE,\n      rate_rescaling = 1e5,\n      by = c(\"geo_value\" = \"abbr\")) |>\n    step_epi_lag(hhs, lag = c(0, 7, 14)) |>\n    step_epi_ahead(hhs, ahead = ahead) |>\n    step_epi_naomit()\n  \n  ewf <- epi_workflow(r, e, f)\n  trained_ewf <- ewf |> fit(flu)\n  latest <- get_test_data(r, flu)\n  preds <- trained_ewf |> predict(new_data = latest)\n  return(preds)\n}\n\nforecast_dates <- seq.Date(as.Date(\"2023-10-04\"), as.Date(\"2024-03-27\"), by = 7L)\nforecasts <- bind_rows(map(forecast_dates, \n                           ~ flu_forecast(weekly_archive, forecast_date = .x, ahead = 14)))\n```\n:::\n\n\n## Version-aware predictions\n\n\n::: {.cell layout-align=\"center\" hash='day2-afternoon_cache/revealjs/plot-flu-predictions_b35294c4d4b10b9cca0b27ebd46048de'}\n::: {.cell-output-display}\n![](day2-afternoon_files/figure-revealjs/plot-flu-predictions-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n# Advanced Topics\n\n## Ensembling\n\n* Instead of choosing one model, [combine]{.primary} the predictions from multiple constituent models\n\n* Ensemble types\n\n  * [untrained]{.primary}: combines multiple constituent models without considering their past performance \n  \n  * [trained]{.primary}: weights different constituent models based on their accuracy\n  \n* Goals\n\n  * [compete-with-best]{.primary}: ensemble should have accuracy competitive with best individual constituent model\n  \n  * [robustness-over-all]{.primary}: ensemble should have greater robustness than any individual constituent model\n\n* Typically: untrained ensembles are robust but less accurate, \nand trained ensembles are accurate but less robust.\n\n## Calibration\n\n* We have seen that prediction intervals often have [nominal coverage << actual empirical coverage]{.primary},\ne.g. 80% predictive intervals that in practice cover the truth $\\approx$ 60% of the times\n\n* Calibration aims at adjusting the intervals so that \nnominal coverage $\\approx$ empirical coverage\n\n\n## Calibration\n\n### Quantile tracking\n\n* Let $\\hat q_{t}^{1-\\alpha}$ = predicted level $1-\\alpha$ quantile of the \ndistribution of $e_t$, the absolute forecast error at time $t$:\n\n\n$$e_t = |y_t - \\hat y_{t|t-1}|.$$\n\n\n* Given a learning rate $\\eta>0$, update the quantiles as\n\n\n$$\\hat q_{t+1}^{1-\\alpha} = \\begin{cases} \n\\hat q_{t}^{1-\\alpha} + \\eta(1-\\alpha) \\quad \\text{if } x_t\\notin I_{t|t-1}^{1-\\alpha} \\\\\n\\hat q_{t}^{1-\\alpha} - \\eta\\alpha \\quad \\quad \\quad \\,\\,\\, \\text{if } x_t\\in I_{t|t-1}^{1-\\alpha}\n\\end{cases}$$\n\nwhere $I_{t|t-1}^{1-\\alpha}$ is the \n$1-\\alpha$ prediction interval made by a forecaster at time $t$ for time $t+1$.\n\n* Quantile tracking in words: if the latest interval does not cover, increase the quantile by \n$\\eta(1-\\alpha)$ (make the next interval wider), otherwise decrease the quantile by $\\eta\\alpha$\n(make the next interval narrower).\n\n## Multi-horizon smoothing\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}