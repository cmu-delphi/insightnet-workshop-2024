[
  {
    "objectID": "slides/day2-morning.html#section",
    "href": "slides/day2-morning.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Forecasting and Time-Series Models",
    "text": "Forecasting and Time-Series Models\n\n\n\n\nVenue – dd Somemonth yyyy"
  },
  {
    "objectID": "slides/day2-morning.html#outline",
    "href": "slides/day2-morning.html#outline",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Outline",
    "text": "Outline\n\nLinear Regression for Time Series Data\nEvaluation Methods\nARX Models\nOverfitting and Regularization\nPrediction Intervals\nForecasting with Versioned Data\nModeling Multiple Time Series"
  },
  {
    "objectID": "slides/day2-morning.html#basics-of-linear-regression",
    "href": "slides/day2-morning.html#basics-of-linear-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Basics of linear regression",
    "text": "Basics of linear regression\n\nAssume we observe a predictor \\(x_i\\) and an outcome \\(y_i\\) for \\(i = 1, \\dots, n\\).\nLinear regression seeks coefficients \\(\\beta_0\\) and \\(\\beta_1\\) such that\n\n\\[y_i \\approx \\beta_0 + \\beta_1 x_i\\]\nis a good approximation for every \\(i = 1, \\dots, n\\).\n\nIn R, the coefficients are found by running lm(y ~ x), where y is the vector of responses and x the vector of predictors."
  },
  {
    "objectID": "slides/day2-morning.html#multiple-linear-regression",
    "href": "slides/day2-morning.html#multiple-linear-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nGiven \\(p\\) different predictors, we seek \\((p+1)\\) coefficients such that\n\n\\[y_i \\approx \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip}\\] is a good approximation for every \\(i = 1, \\dots, n\\)."
  },
  {
    "objectID": "slides/day2-morning.html#linear-regression-with-lagged-predictor",
    "href": "slides/day2-morning.html#linear-regression-with-lagged-predictor",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Linear regression with lagged predictor",
    "text": "Linear regression with lagged predictor\n\nIn time series, outcomes and predictors are usually indexed by time \\(t\\).\nGoal: predicting future \\(y\\), given present \\(x\\).\nModel: linear regression with lagged predictor\n\n\\[\\hat y_t = \\hat \\beta + \\hat \\beta_0 x_{t-k}\\]\ni.e. regress the outcome \\(y\\) at time \\(t\\) on the predictor \\(x\\) at time \\(t-k\\).\n\nEquivalent way to write the model:\n\n\\[\\hat y_{t+k} = \\hat \\beta + \\hat \\beta_0 x_t\\]"
  },
  {
    "objectID": "slides/day2-morning.html#example-predicting-covid-deaths",
    "href": "slides/day2-morning.html#example-predicting-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example: predicting COVID deaths",
    "text": "Example: predicting COVID deaths\n\nDuring the pandemic, interest in predicting COVID deaths 7, 14, 21, 28 days ahead.\nCan we reasonably predict COVID deaths 28 days ahead by just using cases today?\nIf we let\n\n\\[y_{t+28} = \\text{deaths at time } t+28 \\quad\\quad x_{t} = \\text{cases at time } t\\] is the following a good model?\n\\[\\hat y_{t+28} = \\hat\\beta_0 + \\hat\\beta_1 x_{t}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#example-covid-cases-and-deaths-in-california",
    "href": "slides/day2-morning.html#example-covid-cases-and-deaths-in-california",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example: COVID cases and deaths in California",
    "text": "Example: COVID cases and deaths in California\n\nLet’s focus on California.\nCases seem highly correlated with deaths several weeks later.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhead(ca)\n\nAn `epi_df` object, 6 x 4 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-11-06 08:50:44.00687\n\n# A tibble: 6 × 4\n# Groups:   geo_value [1]\n  geo_value time_value cases deaths\n* &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 ca        2020-04-01  3.17 0.0734\n2 ca        2020-04-02  3.48 0.0835\n3 ca        2020-04-03  3.44 0.0894\n4 ca        2020-04-04  3.05 0.0778\n5 ca        2020-04-05  3.28 0.0876\n6 ca        2020-04-06  3.37 0.0848"
  },
  {
    "objectID": "slides/day2-morning.html#checking-correlation",
    "href": "slides/day2-morning.html#checking-correlation",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Checking correlation",
    "text": "Checking correlation\n\nLet’s split the data into a training and a test set (before/after 2021-04-01).\nOn training set: large correlation between cases and deaths 28 days ahead (&gt; 0.95).\n\n\n\nLet’s use (base) R to prepare the data and fit\n\n\\[\\hat y_{t+28} = \\hat\\beta + \\hat\\beta_0 x_{t}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#preparing-the-data",
    "href": "slides/day2-morning.html#preparing-the-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Preparing the data",
    "text": "Preparing the data\n\n# Add column with cases lagged by k\nca$lagged_cases &lt;- dplyr::lag(ca$cases, n = k)\n\n# Split into train and test (before/after t0_date)\nt0_date &lt;- as.Date('2021-04-01')\ntrain &lt;- ca %&gt;% filter(time_value &lt;= t0_date)\ntest &lt;- ca %&gt;% filter(time_value &gt; t0_date)\n\n\nCheck if deaths is approximately linear in lagged_cases:"
  },
  {
    "objectID": "slides/day2-morning.html#fitting-lagged-linear-regression-in-r",
    "href": "slides/day2-morning.html#fitting-lagged-linear-regression-in-r",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fitting lagged linear regression in R",
    "text": "Fitting lagged linear regression in R\n\nreg_lagged = lm(deaths ~ lagged_cases, data = train)\ncoef(reg_lagged)\n\n (Intercept) lagged_cases \n   0.1171839    0.0112714"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics",
    "href": "slides/day2-morning.html#error-metrics",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics",
    "text": "Error metrics\n\nAssume we have predictions \\(\\hat y_{new, t}\\) for the unseen observations \\(y_{new,t}\\) over times \\(t = 1, \\dots, N\\).\nFour commonly used error metrics are:\n\nmean squared error (MSE)\nmean absolute error (MAE)\nmean absolute percentage error (MAPE)\nmean absolute scaled error (MASE)"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics-mse-and-mae",
    "href": "slides/day2-morning.html#error-metrics-mse-and-mae",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics: MSE and MAE",
    "text": "Error metrics: MSE and MAE\n\\[MSE = \\frac{1}{N} \\sum_{t=1}^N (y_{new, t}- \\hat y_{new, t})^2\\] \\[MAE = \\frac{1}{N} \\sum_{t=1}^N |y_{new, t}- \\hat y_{new, t}|\\]\n\nMAE gives less importance to extreme errors than MSE.\nDrawback: both metrics are scale-dependent, so they are not universally interpretable. (For example, if \\(y\\) captures height, MSE and MAE will vary depending on whether we measure in feet or meters.)"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics-mape",
    "href": "slides/day2-morning.html#error-metrics-mape",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics: MAPE",
    "text": "Error metrics: MAPE\n\nFixing scale-dependence:\n\n\\[MAPE = 100 \\times \\frac{1}{N} \\sum_{t=1}^N\n\\left|\\frac{y_{new, t}- \\hat y_{new, t}}{y_{new, t}}\\right|\\]\n\nDrawbacks:\n\nErratic behavior when \\(y_{new, t}\\) is close to zero\nIt assumes the unit of measurement has a meaningful zero (e.g. using Fahrenheit or Celsius to measure temperature will lead to different MAPE)"
  },
  {
    "objectID": "slides/day2-morning.html#comparing-mae-and-mape",
    "href": "slides/day2-morning.html#comparing-mae-and-mape",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Comparing MAE and MAPE",
    "text": "Comparing MAE and MAPE\n\n\n\nNote\n\n\nThere are situations when MAPE is problematic!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n           MAE     MAPE\nyhat1 2.873328 43.14008\nyhat2 5.382247 36.08279"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics-mase",
    "href": "slides/day2-morning.html#error-metrics-mase",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics: MASE",
    "text": "Error metrics: MASE\n\\[MASE = 100 \\times \\frac{\\frac{1}{N} \\sum_{t=1}^N\n|y_{new, t}- \\hat y_{new, t}|}\n{\\frac{1}{N-1} \\sum_{t=2}^N\n|y_{new, t}- y_{new, t-1}|}\\]\n\nAdvantages:\n\nis universally interpretable (not scale dependent)\navoids the zero-pitfall\n\nMASE in words: we normalize the error of our forecasts by that of a naive method which always predicts the last observation."
  },
  {
    "objectID": "slides/day2-morning.html#comparing-mae-mape-and-mase",
    "href": "slides/day2-morning.html#comparing-mae-mape-and-mase",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Comparing MAE, MAPE and MASE",
    "text": "Comparing MAE, MAPE and MASE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n           MAE     MAPE      MASE\nyhat1 2.873328 43.14008  66.10004\nyhat2 5.382247 36.08279 123.81696"
  },
  {
    "objectID": "slides/day2-morning.html#defining-the-error-metrics-in-r",
    "href": "slides/day2-morning.html#defining-the-error-metrics-in-r",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Defining the error metrics in R",
    "text": "Defining the error metrics in R\n\nMSE &lt;- function(truth, prediction) {\n  mean((truth - prediction)^2)}\n\nMAE &lt;- function(truth, prediction) {\n  mean(abs(truth - prediction))}\n\nMAPE &lt;- function(truth, prediction) {\n  100 * mean(abs(truth - prediction) / truth)}\n\nMASE &lt;- function(truth, prediction) {\n  100 * MAE(truth, prediction) / mean(abs(diff(truth)))}"
  },
  {
    "objectID": "slides/day2-morning.html#estimating-the-prediction-error",
    "href": "slides/day2-morning.html#estimating-the-prediction-error",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Estimating the prediction error",
    "text": "Estimating the prediction error\n\nGiven an error metric, we want to estimate the prediction error under that metric.\nThis can be accomplished in different ways, using the\n\nTraining error\nSplit-sample error\nTime series cross-validation error (using all past data or a trailing window)"
  },
  {
    "objectID": "slides/day2-morning.html#training-error",
    "href": "slides/day2-morning.html#training-error",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Training error",
    "text": "Training error\n\nThe easiest but worst approach to estimate the prediction error is to use the training error, i.e. the average error on the training set that was used to fit the model.\nThe training error is\n\ngenerally too optimistic as an estimate of prediction error\nmore optimistic the more complex the model!1\n\n\nMore on this when we talk about overfitting."
  },
  {
    "objectID": "slides/day2-morning.html#training-error-1",
    "href": "slides/day2-morning.html#training-error-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Training error",
    "text": "Training error\nLinear regression of COVID deaths on lagged cases\n\n# Getting the predictions for the training set\npred_train &lt;- predict(reg_lagged)\n\n\n\n\n               MAE     MASE\ntraining 0.0740177 380.9996"
  },
  {
    "objectID": "slides/day2-morning.html#split-sample-error",
    "href": "slides/day2-morning.html#split-sample-error",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Split-sample error",
    "text": "Split-sample error\nTo compute the split-sample error\n\nSplit data into training (up to time \\(t_0\\)), and test set (after \\(t_0\\))\nFit the model to the training data only\nMake predictions for the test set\nCompute the selected error metric on the test set only\n\n\n\n\nNote\n\n\nSplit-sample estimates of prediction error don’t mimic a situation where we would refit the model in the future. They are pessimistic if the relation between outcome and predictors changes over time."
  },
  {
    "objectID": "slides/day2-morning.html#split-sample-error-1",
    "href": "slides/day2-morning.html#split-sample-error-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Split-sample error",
    "text": "Split-sample error\nAssume we want to make \\(h\\)-step ahead predictions, i.e. at time \\(t\\) we want to make a forecast for \\(t+h\\). Then, the split-sample MSE is\n\\[\\text{SplitMSE} = \\frac{1}{n-h-t_0} \\sum_{t = t_0}^{n-h} (\\hat y_{t+h|t_0} - y_{t+h})^2\\]\nwhere \\(\\hat y_{t+h|t_0}\\) indicates a prediction for \\(y\\) at time \\(t+h\\) that was made with a model that was fit on data up to time \\(t_0\\)."
  },
  {
    "objectID": "slides/day2-morning.html#split-sample-error-2",
    "href": "slides/day2-morning.html#split-sample-error-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Split-sample error",
    "text": "Split-sample error\nLinear regression of COVID deaths on lagged cases\n\n# Getting the h-step ahead predictions for the test set\nh &lt;- k\ntest_h &lt;- test[-(1:h-1), ] # drop first h-1 rows to avoid data leakage\npred_test &lt;- predict(reg_lagged, newdata = test_h)\n\n\n\n\n                   MAE      MASE\ntraining     0.0740177  380.9996\nsplit-sample 0.3116854 2914.4575\n\n\n\nNote that we are overestimating the peak due to the changed relationship between cases - deaths over time.\nTalk about data leakage."
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cross-validation-cv",
    "href": "slides/day2-morning.html#time-series-cross-validation-cv",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series cross-validation (CV)",
    "text": "Time-series cross-validation (CV)\n\\(h\\)-step ahead predictions\n\nIf we refit in the future once new data are available, a more appropriate way to estimate the prediction error is time-series cross-validation.\nTo get \\(h\\)-step ahead predictions, we:\n\nFit the model using data up to time \\(t\\)\nMake a prediction for \\(t+h\\)\nRecord the prediction error\n\nThe cross-validation MSE is then\n\n\\[CVMSE = \\frac{1}{n-h-t_0} \\sum_{t = t_0}^{n-h} (\\hat y_{t+h|t} - y_{t+h})^2\\]\nwhere \\(\\hat y_{t+h|t}\\) indicates a prediction for \\(y\\) at time \\(t+h\\) that was made with data available up to time \\(t\\)."
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cross-validation-cv-1",
    "href": "slides/day2-morning.html#time-series-cross-validation-cv-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series cross-validation (CV)",
    "text": "Time-series cross-validation (CV)\nLinear regression of COVID deaths on lagged cases\nGetting the predictions requires slightly more code:\n\nn &lt;- nrow(ca)                               #length of time series\nh &lt;- k                                      #number of days ahead for which prediction is wanted\npred_all_past &lt;- rep(NA, length = n)        #initialize vector of predictions\n\nfor (t in t0:(n-h)) {\n  # fit to all past data and make h-step ahead prediction\n  reg_all_past = lm(deaths ~ lagged_cases, data = ca, subset = (1:n) &lt;= t) \n  pred_all_past[t+h] = predict(reg_all_past, newdata = data.frame(ca[t+h, ]))\n}\n\n\n\n\nNote\n\n\nWith the current model, we can only predict \\(k\\) days ahead (where \\(k\\) = number of days by which predictor is lagged)!"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cross-validation-cv-2",
    "href": "slides/day2-morning.html#time-series-cross-validation-cv-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series cross-validation (CV)",
    "text": "Time-series cross-validation (CV)\nLinear regression of COVID deaths on lagged cases\n\n\n\n                     MAE      MASE\ntraining       0.0740177  380.9996\nsplit-sample   0.3116854 2914.4575\ntime series CV 0.2374931 2212.5992\n\n\n\nSome improvement wrt split-sample, but still overestimating peak."
  },
  {
    "objectID": "slides/day2-morning.html#regression-on-a-trailing-window",
    "href": "slides/day2-morning.html#regression-on-a-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Regression on a trailing window",
    "text": "Regression on a trailing window\n\nSo far, to get \\(h\\)-step ahead predictions for time \\(t+h\\), we have fitted the model on all data available up to time \\(t\\). We can instead use a trailing window, i.e. fit the model on a window of data of length \\(w\\), starting at \\(t-w\\) and ending at \\(t\\).\nAdvantage: if the predictors-outcome relation changes over time, training the forecaster on a window of recent data can better capture the recent relation which might be more relevant to predict the outcome in the near future.\nWindow length \\(w\\) considerations:\n\nif \\(w\\) is too big, the model can’t adapt to the recent predictors-outcome relation\nif \\(w\\) is too small, the fitted model may be too volatile (trained on too little data)"
  },
  {
    "objectID": "slides/day2-morning.html#trailing-window",
    "href": "slides/day2-morning.html#trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Trailing window",
    "text": "Trailing window\nLinear regression of COVID deaths on lagged cases\n\n# Getting the predictions through CV with trailing window\nw &lt;- 120                                    #trailing window size\nh &lt;- k                                      #number of days ahead for which prediction is wanted\npred_trailing &lt;- rep(NA, length = n)        #initialize vector of predictions\n\nfor (t in t0:(n-h)) {\n  # fit to a trailing window of size w and make h-step ahead prediction\n  reg_trailing = lm(deaths ~ lagged_cases, data = ca, \n                    subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n  pred_trailing[t+h] = predict(reg_trailing, newdata = data.frame(ca[t+h, ]))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-all-past-vs-trailing-window",
    "href": "slides/day2-morning.html#time-series-cv-all-past-vs-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series CV: all past vs trailing window",
    "text": "Time-series CV: all past vs trailing window\nLinear regression of COVID deaths on lagged cases\n\n\n\n                                 MAE      MASE\ntraining                  0.07401770  380.9996\nsplit-sample              0.31168536 2914.4575\ntime series CV            0.23749306 2212.5992\ntime series CV + trailing 0.09932651  925.3734\n\n\n\nA lot of improvement: trailing window allows to adapt to the change in relationship between cases and deaths over time."
  },
  {
    "objectID": "slides/day2-morning.html#autoregressive-exogenous-input-arx-model",
    "href": "slides/day2-morning.html#autoregressive-exogenous-input-arx-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Autoregressive exogenous input (ARX) model",
    "text": "Autoregressive exogenous input (ARX) model\n\nIdea: predicting the outcome via a linear combination of its lags and a set of exogenous (i.e. external) input variables\nExample:\n\n\\[\\hat y_{t+h} = \\hat\\phi + \\sum_{i=0}^p \\hat\\phi_i y_{t-i} + \\sum_{j=0}^q \\hat\\beta_j x_{t-j}\\]\n\nNotice: we don’t need to include all contiguous lags, and we could fit e.g.\n\n\\[\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} + \\hat\\phi_2 y_{t-14} +\n\\hat\\beta_0 x_{t} + \\hat\\beta_1 x_{t-7} + \\hat\\beta_2 x_{t-14}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#arx-model-for-covid-deaths",
    "href": "slides/day2-morning.html#arx-model-for-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX model for COVID deaths",
    "text": "ARX model for COVID deaths\n\nLet’s add lagged deaths as a predictor to our previous forecaster:\n\n\\[\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\beta_0 x_{t}\\]\n\n# Prepare data: add column with deaths lagged by 28\nca$lagged_deaths &lt;- dplyr::lag(ca$deaths, n = k)\n\n\nHow does it compare to the previous model in terms of time-series CV?"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-all-past-and-trailing-arx-model",
    "href": "slides/day2-morning.html#time-series-cv-all-past-and-trailing-arx-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-Series CV: all past and trailing (ARX model)",
    "text": "Time-Series CV: all past and trailing (ARX model)\n\n\n\n                                 MAE      MASE\ntime series CV            0.16204381 1509.6779\ntime series CV + trailing 0.07872895  733.4767\n\n\n\nErrors under both metrics are smaller than with previous model."
  },
  {
    "objectID": "slides/day2-morning.html#predictions-for-different-h",
    "href": "slides/day2-morning.html#predictions-for-different-h",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions for different \\(h\\)",
    "text": "Predictions for different \\(h\\)\n\nSo far we only focused on COVID death predictions 28 days ahead.\nWe will now compare the first model\n\n\\[\\hat y_{t+h} = \\hat\\beta + \\hat\\beta_0 x_t\\]\nto the second model\n\\[\\hat y_{t+h} = \\hat\\phi + \\hat\\phi_0 y_t + \\hat\\beta_0 x_t\\]\nfor horizons \\(h = 7, 14, 21, 28\\).\n\nWe will only make forecasts on the \\(1^{st}\\) day of each month, and use a trailing window with \\(w = 120\\)."
  },
  {
    "objectID": "slides/day2-morning.html#predictions-for-different-h-1",
    "href": "slides/day2-morning.html#predictions-for-different-h-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions for different \\(h\\)",
    "text": "Predictions for different \\(h\\)\n\nh_vals &lt;- c(7, 14, 21, 28)  #horizons \npred_m1 = pred_m2 &lt;- data.frame(matrix(NA, nrow = 0, ncol = 3))  #initialize df for predictions\ncolnames(pred_m1) = colnames(pred_m2) = c(\"forecast_date\", \"target_date\", \"prediction\")\nw &lt;- 120    #trailing window size\n\nca_lags &lt;- ca %&gt;% select(!c(lagged_cases, lagged_deaths))\n\n# Create lagged predictors \nfor (i in seq_along(h_vals)) {\n  ca_lags[[paste0(\"lagged_deaths_\", h_vals[i])]] &lt;- dplyr::lag(ca_lags$deaths, n = h_vals[i])\n  ca_lags[[paste0(\"lagged_cases_\", h_vals[i])]] &lt;- dplyr::lag(ca_lags$cases, n = h_vals[i])\n}\n\n# Only forecast on 1st day of the months\nforecast_time &lt;- which(ca_lags$time_value &gt;= t0_date & \n                         ca_lags$time_value &lt; ca_lags$time_value[n-max(h_vals)] &\n                         day(ca_lags$time_value) == 1)\n\nfor (t in forecast_time) {\n  for (i in seq_along(h_vals)) {\n    h = h_vals[i]\n    # formulas including h-lagged variables\n    m1_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h))\n    m2_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h, \" + lagged_deaths_\", h))\n    # fit to trailing window of data\n    m1_fit = lm(m1_formula, data = ca_lags, subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n    m2_fit = lm(m2_formula, data = ca_lags, subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n    # make h-step ahead predictions\n    pred_m1 = rbind(pred_m1, \n                    data.frame(forecast_date = ca_lags$time_value[t],\n                               target_date = ca_lags$time_value[t+h],\n                               prediction = predict(m1_fit, newdata = data.frame(ca_lags[t+h, ]))))\n    pred_m2 = rbind(pred_m2, \n                    data.frame(forecast_date = ca_lags$time_value[t],\n                               target_date = ca_lags$time_value[t+h],\n                               prediction = predict(m2_fit, newdata = data.frame(ca_lags[t+h, ]))))\n    }\n}"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-for-different-h-model-1",
    "href": "slides/day2-morning.html#predictions-for-different-h-model-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions for different \\(h\\) (Model 1)",
    "text": "Predictions for different \\(h\\) (Model 1)\n\n\n\n              MAE    MASE\nModel 1 0.1049742 304.007"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-for-different-h-model-2",
    "href": "slides/day2-morning.html#predictions-for-different-h-model-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions for different \\(h\\) (Model 2)",
    "text": "Predictions for different \\(h\\) (Model 2)\n\n\n\n               MAE     MASE\nModel 2 0.04463132 129.2531"
  },
  {
    "objectID": "slides/day2-morning.html#arx-with-more-predictors",
    "href": "slides/day2-morning.html#arx-with-more-predictors",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX with more predictors",
    "text": "ARX with more predictors\n\nThe ARX model with only two predictors seems to forecast quite well for different \\(h\\).\nWe will try to improve it by adding some more lags. We will fit and compare\n\n\\[\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} +\n\\hat\\beta_0 x_{t} + \\hat\\beta_1 x_{t-7}\\]\nand\n\\[\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} + \\hat\\phi_2 y_{t-14} +\n\\hat\\beta_0 x_{t} + \\hat\\beta_1 x_{t-7} + \\hat\\beta_2 x_{t-14}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-using-arx-with-2-lags",
    "href": "slides/day2-morning.html#predictions-using-arx-with-2-lags",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions using ARX with 2 lags",
    "text": "Predictions using ARX with 2 lags\n\n\n\n              MAE     MASE\nModel 3 0.0495936 143.6239"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-using-arx-with-3-lags",
    "href": "slides/day2-morning.html#predictions-using-arx-with-3-lags",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions using ARX with 3 lags",
    "text": "Predictions using ARX with 3 lags\n\n\n\n               MAE     MASE\nModel 4 0.05836984 169.0401"
  },
  {
    "objectID": "slides/day2-morning.html#too-many-predictors",
    "href": "slides/day2-morning.html#too-many-predictors",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Too many predictors",
    "text": "Too many predictors\n\nWhat if we try to incorporate past information extensively by fitting a model with a very large number of predictors?\n\nThe estimated coefficients will be chosen to mimic the observed data very closely on the training set, leading to small training error\nThe predictive performance on the test set might be very poor, producing large split-sample and CV error\n\n\n\n\n\nIssue\n\n\nOverfitting!"
  },
  {
    "objectID": "slides/day2-morning.html#arx-model-for-covid-deaths-with-many-predictors",
    "href": "slides/day2-morning.html#arx-model-for-covid-deaths-with-many-predictors",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX model for COVID deaths with many predictors",
    "text": "ARX model for COVID deaths with many predictors\n\nWhen predicting COVID deaths 28 days ahead, we can try to use more past information by fitting a model that includes the past two months of COVID deaths and cases as predictors\n\n\\[\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-1} + \\dots +\n\\hat\\phi_{59} y_{t-59} +\n\\hat\\beta_0 x_{t} + \\dots + \\hat\\beta_{t-59} x_{t-59}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#preparing-the-data-1",
    "href": "slides/day2-morning.html#preparing-the-data-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Preparing the data",
    "text": "Preparing the data\n\ny &lt;- ca$deaths  #outcome\nlags &lt;- 28:87   #lags used for predictors (deaths and cases)\nh &lt;- 28\n\n# Build predictor matrix with 60 columns\nX &lt;- data.frame(matrix(NA, nrow = length(y), ncol = 2*length(lags)))\ncolnames(X) &lt;- paste('X', 1:ncol(X), sep = '')\n\nfor (j in 1:length(lags)) {\n  # first 60 columns contain deaths lagged by 28, 29, ..., 87\n  X[, j] = dplyr::lag(ca$deaths, lags[j])\n  # last 60 columns contain cases lagged by 28, 29, ..., 87\n  X[, length(lags) + j] = dplyr::lag(ca$cases, lags[j])\n}"
  },
  {
    "objectID": "slides/day2-morning.html#fitting-the-arx-model",
    "href": "slides/day2-morning.html#fitting-the-arx-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fitting the ARX model",
    "text": "Fitting the ARX model\n\n# Train/test split\ny_train &lt;- y[1:t0]\nX_train &lt;- X[1:t0, ]\ny_test &lt;- y[(t0+h):length(y)]\nX_test &lt;- X[(t0+h):length(y), ]\n\n# Fitting the ARX model\nreg = lm(y_train ~ ., data = X_train)\ncoef(reg)\n\n  (Intercept)            X1            X2            X3            X4 \n 0.0775116437 -0.5593818462  0.7979659233 -0.4175920623 -0.2780809101 \n           X5            X6            X7            X8            X9 \n 0.3031742752 -0.0809244359  0.2548033065 -0.4860940499  0.1322930625 \n          X10           X11           X12           X13           X14 \n-0.2352041391 -0.1327834155  0.2155747658 -0.3380379255  0.4239820677 \n          X15           X16           X17           X18           X19 \n-0.2012041267 -0.3367851572 -0.2889890062  0.5328712849  0.5388650654 \n          X20           X21           X22           X23           X24 \n-0.3065835983  0.0724595436 -0.0168042757 -0.1171985635  0.2046513639 \n          X25           X26           X27           X28           X29 \n 0.1810480128  0.1213875691  0.0230516587  0.0196208441  0.0397085778 \n          X30           X31           X32           X33           X34 \n-0.3884271784  0.2088690345  0.1248242133  0.0706165553 -0.4882035875 \n          X35           X36           X37           X38           X39 \n 0.3609708771 -0.3169047917  0.4216666798  0.1891753615 -0.1106475626 \n          X40           X41           X42           X43           X44 \n 0.1498605000 -0.0692090064  0.1336287081 -0.1875462008 -0.2449003857 \n          X45           X46           X47           X48           X49 \n-0.0001337325 -0.5738823399  0.0695056705 -0.2460256934  1.0173509442 \n          X50           X51           X52           X53           X54 \n-0.1853591480 -0.5428279059  0.2678983608 -0.6935743948  0.3829408389 \n          X55           X56           X57           X58           X59 \n 0.1088530454  0.9466159031 -0.5618240450 -0.4660113206  0.6102916420 \n          X60           X61           X62           X63           X64 \n-0.2859449807  0.0283237204 -0.0099051792 -0.0070208086  0.0021192306 \n          X65           X66           X67           X68           X69 \n-0.0047341417 -0.0111532015  0.0038542335  0.0184565802 -0.0060684485 \n          X70           X71           X72           X73           X74 \n-0.0005801373  0.0048246180 -0.0061516656 -0.0066597399  0.0039021597 \n          X75           X76           X77           X78           X79 \n 0.0126296042 -0.0080708988 -0.0027091539  0.0052517573 -0.0052000323 \n          X80           X81           X82           X83           X84 \n 0.0029961750  0.0013593227  0.0083628716 -0.0063778828 -0.0018882435 \n          X85           X86           X87           X88           X89 \n-0.0097221295  0.0003314155 -0.0013911110  0.0066935430  0.0107961484 \n          X90           X91           X92           X93           X94 \n-0.0052473765 -0.0057177036  0.0023462634 -0.0112827594  0.0008517257 \n          X95           X96           X97           X98           X99 \n-0.0004388072  0.0231342674 -0.0056794349 -0.0046693142 -0.0061536587 \n         X100          X101          X102          X103          X104 \n-0.0094880392  0.0071605921  0.0021423255  0.0108738290 -0.0015420116 \n         X105          X106          X107          X108          X109 \n 0.0015155025  0.0022482275 -0.0148197121  0.0129113709  0.0009150566 \n         X110          X111          X112          X113          X114 \n 0.0021338029 -0.0019029077 -0.0040171812 -0.0025674957 -0.0069761237 \n         X115          X116          X117          X118          X119 \n 0.0226899068 -0.0022271856 -0.0060651747  0.0071536700 -0.0016426930 \n         X120 \n-0.0127949778"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-on-training-and-test-set",
    "href": "slides/day2-morning.html#predictions-on-training-and-test-set",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions on training and test set",
    "text": "Predictions on training and test set\n\n\n\n                    MAE      MASE\ntraining     0.04230235  189.9364\nsplit-sample 0.41684935 3883.5685\n\n\n\n\n\nNote\n\n\nSome predictions are negative, which doesn’t make sense for count data, so let’s truncate them at 0."
  },
  {
    "objectID": "slides/day2-morning.html#truncated-predictions-on-training-and-test-set",
    "href": "slides/day2-morning.html#truncated-predictions-on-training-and-test-set",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Truncated predictions on training and test set",
    "text": "Truncated predictions on training and test set\n\n\n\n                             MAE    MASE\nsplit-sample truncated 0.3978198 3706.28"
  },
  {
    "objectID": "slides/day2-morning.html#regularization",
    "href": "slides/day2-morning.html#regularization",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Regularization",
    "text": "Regularization\n\nIf we want to consider a large number of predictors, how can we avoid overfitting?\nIdea: introduce a regularization parameter \\(\\lambda\\) that shrinks or sets some of the estimated coefficients to zero, i.e. some predictors are estimated to have limited or no predictive power\nMost common regularization methods\n\nRidge: shrinks coefficients to zero\nLasso: sets some coefficients to zero"
  },
  {
    "objectID": "slides/day2-morning.html#arx-ridgelasso-for-covid-deaths",
    "href": "slides/day2-morning.html#arx-ridgelasso-for-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX + ridge/lasso for COVID deaths",
    "text": "ARX + ridge/lasso for COVID deaths\nLet’s consider a model with lagged cases and deaths: 7 lags for each, spaced by one week.\n\nh &lt;- 28\nlags &lt;- h + 7*(0:6)   #lags used for predictors (deaths and cases)\n\n# Build predictor matrix \nX &lt;- data.frame(matrix(NA, nrow = length(y), ncol = 2*length(lags)))\ncolnames(X) &lt;- paste('X', 1:ncol(X), sep = '')\n\nfor (j in 1:length(lags)) {\n  # lagged deaths \n  X[, j] = dplyr::lag(ca$deaths, lags[j])\n  # lagged cases\n  X[, length(lags) + j] = dplyr::lag(ca$cases, lags[j])\n}\n\n# Train/test split\ny_train &lt;- y[1:t0]\nX_train &lt;- X[1:t0, ]\ny_test &lt;- y[(t0+h):length(y)]\nX_test &lt;- X[(t0+h):length(y), ]"
  },
  {
    "objectID": "slides/day2-morning.html#fit-arx-ridgelasso-for-covid-deaths",
    "href": "slides/day2-morning.html#fit-arx-ridgelasso-for-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fit ARX + ridge/lasso for COVID deaths",
    "text": "Fit ARX + ridge/lasso for COVID deaths\n\nlibrary(glmnet) # Implements ridge and lasso\n\n# We'll need to omit NA values explicitly, as otherwise glmnet will complain\nna_obs &lt;- 1:max(lags)\nX_train &lt;- X_train[-na_obs, ]\ny_train &lt;- y_train[-na_obs]\n\n# Ridge regression: set alpha = 0, lambda sequence will be chosen automatically\nridge &lt;- glmnet(X_train, y_train, alpha = 0)\nbeta_ridge &lt;- coef(ridge)       # matrix of estimated coefficients \nlambda_ridge &lt;- ridge$lambda    # sequence of lambdas used to fit ridge \n\n# Lasso regression: set alpha = 1, lambda sequence will be chosen automatically\nlasso &lt;- glmnet(X_train, y_train, alpha = 1)\nbeta_lasso &lt;- coef(lasso)       # matrix of estimated coefficients \nlambda_lasso &lt;- lasso$lambda    # sequence of lambdas used to fit lasso \n\ndim(beta_lasso)      # One row per coefficient, one column per lambda value\n\n[1] 15 92"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-on-test-set-and-best-lambda",
    "href": "slides/day2-morning.html#predictions-on-test-set-and-best-lambda",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions on test set and best \\(\\lambda\\)",
    "text": "Predictions on test set and best \\(\\lambda\\)\n\n# Predict values for second half of the time series\nyhat_ridge &lt;- predict(ridge, newx = as.matrix(X_test))\nyhat_lasso &lt;- predict(lasso, newx = as.matrix(X_test))\n\n# Compute MAE \nmae_ridge &lt;- colMeans(abs(yhat_ridge - y_test))\nmae_lasso &lt;- colMeans(abs(yhat_lasso - y_test))\n\n# Select index of lambda vector which gives lowest MAE\nmin_ridge &lt;- which.min(mae_ridge)\nmin_lasso &lt;- which.min(mae_lasso)\npaste('Best MAE ridge:', round(min(mae_ridge), 3),\n      '; Best MAE lasso:', round(min(mae_lasso), 3))\n\n[1] \"Best MAE ridge: 0.292 ; Best MAE lasso: 0.295\"\n\n# Get predictions for train and test sets\npred_train_ridge &lt;- predict(ridge, newx = as.matrix(X_train))[, min_ridge] \npred_test_ridge &lt;- yhat_ridge[, min_ridge]\npred_train_lasso &lt;- predict(lasso, newx = as.matrix(X_train))[, min_lasso] \npred_test_lasso &lt;- yhat_lasso[, min_lasso]"
  },
  {
    "objectID": "slides/day2-morning.html#estimated-coefficients-shrinkage-vs-sparsity",
    "href": "slides/day2-morning.html#estimated-coefficients-shrinkage-vs-sparsity",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Estimated coefficients: shrinkage vs sparsity",
    "text": "Estimated coefficients: shrinkage vs sparsity\n\n\n\n\n                    ridge       lasso\n(Intercept)  0.2978514823 0.124915807\nX1           0.0433892112 0.069300307\nX2           0.0292256563 0.000000000\nX3           0.0179647838 0.000000000\nX4           0.0083918680 0.000000000\nX5          -0.0015177021 0.000000000\nX6          -0.0125786976 0.000000000\nX7          -0.0191532557 0.000000000\nX8           0.0010586265 0.008320956\nX9           0.0009417383 0.000000000\nX10          0.0008208805 0.001690258\nX11          0.0006535137 0.000000000\nX12          0.0004488789 0.000000000\nX13          0.0002816751 0.000000000\nX14          0.0001839354 0.000000000"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-arx-ridgelasso-train-and-test-set",
    "href": "slides/day2-morning.html#predictions-arx-ridgelasso-train-and-test-set",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions: ARX + ridge/lasso (train and test set)",
    "text": "Predictions: ARX + ridge/lasso (train and test set)\n\n\n\n                         MAE      MASE\nridge training     0.1975073  924.4584\nridge split-sample 0.2923452 2723.6281\nlasso training     0.0790951  370.2149\nlasso split-sample 0.2945295 2743.9784"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-for-arx-ridgelasso-trailing",
    "href": "slides/day2-morning.html#time-series-cv-for-arx-ridgelasso-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series CV for ARX + ridge/lasso (trailing)",
    "text": "Time-series CV for ARX + ridge/lasso (trailing)\n\nh &lt;- 28  # number of days ahead \nw &lt;- 120 # window length\n\n# Initialize matrices for predictions (one column per lambda value)\nyhat_ridge &lt;- rep(NA, length = n) \nyhat_lasso &lt;- rep(NA, length = n) \n\nfor (t in t0:(n-h)) {\n  # Choose best lambda\n  cv_inds = max(lags) &lt; 1:n & 1:n &lt;= t-w\n  ridge_cv = cv.glmnet(as.matrix(X[cv_inds, ]), y[cv_inds], alpha = 0)\n  lasso_cv = cv.glmnet(as.matrix(X[cv_inds, ]), y[cv_inds], alpha = 1)\n  best_lambda_ridge = ridge_cv$lambda.min\n  best_lambda_lasso = lasso_cv$lambda.min\n  # Indices of data within window\n  inds = t-w &lt; 1:n & 1:n &lt;= t\n  # Fit ARX + ridge/lasso\n  ridge_trail = glmnet(X[inds, ], y[inds], alpha = 0, lambda = best_lambda_ridge)\n  lasso_trail = glmnet(X[inds, ], y[inds], alpha = 1, lambda = best_lambda_lasso)\n  # Predict\n  yhat_ridge[t+h] = predict(ridge_trail, newx = as.matrix(X[(t+h), ]))\n  yhat_lasso[t+h] = predict(lasso_trail, newx = as.matrix(X[(t+h), ]))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-time-series-cv-for-arx-ridgelasso-trailing",
    "href": "slides/day2-morning.html#predictions-time-series-cv-for-arx-ridgelasso-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions: time-series CV for ARX + ridge/lasso (trailing)",
    "text": "Predictions: time-series CV for ARX + ridge/lasso (trailing)\n\n\n\n                          MAE     MASE\nridge CV + trailing 0.1068111  995.103\nlasso CV + trailing 0.1328789 1237.964"
  },
  {
    "objectID": "slides/day2-morning.html#point-predictions-vs-intervals",
    "href": "slides/day2-morning.html#point-predictions-vs-intervals",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Point predictions vs intervals",
    "text": "Point predictions vs intervals\n\nSo far, we have only considered point predictions, i.e.  we have fitted models to provide our best guess on the outcome at time \\(t+h\\).\n\n\n\n\nImportant\n\n\nWhat if we want to provide a measure of uncertainty around the point prediction or a likely range of values for the outcome at time \\(t+h\\)?\n\n\n\n\nFor each target time \\(t+h\\), we can construct prediction intervals, i.e. provide ranges of values that are expected to cover the true outcome value a fixed fraction of times."
  },
  {
    "objectID": "slides/day2-morning.html#prediction-intervals-for-lm-fits",
    "href": "slides/day2-morning.html#prediction-intervals-for-lm-fits",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Prediction intervals for lm fits",
    "text": "Prediction intervals for lm fits\n\nTo get prediction intervals for the models we previously fitted, we only need to tweak our call to predict by adding as an input:\ninterval = \"prediction\", level = p\nwhere \\(p \\in (0, 1)\\) is the desired coverage.\nThe output from predict will then be a matrix with\n\nfirst column a point estimate\nsecond column the lower limit of the interval\nthird column the upper limit of the interval"
  },
  {
    "objectID": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window",
    "href": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Prediction intervals for ARX (CV, trailing window)",
    "text": "Prediction intervals for ARX (CV, trailing window)\n\n# Initialize matrices to store predictions \n# 3 columns: point estimate, lower limit, and upper limit\npred_trailing &lt;- matrix(NA, nrow = n, ncol = 3)\ncolnames(pred_trailing) &lt;- c('prediction', 'lower', 'upper')\n\nfor (t in t0:(n-h)) {\n  # Fit ARX and predict\n  arx_trailing = lm(deaths ~ lagged_deaths + lagged_cases, data = ca, \n                    subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n  pred_trailing[t+h, ] = predict(arx_trailing, newdata = data.frame(ca[t+h, ]),\n                                 interval = \"prediction\", level = 0.95)\n}"
  },
  {
    "objectID": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window-1",
    "href": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Prediction intervals for ARX (CV, trailing window)",
    "text": "Prediction intervals for ARX (CV, trailing window)\n\n\n\n                 MAE     MASE\nlm.trailing 0.104397 972.6125"
  },
  {
    "objectID": "slides/day2-morning.html#quantile-regression",
    "href": "slides/day2-morning.html#quantile-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Quantile regression",
    "text": "Quantile regression\n\nSo far we only considered different ways to apply linear regression.\nQuantile regression is a different estimation method, and it directly targets conditional quantiles of the outcome over time.\n\n\n\n\n\n\n\nDefinition\n\n\nConditional quantile = value below which a given percentage (e.g. 25%, 50%, 75%) of observations fall, given specific values of the predictor variables.\n\n\n\n\nAdvantage: it provides a more complete picture of the outcome distribution."
  },
  {
    "objectID": "slides/day2-morning.html#arx-model-for-covid-deaths-via-quantile-regression",
    "href": "slides/day2-morning.html#arx-model-for-covid-deaths-via-quantile-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX model for COVID deaths via quantile regression",
    "text": "ARX model for COVID deaths via quantile regression\n\n#install.packages(\"quantreg\")\nlibrary(quantreg)  #library to perform quantile regression\n\n# Set quantiles of interest: we will focus on 2.5%, 50% (i.e. median), and 97.5% quantiles\nquantiles &lt;- c(0.025, 0.5, 0.975)  \n\n# Fit quantile regression to training set\nq_reg &lt;- rq(deaths ~ lagged_deaths + lagged_cases, data = train, tau = quantiles)\n\n# Estimated coefficients\ncoef(q_reg)\n\n               tau= 0.025 tau= 0.500 tau= 0.975\n(Intercept)   0.009351562 0.06896010 0.12257658\nlagged_deaths 0.229011485 0.19821254 0.28469573\nlagged_cases  0.007439881 0.01022547 0.01265167\n\n# Sort estimated coefficients \ncoefs_sorted &lt;- t(apply(coef(q_reg), 1, sort))\ncolnames(coefs_sorted) &lt;- colnames(coef(q_reg))\ncoefs_sorted\n\n               tau= 0.025 tau= 0.500 tau= 0.975\n(Intercept)   0.009351562 0.06896010 0.12257658\nlagged_deaths 0.198212543 0.22901149 0.28469573\nlagged_cases  0.007439881 0.01022547 0.01265167\n\nq_reg$coefficients &lt;- coefs_sorted"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-via-quantile-regression-cv-trailing",
    "href": "slides/day2-morning.html#predictions-via-quantile-regression-cv-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions via quantile regression (CV, trailing)",
    "text": "Predictions via quantile regression (CV, trailing)\n\n# Initialize matrix to store predictions \n# 3 columns: lower limit, median, and upper limit\npred_trailing &lt;- matrix(NA, nrow = n, ncol = 3)\ncolnames(pred_trailing) &lt;- c('lower', 'median', 'upper')\n\nfor (t in t0:(n-h)) {\n  # Fit quantile regression\n  rq_trailing = rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles,\n                   data = ca, subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n  # Sort estimated coefficients \n  coefs_sorted &lt;- t(apply(coef(rq_trailing), 1, sort))\n  rq_trailing$coefficients &lt;- coefs_sorted\n  # Predict\n  pred_trailing[t+h, ] = predict(rq_trailing, newdata = data.frame(ca[t+h, ]))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-via-quantile-regression-cv-trailing-1",
    "href": "slides/day2-morning.html#predictions-via-quantile-regression-cv-trailing-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions via quantile regression (CV, trailing)",
    "text": "Predictions via quantile regression (CV, trailing)\n\n\n\n                  MAE     MASE\nrq.trailing 0.1244401 1159.343"
  },
  {
    "objectID": "slides/day2-morning.html#actual-coverage",
    "href": "slides/day2-morning.html#actual-coverage",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Actual Coverage",
    "text": "Actual Coverage\n\nWe would expect the ARX model fitted via lm and via rq to cover the truth about 95% of the times. Is this actually true in practice?\nThe actual coverage of each predictive interval is lower:\n\n\n\n         lm.trailing rq.trailing\nCoverage   0.8294118   0.8117647"
  },
  {
    "objectID": "slides/day2-morning.html#evaluation-1",
    "href": "slides/day2-morning.html#evaluation-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Evaluation",
    "text": "Evaluation\n\nPrediction intervals are “good” if they\n\ncover the truth most of the time\nare not too wide\n\nError metric that captures both desiderata: Weighted Interval Score (WIS)\n\\(F\\) = forecast composed of predicted quantiles \\(q_{\\tau}\\) for the set of quantile levels \\(\\tau\\). The WIS for target variable \\(Y\\) is represented as (McDonald et al., 2021):\n\n\\[WIS(F, Y) = 2\\sum_{\\tau} \\phi_{\\tau} (Y - q_{\\tau})\\]\nwhere \\(\\phi_{\\tau}(x) = \\tau |x|\\) for \\(x \\geq 0\\) and \\(\\phi_{\\tau}(x) = (1-\\tau) |x|\\) for \\(x &lt; 0\\)."
  },
  {
    "objectID": "slides/day2-morning.html#computing-the-wis",
    "href": "slides/day2-morning.html#computing-the-wis",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Computing the WIS",
    "text": "Computing the WIS\n\nWIS &lt;- function(truth, estimates, quantiles) {\n  2 * sum(pmax(\n    quantiles * (truth - estimates),\n    (1 - quantiles) * (estimates - truth),\n    na.rm = TRUE\n  ))\n}\n\n\n\n\nNote\n\n\nWIS tends to prioritize sharpness (how wide the interval is) relative to coverage (if the interval contains the truth)."
  },
  {
    "objectID": "slides/day2-morning.html#wis-for-arx-fitted-via-lm-and-rq",
    "href": "slides/day2-morning.html#wis-for-arx-fitted-via-lm-and-rq",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "WIS for ARX fitted via lm and rq",
    "text": "WIS for ARX fitted via lm and rq\n\nThe lowest mean WIS is attained by quantile regression.\nNotice: this method has coverage below 95% but is still preferred under WIS because its intervals are narrower than for linear regression.\n\n\n\n  Mean WIS lm Mean WIS rq\n1   0.1335326   0.1056215"
  },
  {
    "objectID": "slides/day2-morning.html#versioned-data",
    "href": "slides/day2-morning.html#versioned-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Versioned data",
    "text": "Versioned data\n\nIn our forecasting examples, we have assumed the data are never revised (or have simply ignored revisions, and used data as_of today)\n\n\n\n\nImportant\n\n\nHow can we train forecasters when dealing with versioned data?\n\n\n\n\ndata_archive\n\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-04-01 / 2023-03-09\nℹ First/last version with update: 2020-04-02 / 2023-03-10\nℹ Versions end: 2023-03-10\nℹ A preview of the table (148820 rows x 5 columns):\n        geo_value time_value    version case_rate death_rate\n     1:        ak 2020-04-01 2020-04-02  1.797489  0.0000000\n     2:        ak 2020-04-01 2020-05-07  1.777061  0.0000000\n     3:        ak 2020-04-01 2020-10-28  1.106147  0.0000000\n     4:        ak 2020-04-01 2020-10-29  1.797489  0.0000000\n     5:        ak 2020-04-01 2020-10-30  1.797489  0.0000000\n    ---                                                     \n148816:        wy 2023-03-05 2023-03-06  0.000000  0.0000000\n148817:        wy 2023-03-06 2023-03-07  0.000000  0.0000000\n148818:        wy 2023-03-07 2023-03-08 38.809743  0.3434491\n148819:        wy 2023-03-08 2023-03-09  0.000000  0.0000000\n148820:        wy 2023-03-09 2023-03-10  0.000000  0.0000000"
  },
  {
    "objectID": "slides/day2-morning.html#version-aware-forecasting",
    "href": "slides/day2-morning.html#version-aware-forecasting",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version-aware forecasting",
    "text": "Version-aware forecasting\n\n# initialize dataframe for predictions\n# 5 columns: forecast date, target date, 2.5%, 50%, and 97.5% quantiles\npred_trailing &lt;- data.frame(matrix(NA, ncol = 5, nrow = 0))\ncolnames(pred_trailing) &lt;- c(\"forecast_date\", \"target_date\", 'tau..0.025', 'tau..0.500', 'tau..0.975')\n\nw &lt;- 120         #trailing window size\nh &lt;- 28          #number of days ahead\n\n# dates when predictions are made (set to be 1 month apart)\nfc_time_values &lt;- seq(from = t0_date, to = as.Date(\"2023-02-01\"), by = \"1 month\")\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data &lt;- epix_as_of(ca_archive, max_version = as.Date(fc_date))\n  # create lagged predictors\n  data$lagged_deaths &lt;- dplyr::lag(data$deaths, h) \n  data$lagged_cases &lt;- dplyr::lag(data$cases, h)\n  # perform quantile regression\n  rq_trailing &lt;- rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles, \n                    # only consider window of data\n                    data = data %&gt;% filter(time_value &gt; (max(time_value) - w))) \n  # sort estimated coefficients \n  coefs_sorted &lt;- t(apply(coef(rq_trailing), 1, sort))\n  colnames(coefs_sorted) &lt;- c('tau..0.025', 'tau..0.500', 'tau..0.975')\n  rq_trailing$coefficients &lt;- coefs_sorted\n  # construct data.frame with the right predictors for the target date\n  predictors &lt;- data.frame(lagged_deaths = tail(data$deaths, 1), \n                           lagged_cases = tail(data$cases, 1))\n  # make predictions for target date and add them to matrix of predictions\n  pred_trailing &lt;- rbind(pred_trailing, \n                         data.frame('forecast_date' = max(data$time_value),\n                                    'target_date' = max(data$time_value) + h, \n                                    predict(rq_trailing, newdata = predictors)))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#version-aware-predictions-cv-trailing",
    "href": "slides/day2-morning.html#version-aware-predictions-cv-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version-aware predictions (CV, trailing)",
    "text": "Version-aware predictions (CV, trailing)"
  },
  {
    "objectID": "slides/day2-morning.html#using-geo-information",
    "href": "slides/day2-morning.html#using-geo-information",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using geo information",
    "text": "Using geo information\n\nAssume we observe data over time from multiple locations (e.g. states or counties).\nWe could\n\nEstimate coefficients separately for each location (as we have done so far).\nFit one model using all locations together at each time point (geo-pooling). Estimated coefficients will not be location specific.\nEstimate coefficients separately for each location, but include predictors capturing averages across locations (partial geo-pooling)."
  },
  {
    "objectID": "slides/day2-morning.html#geo-pooling-trailing-window",
    "href": "slides/day2-morning.html#geo-pooling-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Geo-pooling (trailing window)",
    "text": "Geo-pooling (trailing window)\n\nusa_archive &lt;- data_archive$DT %&gt;% \n  as_epi_archive()\n\n# initialize dataframe for predictions\n# 6 columns: geo value, forecast date, target date, 2.5%, 50%, and 97.5% quantiles\npred_trailing &lt;- data.frame(matrix(NA, ncol = 6, nrow = 0))\ncolnames(pred_trailing) &lt;- c('geo_value', 'forecast_date', 'target_date',\n                             'tau..0.025', 'tau..0.500', 'tau..0.975')\n\nw &lt;- 120         #trailing window size\nh &lt;- 28          #number of days ahead\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data &lt;- epix_as_of(usa_archive, max_version = as.Date(fc_date))\n  \n  # create lagged predictors for each state \n  data &lt;- data %&gt;%\n    arrange(geo_value, time_value) %&gt;%  \n    group_by(geo_value) %&gt;%\n    mutate(lagged_deaths = dplyr::lag(deaths, h),\n           lagged_cases = dplyr::lag(cases, h)) %&gt;%\n    ungroup()\n  \n  # perform quantile regression\n  rq_trailing &lt;- rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles, \n                    # only consider window of data\n                    data = data %&gt;% filter(time_value &gt; (max(time_value) - w))) \n  # sort estimated coefficients \n  coefs_sorted &lt;- t(apply(coef(rq_trailing), 1, sort))\n  colnames(coefs_sorted) &lt;- c('tau..0.025', 'tau..0.500', 'tau..0.975')\n  rq_trailing$coefficients &lt;- coefs_sorted\n  \n  # construct dataframe with the right predictors for the target date\n  new_lagged_deaths &lt;- data %&gt;% \n    filter(time_value == max(time_value)) %&gt;%\n    select(geo_value, deaths)\n  \n  new_lagged_cases &lt;- data %&gt;% \n    filter(time_value == max(time_value)) %&gt;%\n    select(geo_value, cases)\n  \n  predictors &lt;- new_lagged_deaths %&gt;%\n    inner_join(new_lagged_cases, join_by(geo_value)) %&gt;%\n    rename(lagged_deaths = deaths,\n           lagged_cases = cases)\n  \n  # make predictions for target date and add them to matrix of predictions\n  pred_trailing &lt;- rbind(pred_trailing, \n                         data.frame(\n                           'geo_value' = predictors$geo_value,\n                           'forecast_date' = max(data$time_value),\n                           'target_date' = max(data$time_value) + h, \n                           predict(rq_trailing, newdata = predictors)))\n}\n\n# geo-pooled predictions for California\npred_ca &lt;- pred_trailing %&gt;%\n  filter(geo_value == 'ca') %&gt;%\n  rename(median = `tau..0.500`,\n         lower = `tau..0.025`,\n         upper = `tau..0.975`) %&gt;%\n  full_join(ca %&gt;% select(time_value, deaths), join_by(target_date == time_value)) %&gt;%\n  arrange(target_date)"
  },
  {
    "objectID": "slides/day2-morning.html#geo-pooled-predictions-for-california",
    "href": "slides/day2-morning.html#geo-pooled-predictions-for-california",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Geo-pooled predictions for California",
    "text": "Geo-pooled predictions for California"
  },
  {
    "objectID": "slides/day2-morning.html#partial-geo-pooling-trailing-window",
    "href": "slides/day2-morning.html#partial-geo-pooling-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Partial geo-pooling (trailing window)",
    "text": "Partial geo-pooling (trailing window)\n\n# initialize dataframe for predictions\n# 6 columns: geo value, forecast date, target date, 2.5%, 50%, and 97.5% quantiles\npred_trailing &lt;- data.frame(matrix(NA, ncol = 6, nrow = 0))\ncolnames(pred_trailing) &lt;- c('geo_value', 'forecast_date', 'target_date',\n                             'tau..0.025', 'tau..0.500', 'tau..0.975')\n\nw &lt;- 120         #trailing window size\nh &lt;- 28          #number of days ahead\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data &lt;- epix_as_of(usa_archive, max_version = as.Date(fc_date))\n  \n  # create lagged predictors \n  data &lt;- data %&gt;%\n    arrange(geo_value, time_value) %&gt;%  \n    group_by(geo_value) %&gt;%\n    mutate(lagged_deaths = dplyr::lag(deaths, h),\n           lagged_cases = dplyr::lag(cases, h)) %&gt;%\n    ungroup() %&gt;%\n    group_by(time_value) %&gt;%\n    mutate(avg_lagged_deaths = mean(lagged_deaths, na.rm = T),\n           avg_lagged_cases = mean(lagged_cases, na.rm = T)) %&gt;%\n    ungroup() \n  \n  # perform quantile regression\n  rq_trailing &lt;- rq(deaths ~ lagged_deaths + lagged_cases + avg_lagged_deaths +\n                      avg_lagged_cases, tau = quantiles, \n                    data = (data %&gt;% filter(geo_value == 'ca'))) \n  \n  # sort estimated coefficients \n  coefs_sorted &lt;- t(apply(coef(rq_trailing), 1, sort))\n  colnames(coefs_sorted) &lt;- c('tau..0.025', 'tau..0.500', 'tau..0.975')\n  rq_trailing$coefficients &lt;- coefs_sorted\n  \n  # construct data.frame with the right predictors for the target date\n  new_lagged_deaths &lt;- data %&gt;% \n    filter(time_value == max(time_value)) %&gt;%\n    select(geo_value, deaths) %&gt;%\n    mutate(avg_lagged_deaths = mean(deaths, na.rm = T)) %&gt;%\n    filter(geo_value == 'ca')\n  \n  new_lagged_cases &lt;- data %&gt;% \n    filter(time_value == max(time_value)) %&gt;%\n    select(geo_value, cases) %&gt;%\n    mutate(avg_lagged_cases = mean(cases, na.rm = T)) %&gt;%\n    filter(geo_value == 'ca')\n  \n  predictors &lt;- new_lagged_deaths %&gt;%\n    inner_join(new_lagged_cases, join_by(geo_value)) %&gt;%\n    rename(lagged_deaths = deaths,\n           lagged_cases = cases)\n  \n  # make predictions for target date and add them to matrix of predictions\n  pred_trailing &lt;- rbind(pred_trailing, \n                         data.frame(\n                           'geo_value' = predictors$geo_value,\n                           'forecast_date' = max(data$time_value),\n                           'target_date' = max(data$time_value) + h, \n                           predict(rq_trailing, newdata = predictors)))\n}\n\n# partially geo-pooled predictions for California\npred_ca &lt;- pred_trailing %&gt;%\n  filter(geo_value == 'ca') %&gt;%\n  rename(median = `tau..0.500`,\n         lower = `tau..0.025`,\n         upper = `tau..0.975`) %&gt;%\n  full_join(ca %&gt;% select(time_value, deaths), join_by(target_date == time_value)) %&gt;%\n  arrange(target_date)"
  },
  {
    "objectID": "slides/day2-morning.html#partially-geo-pooled-predictions-for-california",
    "href": "slides/day2-morning.html#partially-geo-pooled-predictions-for-california",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Partially geo-pooled predictions for California",
    "text": "Partially geo-pooled predictions for California"
  },
  {
    "objectID": "slides/day2-morning.html#final-slide",
    "href": "slides/day2-morning.html#final-slide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Final slide",
    "text": "Final slide\nThanks:\n\nThe whole CMU Delphi Team (across many institutions)\nOptum/UnitedHealthcare, Change Healthcare.\nGoogle, Facebook, Amazon Web Services.\nQuidel, SafeGraph, Qualtrics.\nCenters for Disease Control and Prevention.\nCouncil of State and Territorial Epidemiologists\n\n\n    \n\n\n\n\n\nForecasting and Time-Series Models — cmu-delphi/insightnet-workshop-2024"
  },
  {
    "objectID": "slides/day2-afternoon.html#section",
    "href": "slides/day2-afternoon.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Forecasting with {epipredict}",
    "text": "Forecasting with {epipredict}\n\n\n\n\nVenue – dd Somemonth yyyy"
  },
  {
    "objectID": "slides/day2-afternoon.html#outline",
    "href": "slides/day2-afternoon.html#outline",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Outline",
    "text": "Outline\n\n{epipredict}\nARX Models\nForecasting with Versioned Data"
  },
  {
    "objectID": "slides/day2-afternoon.html#fit-arx-on-training-set",
    "href": "slides/day2-afternoon.html#fit-arx-on-training-set",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fit ARX on training set",
    "text": "Fit ARX on training set\n\n# Split into train and test (before/after t0_date)\nt0_date &lt;- as.Date('2021-03-01')\ntrain &lt;- ca %&gt;% filter(time_value &lt;= t0_date)\ntest &lt;- ca %&gt;% filter(time_value &gt; t0_date)\n\nh &lt;- 28 \n\nepi_arx &lt;- arx_forecaster(epi_data = train %&gt;% as_epi_df(), \n                          outcome = \"deaths\", \n                          predictors = c(\"cases\", \"deaths\"),\n                          trainer = linear_reg() %&gt;% set_engine(\"lm\"),\n                          args_list = arx_args_list(lags = 0, \n                                                    ahead = h))\nepi_arx"
  },
  {
    "objectID": "slides/day2-afternoon.html#extract-workflow",
    "href": "slides/day2-afternoon.html#extract-workflow",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extract workflow",
    "text": "Extract workflow\n\nepi_arx$epi_workflow\n\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n (Intercept)   lag_0_cases  lag_0_deaths  \n     0.08133       0.01030       0.14011"
  },
  {
    "objectID": "slides/day2-afternoon.html#extract-prediction",
    "href": "slides/day2-afternoon.html#extract-prediction",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extract prediction",
    "text": "Extract prediction\n\nepi_arx$predictions\n\n# A tibble: 1 × 5\n  geo_value .pred        .pred_distn forecast_date target_date\n  &lt;chr&gt;     &lt;dbl&gt;             &lt;dist&gt; &lt;date&gt;        &lt;date&gt;     \n1 ca        0.368 quantiles(0.37)[2] 2021-03-01    2021-03-29 \n\n\n\nepi_arx$predictions %&gt;%\n  # first create a \"nested\" list-column\n  mutate(.pred_distn = nested_quantiles(.pred_distn)) %&gt;%\n  unnest(.pred_distn) # then unnest it\n\n# A tibble: 2 × 6\n  geo_value .pred values quantile_levels forecast_date target_date\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;           &lt;dbl&gt; &lt;date&gt;        &lt;date&gt;     \n1 ca        0.368  0.224            0.05 2021-03-01    2021-03-29 \n2 ca        0.368  0.513            0.95 2021-03-01    2021-03-29"
  },
  {
    "objectID": "slides/day2-afternoon.html#arx-on-trailing-window",
    "href": "slides/day2-afternoon.html#arx-on-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX on trailing window",
    "text": "ARX on trailing window\n\n# Specify the forecast dates\nfc_time_values &lt;- seq(\n  from = t0_date,\n  to = tail(ca$time_value, 1) - h,\n  by = \"1 day\"\n)\n\nw &lt;- 200  # trailing window length\n\n# Slide an arx_forecaster with appropriate outcome, predictions, lags, and trailing window\nepi_pred_cv_trailing &lt;- ca %&gt;%\n  epi_slide(\n    ~ arx_forecaster(epi_data = .x,\n                   outcome = \"deaths\", \n                   predictors = c(\"cases\", \"deaths\"), \n                   trainer = linear_reg() %&gt;% set_engine(\"lm\"),\n                   args_list = arx_args_list(lags = 0, ahead = h)\n                   )$predictions %&gt;%\n      pivot_quantiles_wider(.pred_distn),\n  # notice that `before` is not simply equal to w-1. That's because previously, \n  # when considering a window from t to t+w, we had access to y_t, ..., y_{t+w} \n  # and also to x_{t-h}, ..., x_{t+w-h}. (That's because of how we structured \n  # the dataframe after manually lagging x.) So we were \"cheating\" by saying that \n  # the trailing window had length w, as its actual size was w+h! \n  .window_size = (w+h-1), \n  .ref_time_values = fc_time_values,\n  .new_col_name = \"fc\"\n)\n\n# they match exactly\nhead(epi_pred_cv_trailing %&gt;% select(fc))\nhead(test %&gt;% select(pred_trailing_cv, time_value))\n\nThe method fitting on all past data up to the forecasting date can be implemented by changing before = Inf in epi_slide."
  },
  {
    "objectID": "slides/day2-afternoon.html#thanks",
    "href": "slides/day2-afternoon.html#thanks",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Thanks:",
    "text": "Thanks:\n\nThe whole CMU Delphi Team (across many institutions)\nOptum/UnitedHealthcare, Change Healthcare.\nGoogle, Facebook, Amazon Web Services.\nQuidel, SafeGraph, Qualtrics.\nCenters for Disease Control and Prevention.\nCouncil of State and Territorial Epidemiologists\n\n\n    \n\n\n\n\n\nForecasting with {epipredict} — cmu-delphi/insightnet-workshop-2024"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Schedule",
    "text": "Schedule\nShort description\n\nDay 1 Morning\nDay 1 Afternoon\nDay 2 Morning\nDay 2 Afternoon"
  },
  {
    "objectID": "index.html#instructors",
    "href": "index.html#instructors",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Instructors",
    "text": "Instructors\n\nRyan J. Tibshirani\nDaniel J. McDonald\nAlice Cima\nRachel Lobay"
  },
  {
    "objectID": "slides/day1-morning.html#section",
    "href": "slides/day1-morning.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Signal Discovery & Data Fetching",
    "text": "Signal Discovery & Data Fetching"
  },
  {
    "objectID": "slides/day1-morning.html#outline",
    "href": "slides/day1-morning.html#outline",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Outline",
    "text": "Outline\n\nAbout Delphi\nGoals of Delphi Epidata platform\nEpidata API\nFinding data sources and signals\nVersioned data"
  },
  {
    "objectID": "slides/day1-morning.html#about-delphi",
    "href": "slides/day1-morning.html#about-delphi",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "About Delphi",
    "text": "About Delphi\n\nFounded in 2012 at Carnegie Mellon University, now expanded to UC Berkeley, and University of British Columbia.\nCurrently 5 faculty, ~10 PhD students, ~15 staff (mostly software engineers).\nEasy to join us from anywhere (lots of volunteers during Covid-19 pandemic).\nWe are:\n\nCDC Center of Excellence for Influenza and Covid-19 Forecasting (2019-24).\nCDC Innovation Center for Outbreak Analytics and Disease Modeling (2024-29).\n\n\nOur mission: To develop the theory and practice of epidemic detection, tracking and forecasting, and their use in decision making, both public and private."
  },
  {
    "objectID": "slides/day1-morning.html#what-does-delphi-do",
    "href": "slides/day1-morning.html#what-does-delphi-do",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What does Delphi do?",
    "text": "What does Delphi do?\n\nProcure real-time, aggregated data streams informative of infectious diseases and syndromes, in collaboration with partners in industry and government.\nExtract signals and make them widely available via the Epidata platform & API.\nDevelop and deploy algorithms for epidemic detection, tracking, forecasting.\nDevelop and maintain statistical software packages for these tasks.\nMake it all production-grade, maximally-accessible, and open-source (to serve CDC, state and local public health agencies, epi-forecasting researchers, data journalists, the public)"
  },
  {
    "objectID": "slides/day1-morning.html#what-we-provide",
    "href": "slides/day1-morning.html#what-we-provide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What we provide",
    "text": "What we provide"
  },
  {
    "objectID": "slides/day1-morning.html#goals-of-delphi-epidata-platform-and-repository",
    "href": "slides/day1-morning.html#goals-of-delphi-epidata-platform-and-repository",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Goals of Delphi Epidata platform and repository",
    "text": "Goals of Delphi Epidata platform and repository\n\n\nBe the one-stop shop for aggregated epi-surveillance time-series (“epi-signals”)\n\nHence: include also signals available elsewhere, especially if they don’t keep data revisions - E.g. CDC’s own NSSP, NWSS\nBe the national historical repository of record & preserve the raw data\n\nBe the national clearinghouse for epi-signals, including those held elsewhere\n\nThe go-to place for signal discovery\n\nAdd value to existing signals and synthesize new ones\n\nAdded value: see next slide\nSynthesize new: via signal fusion, e.g. nowcasting\n\nBe the focal point for community-wide efforts to open up privately held data\n\nBetter positioned than government or industry"
  },
  {
    "objectID": "slides/day1-morning.html#the-bigger-goal",
    "href": "slides/day1-morning.html#the-bigger-goal",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "The bigger goal",
    "text": "The bigger goal\nThe goal is to make epi-surveillance more nimble, complete, standardized, robust, and real-time; and less burdensome on the health system itself. Epidata is not the solution; but we hope it is a blueprint towards such a solution."
  },
  {
    "objectID": "slides/day1-morning.html#what-is-the-epidata-repository",
    "href": "slides/day1-morning.html#what-is-the-epidata-repository",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What is the Epidata repository",
    "text": "What is the Epidata repository\nEpidata is a repository of aggregated epi-surveillance time series. To the full extent we can, we make everything free and open-source.\n\nTo date, it has accumulated over 5 billion records (each record is the value of a signal, at a particular date, and a particular location).\nAt the peak of the pandemic, we were receiving millions of API queries per day.\nData comes from: public health reporting, medical insurance claims, medical device data, Google search queries, wastewater, app-based mobility patterns.\nMany of our data streams simply aren’t available anywhere else.\nAdded value we provide: revision tracking, anomaly detection, trend detection, smoothing, imputation, geo-temporal-demographic disaggregation"
  },
  {
    "objectID": "slides/day1-morning.html#features-of-delphi-epidata",
    "href": "slides/day1-morning.html#features-of-delphi-epidata",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Features of Delphi Epidata",
    "text": "Features of Delphi Epidata\n\n\nBuilt-in support for:\n\nData revisions (“backfill”). Concepts of “reporting date” and “as of”.\nBackfill projection and alerting to changes in backfill dynamics\nGeo levels w/ auto-aggregation: county, MSA, HRR, state, HHS region, nation\n\nAlso esoteric ones: DMA, sewer sheds\n\nDemographic breakdown\nRepresentation for missingness and censoring\nPopulation sizes and fine-grained population density\n\nPre-computed smoothing and normalization (customization planned)\nAccess control\nCode is Open Source. Signals are as accessible (w/ API, SDK) as allowed by DUAs"
  },
  {
    "objectID": "slides/day1-morning.html#epidata-api-1",
    "href": "slides/day1-morning.html#epidata-api-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Epidata API",
    "text": "Epidata API\n\nDelphi’s Epidata API provides real-time access to epidemiological surveillance data.\nThe main endpoint (covidcast) providing daily updates about current COVID-19 and influenza activity across the United States.\nA variety of other endpoints, providing primarily historical data about various diseases including COVID-19, influenza, dengue fever, and norovirus in several countries.\nA full-featured R client is available for quick access to all data.\nA Legacy Python client is available, full-featured Python client in development."
  },
  {
    "objectID": "slides/day1-morning.html#some-of-our-data-sources",
    "href": "slides/day1-morning.html#some-of-our-data-sources",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Some of our data sources",
    "text": "Some of our data sources\n\nOngoing Sources:\n\nInsurance claims: %Covid {inpatient, outpatient}, by {county x day}\nGoogle Symptom searches: 7 symptoms groups, by {county x day}\nQuidel/Ortho antigen tests: %Covid by age group, by {county x day}\nNCHS Deaths: all-cause, pneumonia, flu, Covid, by {state x week}\nNSSP ED visits: %Covid, %flu, %RSV, by {county x week} (new!)\nNWSS Covid, by {sampling-site x day} (in progress)"
  },
  {
    "objectID": "slides/day1-morning.html#some-of-our-data-sources-1",
    "href": "slides/day1-morning.html#some-of-our-data-sources-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Some of our data sources",
    "text": "Some of our data sources\n\nActive during the pandemic, and could be restarted for the next PHE:\n\nHHS Hosp/ICU beds: Covid, flu, by age-group, by {state x day}, {facility x week}\nCTIS (“Delphi Facebook Survey”): many dozens of questions, by (county x day)\nSTLT-reported {cases, deaths} via {JHU, USAFacts}, by (country x day)\nSafegraph mobility: misc measures by {county x day},{county x week}"
  },
  {
    "objectID": "slides/day1-morning.html#some-of-our-pre-pandemic-data-sources",
    "href": "slides/day1-morning.html#some-of-our-pre-pandemic-data-sources",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Some of our Pre-Pandemic Data Sources",
    "text": "Some of our Pre-Pandemic Data Sources\n\n\nFluView ILINet, by {state x week}\nFluView Clinical (% positive flu, PH and clinical labs)\nGoogle Health Trends (GHT), precursor to Google Symptoms\nGoogle Flu Trends (GFT), precursor to to GHT\nTwitter flu\nAccess counts for flu-related CDC pages, by {city x week}\nAccess counts for flu-related Wikipedia entries by {day x hour}\nFlu-surv (flu hosp rates, now expanded to RESP-NET)\nMisc signals for dengue, norovirus\nMisc signals for PAHO countries, ECDC, KCDC, Taiwan,…\nDelphi ILI nowcasts, by {state x week}, visualized in “ILI Nearby” website\nDelphi ILI forecasts, by {state x week}"
  },
  {
    "objectID": "slides/day1-morning.html#installing-epidatr",
    "href": "slides/day1-morning.html#installing-epidatr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Installing epidatr",
    "text": "Installing epidatr\nInstalling the package is straightforward:\n\n# Install the CRAN version\npak::pkg_install(\"epidatr\")\n# Install the development version from the GitHub dev branch\n# pak::pkg_install(\"cmu-delphi/epidatr@dev\")\n\nThe CRAN listing is here.\n\n\n\nPython\n\n\nIn Python, install delphi-epidata from PyPI with pip install delphi-epidata."
  },
  {
    "objectID": "slides/day1-morning.html#using-epidatr-and-epidatpy",
    "href": "slides/day1-morning.html#using-epidatr-and-epidatpy",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using epidatr and epidatpy",
    "text": "Using epidatr and epidatpy\n\nThe following shows how to import the library and fetch Delphi’s COVID-19 Surveillance Streams from Facebook Survey CLI for county 06001:\n\n\n# Configure API key interactively, if needed. See\n# https://cmu-delphi.github.io/epidatr/articles/epidatr.html#api-keys for details.\n#save_api_key()\nlibrary(epidatr)\nres &lt;- pub_covidcast('fb-survey', 'smoothed_cli', 'county', 'day', geo_values = '06001',\n                     time_values = c(20200401, 20200405:20200414))\nhead(res)\n\n# A tibble: 6 × 15\n  geo_value signal     source geo_type time_type time_value direction issue     \n  &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;date&gt;         &lt;dbl&gt; &lt;date&gt;    \n1 06001     smoothed_… fb-su… county   day       2020-04-06        NA 2020-09-03\n2 06001     smoothed_… fb-su… county   day       2020-04-07        NA 2020-09-03\n3 06001     smoothed_… fb-su… county   day       2020-04-08        NA 2020-09-03\n4 06001     smoothed_… fb-su… county   day       2020-04-09        NA 2020-09-03\n5 06001     smoothed_… fb-su… county   day       2020-04-10        NA 2020-09-03\n6 06001     smoothed_… fb-su… county   day       2020-04-11        NA 2020-09-03\n# ℹ 7 more variables: lag &lt;dbl&gt;, missing_value &lt;dbl&gt;, missing_stderr &lt;dbl&gt;,\n#   missing_sample_size &lt;dbl&gt;, value &lt;dbl&gt;, stderr &lt;dbl&gt;, sample_size &lt;dbl&gt;"
  },
  {
    "objectID": "slides/day1-morning.html#api-keys",
    "href": "slides/day1-morning.html#api-keys",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "API keys",
    "text": "API keys\n\n\nAnyone may access the Epidata API anonymously without providing any personal data.\nAnonymous API access is subject to the following restrictions:\n\npublic datasets only\nrate limited to 60 requests per hour\nonly two parameters may have multiple selections\n\nAn API key grants priviledged access to the Epidata API and can be obtained by registering with us.\nPrivileges of registration:\n\nno rate limit\nno limit on multiple selections\n\n\n\n\n\n\n\n\n\nTip\n\n\nThe epidatr client automatically searches for the key in the DELPHI_EPIDATA_KEY environment variable. We recommend storing it in your .Renviron file, which R reads by default. More on setting your API key here."
  },
  {
    "objectID": "slides/day1-morning.html#finding-data-sources-and-signals-of-interest",
    "href": "slides/day1-morning.html#finding-data-sources-and-signals-of-interest",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Finding data sources and signals of interest",
    "text": "Finding data sources and signals of interest\n\n\nDiverse Data Streams\n\nVariety of Data: Access to medical claims data, cases and deaths, mobility data, and more.\nGeographic Coverage: Includes multiple regions, making it comprehensive yet complex.\nChallenge: Difficulty in pinpointing the specific data stream of interest.\n\nUsing the Documentation\n\nComprehensive Listings: Documentation details all available data sources and signals for both COVID-19 and other endpoints.\n\nDocs are great for a deep dive into the data, whereas the apps & tools are useful to see what is available…"
  },
  {
    "objectID": "slides/day1-morning.html#cheatsheet-of-tools-we-provide",
    "href": "slides/day1-morning.html#cheatsheet-of-tools-we-provide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Cheatsheet of tools we provide",
    "text": "Cheatsheet of tools we provide\nWe provide…\n\nA signal discovery app, to explore what epi-signals are available in Delphi Epidata and elsewhere in the community.\nA general signal visualization tool.\nA signal dashboard and a “classic” map-based version to visualize a core set of COVID-19 and flu indicators.\nA COVID-19 signal export app, a dashboard builder, and more!"
  },
  {
    "objectID": "slides/day1-morning.html#signal-dashboard---for-covid-19-flu-data",
    "href": "slides/day1-morning.html#signal-dashboard---for-covid-19-flu-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Signal dashboard - For COVID-19 & flu data",
    "text": "Signal dashboard - For COVID-19 & flu data\n\n\n\nThe signal dashboard displays a selection of our signals for COVID-19 and the flu.\nIncludes an “Advanced Data Export” to pull a selected signal & download as a CSV.\nBrowse by location or indicator to choose which signal you are interested in & then export the data for further analysis."
  },
  {
    "objectID": "slides/day1-morning.html#signal-discovery-app---browse-for-more-data",
    "href": "slides/day1-morning.html#signal-discovery-app---browse-for-more-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Signal discovery app - Browse for more data",
    "text": "Signal discovery app - Browse for more data\n\nSignal discovery app: An easy way to find data sources and signals (no programming required).\n\nSearch tool that is a good to browse & find data.\n\nLet’s try it out together! {height=auto, width = 50%}"
  },
  {
    "objectID": "slides/day1-morning.html#interactive-tooling",
    "href": "slides/day1-morning.html#interactive-tooling",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Interactive tooling",
    "text": "Interactive tooling\n\nOther main way to find data sources and signals in R… Functions to enhance data discovery in epidatr:\n\navail_endpoints() Function:\n\nLists all endpoints with brief descriptions.\nHighlights specific endpoints that cover non-US locations, facilitating targeted searches.\n\nOutput Format: Returns a tibble for easy viewing and analysis of available data sources.\n\n\n\navail_endpoints()"
  },
  {
    "objectID": "slides/day1-morning.html#using-the-covidcast_epidata-function",
    "href": "slides/day1-morning.html#using-the-covidcast_epidata-function",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using the covidcast_epidata() function",
    "text": "Using the covidcast_epidata() function\n\n\nIn-Depth Data Exploration\n\nFunction Overview: covidcast_epidata() provides detailed insights into data sources from the COVIDcast endpoint.\nSource List: Each data source is listed in covid_sources$sources, with associated tibbles describing included signals.\n\nTab Completion for Ease of Use\n\nEditor Support: In RStudio or similar editors, use tab completion to explore:\n\nData Sources: Type covid_sources$source$ to view available data sources.\nSignals: Type covid_sources$signals$ to see signal options with autocomplete assistance.\n\n\nFiltering Convenience: Signal names are prefixed with their respective data source for easier navigation.\n\n\n\ncovid_sources &lt;- covidcast_epidata()\nhead(covid_sources$sources, n = 2) # head(list, n = 2) will print the first two elements of the list"
  },
  {
    "objectID": "slides/day1-morning.html#fetching-data---covidcast-main-endpoint",
    "href": "slides/day1-morning.html#fetching-data---covidcast-main-endpoint",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetching data - COVIDcast main endpoint",
    "text": "Fetching data - COVIDcast main endpoint\n\n\nFetching data from the Delphi Epidata API is simple.\nThe pub_covidcast() function lets us access the covidcast endpoint.\nWe need to specify the following six arguments…\n\nsource: Data source name\nsignals: Signal name\ngeo_type: Geographic level\ntime_type: Time resolution\ngeo_values: Location(s)\ntime_values: times of interest\n\nLet’s give this a try!"
  },
  {
    "objectID": "slides/day1-morning.html#fetching-data---covidcast-main-endpoint-1",
    "href": "slides/day1-morning.html#fetching-data---covidcast-main-endpoint-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetching data - COVIDcast main endpoint",
    "text": "Fetching data - COVIDcast main endpoint\n\n\nlibrary(epidatr)\nlibrary(dplyr)\n\n\n# Obtain the most up-to-date version of the smoothed covid-like illness (CLI)\n# signal from the COVID-19 Trends and Impact survey for the US\nepidata &lt;- pub_covidcast(\n  source = \"fb-survey\",\n  signals = \"smoothed_cli\",\n  geo_type = \"nation\",\n  time_type = \"day\",\n  geo_values = \"us\",\n  time_values = epirange(20210105, 20210410)\n)\nhead(epidata) %&gt;% select(geo_value, signal, source, geo_type, time_value, issue, lag, value, stderr)\n\n# A tibble: 6 × 9\n  geo_value signal      source geo_type time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;  &lt;fct&gt;    &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 us        smoothed_c… fb-su… nation   2021-01-05 2021-01-10     5  1.18 0.0162\n2 us        smoothed_c… fb-su… nation   2021-01-06 2021-01-29    23  1.18 0.0163\n3 us        smoothed_c… fb-su… nation   2021-01-07 2021-01-29    22  1.20 0.0165\n4 us        smoothed_c… fb-su… nation   2021-01-08 2021-01-29    21  1.22 0.0167\n5 us        smoothed_c… fb-su… nation   2021-01-09 2021-01-29    20  1.22 0.0169\n6 us        smoothed_c… fb-su… nation   2021-01-10 2021-01-29    19  1.23 0.0171\n\n\nHere value is the requested signal – in this case, the smoothed estimate of the percentage of people with COVID-like illness, based on the symptom surveys, and stderr is its standard error."
  },
  {
    "objectID": "slides/day1-morning.html#returned-data---covidcast-main-endpoint",
    "href": "slides/day1-morning.html#returned-data---covidcast-main-endpoint",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Returned data - COVIDcast main endpoint",
    "text": "Returned data - COVIDcast main endpoint\n\n\npub_covidcast() outputs a tibble, where each row represents one observation.\nEach observation covers a set of events aggregated by time and by geographic region is a record in our database. Each such record includes:\ntime_value: time period when the events occurred.\ngeo_value: geographic region where the events occurred.\nvalue: estimated value.\nstderr: standard error of the estimate, usually referring to the sampling error.\nsample_size: number of events used in the estimation."
  },
  {
    "objectID": "slides/day1-morning.html#returned-data---covidcast-main-endpoint-1",
    "href": "slides/day1-morning.html#returned-data---covidcast-main-endpoint-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Returned data - COVIDcast main endpoint",
    "text": "Returned data - COVIDcast main endpoint\nCrucially—and unlike most other sources of COVID-19 data—our API reports two additional fields with each record:\n\nissue: The time period when this observation was published.\nlag: The time delay between when the events occurred and when this observation was published.\nMeaning that unlike most other sources of COVID data, it tracks the complete revision history of every signal.\nThis allows for historical reconstructions of what information was available at specific times. More on this soon!"
  },
  {
    "objectID": "slides/day1-morning.html#geographic-levels",
    "href": "slides/day1-morning.html#geographic-levels",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Geographic levels",
    "text": "Geographic levels\n\n\nThe Epidata API makes signals available at different geographic levels, depending on the endpoint\nFor the smoothed_cli signal, we can obtain values for each state\nSimply change geo_type and geo_values in the previous example to get…\n\n\n# Obtain the most up-to-date version of the smoothed covid-like illness (CLI)\n# signal from the COVID-19 Trends and Impact survey for all states\nstate_epidata &lt;- pub_covidcast(\n  source = \"fb-survey\",\n  signals = \"smoothed_cli\",\n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"*\",\n  time_values = epirange(20210105, 20210410)\n)\nhead(state_epidata) %&gt;% select(geo_value, signal, source, geo_type, time_value, issue, lag, value, stderr)\n\n# A tibble: 6 × 9\n  geo_value signal      source geo_type time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;  &lt;fct&gt;    &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 ak        smoothed_c… fb-su… state    2021-01-05 2021-01-10     5 0.747 0.250 \n2 al        smoothed_c… fb-su… state    2021-01-05 2021-01-10     5 2.36  0.187 \n3 ar        smoothed_c… fb-su… state    2021-01-05 2021-01-10     5 1.93  0.200 \n4 az        smoothed_c… fb-su… state    2021-01-05 2021-01-10     5 1.56  0.129 \n5 ca        smoothed_c… fb-su… state    2021-01-05 2021-01-10     5 1.24  0.0542\n6 co        smoothed_c… fb-su… state    2021-01-05 2021-01-10     5 0.934 0.107"
  },
  {
    "objectID": "slides/day1-morning.html#covidcast-main-endpoint---example-query",
    "href": "slides/day1-morning.html#covidcast-main-endpoint---example-query",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "COVIDcast main endpoint - Example query",
    "text": "COVIDcast main endpoint - Example query\n\nCounty geo_values are FIPS codes and are discussed in the API docs here. The example below is for Orange County, California.\n\nfb_county_data &lt;- pub_covidcast(\n  source = \"fb-survey\",\n  signals = \"smoothed_accept_covid_vaccine\",\n  geo_type = \"county\",\n  time_type = \"day\",\n  time_values = epirange(20201221, 20201225),\n  geo_values = \"06059\"\n)\nhead(fb_county_data) %&gt;% select(geo_value, signal, source, geo_type, time_value, issue, lag, value, stderr)\n\n# A tibble: 5 × 9\n  geo_value signal      source geo_type time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;  &lt;fct&gt;    &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 06059     smoothed_a… fb-su… county   2020-12-21 2020-12-22     1  80.9   2.08\n2 06059     smoothed_a… fb-su… county   2020-12-22 2020-12-23     1  78.9   1.76\n3 06059     smoothed_a… fb-su… county   2020-12-23 2020-12-24     1  80.0   1.50\n4 06059     smoothed_a… fb-su… county   2020-12-24 2020-12-25     1  79.3   1.35\n5 06059     smoothed_a… fb-su… county   2020-12-25 2020-12-26     1  80.3   1.21\n\n\n\n\n\n\nNote\n\n\nThe covidcast endpoint supports * in its time and geo fields. Try to obtain the signal values for all available counties by replacing geo_values = \"06059\" with geo_values = \"*\"."
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints  Hospitalizations",
    "text": "Example queries - Other endpoints  Hospitalizations\n\nCOVID-19 Hospitalization: Facility Lookup\n\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp_facility_lookup.html\n\npub_covid_hosp_facility_lookup(city = \"southlake\")\n\n# A tibble: 2 × 10\n  hospital_pk state ccn    hospital_name    address city  zip   hospital_subtype\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           \n1 450888      TX    450888 TEXAS HEALTH HA… 1545 E… SOUT… 76092 Short Term      \n2 670132      TX    670132 METHODIST SOUTH… 421 E … SOUT… 76092 Short Term      \n# ℹ 2 more variables: fips_code &lt;chr&gt;, is_metro_micro &lt;dbl&gt;\n\n# pub_covid_hosp_facility_lookup(state = \"WY\")\n# A non-example (there is no city called New York in Wyoming)\n# pub_covid_hosp_facility_lookup(state = \"WY\", city = \"New York\")"
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations-1",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints  Hospitalizations",
    "text": "Example queries - Other endpoints  Hospitalizations\n\nCOVID-19 Hospitalization by Facility\n\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp_facility.html\n\npub_covid_hosp_facility(\n  hospital_pks = \"100075\",\n  collection_weeks = epirange(20200101, 20200501)\n)\n\n\nCOVID-19 Hospitalization by State\n\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp.html\n\npub_covid_hosp_state_timeseries(states = \"MA\", dates = \"20200510\")"
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-flu-endpoints",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-flu-endpoints",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints  Flu endpoints",
    "text": "Example queries - Other endpoints  Flu endpoints\n\nFluSurv hospitalization data\n\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/flusurv.html\n\npub_flusurv(locations = \"ca\", epiweeks = 202001)\n\n\nFluview data\n\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/fluview.html\n\npub_fluview(regions = \"nat\", epiweeks = epirange(201201, 202001))\n\n\nNIDSS Flu\n\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/nidss_flu.html\n\npub_nidss_flu(regions = \"taipei\", epiweeks = epirange(200901, 201301))"
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-dengue-endpoints",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-dengue-endpoints",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints  Dengue endpoints",
    "text": "Example queries - Other endpoints  Dengue endpoints\n\nDelphi’s Dengue Nowcast\n\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/dengue_nowcast.html\n\npub_dengue_nowcast(locations = \"pr\", epiweeks = epirange(201401, 202301))\n\n\nNIDSS dengue\n\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/nidss_dengue.html\n\npub_nidss_dengue(locations = \"taipei\", epiweeks = epirange(200301, 201301))\n\n\nPAHO Dengue\n\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/paho_dengue.html\n\npub_paho_dengue(regions = \"ca\", epiweeks = epirange(200201, 202319))"
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-wikipedia",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-wikipedia",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints  Wikipedia",
    "text": "Example queries - Other endpoints  Wikipedia\nWikipedia access\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/wiki.html\n\npub_wiki(\n  language = \"en\",\n  articles = \"influenza\",\n  time_type = \"week\",\n  time_values = epirange(202001, 202319)\n)\n\n# A tibble: 64 × 6\n   article   count     total  hour epiweek     value\n   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;      &lt;dbl&gt;\n 1 influenza  6516 663604044    -1 2019-12-29   9.82\n 2 influenza 10244 789885521    -1 2020-01-05  13.0 \n 3 influenza 10728 783760384    -1 2020-01-12  13.7 \n 4 influenza 24843 785222292    -1 2020-01-19  31.6 \n 5 influenza 62850 780291898    -1 2020-01-26  80.5 \n 6 influenza 41768 778222703    -1 2020-02-02  53.7 \n 7 influenza 29434 767244708    -1 2020-02-09  38.4 \n 8 influenza 22714 764074572    -1 2020-02-16  29.7 \n 9 influenza 88758 767718009    -1 2020-02-23 116.  \n10 influenza 62433 759825311    -1 2020-03-01  82.2 \n# ℹ 54 more rows\n\n\n\n\n\n\n\n\nTip - public vs private methods\n\n\nAside from these public methods we’ve gone through (these start with pub_), there are private methods (these start with pvt_ when you type avail_endpoints()). These require private access keys to use (separate from the Delphi Epidata API key). To run these locally, you will need to store these secrets in your .Reviron file, or set them as environmental variables. See Private methods for examples of using private endpoints."
  },
  {
    "objectID": "slides/day1-morning.html#signal-metadata",
    "href": "slides/day1-morning.html#signal-metadata",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Signal metadata",
    "text": "Signal metadata\n\nSome endpoints provide additional metadata for signals.\n\nTime Information: Details on available time frames and last update times.\nGeography Information: Details on available geography types.\n\nKey Endpoints for Metadata\n\npub_covidcast_meta(): Access metadata for the COVIDcast endpoint.\npub_fluview_meta(): Get metadata for the FluView endpoint.\npub_meta(): General metadata for the Delphi Epidata API."
  },
  {
    "objectID": "slides/day1-morning.html#panel-data-1",
    "href": "slides/day1-morning.html#panel-data-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Panel data",
    "text": "Panel data\n\n\nPanel data or longitudinal data, contain cross-sectional measurements of subjects over time.\nIn table form, panel data is a time index + one or more locations/keys.\nFor example: The estimated percentage of outpatient doctor visits that are COVID-related in MA over 2021 (docs):\n\n\n\nAn `epi_df` object, 6 x 3 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2021-12-17\n\n# A tibble: 6 × 3\n  geo_value time_value percent_cli\n* &lt;chr&gt;     &lt;date&gt;           &lt;dbl&gt;\n1 ma        2021-03-01        3.31\n2 ma        2021-03-02        2.87\n3 ma        2021-03-03        2.95\n4 ma        2021-03-04        3.17\n5 ma        2021-03-05        3.35\n6 ma        2021-03-06        3.38"
  },
  {
    "objectID": "slides/day1-morning.html#examples-of-panel-data---covid-19-cases",
    "href": "slides/day1-morning.html#examples-of-panel-data---covid-19-cases",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of panel data - COVID-19 cases",
    "text": "Examples of panel data - COVID-19 cases\nJHU CSSE COVID cases in the U.S. (smoothed with a 7-day trailing average) over the year of the pandemic (April 15, 2020 – April 15, 2021).\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/jhu-csse.html"
  },
  {
    "objectID": "slides/day1-morning.html#examples-of-panel-data---chng-cli",
    "href": "slides/day1-morning.html#examples-of-panel-data---chng-cli",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of panel data - CHNG-CLI",
    "text": "Examples of panel data - CHNG-CLI\nChange Healthcare COVID-like illness (CHNG-CLI) reports the percentage of outpatient visits for COVID-related symptoms, based on deidentified Change Healthcare claims data.\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/chng.html"
  },
  {
    "objectID": "slides/day1-morning.html#examples-of-panel-data---chng-covid",
    "href": "slides/day1-morning.html#examples-of-panel-data---chng-covid",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of panel data - CHNG-COVID",
    "text": "Examples of panel data - CHNG-COVID\nChange Healthcare COVID (CHNG-COVID) reports the percentage of outpatient visits with confirmed COVID-19, based on Change Healthcare claims data.\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/paho_dengue.html"
  },
  {
    "objectID": "slides/day1-morning.html#examples-of-panel-data---ctis-cli",
    "href": "slides/day1-morning.html#examples-of-panel-data---ctis-cli",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of panel data - CTIS-CLI",
    "text": "Examples of panel data - CTIS-CLI\nCOVID-19 Trends and Impact Survey CLI (CTIS-CLI) estimates the percentage of the population with COVID-like illness based on Delphi’s Facebook user surveys.\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/fb-survey.html"
  },
  {
    "objectID": "slides/day1-morning.html#all-together---visualizing-multiple-panel-data-signals",
    "href": "slides/day1-morning.html#all-together---visualizing-multiple-panel-data-signals",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "All together - Visualizing multiple panel data signals",
    "text": "All together - Visualizing multiple panel data signals\nExample: gathering different signals + visualizing panel data"
  },
  {
    "objectID": "slides/day1-morning.html#all-together---visualizing-multiple-panel-data-signals-1",
    "href": "slides/day1-morning.html#all-together---visualizing-multiple-panel-data-signals-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "All together - Visualizing multiple panel data signals",
    "text": "All together - Visualizing multiple panel data signals\nExample: gathering different signals + scaling + visualizing panel data\n\nThe auxiliary signals track changes in officially reported cases quite well. This is more clear when they have all been placed on the same range as reported cases per 100,000 people."
  },
  {
    "objectID": "slides/day1-morning.html#covid-19-cases-and-deaths-in-ca-example",
    "href": "slides/day1-morning.html#covid-19-cases-and-deaths-in-ca-example",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "COVID-19 cases and deaths in CA example",
    "text": "COVID-19 cases and deaths in CA example\n\nTakeaway: Cases appear to strongly correlate with deaths several weeks later."
  },
  {
    "objectID": "slides/day1-morning.html#intro-to-versioned-data",
    "href": "slides/day1-morning.html#intro-to-versioned-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Intro to versioned data",
    "text": "Intro to versioned data\n\nIn panel data, we’ve seen that time is indicated by time_value.\nNow, we add a second time index to indicate the data version…\n\n\n\nKey: &lt;geo_value, time_value, version&gt;\n   geo_value time_value    version percent_cli\n      &lt;char&gt;     &lt;Date&gt;     &lt;Date&gt;       &lt;num&gt;\n1:        ma 2021-03-01 2021-03-04    6.470187\n2:        ma 2021-03-01 2021-03-05    6.207676\n3:        ma 2021-03-01 2021-03-06    5.664716\n4:        ma 2021-03-01 2021-03-07    5.636590\n5:        ma 2021-03-01 2021-03-08    5.665734\n6:        ma 2021-03-01 2021-03-09    5.537332\n\n\n\nNote that this feature can be indicated in different ways (ex. version, issue, release, as_of)."
  },
  {
    "objectID": "slides/day1-morning.html#versioned-panel-data",
    "href": "slides/day1-morning.html#versioned-panel-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Versioned panel data",
    "text": "Versioned panel data\nEstimated percentage of outpatient (DV-CLI) data across multiple issue dates, with updates and revisions to past data as new issue dates are released:"
  },
  {
    "objectID": "slides/day1-morning.html#latency-and-revision-in-signals",
    "href": "slides/day1-morning.html#latency-and-revision-in-signals",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Latency and revision in signals",
    "text": "Latency and revision in signals\n\nLatency refers to the delay between data collection and availability.\n\nExample: A signal based on medical insurance claims may take several days to appear but is subject to delays as claims are processed over weeks.\n\nRevision occurs when data is updated or corrected after initial publication, often due to new information or late reporting.\n\nExample: COVID-19 case reports are revised frequently after initial publication as new data comes in or reporting backlogs are cleared."
  },
  {
    "objectID": "slides/day1-morning.html#latency-and-revision-in-signals---example",
    "href": "slides/day1-morning.html#latency-and-revision-in-signals---example",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Latency and revision in signals - Example",
    "text": "Latency and revision in signals - Example\n\n\nRecall the first example of panel & versioned data we’ve seen.\n\n\n\nThis signal is 3 days latent (version - time_value) & clearly undergoes revision over time (ex. consider March 1’s percent_cli across version).\n\n\n\nKey: &lt;geo_value, time_value, version&gt;\n   geo_value time_value    version percent_cli\n      &lt;char&gt;     &lt;Date&gt;     &lt;Date&gt;       &lt;num&gt;\n1:        ma 2021-03-01 2021-03-04    6.470187\n2:        ma 2021-03-01 2021-03-05    6.207676\n3:        ma 2021-03-01 2021-03-06    5.664716\n4:        ma 2021-03-01 2021-03-07    5.636590\n5:        ma 2021-03-01 2021-03-08    5.665734\n6:        ma 2021-03-01 2021-03-09    5.537332\n\n\n\nThe amount of lag in reporting can vary, and not all visits are reported with the same lag.\n\n\n\n     min median     mean     max\n  3 days 3 days 3.6 days 16 days"
  },
  {
    "objectID": "slides/day1-morning.html#revisions",
    "href": "slides/day1-morning.html#revisions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Revisions",
    "text": "Revisions\nMany data sources are subject to revisions:\n\nCase and death counts are frequently corrected or adjusted by authorities.\nMedical claims data can take weeks to be submitted and processed.\n\n\n\nLab tests and medical records can be backlogged for a variety of reasons.\nSurveys are not always completed promptly.\nKey: An accurate revision log is crucial for researchers building forecasts of COVID-19 cases or outcomes. A forecast that is made today can should rely on information we have access to today."
  },
  {
    "objectID": "slides/day1-morning.html#types-of-revisions",
    "href": "slides/day1-morning.html#types-of-revisions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Types of revisions",
    "text": "Types of revisions\n\nSources that don’t revise - Ex. Facebook or Google symptoms (provisional and final are the same)\nPredictable revisions - Ex. Claims data (CHNG) and public health reports aligned by observation/test, hosp, or death date\nRevisions that are large and erratic to predict - Ex. COVID cases and deaths"
  },
  {
    "objectID": "slides/day1-morning.html#types-of-revisions---comparison-between-2.-and-3.",
    "href": "slides/day1-morning.html#types-of-revisions---comparison-between-2.-and-3.",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Types of revisions - Comparison between 2. and 3.",
    "text": "Types of revisions - Comparison between 2. and 3.\n\n\nRevision behavior for two indicators in the HRR containing Charlotte, NC.\n\n\n\nDV-CLI signal (left)  was regularly revised throughout the period, although effects fade farther back.\nJHU CSSE cases (right)  remain “as reported” on Sept. 28, with a spike toward the end of this period, until a major correction is made on Oct. 19, which brings this down & affects prior data."
  },
  {
    "objectID": "slides/day1-morning.html#key-takeaways",
    "href": "slides/day1-morning.html#key-takeaways",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nMedical claims revisions: More systematic and predictable.\nCOVID-19 case report revisions: Erratic and often unpredictable.\nLarge spikes or anomalies can occur as:\n\nReporting backlogs are cleared.\nChanges in case definitions are implemented."
  },
  {
    "objectID": "slides/day1-morning.html#reporting-backlogs---example",
    "href": "slides/day1-morning.html#reporting-backlogs---example",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Reporting backlogs - Example",
    "text": "Reporting backlogs - Example\n\nLeft: Reported cases per day in Bexar County, Texas, during the summer of 2020. On July 16, 4,810 backlogged cases were reported, reflecting a 2-week delay. This caused a prolonged spike due to the 7-day trailing average applied to the counts.\nRight: CTIS estimates of CLI-in-community showed more stable underlying trends."
  },
  {
    "objectID": "slides/day1-morning.html#reporting-backlogs---key-takeaways",
    "href": "slides/day1-morning.html#reporting-backlogs---key-takeaways",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Reporting backlogs - Key takeaways",
    "text": "Reporting backlogs - Key takeaways\n\nReporting issues been common across U.S. jurisdictions.\nFor example, audits have regularly discovered misclassified or unreported cases and deaths.\nThis underscores the value of cross-checking data with external sources not part of the same reporting systems."
  },
  {
    "objectID": "slides/day1-morning.html#versioned-data-in-epidatr",
    "href": "slides/day1-morning.html#versioned-data-in-epidatr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Versioned data in epidatr",
    "text": "Versioned data in epidatr\n\n\nEpidata API contains comprehensive data record, capturing each signal’s estimate, location, date, and update timeline.\nExample: Doctor Visits Signal (from the covidcast endpoint)\n\nEstimates the percentage of outpatient doctor visits that are COVID-related. To give a specific example, let’s consider the estimate for PA on May 1, 2020:\n\n\n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-01\"),\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  as_of = \"2020-05-07\"\n)\nhead(epidata) %&gt;% select(geo_value, signal, source, time_value, issue, lag, value)\n\n# A tibble: 1 × 7\n  geo_value signal           source        time_value issue        lag value\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-visits 2020-05-01 2020-05-07     6  2.58\n\n\n\nInitial estimate was issued on May 7, 2020 (due to delay from aggregation and ingestion by the API)."
  },
  {
    "objectID": "slides/day1-morning.html#understanding-data-as-of-a-specific-date",
    "href": "slides/day1-morning.html#understanding-data-as-of-a-specific-date",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Understanding data “as of” a specific date",
    "text": "Understanding data “as of” a specific date\n\n\nRequesting Specific Data Versions:\n\nUse as_of, issues, or lag arguments to specify data availability.\nOnly one argument can be used at a time; not all endpoints support all three.\n\nWe’ve already used the as_of argument, so let’s try lag\n\nExample for May 7, 2020 (we should get the same output as before):\n\n\n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-01\"),\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  lag = 6\n)\nhead(epidata) %&gt;% select(geo_value, signal, source, time_value, issue, lag, value, stderr)\n\n# A tibble: 1 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-07     6  2.58     NA\n\n\nResult: Estimate of &lt;3% issued on May 7, 2020."
  },
  {
    "objectID": "slides/day1-morning.html#understanding-data-as-of-a-specific-date-1",
    "href": "slides/day1-morning.html#understanding-data-as-of-a-specific-date-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Understanding data “as of” a specific date",
    "text": "Understanding data “as of” a specific date\n\nDefault behaviour: If we don’t specify as_of, we get the most recent estimate:\n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-01\"),\n  geo_type = \"state\",\n  geo_values = \"pa\"\n)\nhead(epidata) %&gt;% select(geo_value, signal, source, time_value, issue, lag, value, stderr)\n\n# A tibble: 1 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  5.97     NA\n\n\n\nSubstantial Estimate Change:\n\nEstimate increased from &lt;3% to almost 6% after May 7, reflecting new data on visits from May 1.\n\nCritical for Forecasting:\n\nAccurate backtesting requires using data available at the time of model fitting, not later updates, to ensure valid forecasting results."
  },
  {
    "objectID": "slides/day1-morning.html#multiple-issues-of-observations",
    "href": "slides/day1-morning.html#multiple-issues-of-observations",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Multiple issues of observations",
    "text": "Multiple issues of observations\nBy using the issues argument, we can request all issues in a certain time period:\n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-01\"),\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  issues = epirange(\"2020-05-01\", \"2020-05-15\")\n)\nhead(epidata) %&gt;% select(geo_value, signal, source, time_value, issue, lag, value, stderr)\n\n# A tibble: 6 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-07     6  2.58     NA\n2 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-08     7  3.28     NA\n3 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-09     8  3.32     NA\n4 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-12    11  3.59     NA\n5 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-13    12  3.63     NA\n6 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-14    13  3.66     NA"
  },
  {
    "objectID": "slides/day1-morning.html#observations-issued-with-a-specific-lag",
    "href": "slides/day1-morning.html#observations-issued-with-a-specific-lag",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Observations issued with a specific lag",
    "text": "Observations issued with a specific lag\n\n\nWe can use the lag argument to request only data reported with a certain lag.\nExample: Request a lag of 7 days fetches only data issued exactly 7 days after the corresponding time_value:\n\n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-07\"),\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  lag = 7\n)\nhead(epidata) %&gt;% select(geo_value, signal, source, time_value, issue, lag, value, stderr)\n\n# A tibble: 5 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-08     7  3.28     NA\n2 pa        smoothed_adj_cli doctor-vi… 2020-05-02 2020-05-09     7  3.23     NA\n3 pa        smoothed_adj_cli doctor-vi… 2020-05-05 2020-05-12     7  2.78     NA\n4 pa        smoothed_adj_cli doctor-vi… 2020-05-06 2020-05-13     7  2.56     NA\n5 pa        smoothed_adj_cli doctor-vi… 2020-05-07 2020-05-14     7  2.19     NA"
  },
  {
    "objectID": "slides/day1-morning.html#query-results-exclusion",
    "href": "slides/day1-morning.html#query-results-exclusion",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Query results exclusion",
    "text": "Query results exclusion\n\n\nAlthough the query we ran on the previous slide requested values from May 1 to May 7, May 3 and May 4 were not included due to a 7-day lag.\nResults for those dates appear only if updates are issued on the corresponding lag day (e.g., May 10).\n\n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-03\", \"2020-05-03\"),\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  issues = epirange(\"2020-05-09\", \"2020-05-15\")\n)\nhead(epidata) %&gt;% select(geo_value, signal, source, time_value, issue, lag, value, stderr)\n\n# A tibble: 5 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-03 2020-05-09     6  2.79     NA\n2 pa        smoothed_adj_cli doctor-vi… 2020-05-03 2020-05-12     9  3.02     NA\n3 pa        smoothed_adj_cli doctor-vi… 2020-05-03 2020-05-13    10  3.04     NA\n4 pa        smoothed_adj_cli doctor-vi… 2020-05-03 2020-05-14    11  3.02     NA\n5 pa        smoothed_adj_cli doctor-vi… 2020-05-03 2020-05-15    12  3.05     NA"
  },
  {
    "objectID": "slides/day1-morning.html#main-takeaways",
    "href": "slides/day1-morning.html#main-takeaways",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Main takeaways",
    "text": "Main takeaways\n\n\nDelphi Epidata: A one-stop platform for real-time epidemic data, providing aggregated signals for disease tracking and forecasting from diverse sources like health records, mobility patterns, and more.\nEpidata API: Open-access API delivering up-to-date, granular epidemiological data + makes all historical versions available.\nEpidatr: Enables you to access Delphi’s epidemiological data through R and Python, offering easy installation, powerful API functions, and interactive tools for discovering and analyzing health signals.\nVersioned Data and Latency: Panel data captures time-series trends, which are often subject to revision. A standout feature of this API is its inclusion of two critical fields…\n\nissue: When the data was published\nlag: The delay between the event and when it was published\n\nto manage latency and revisions for transparency and more accurate analysis."
  },
  {
    "objectID": "slides/day1-morning.html#final-slide",
    "href": "slides/day1-morning.html#final-slide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Final slide",
    "text": "Final slide\nThanks:\n\nThe whole CMU Delphi Team (across many institutions)\nOptum/UnitedHealthcare, Change Healthcare.\nGoogle, Facebook, Amazon Web Services.\nQuidel, SafeGraph, Qualtrics.\nCenters for Disease Control and Prevention.\nCouncil of State and Territorial Epidemiologists\n\n\n    \n\n\n\n\n\nDay 1 Morning — cmu-delphi/insightnet-workshop-2024"
  }
]