[
  {
    "objectID": "slides/day1-afternoon.html#section",
    "href": "slides/day1-afternoon.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Explore, clean & transform data",
    "text": "Explore, clean & transform data"
  },
  {
    "objectID": "slides/day1-afternoon.html#outline",
    "href": "slides/day1-afternoon.html#outline",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Outline",
    "text": "Outline\n\nEssentials of dplyr and tidyr\nEpiverse software ecosystem\nPanel and versioned data in the epiverse\nBasic Nowcasting using epiprocess\nMotivating case study"
  },
  {
    "objectID": "slides/day1-afternoon.html#down-with-spreadsheets-for-data-manipulation",
    "href": "slides/day1-afternoon.html#down-with-spreadsheets-for-data-manipulation",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Down with Spreadsheets for Data Manipulation",
    "text": "Down with Spreadsheets for Data Manipulation\n\nSpreadsheets make it difficult to rerun analyses consistently.\nUsing R (and dplyr) allows for:\n\nReproducibility\nEase of modification\n\nRecommendation: Avoid manual edits; instead, use code for transformations.\nLet’s see what we mean by this…"
  },
  {
    "objectID": "slides/day1-afternoon.html#introduction-to-dplyr",
    "href": "slides/day1-afternoon.html#introduction-to-dplyr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Introduction to dplyr",
    "text": "Introduction to dplyr\n\n\ndplyr is a powerful package in R for data manipulation.\nIt is part of the tidyverse, which includes a collection of packages designed to work together… Here’s some of it’s greatest hits:\n\n\n\n  Source"
  },
  {
    "objectID": "slides/day1-afternoon.html#introduction-to-dplyr-1",
    "href": "slides/day1-afternoon.html#introduction-to-dplyr-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Introduction to dplyr",
    "text": "Introduction to dplyr\n\nTo load dplyr you may simply load the tidyverse package:\n\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)  # Load tidyverse, which includes dplyr & tidyr"
  },
  {
    "objectID": "slides/day1-afternoon.html#introduction-to-dplyr-2",
    "href": "slides/day1-afternoon.html#introduction-to-dplyr-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Introduction to dplyr",
    "text": "Introduction to dplyr\nOur focus will be on basic operations like selecting and filtering data.\n\n\nSource"
  },
  {
    "objectID": "slides/day1-afternoon.html#downloading-jhu-csse-covid-19-case-data",
    "href": "slides/day1-afternoon.html#downloading-jhu-csse-covid-19-case-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Downloading JHU CSSE COVID-19 Case Data",
    "text": "Downloading JHU CSSE COVID-19 Case Data\n\nLet’s start with something familiar… Here’s a task for you:\nUse pub_covidcast() to download JHU CSSE COVID-19 confirmed case data (confirmed_incidence_num) for CA, NC, and NY from March 1, 2022 to March 31, 2022 as of January 1, 2024.\nTry this for yourself. Then click the dropdown on the next slide to check your work…"
  },
  {
    "objectID": "slides/day1-afternoon.html#downloading-jhu-csse-covid-19-case-data-1",
    "href": "slides/day1-afternoon.html#downloading-jhu-csse-covid-19-case-data-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Downloading JHU CSSE COVID-19 Case Data",
    "text": "Downloading JHU CSSE COVID-19 Case Data\n\n\nCode\nlibrary(epidatr)\n\ncases_df &lt;- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_incidence_num\",\n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"ca,nc,ny\",\n  time_values = epirange(20220301, 20220331),\n  as_of = as.Date(\"2024-01-01\")\n)\n\n\nNow we only really need a few columns here…\n\ncases_df &lt;- cases_df |&gt; \n  select(geo_value, time_value, raw_cases = value) # We'll talk more about this soon :)"
  },
  {
    "objectID": "slides/day1-afternoon.html#ways-to-inspect-the-dataset",
    "href": "slides/day1-afternoon.html#ways-to-inspect-the-dataset",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Ways to Inspect the Dataset",
    "text": "Ways to Inspect the Dataset\nUse head() to view the first six row of the data\n\nhead(cases_df)  # First 6 rows\n\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 nc        2022-03-01      1231\n3 ny        2022-03-01      1487\n4 ca        2022-03-02      7044\n5 nc        2022-03-02      2243\n6 ny        2022-03-02      1889\n\n\nand tail to view the last six\n\n\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-30      3785\n2 nc        2022-03-30      1067\n3 ny        2022-03-30      3127\n4 ca        2022-03-31      4533\n5 nc        2022-03-31      1075\n6 ny        2022-03-31      4763"
  },
  {
    "objectID": "slides/day1-afternoon.html#ways-to-inspect-the-dataset-1",
    "href": "slides/day1-afternoon.html#ways-to-inspect-the-dataset-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Ways to Inspect the Dataset",
    "text": "Ways to Inspect the Dataset\nNow, for our first foray into the tidyverse…\nUse glimpse() to get a compact overview of the dataset.\n\nglimpse(cases_df)\n\nRows: 93\nColumns: 3\n$ geo_value  &lt;chr&gt; \"ca\", \"nc\", \"ny\", \"ca\", \"nc\", \"ny\", \"ca\", \"nc\", \"ny\", \"ca\",…\n$ time_value &lt;date&gt; 2022-03-01, 2022-03-01, 2022-03-01, 2022-03-02, 2022-03-02…\n$ raw_cases  &lt;dbl&gt; 4310, 1231, 1487, 7044, 2243, 1889, 7509, 2377, 2390, 3586,…"
  },
  {
    "objectID": "slides/day1-afternoon.html#creating-tibbles",
    "href": "slides/day1-afternoon.html#creating-tibbles",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Creating Tibbles",
    "text": "Creating Tibbles\n\nTibbles: Modern data frames with enhanced features.\nRows represent observations (or cases).\nColumns represent variables (or features).\nYou can create tibbles manually using the tibble() function.\n\n\ntibble(x = letters, y = 1:26)\n\n# A tibble: 26 × 2\n   x         y\n   &lt;chr&gt; &lt;int&gt;\n 1 a         1\n 2 b         2\n 3 c         3\n 4 d         4\n 5 e         5\n 6 f         6\n 7 g         7\n 8 h         8\n 9 i         9\n10 j        10\n# ℹ 16 more rows"
  },
  {
    "objectID": "slides/day1-afternoon.html#selecting-columns-with-select",
    "href": "slides/day1-afternoon.html#selecting-columns-with-select",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Selecting Columns with select()",
    "text": "Selecting Columns with select()\nThe select() function is used to pick specific columns from your dataset.\n\nselect(cases_df, geo_value, time_value)  # Select the 'geo_value' and 'time_value' columns\n\n# A tibble: 93 × 2\n   geo_value time_value\n   &lt;chr&gt;     &lt;date&gt;    \n 1 ca        2022-03-01\n 2 nc        2022-03-01\n 3 ny        2022-03-01\n 4 ca        2022-03-02\n 5 nc        2022-03-02\n 6 ny        2022-03-02\n 7 ca        2022-03-03\n 8 nc        2022-03-03\n 9 ny        2022-03-03\n10 ca        2022-03-04\n# ℹ 83 more rows"
  },
  {
    "objectID": "slides/day1-afternoon.html#selecting-columns-with-select-1",
    "href": "slides/day1-afternoon.html#selecting-columns-with-select-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Selecting Columns with select()",
    "text": "Selecting Columns with select()\nYou can exclude columns by prefixing the column names with a minus sign -.\n\nselect(cases_df, -raw_cases)  # Exclude the 'raw_cases' column from the dataset\n\n# A tibble: 93 × 2\n   geo_value time_value\n   &lt;chr&gt;     &lt;date&gt;    \n 1 ca        2022-03-01\n 2 nc        2022-03-01\n 3 ny        2022-03-01\n 4 ca        2022-03-02\n 5 nc        2022-03-02\n 6 ny        2022-03-02\n 7 ca        2022-03-03\n 8 nc        2022-03-03\n 9 ny        2022-03-03\n10 ca        2022-03-04\n# ℹ 83 more rows"
  },
  {
    "objectID": "slides/day1-afternoon.html#extracting-columns-with-pull",
    "href": "slides/day1-afternoon.html#extracting-columns-with-pull",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extracting Columns with pull()",
    "text": "Extracting Columns with pull()\n\npull(): Extract a column as a vector.\nLet’s try this with the cases column…\n\n\npull(cases_df, raw_cases) \n\n [1] 4310 1231 1487 7044 2243 1889 7509 2377 2390 3586 2646  350 1438    0 3372\n[16] 6465    0 2343 6690 4230 1033 3424  894 1025 4591 1833 1691 5359 1783 1747\n[31] 2713 1849 2229 1623    0 1396 5151    0 2202 4826 3130  982 1831  649 3128\n[46] 3706    0 2039 6143 2742 2356 4204 1740 2052 3256    0 2188 4659    0 2667\n[61] 5499 2508 1177 3004  819 1603 3943 1602  551 3550 1288 6596 1960 1224 3542\n[76] 1035    0    0 3384    0 5908 2811 2291 2286 1846  624 2394 3785 1067 3127\n[91] 4533 1075 4763"
  },
  {
    "objectID": "slides/day1-afternoon.html#filtering-rows-with-filter",
    "href": "slides/day1-afternoon.html#filtering-rows-with-filter",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Filtering Rows with filter()",
    "text": "Filtering Rows with filter()\n\nThe filter() function allows you to select rows that meet specific conditions.\nConditions can involve column values, such as filtering for only NC or higher numbers of cases.\nThis enables you to narrow down your dataset to focus on relevant data.\n\n\nfilter(cases_df, geo_value == \"nc\", raw_cases &gt; 500)  # Filter for NC with raw daily cases &gt; 500\n\n# A tibble: 22 × 3\n   geo_value time_value raw_cases\n   &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n 1 nc        2022-03-01      1231\n 2 nc        2022-03-02      2243\n 3 nc        2022-03-03      2377\n 4 nc        2022-03-04      2646\n 5 nc        2022-03-07      4230\n 6 nc        2022-03-08       894\n 7 nc        2022-03-09      1833\n 8 nc        2022-03-10      1783\n 9 nc        2022-03-11      1849\n10 nc        2022-03-14      3130\n# ℹ 12 more rows"
  },
  {
    "objectID": "slides/day1-afternoon.html#combining-select-and-filter-functions",
    "href": "slides/day1-afternoon.html#combining-select-and-filter-functions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Combining select() and filter() Functions",
    "text": "Combining select() and filter() Functions\n\nYou can further combine select() and filter() to further refine the dataset.\nUse select() to choose columns and filter() to narrow down rows.\nThis helps in extracting the exact data needed for analysis.\n\n\nselect(filter(cases_df, geo_value == \"nc\", raw_cases &gt; 1000), time_value, raw_cases) |&gt; \n  head()\n\n# A tibble: 6 × 2\n  time_value raw_cases\n  &lt;date&gt;         &lt;dbl&gt;\n1 2022-03-01      1231\n2 2022-03-02      2243\n3 2022-03-03      2377\n4 2022-03-04      2646\n5 2022-03-07      4230\n6 2022-03-09      1833"
  },
  {
    "objectID": "slides/day1-afternoon.html#using-the-pipe-operator",
    "href": "slides/day1-afternoon.html#using-the-pipe-operator",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using the Pipe Operator |>",
    "text": "Using the Pipe Operator |&gt;\n\nThe pipe operator (|&gt;) makes code more readable by chaining multiple operations together.\nThe output of one function is automatically passed to the next function.\nThis allows you to perform multiple steps (e.g., filter() followed by select()) in a clear and concise manner.\n\n\n# This code reads more like poetry!\ncases_df |&gt; \n  filter(geo_value == \"nc\", raw_cases &gt; 1000) |&gt; \n  select(time_value, raw_cases) |&gt; \n  head()\n\n# A tibble: 6 × 2\n  time_value raw_cases\n  &lt;date&gt;         &lt;dbl&gt;\n1 2022-03-01      1231\n2 2022-03-02      2243\n3 2022-03-03      2377\n4 2022-03-04      2646\n5 2022-03-07      4230\n6 2022-03-09      1833"
  },
  {
    "objectID": "slides/day1-afternoon.html#key-practices-in-dplyr",
    "href": "slides/day1-afternoon.html#key-practices-in-dplyr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Key Practices in dplyr",
    "text": "Key Practices in dplyr\n\nUse tibbles for easier data handling.\nUse select() and filter() for data manipulation.\nUse pull() to extract columns as vectors.\nUse head(), tail(), and glimpse() for quick data inspection.\nChain functions with |&gt; for cleaner code."
  },
  {
    "objectID": "slides/day1-afternoon.html#grouping-data-with-group_by",
    "href": "slides/day1-afternoon.html#grouping-data-with-group_by",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Grouping Data with group_by()",
    "text": "Grouping Data with group_by()\n\nUse group_by() to group data by one or more columns.\nAllows performing operations on specific groups of data.\n\n\ncases_df |&gt;\n  group_by(geo_value) |&gt;\n  filter(raw_cases == max(raw_cases, na.rm = TRUE))\n\n# A tibble: 3 × 3\n# Groups:   geo_value [3]\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-03      7509\n2 nc        2022-03-07      4230\n3 ny        2022-03-24      6596"
  },
  {
    "objectID": "slides/day1-afternoon.html#creating-new-columns-with-mutate",
    "href": "slides/day1-afternoon.html#creating-new-columns-with-mutate",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Creating New Columns with mutate()",
    "text": "Creating New Columns with mutate()\n\n  Artwork by @allison_horst"
  },
  {
    "objectID": "slides/day1-afternoon.html#creating-new-columns-with-mutate-1",
    "href": "slides/day1-afternoon.html#creating-new-columns-with-mutate-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Creating New Columns with mutate()",
    "text": "Creating New Columns with mutate()\n\nmutate() is used to create new columns.\nPerform calculations using existing columns and assign to new columns.\n\n\nny_subset = cases_df |&gt;\n  filter(geo_value == \"ny\")\n\nny_subset |&gt; \n  mutate(cumulative_cases = cumsum(raw_cases)) |&gt; \n  head()\n\n# A tibble: 6 × 4\n  geo_value time_value raw_cases cumulative_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;            &lt;dbl&gt;\n1 ny        2022-03-01      1487             1487\n2 ny        2022-03-02      1889             3376\n3 ny        2022-03-03      2390             5766\n4 ny        2022-03-04       350             6116\n5 ny        2022-03-05      3372             9488\n6 ny        2022-03-06      2343            11831"
  },
  {
    "objectID": "slides/day1-afternoon.html#creating-new-columns-with-mutate-2",
    "href": "slides/day1-afternoon.html#creating-new-columns-with-mutate-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Creating New Columns with mutate()",
    "text": "Creating New Columns with mutate()\n\nmutate() can create multiple new columns in one step.\nLogical comparisons (e.g., over_5000 = raw_cases &gt; 5000) can be used within mutate().\n\n\nny_subset |&gt; \n  mutate(over_5000 = raw_cases &gt; 5000,\n         cumulative_cases = cumsum(raw_cases)) |&gt; \n  head()\n\n# A tibble: 6 × 5\n  geo_value time_value raw_cases over_5000 cumulative_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt; &lt;lgl&gt;                &lt;dbl&gt;\n1 ny        2022-03-01      1487 FALSE                 1487\n2 ny        2022-03-02      1889 FALSE                 3376\n3 ny        2022-03-03      2390 FALSE                 5766\n4 ny        2022-03-04       350 FALSE                 6116\n5 ny        2022-03-05      3372 FALSE                 9488\n6 ny        2022-03-06      2343 FALSE                11831"
  },
  {
    "objectID": "slides/day1-afternoon.html#combining-group_by-and-mutate",
    "href": "slides/day1-afternoon.html#combining-group_by-and-mutate",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Combining group_by() and mutate()",
    "text": "Combining group_by() and mutate()\n\nFirst, group data using group_by().\nThen, use mutate to perform the calculations for each group.\nFinally, use arrange to display the output by geo_value.\n\n\ncases_df |&gt;\n  group_by(geo_value) |&gt;\n  mutate(cumulative_cases = cumsum(raw_cases)) |&gt; \n  arrange(geo_value) |&gt; \n  head()\n\n# A tibble: 6 × 4\n# Groups:   geo_value [1]\n  geo_value time_value raw_cases cumulative_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;            &lt;dbl&gt;\n1 ca        2022-03-01      4310             4310\n2 ca        2022-03-02      7044            11354\n3 ca        2022-03-03      7509            18863\n4 ca        2022-03-04      3586            22449\n5 ca        2022-03-05      1438            23887\n6 ca        2022-03-06      6465            30352"
  },
  {
    "objectID": "slides/day1-afternoon.html#conditional-calculations-with-if_else",
    "href": "slides/day1-afternoon.html#conditional-calculations-with-if_else",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Conditional Calculations with if_else()",
    "text": "Conditional Calculations with if_else()\n\nif_else() allows conditional logic within mutate().\nPerform different operations depending on conditions, like “high” or “low.”\n\n\nt &lt;- 5000\n\ncases_df |&gt;\n  mutate(high_low_cases = if_else(raw_cases &gt; t, \"high\", \"low\")) |&gt; \n  head()\n\n# A tibble: 6 × 4\n  geo_value time_value raw_cases high_low_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt; &lt;chr&gt;         \n1 ca        2022-03-01      4310 low           \n2 nc        2022-03-01      1231 low           \n3 ny        2022-03-01      1487 low           \n4 ca        2022-03-02      7044 high          \n5 nc        2022-03-02      2243 low           \n6 ny        2022-03-02      1889 low"
  },
  {
    "objectID": "slides/day1-afternoon.html#summarizing-data-with-summarise",
    "href": "slides/day1-afternoon.html#summarizing-data-with-summarise",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Summarizing Data with summarise()",
    "text": "Summarizing Data with summarise()\n\nsummarise() reduces data to summary statistics (e.g., mean, median).\nTypically used after group_by() to summarize each group.\n\n\ncases_df |&gt;\n  group_by(geo_value) |&gt;\n  summarise(median_cases = median(raw_cases))\n\n# A tibble: 3 × 2\n  geo_value median_cases\n  &lt;chr&gt;            &lt;dbl&gt;\n1 ca                3785\n2 nc                1224\n3 ny                2188"
  },
  {
    "objectID": "slides/day1-afternoon.html#using-count-to-aggregate-data",
    "href": "slides/day1-afternoon.html#using-count-to-aggregate-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using count() to Aggregate Data",
    "text": "Using count() to Aggregate Data\ncount() is a shortcut for grouping and summarizing the data.\nFor example, if we want to get the total number of complete rows for each state, then\n\ncases_count &lt;- cases_df |&gt;\n  drop_na() |&gt; # Removes rows where any value is missing (from tidyr)\n  group_by(geo_value) |&gt;\n  summarize(count = n())\n\nis equivalent to\n\ncases_count &lt;- cases_df |&gt;\n  drop_na() |&gt; \n  count(geo_value)\n\ncases_count # Let's see what the counts are.\n\n# A tibble: 3 × 2\n  geo_value     n\n  &lt;chr&gt;     &lt;int&gt;\n1 ca           31\n2 nc           31\n3 ny           31"
  },
  {
    "objectID": "slides/day1-afternoon.html#key-practices-in-dplyr-round-2",
    "href": "slides/day1-afternoon.html#key-practices-in-dplyr-round-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Key Practices in dplyr: Round 2",
    "text": "Key Practices in dplyr: Round 2\n\nUse group_by() to group data by one or more variables before applying functions.\nUse mutate to create new columns or modify existing ones by applying functions to existing data.\nUse summarise to reduce data to summary statistics (e.g., mean, median).\ncount() is a convenient shortcut for counting rows by group without needing group_by() and summarise()."
  },
  {
    "objectID": "slides/day1-afternoon.html#tidy-data-and-tolstoy",
    "href": "slides/day1-afternoon.html#tidy-data-and-tolstoy",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Tidy Data and Tolstoy",
    "text": "Tidy Data and Tolstoy\n\n“Happy families are all alike; every unhappy family is unhappy in its own way.” — Leo Tolstoy\n\n\nTidy datasets are like happy families: consistent, standardized, and easy to work with.\n\nMessy datasets are like unhappy families: each one messy in its own unique way.\nIn this section:\nWe’ll define what makes data tidy and how to transform between the tidy and messy formats."
  },
  {
    "objectID": "slides/day1-afternoon.html#tidy-data-and-tolstoy-1",
    "href": "slides/day1-afternoon.html#tidy-data-and-tolstoy-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Tidy Data and Tolstoy",
    "text": "Tidy Data and Tolstoy\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "slides/day1-afternoon.html#what-is-tidy-data",
    "href": "slides/day1-afternoon.html#what-is-tidy-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What is Tidy Data?",
    "text": "What is Tidy Data?\n\nTidy data follows a consistent structure: each row represents one observation, and each column represents one variable.\ncases_df is one classic example of tidy data.\n\n\n\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 nc        2022-03-01      1231\n3 ny        2022-03-01      1487\n4 ca        2022-03-02      7044\n5 nc        2022-03-02      2243\n6 ny        2022-03-02      1889\n\n\n\nTo convert between tidy and messy data, we can use the tidyr package in the tidyverse."
  },
  {
    "objectID": "slides/day1-afternoon.html#pivot_wider-and-pivot_longer",
    "href": "slides/day1-afternoon.html#pivot_wider-and-pivot_longer",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "pivot_wider() and pivot_longer()",
    "text": "pivot_wider() and pivot_longer()\n\n  Artwork by @allison_horst"
  },
  {
    "objectID": "slides/day1-afternoon.html#making-data-wider-with-pivot_wider",
    "href": "slides/day1-afternoon.html#making-data-wider-with-pivot_wider",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Making Data Wider with pivot_wider()",
    "text": "Making Data Wider with pivot_wider()\n\n\nTo convert data from long format to wide/messy format usepivot_wider().\nFor example, let’s try creating a column for each time value in cases_df:\n\n\n\n\nmessy_cases_df &lt;- cases_df |&gt;\n  pivot_wider(\n    names_from = time_value,   # Create new columns for each unique date\n    values_from = raw_cases    # Fill those columns with the raw_case values\n  )\n\n# View the result\nmessy_cases_df\n\n# A tibble: 3 × 32\n  geo_value `2022-03-01` `2022-03-02` `2022-03-03` `2022-03-04` `2022-03-05`\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 ca                4310         7044         7509         3586         1438\n2 nc                1231         2243         2377         2646            0\n3 ny                1487         1889         2390          350         3372\n# ℹ 26 more variables: `2022-03-06` &lt;dbl&gt;, `2022-03-07` &lt;dbl&gt;,\n#   `2022-03-08` &lt;dbl&gt;, `2022-03-09` &lt;dbl&gt;, `2022-03-10` &lt;dbl&gt;,\n#   `2022-03-11` &lt;dbl&gt;, `2022-03-12` &lt;dbl&gt;, `2022-03-13` &lt;dbl&gt;,\n#   `2022-03-14` &lt;dbl&gt;, `2022-03-15` &lt;dbl&gt;, `2022-03-16` &lt;dbl&gt;,\n#   `2022-03-17` &lt;dbl&gt;, `2022-03-18` &lt;dbl&gt;, `2022-03-19` &lt;dbl&gt;,\n#   `2022-03-20` &lt;dbl&gt;, `2022-03-21` &lt;dbl&gt;, `2022-03-22` &lt;dbl&gt;,\n#   `2022-03-23` &lt;dbl&gt;, `2022-03-24` &lt;dbl&gt;, `2022-03-25` &lt;dbl&gt;, …"
  },
  {
    "objectID": "slides/day1-afternoon.html#tidying-messy-data-with-pivot_longer",
    "href": "slides/day1-afternoon.html#tidying-messy-data-with-pivot_longer",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Tidying Messy Data with pivot_longer()",
    "text": "Tidying Messy Data with pivot_longer()\n\nUse pivot_longer() to convert data from wide format (multiple columns for the same variable) to long format (one column per variable).\nLet’s try turning messy_cases_df back into the original tidy cases_df!\n\n\ntidy_cases_df &lt;- messy_cases_df |&gt;\n  pivot_longer(\n    cols = -geo_value,          # Keep the 'geo_value' column as it is\n    names_to = \"time_value\",    # Create a new 'time_value' column from the column names\n    values_to = \"raw_cases\"     # Values from the wide columns should go into 'raw_cases'\n  )\n\n# View the result\nhead(tidy_cases_df, n = 3) # Notice the class of time_value here\n\n# A tibble: 3 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-03      7509"
  },
  {
    "objectID": "slides/day1-afternoon.html#tidying-messy-data-with-pivot_longer-1",
    "href": "slides/day1-afternoon.html#tidying-messy-data-with-pivot_longer-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Tidying Messy Data with pivot_longer()",
    "text": "Tidying Messy Data with pivot_longer()\n\nWhen we used pivot_longer(), the time_value column is converted to a character class because the column names are treated as strings.\nSo, to truly get the original cases_df we need to convert time_value back to the Date class.\nThen, we can use identical() to check if the two data frames are exactly the same.\n\n\ntidy_cases_df = tidy_cases_df |&gt; mutate(time_value = as.Date(time_value))\n\nidentical(tidy_cases_df |&gt; arrange(time_value), cases_df)\n\n[1] TRUE\n\n\nGreat. That was a success!"
  },
  {
    "objectID": "slides/day1-afternoon.html#missing-data",
    "href": "slides/day1-afternoon.html#missing-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Missing Data",
    "text": "Missing Data\n\nSometimes you may have missing data in your time series.\nCan be due to actual missing data, or it can be due to the fact that the data is only reported on certain days.\nLet’s create a dataset with missing data & consider each of those cases:\n\n\nca_missing &lt;- cases_df |&gt;\n  filter(geo_value == \"ca\") |&gt;\n  slice(1:2, 4:6) # Select rows 1 to 2 and 4 to 6; ie. omit 2022-03-03\n\nca_missing\n\n# A tibble: 5 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-04      3586\n4 ca        2022-03-05      1438\n5 ca        2022-03-06      6465"
  },
  {
    "objectID": "slides/day1-afternoon.html#complete-and-fill-to-handle-missing-data",
    "href": "slides/day1-afternoon.html#complete-and-fill-to-handle-missing-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "complete() and fill() to Handle Missing Data",
    "text": "complete() and fill() to Handle Missing Data\nA simple workflow to handle missing data relies on one or both of these functions:\n\ncomplete(): Adds missing rows for combinations of specified variables.\nfill(): Fills missing values in columns, typically from previous or next available values (default is LOCF)."
  },
  {
    "objectID": "slides/day1-afternoon.html#data-only-reported-on-certain-days",
    "href": "slides/day1-afternoon.html#data-only-reported-on-certain-days",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Data Only Reported on Certain Days",
    "text": "Data Only Reported on Certain Days\n\nIf the data is only reported on certain days, it is often useful to fill in the missing data with explicit zeros.\ncomplete() is enough to handle this:\n\n\n# First, use complete() to add missing time_value (2022-03-03)\nca_complete &lt;- ca_missing |&gt;\n  complete(geo_value, time_value = seq(min(time_value), max(time_value), by = \"day\"),\n           fill = list(raw_cases = 0))\nca_complete\n\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-03         0\n4 ca        2022-03-04      3586\n5 ca        2022-03-05      1438\n6 ca        2022-03-06      6465"
  },
  {
    "objectID": "slides/day1-afternoon.html#data-is-genuinely-missing",
    "href": "slides/day1-afternoon.html#data-is-genuinely-missing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Data is Genuinely Missing",
    "text": "Data is Genuinely Missing\n\nIf the data is truly missing, then there are multiple options (ex. omission, single imputation, multiple imputation).\nA common single imputation method used to handle missing data in time series or longitudinal datasets is LOCF.\nWe can easily perform LOCF using complete() followed by fill().\nStart with complete():\n\n\n# First, use complete() to add missing time_value (2022-03-03)\nca_complete &lt;- ca_missing |&gt;\n  complete(geo_value, time_value = seq(min(time_value), max(time_value), by = \"day\"))\nhead(ca_complete, n = 4) # notice no fill with 0s this time, NA by default\n\n# A tibble: 4 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-03        NA\n4 ca        2022-03-04      3586"
  },
  {
    "objectID": "slides/day1-afternoon.html#data-is-genuinely-missing-1",
    "href": "slides/day1-afternoon.html#data-is-genuinely-missing-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Data is Genuinely Missing",
    "text": "Data is Genuinely Missing\nThen, use fill() to fill the counts using LOCF (default):\n\nca_complete |&gt;\n  fill(raw_cases)\n\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-03      7044\n4 ca        2022-03-04      3586\n5 ca        2022-03-05      1438\n6 ca        2022-03-06      6465"
  },
  {
    "objectID": "slides/day1-afternoon.html#introduction-to-joins-in-dplyr",
    "href": "slides/day1-afternoon.html#introduction-to-joins-in-dplyr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Introduction to Joins in dplyr",
    "text": "Introduction to Joins in dplyr\n\nJoining datasets is a powerful tool for combining info. from multiple sources.\nIn R, dplyr provides several functions to perform different types of joins.\nWe’ll demonstrate joining a subset of cases_df (our case counts dataset) with state_census.\nMotivation: We can scale the case counts by population to make them comparable across regions of different sizes."
  },
  {
    "objectID": "slides/day1-afternoon.html#subset-cases_df",
    "href": "slides/day1-afternoon.html#subset-cases_df",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Subset cases_df",
    "text": "Subset cases_df\nTo simplify things, let’s use filter() to only grab one date of cases_df:\n\ncases_df_sub = cases_df |&gt; filter(time_value == \"2022-03-01\") \ncases_df_sub\n\n# A tibble: 3 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 nc        2022-03-01      1231\n3 ny        2022-03-01      1487\n\n\nThough note that what we’re going to do can be applied to the entirety of cases_df."
  },
  {
    "objectID": "slides/day1-afternoon.html#load-state-census-data",
    "href": "slides/day1-afternoon.html#load-state-census-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Load State Census Data",
    "text": "Load State Census Data\nThe state_census dataset from epidatasets contains state populations from the 2019 census.\n\n# State census dataset from epidatasets\nlibrary(epidatasets)\nstate_census = state_census |&gt; select(abbr, pop) |&gt; filter(abbr != \"us\")\n\nstate_census |&gt; head()\n\n# A tibble: 6 × 2\n  abbr       pop\n  &lt;chr&gt;    &lt;dbl&gt;\n1 al     4903185\n2 ak      731545\n3 az     7278717\n4 ar     3017804\n5 ca    39512223\n6 co     5758736\n\n\nNotice that this includes many states that are not in cases_df_sub."
  },
  {
    "objectID": "slides/day1-afternoon.html#left-join-keep-all-rows-from-the-first-dataset",
    "href": "slides/day1-afternoon.html#left-join-keep-all-rows-from-the-first-dataset",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Left Join: Keep All Rows from the First Dataset",
    "text": "Left Join: Keep All Rows from the First Dataset\n\nA left join keeps all rows from the first dataset (cases_df_sub), and adds matching data from the second dataset (state_census).\nSo all rows from the first dataset (cases_df_sub) will be preserved.\nThe datasets are joined by matching the geo_value column, specified by the by argument.\n\n\n# Left join: combining March 1, 2022 state case data with the census data\ncases_left_join &lt;- cases_df_sub |&gt;\n  left_join(state_census, by = c(\"geo_value\" = \"abbr\"))\n\ncases_left_join\n\n# A tibble: 3 × 4\n  geo_value time_value raw_cases      pop\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561"
  },
  {
    "objectID": "slides/day1-afternoon.html#right-join-keep-all-rows-from-the-second-dataset",
    "href": "slides/day1-afternoon.html#right-join-keep-all-rows-from-the-second-dataset",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Right Join: Keep All Rows from the Second Dataset",
    "text": "Right Join: Keep All Rows from the Second Dataset\n\n\nA right join keeps all rows from the second dataset (state_census), and adds matching data from the first dataset (cases_df_sub).\nIf a row in the second dataset doesn’t have a match in the first, then the columns from the first will be filled with NA.\nFor example, can see this for the al row from state_census…\n\n\n\n# Right join: keep all rows from state_census\ncases_right_join &lt;- cases_df_sub |&gt;\n  right_join(state_census, by = c(\"geo_value\" = \"abbr\"))\n\nhead(cases_right_join)\n\n# A tibble: 6 × 4\n  geo_value time_value raw_cases      pop\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561\n4 al        NA                NA  4903185\n5 ak        NA                NA   731545\n6 az        NA                NA  7278717"
  },
  {
    "objectID": "slides/day1-afternoon.html#inner-join-only-keeping-matching-rows",
    "href": "slides/day1-afternoon.html#inner-join-only-keeping-matching-rows",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Inner Join: Only Keeping Matching Rows",
    "text": "Inner Join: Only Keeping Matching Rows\n\nAn inner join will only keep rows where there is a match in both datasets.\nSo, if a state in state_census does not have a corresponding entry in cases_df_sub, then that row will be excluded.\n\n\n# Inner join: only matching rows are kept\ncases_inner_join &lt;- cases_df_sub |&gt;\n  inner_join(state_census, by = c(\"geo_value\" = \"abbr\"))\n\ncases_inner_join\n\n# A tibble: 3 × 4\n  geo_value time_value raw_cases      pop\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561"
  },
  {
    "objectID": "slides/day1-afternoon.html#full-join-keeping-all-rows-from-both-datasets",
    "href": "slides/day1-afternoon.html#full-join-keeping-all-rows-from-both-datasets",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Full Join: Keeping All Rows from Both Datasets",
    "text": "Full Join: Keeping All Rows from Both Datasets\n\nA full join will keep all rows from both datasets.\nIf a state in either dataset has no match in the other, the missing values will be filled with NA.\n\n\n# Full join: keep all rows from both datasets\ncases_full_join &lt;- cases_df_sub |&gt;\n  full_join(state_census, by = c(\"geo_value\" = \"abbr\"))\n\nhead(cases_full_join)\n\n# A tibble: 6 × 4\n  geo_value time_value raw_cases      pop\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561\n4 al        NA                NA  4903185\n5 ak        NA                NA   731545\n6 az        NA                NA  7278717"
  },
  {
    "objectID": "slides/day1-afternoon.html#summary-of-the-four-join-functions",
    "href": "slides/day1-afternoon.html#summary-of-the-four-join-functions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Summary of the Four Join Functions",
    "text": "Summary of the Four Join Functions\n\nLeft join: All rows from the left dataset and matching rows from the right dataset.\nRight join: All rows from the right dataset and matching rows from the left dataset.\nInner join: Only matching rows from both datasets.\nFull join: All rows from both datasets, with NA where no match exists."
  },
  {
    "objectID": "slides/day1-afternoon.html#final-thoughts-on-joins",
    "href": "slides/day1-afternoon.html#final-thoughts-on-joins",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Final Thoughts on Joins",
    "text": "Final Thoughts on Joins\n\nJoins are an essential part of data wrangling in R.\nThe choice of join depends on the analysis you need to perform:\n\nUse left joins when you want to keep all data from the first dataset.\nUse right joins when you want to keep all data from the second dataset.\nUse inner joins when you’re only interested in matching rows.\nUse full joins when you want to preserve all information from both datasets."
  },
  {
    "objectID": "slides/day1-afternoon.html#three-review-questions",
    "href": "slides/day1-afternoon.html#three-review-questions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Three Review Questions",
    "text": "Three Review Questions\nQ1): What can we use to fill in the missing time_value for the states in cases_full_join?\n\n\nCode\ncases_full_join |&gt; \n     fill(time_value)\n\n\n# A tibble: 56 × 4\n   geo_value time_value raw_cases      pop\n   &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1 ca        2022-03-01      4310 39512223\n 2 nc        2022-03-01      1231 10488084\n 3 ny        2022-03-01      1487 19453561\n 4 al        2022-03-01        NA  4903185\n 5 ak        2022-03-01        NA   731545\n 6 az        2022-03-01        NA  7278717\n 7 ar        2022-03-01        NA  3017804\n 8 co        2022-03-01        NA  5758736\n 9 ct        2022-03-01        NA  3565287\n10 de        2022-03-01        NA   973764\n# ℹ 46 more rows\n\n\nQ2): Now, what join function should you use if your goal is to scale the cases by population in cases_df?\n\n\nCode\n# Either left_join\ncases_left_join &lt;- cases_df |&gt;\n  left_join(state_census, by = c(\"geo_value\" = \"abbr\"))\n\ncases_left_join\n\n\n# A tibble: 93 × 4\n   geo_value time_value raw_cases      pop\n   &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1 ca        2022-03-01      4310 39512223\n 2 nc        2022-03-01      1231 10488084\n 3 ny        2022-03-01      1487 19453561\n 4 ca        2022-03-02      7044 39512223\n 5 nc        2022-03-02      2243 10488084\n 6 ny        2022-03-02      1889 19453561\n 7 ca        2022-03-03      7509 39512223\n 8 nc        2022-03-03      2377 10488084\n 9 ny        2022-03-03      2390 19453561\n10 ca        2022-03-04      3586 39512223\n# ℹ 83 more rows\n\n\nCode\ncases_df = cases_left_join\n\n# Or inner_join\ncases_inner_join &lt;- cases_df |&gt;\n  inner_join(state_census, by = c(\"geo_value\" = \"abbr\"))\n\ncases_inner_join\n\n\n# A tibble: 93 × 5\n   geo_value time_value raw_cases    pop.x    pop.y\n   &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 ca        2022-03-01      4310 39512223 39512223\n 2 nc        2022-03-01      1231 10488084 10488084\n 3 ny        2022-03-01      1487 19453561 19453561\n 4 ca        2022-03-02      7044 39512223 39512223\n 5 nc        2022-03-02      2243 10488084 10488084\n 6 ny        2022-03-02      1889 19453561 19453561\n 7 ca        2022-03-03      7509 39512223 39512223\n 8 nc        2022-03-03      2377 10488084 10488084\n 9 ny        2022-03-03      2390 19453561 19453561\n10 ca        2022-03-04      3586 39512223 39512223\n# ℹ 83 more rows\n\n\nQ3): Finally, please create a new column in cases_df where you scale the cases by population and multiply by 1e5 to get cases / 100k.\n\n\nCode\ncases_df &lt;- cases_df |&gt;\n  mutate(scaled_cases = raw_cases / pop * 1e5) # cases / 100K\nhead(cases_df)\n\n\n# A tibble: 6 × 5\n  geo_value time_value raw_cases      pop scaled_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223        10.9 \n2 nc        2022-03-01      1231 10488084        11.7 \n3 ny        2022-03-01      1487 19453561         7.64\n4 ca        2022-03-02      7044 39512223        17.8 \n5 nc        2022-03-02      2243 10488084        21.4 \n6 ny        2022-03-02      1889 19453561         9.71"
  },
  {
    "objectID": "slides/day1-afternoon.html#epi.-data-processing-with-epiprocess",
    "href": "slides/day1-afternoon.html#epi.-data-processing-with-epiprocess",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Epi. Data Processing with epiprocess",
    "text": "Epi. Data Processing with epiprocess\n\n\nepiprocess is a package that offers additional functionality to pre-process such epidemiological data.\nYou can work with an epi_df like you can with a tibble by using dplyr verbs.\nFor example, on cases_df, we can easily use epi_slide_mean() to calculate trailing 14 day averages of cases:\n\n\n\ncases_df &lt;- cases_df |&gt;\n  as_epi_df(as_of = as.Date(\"2024-01-01\")) |&gt;\n  group_by(geo_value) |&gt;\n  epi_slide_mean(scaled_cases, .window_size = 14, na.rm = TRUE) |&gt;\n  rename(smoothed_scaled_cases = slide_value_scaled_cases) \n\nhead(cases_df)\n\nAn `epi_df` object, 6 x 6 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-01-01\n\n# A tibble: 6 × 6\n# Groups:   geo_value [1]\n  geo_value time_value raw_cases      pop scaled_cases smoothed_scaled_cases\n* &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;                 &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223        10.9                   10.9\n2 ca        2022-03-02      7044 39512223        17.8                   14.4\n3 ca        2022-03-03      7509 39512223        19.0                   15.9\n4 ca        2022-03-04      3586 39512223         9.08                  14.2\n5 ca        2022-03-05      1438 39512223         3.64                  12.1\n6 ca        2022-03-06      6465 39512223        16.4                   12.8"
  },
  {
    "objectID": "slides/day1-afternoon.html#epi.-data-processing-with-epiprocess-1",
    "href": "slides/day1-afternoon.html#epi.-data-processing-with-epiprocess-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Epi. Data Processing with epiprocess",
    "text": "Epi. Data Processing with epiprocess\nIt is easy to produce an autoplot the smoothed confirmed daily cases for each geo_value:\n\ncases_df |&gt;\n  autoplot(smoothed_scaled_cases)"
  },
  {
    "objectID": "slides/day1-afternoon.html#epi.-data-processing-with-epiprocess-2",
    "href": "slides/day1-afternoon.html#epi.-data-processing-with-epiprocess-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Epi. Data Processing with epiprocess",
    "text": "Epi. Data Processing with epiprocess\nAlternatively, we can display both the smoothed and the original daily case rates:\n\nNow, before exploring some more features of epiprocess, let’s have a look at the epiverse software ecosystem it’s part of…"
  },
  {
    "objectID": "slides/day1-afternoon.html#the-epiverse-ecosystem",
    "href": "slides/day1-afternoon.html#the-epiverse-ecosystem",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "The Epiverse Ecosystem",
    "text": "The Epiverse Ecosystem\nInterworking, community-driven, packages for epi tracking & forecasting."
  },
  {
    "objectID": "slides/day1-afternoon.html#what-is-panel-data",
    "href": "slides/day1-afternoon.html#what-is-panel-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What is Panel Data?",
    "text": "What is Panel Data?\n\n\nRecall that panel data, or longitudinal data, contain cross-sectional measurements of subjects over time.\nBuilt-in example: covid_case_death_rates dataset, which is a snapshot as of May 31, 2022 that contains daily state-wise measures of case_rate and death_rate for COVID-19 in 2021:\n\n\n\nAn `epi_df` object, 6 x 4 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2022-05-31\n\n# A tibble: 6 × 4\n  geo_value time_value case_rate death_rate\n* &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n1 ak        2020-12-31      35.9      0.158\n2 al        2020-12-31      65.1      0.438\n3 ar        2020-12-31      66.0      1.27 \n4 as        2020-12-31       0        0    \n5 az        2020-12-31      76.8      1.10 \n6 ca        2020-12-31      96.0      0.751\n\n\n\nHow do we store & work with such snapshots in the epiverse software ecosystem?"
  },
  {
    "objectID": "slides/day1-afternoon.html#epi_df-snapshot-of-a-dataset",
    "href": "slides/day1-afternoon.html#epi_df-snapshot-of-a-dataset",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "epi_df: Snapshot of a Dataset",
    "text": "epi_df: Snapshot of a Dataset\n\nYou can convert panel data into an epi_df with the required geo_value and time_value columns\n\nTherefore, an epi_df is… * a tibble that requires columns geo_value and time_value. * arbitrary additional columns containing measured values * additional keys to index (age_group, ethnicity, etc.)\n\n\n\n\n\n\nepi_df\n\n\nRepresents a snapshot that contains the most up-to-date values of the signal variables, as of a given time."
  },
  {
    "objectID": "slides/day1-afternoon.html#epi_df-snapshot-of-a-dataset-1",
    "href": "slides/day1-afternoon.html#epi_df-snapshot-of-a-dataset-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "epi_df: Snapshot of a Dataset",
    "text": "epi_df: Snapshot of a Dataset\n\nedf &lt;- covid_case_death_rates\nedf\n\nAn `epi_df` object, 20,496 x 4 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2022-05-31\n\n# A tibble: 20,496 × 4\n   geo_value time_value case_rate death_rate\n * &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n 1 ak        2020-12-31      35.9      0.158\n 2 al        2020-12-31      65.1      0.438\n 3 ar        2020-12-31      66.0      1.27 \n 4 as        2020-12-31       0        0    \n 5 az        2020-12-31      76.8      1.10 \n 6 ca        2020-12-31      96.0      0.751\n 7 co        2020-12-31      35.8      0.649\n 8 ct        2020-12-31      52.1      0.819\n 9 dc        2020-12-31      31.0      0.601\n10 de        2020-12-31      64.3      0.912\n# ℹ 20,486 more rows"
  },
  {
    "objectID": "slides/day1-afternoon.html#examples-of-preprocessing",
    "href": "slides/day1-afternoon.html#examples-of-preprocessing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of Preprocessing",
    "text": "Examples of Preprocessing\nEDA Features\n\nMaking locations commensurate (per capita scaling)\nCorrelating signals across location or time\nComputing growth rates\nDetecting and removing outliers\nDealing with revisions"
  },
  {
    "objectID": "slides/day1-afternoon.html#features---correlations-at-different-lags",
    "href": "slides/day1-afternoon.html#features---correlations-at-different-lags",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Features - Correlations at Different Lags",
    "text": "Features - Correlations at Different Lags\n\ncor0 &lt;- epi_cor(edf, case_rate, death_rate, cor_by = time_value)\ncor14 &lt;- epi_cor(edf, case_rate, death_rate, cor_by = time_value, dt1 = -14)"
  },
  {
    "objectID": "slides/day1-afternoon.html#features---compute-growth-rates",
    "href": "slides/day1-afternoon.html#features---compute-growth-rates",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Features - Compute Growth Rates",
    "text": "Features - Compute Growth Rates\n\nedf &lt;- filter(edf, geo_value %in% c(\"ut\", \"ca\")) |&gt;\n  group_by(geo_value) |&gt;\n  mutate(gr_cases = growth_rate(time_value, case_rate, method = \"trend_filter\"))"
  },
  {
    "objectID": "slides/day1-afternoon.html#features---outlier-detection",
    "href": "slides/day1-afternoon.html#features---outlier-detection",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Features - Outlier Detection",
    "text": "Features - Outlier Detection"
  },
  {
    "objectID": "slides/day1-afternoon.html#epi_archive-collection-of-epi_dfs",
    "href": "slides/day1-afternoon.html#epi_archive-collection-of-epi_dfs",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "epi_archive: Collection of epi_dfs",
    "text": "epi_archive: Collection of epi_dfs\n\nfull version history of a data set\nacts like a bunch of epi_dfs — but stored compactly\nallows similar functionality as epi_df but using only data that would have been available at the time\n\n\n\n\n\n\n\nRevisions\n\n\nEpidemiology data gets revised frequently.\n\nWe may want to use the data as it looked in the past\nor we may want to examine the history of revisions."
  },
  {
    "objectID": "slides/day1-afternoon.html#epi_archive-collection-of-epi_dfs-1",
    "href": "slides/day1-afternoon.html#epi_archive-collection-of-epi_dfs-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "epi_archive: Collection of epi_dfs",
    "text": "epi_archive: Collection of epi_dfs\n\narchive_cases_dv_subset\n\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-06-01 / 2021-11-30\nℹ First/last version with update: 2020-06-02 / 2021-12-01\nℹ Versions end: 2021-12-01\nℹ A preview of the table (129638 rows x 5 columns):\nKey: &lt;geo_value, time_value, version&gt;\n        geo_value time_value    version percent_cli case_rate_7d_av\n           &lt;char&gt;     &lt;Date&gt;     &lt;Date&gt;       &lt;num&gt;           &lt;num&gt;\n     1:        ca 2020-06-01 2020-06-02          NA        6.628329\n     2:        ca 2020-06-01 2020-06-06    2.140116        6.628329\n     3:        ca 2020-06-01 2020-06-07    2.140116        6.628329\n     4:        ca 2020-06-01 2020-06-08    2.140379        6.628329\n     5:        ca 2020-06-01 2020-06-09    2.114430        6.628329\n    ---                                                            \n129634:        tx 2021-11-26 2021-11-29    1.858596        7.957657\n129635:        tx 2021-11-27 2021-11-28          NA        7.174299\n129636:        tx 2021-11-28 2021-11-29          NA        6.834681\n129637:        tx 2021-11-29 2021-11-30          NA        8.841247\n129638:        tx 2021-11-30 2021-12-01          NA        9.566218"
  },
  {
    "objectID": "slides/day1-afternoon.html#revision-patterns",
    "href": "slides/day1-afternoon.html#revision-patterns",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Revision Patterns",
    "text": "Revision Patterns"
  },
  {
    "objectID": "slides/day1-afternoon.html#finalized-data",
    "href": "slides/day1-afternoon.html#finalized-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Finalized Data",
    "text": "Finalized Data\n\n\nCounts are revised as time proceeds\nWant to know the final value\nOften not available until weeks/months later\n\n\n\nForecasting\n\nAt time \\(t\\), predict the final value for time \\(t+h\\), \\(h &gt; 0\\)\n\n\n\n\nBackcasting\n\nAt time \\(t\\), predict the final value for time \\(t-h\\), \\(h &lt; 0\\)\n\n\n\n\nNowcasting\n\nAt time \\(t\\), predict the final value for time \\(t\\)"
  },
  {
    "objectID": "slides/day1-afternoon.html#backfill-canadian-edition",
    "href": "slides/day1-afternoon.html#backfill-canadian-edition",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Backfill Canadian edition",
    "text": "Backfill Canadian edition\n\nEvery week the BC CDC releases COVID-19 hospitalization data.\nFollowing week they revise the number upward (by ~25%) due to lagged reports.\n\n \n\nTakeaway: Once the data is backfilled, hospitalizations rarely show a decline, challenging the common media narrative."
  },
  {
    "objectID": "slides/day1-afternoon.html#aside-on-nowcasting",
    "href": "slides/day1-afternoon.html#aside-on-nowcasting",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Aside on Nowcasting",
    "text": "Aside on Nowcasting\n\nTo some Epis, “nowcasting” can be equated with “estimate the time-varying instantaneous reproduction number, \\(R_t\\)”\nExample using the number of reported COVID-19 cases in British Columbia between January 2020 and April 15, 2023. \n\n\n\n\n\n\n\n\n\n\n\nGroup built {rtestim} doing for this nonparametrically.\nWe may come back to this later…"
  },
  {
    "objectID": "slides/day1-afternoon.html#mathematical-setup",
    "href": "slides/day1-afternoon.html#mathematical-setup",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Mathematical Setup",
    "text": "Mathematical Setup\n\nSuppose today is time \\(t\\)\nLet \\(y_i\\) denote a series of interest observed at times \\(i=1,\\ldots, t\\).\n\n\n\n\nOur goal\n\n\n\nProduce a point nowcast for the finalized values of \\(y_t\\).\nAccompany with time-varying prediction intervals\n\n\n\n\n\nWe also have access to \\(p\\) other time series \\(x_{ij},\\; i=1,\\ldots,t, \\; j = 1,\\ldots,p\\)\nAll may be subject to revisions."
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-simple-ratio-ex-nchs-mortality",
    "href": "slides/day1-afternoon.html#nowcasting-simple-ratio-ex-nchs-mortality",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting Simple Ratio Ex: NCHS Mortality",
    "text": "Nowcasting Simple Ratio Ex: NCHS Mortality\n\nIn this example, we’ll demonstrate the concept of nowcasting using NHCS mortality data (the number of weekly new deaths with confirmed or presumed COVID-19, per 100,000 population).\nWe will work with provisional data (real-time reports) and compare them to finalized data (final reports).\nThe goal is to estimate or nowcast the mortality rate for weeks when only provisional data is available."
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-versioned-data",
    "href": "slides/day1-afternoon.html#fetch-versioned-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Versioned Data",
    "text": "Fetch Versioned Data\nLet’s fetch versioned mortality data from the API (pub_covidcast) for CA (geo_values = \"ca\") and the signal of interest (deaths_covid_incidence_num) over early 2024.\n\n# Fetch the versioned NCHS mortality data (weekly)\nmortality_archive &lt;- pub_covidcast(\n  source = \"nchs-mortality\",\n  signals = \"deaths_covid_incidence_num\",\n  geo_type = \"state\",\n  time_type = \"week\",\n  geo_values = \"ca\",  # California (CA)\n  time_values = epirange(202401, 202413),  \n  issues = \"*\"\n) |&gt; \n  select(geo_value, time_value, version = issue, mortality = value) |&gt; \n  as_epi_archive(compactify = TRUE)\n\n# Set the start and end days for the analysis \n# corresponding to the weeks entered in time_values\nstart_time = as.Date(\"2023-12-31\")\nend_time = as.Date(\"2024-03-24\")"
  },
  {
    "objectID": "slides/day1-afternoon.html#latency-in-reporting---minimum-lag",
    "href": "slides/day1-afternoon.html#latency-in-reporting---minimum-lag",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Latency in Reporting - Minimum Lag",
    "text": "Latency in Reporting - Minimum Lag\n\nA quick inspection reveals that mortality rates are systematically 7 days latent (fixed lag).\n\n\nmortality_revision_inspect = mortality_archive$DT |&gt; mutate(version_time_diff = version - time_value)\n\n# Look at the first revision for each week\nmortality_revision_inspect |&gt; group_by(time_value) |&gt; slice(1) |&gt; head()\n\n# A tibble: 6 × 5\n# Groups:   time_value [6]\n  geo_value time_value version    mortality version_time_diff\n  &lt;chr&gt;     &lt;date&gt;     &lt;date&gt;         &lt;dbl&gt; &lt;drtn&gt;           \n1 ca        2023-12-31 2024-01-07        48 7 days           \n2 ca        2024-01-07 2024-01-14        28 7 days           \n3 ca        2024-01-14 2024-01-21        47 7 days           \n4 ca        2024-01-21 2024-01-28        41 7 days           \n5 ca        2024-01-28 2024-02-04        31 7 days           \n6 ca        2024-02-04 2024-02-11        47 7 days           \n\n\n\nUse revision_summary() from epiprocess to generate basic statistics about the revision behavior for the dataset."
  },
  {
    "objectID": "slides/day1-afternoon.html#latency-in-reporting---finalized-value-attainment",
    "href": "slides/day1-afternoon.html#latency-in-reporting---finalized-value-attainment",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Latency in Reporting - Finalized Value Attainment",
    "text": "Latency in Reporting - Finalized Value Attainment\n\n\nQuestion: When is the finalized value first attained for each date? Would we have access to any in real-time?\nHow fast are the final values attained & what’s the pattern for these times, if any?\n\n\n\n# A tibble: 6 × 4\n  geo_value time_value min_version diff    \n  &lt;chr&gt;     &lt;date&gt;     &lt;date&gt;      &lt;drtn&gt;  \n1 ca        2023-12-31 2024-10-13  287 days\n2 ca        2024-01-07 2024-10-27  294 days\n3 ca        2024-01-14 2024-06-09  147 days\n4 ca        2024-01-21 2024-08-11  203 days\n5 ca        2024-01-28 2024-07-07  161 days\n6 ca        2024-02-04 2024-10-13  252 days\n\n\nAnd here’s a numerical summary:\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   84.0   147.0   189.0   192.8   259.0   294.0 \n\n\n\nConclusion: Tends to take a long time & varies. Even for this relatively small time period… Goes as low as 84 days or as high as 294 days. Yikes.\nSo if we were doing this in real-time, then we wouldn’t have access to the finalized data."
  },
  {
    "objectID": "slides/day1-afternoon.html#comparison-of-final-vs.-multiple-revisions",
    "href": "slides/day1-afternoon.html#comparison-of-final-vs.-multiple-revisions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Comparison of Final vs. Multiple Revisions",
    "text": "Comparison of Final vs. Multiple Revisions\nThis figure shows the finalized rates in comparison to multiple revisions to see how the data changes over time:"
  },
  {
    "objectID": "slides/day1-afternoon.html#comparison-of-final-vs.-one-revision",
    "href": "slides/day1-afternoon.html#comparison-of-final-vs.-one-revision",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Comparison of Final vs. One Revision",
    "text": "Comparison of Final vs. One Revision\n\nThe below figure compares the finalized rates (in black) to one revision (in yellow) from March 3, 2024.\n\n\n\n\n\n\n\n\n\nThe real-time data is biased downwards (systematically below the true value). That is, the signal tends to get scaled up with future revisions."
  },
  {
    "objectID": "slides/day1-afternoon.html#calculate-one-ratio-provisional-vs.-finalized-data",
    "href": "slides/day1-afternoon.html#calculate-one-ratio-provisional-vs.-finalized-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Calculate One Ratio: Provisional vs. Finalized Data",
    "text": "Calculate One Ratio: Provisional vs. Finalized Data\n\n\n\nSuppose that the day is March 10, 2024. Then, because the data is 7 days latent, we can compute the ratio between provisional and finalized data for March 3, 2024.\n\n\nas_of_date = as.Date(\"2024-03-10\"); fixed_lag = 7\n\n# Load the finalized mortality data for CA\nca_finalized &lt;- mortality_latest |&gt;\n  filter(time_value == (as_of_date - fixed_lag)) |&gt;\n  dplyr::select(mortality)\n\n# Load the provisional mortality data for the same week\nmortality_old = epix_as_of(mortality_archive, max_version = as_of_date)\n\nca_provisional &lt;- mortality_old |&gt;\n  filter(time_value == (as_of_date - fixed_lag)) |&gt;\n  dplyr::select(mortality)\n\n# Calculate ratio between provisional and finalized cases for the week of interest\nratio &lt;- ca_provisional$mortality / ca_finalized$mortality\nratio\n\n[1] 0.3611111\n\n\nConclusion: The real-time rate is well below the finalized for this time (26 vs 72 here).\nQuestion: Can we generalize this over many days?"
  },
  {
    "objectID": "slides/day1-afternoon.html#calculating-the-ratio-using-multiple-dates",
    "href": "slides/day1-afternoon.html#calculating-the-ratio-using-multiple-dates",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Calculating the Ratio using Multiple Dates",
    "text": "Calculating the Ratio using Multiple Dates\n\nLet’s move from calculating the ratio by using one day to multiple days with the goal to use it to nowcast for Feb. 18, which has a provisional value of 23\n\n\nas_of_date = as.Date(\"2024-02-25\")\n\nprovisional &lt;- epix_as_of(mortality_archive, max_version = as_of_date) |&gt;\n  filter(time_value == as_of_date - 7) |&gt;\n  pull(mortality)\nprovisional\n\n[1] 23\n\n\nand a finalized value of 104\n\nfinalized &lt;- mortality_latest |&gt;\n  filter(time_value == as_of_date - 7) |&gt;\n  pull(mortality)\nfinalized\n\n[1] 104"
  },
  {
    "objectID": "slides/day1-afternoon.html#calculating-the-ratio-using-multiple-dates-1",
    "href": "slides/day1-afternoon.html#calculating-the-ratio-using-multiple-dates-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Calculating the Ratio using Multiple Dates",
    "text": "Calculating the Ratio using Multiple Dates\nFirst, let’s download the real-time rates for CA, and compare them to their finalized version.\n\ndates &lt;- seq(start_time, (as_of_date - 7), by = \"day\")\nmortality_real_time &lt;- function(date) {\n  epix_as_of(mortality_archive, max_version = (date + 7L)) |&gt;\n    filter(time_value == date)\n}\nmortality_real_time_df &lt;- map_dfr(dates, mortality_real_time)\nhead(mortality_real_time_df)\n\nAn `epi_df` object, 6 x 3 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-01-07\n\n# A tibble: 6 × 3\n  geo_value time_value mortality\n* &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2023-12-31        48\n2 ca        2024-01-07        28\n3 ca        2024-01-14        47\n4 ca        2024-01-21        41\n5 ca        2024-01-28        31\n6 ca        2024-02-04        47"
  },
  {
    "objectID": "slides/day1-afternoon.html#calculating-the-ratio-using-multiple-dates-2",
    "href": "slides/day1-afternoon.html#calculating-the-ratio-using-multiple-dates-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Calculating the Ratio using Multiple Dates",
    "text": "Calculating the Ratio using Multiple Dates\nNow, let’s plot the real-time vs the finalized mortality rates:\n\n\nTakeaways: The real-time counts are biased well below the finalized counts.\nSystematic underreporting tends to lessen over time (the gap between the lines decreases)."
  },
  {
    "objectID": "slides/day1-afternoon.html#realistic-limitation-of-nowcasting---finalized-data",
    "href": "slides/day1-afternoon.html#realistic-limitation-of-nowcasting---finalized-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Realistic Limitation of Nowcasting - Finalized Data",
    "text": "Realistic Limitation of Nowcasting - Finalized Data\n\nRecall that real-time access to finalized data is limited as finalized values can take months to report (e.g., Jan. 7 is finalized 294 days later).\nTo nowcast accurately, we must rely on the best available approximation of finalized data at the time of estimation (Feb. 25).\n\n\nmortality_as_of_feb25 &lt;- epix_as_of(mortality_archive, max_version = as_of_date)\nhead(mortality_as_of_feb25)\n\nAn `epi_df` object, 6 x 3 with metadata:\n* geo_type  = state\n* time_type = week\n* as_of     = 2024-02-25\n\n# A tibble: 6 × 3\n  geo_value time_value mortality\n* &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2023-12-31       213\n2 ca        2024-01-07       183\n3 ca        2024-01-14       183\n4 ca        2024-01-21       146\n5 ca        2024-01-28       124\n6 ca        2024-02-04       120"
  },
  {
    "objectID": "slides/day1-afternoon.html#ratio-calculation-summary",
    "href": "slides/day1-afternoon.html#ratio-calculation-summary",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Ratio Calculation & Summary",
    "text": "Ratio Calculation & Summary\n\nWe then use these “finalized” and real-time values to compute the mean ratio:\n\n# exclude date we're nowcasting for\nmortality_real_time_df = mortality_real_time_df |&gt; filter(time_value != \"2024-02-18\") \nmortality_as_of_feb25 = mortality_as_of_feb25 |&gt; filter(time_value != \"2024-02-18\")\nratio_real_time_to_feb25 &lt;- mortality_real_time_df$mortality / mortality_as_of_feb25$mortality\nsummary(ratio_real_time_to_feb25)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.1530  0.2317  0.2500  0.2565  0.2688  0.3917 \n\n\nOn average, the real-time rates are ~25.7% of the finalized.\n\n\n\nTells us the distribution is right-skewed (mean &gt; median) and so we should opt for the median."
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-on-feb.-25",
    "href": "slides/day1-afternoon.html#nowcasting-on-feb.-25",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting on Feb. 25",
    "text": "Nowcasting on Feb. 25\nSince the median ratio between real-time and finalized values is 0.250 (i.e., real-time values are typically 25% of the finalized), then the nowcast is\n\n# Now we can nowcast properly:\nnowcast &lt;- provisional *\n  1 / median(ratio_real_time_to_feb25)\nnowcast\n\n[1] 92\n\n\nSo, this nowcast is 92, which is much closer to the finalized value of 104 than the provisional value of 23."
  },
  {
    "objectID": "slides/day1-afternoon.html#summary-of-three-main-steps",
    "href": "slides/day1-afternoon.html#summary-of-three-main-steps",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Summary of Three Main Steps",
    "text": "Summary of Three Main Steps\nSo the main steps for this type of fixed lag nowcasting are…\n\nObtain the provisional value for the target.\nEstimate the ratio using the real-time and “finalized” data (for all previous dates that follow a consistent pattern in reporting).\nProfit.\n\n\n\nExpand for the accompanying code\n# Today\nas_of_date = as.Date(\"2024-02-25\")\n\n# 1. Obtain the provisional value\nprovisional &lt;- epix_as_of(mortality_archive, max_version = as_of_date) |&gt;\n  filter(time_value == as_of_date - 7) |&gt;\n  pull(mortality)\nprovisional\n\n# 2. Estimate the ratio \nmortality_real_time_df &lt;- map_dfr(dates, mortality_real_time) |&gt; filter(time_value != \"2024-02-18\") # Real-time\nmortality_as_of_feb25 &lt;- epix_as_of(mortality_archive, max_version = as_of_date) |&gt; filter(time_value != \"2024-02-18\")  # \"Finalized\"\n\nratio_real_time_to_feb25 &lt;- mortality_real_time_df$mortality / mortality_as_of_feb25$mortality\n\n# 3. Profit.\nnowcast &lt;- provisional *\n  1 / median(ratio_real_time_to_feb25)\nnowcast"
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-mortality-for-multiple-dates",
    "href": "slides/day1-afternoon.html#nowcasting-mortality-for-multiple-dates",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting Mortality for Multiple Dates",
    "text": "Nowcasting Mortality for Multiple Dates\n\nDefine Nowcast Function:\n\nInput: Takes in the dates to nowcast and the fixed lag\nOutput: The nowcasted mortality rates based on the ratio of real-time to finalized data.\n\n\n\n\nCode\nnowcast_function &lt;- function(nowcast_date, fixed_lag) {\n  as_of_date = nowcast_date + fixed_lag\n  \n  # 1. Obtain the provisional value for the target.\n  provisional &lt;- epix_as_of(mortality_archive, max_version = as_of_date) |&gt;\n    filter(time_value == as_of_date - fixed_lag) |&gt;\n    pull(mortality)\n  \n  #2. Estimate the ratio multiplier using\n  # real-time\n  dates_seq &lt;- seq(start_time, (nowcast_date - fixed_lag), by = \"week\")\n  mortality_real_time &lt;- map_dfr(dates_seq, mortality_real_time)\n  \n  # and \"finalized\" data\n  finalized &lt;- epix_as_of(mortality_archive, max_version = as_of_date) |&gt; filter(time_value &gt;= start_time & time_value &lt;= (nowcast_date - fixed_lag)) \n  \n  ratios &lt;- mortality_real_time$mortality / finalized$mortality\n  \n  # Remove infinite or NaN ratios (i.e., keep only finite values)\n  median_ratio &lt;- median(ratios[is.finite(ratios)])\n  \n  #3. Profit.\n  nowcast &lt;- provisional * (1 / median_ratio)\n  \n  # Return a dataframe with the nowcast and date\n  tibble(\n    time_value = nowcast_date,\n    nowcast_mortality = nowcast\n  )\n}"
  },
  {
    "objectID": "slides/day1-afternoon.html#map-nowcast-over-multiple-dates",
    "href": "slides/day1-afternoon.html#map-nowcast-over-multiple-dates",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Map Nowcast Over Multiple Dates",
    "text": "Map Nowcast Over Multiple Dates\n\nWe can use map2() to apply the function to a series of weeks (e.g., Jan. 28 to Mar. 24).\nReturns a dataframe with nowcasted results.\n\n\n# Apply Nowcast Function Over Multiple Dates\nnowcast_dates &lt;- seq(as.Date(\"2024-01-28\"), as.Date(\"2024-03-24\"), by = \"week\")\nfixed_lag &lt;- 7\nnowcast_results_df &lt;- map2(nowcast_dates, fixed_lag, nowcast_function) |&gt; list_rbind()"
  },
  {
    "objectID": "slides/day1-afternoon.html#map-nowcast-over-multiple-dates-1",
    "href": "slides/day1-afternoon.html#map-nowcast-over-multiple-dates-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Map Nowcast Over Multiple Dates",
    "text": "Map Nowcast Over Multiple Dates\nLet’s smooth with a rolling trailing mean (window size 4) & see the results:\n\n\n# A tibble: 9 × 2\n  time_value nowcast_mortality\n  &lt;date&gt;                 &lt;dbl&gt;\n1 2024-01-28             116. \n2 2024-02-04             145. \n3 2024-02-11             114. \n4 2024-02-18             109. \n5 2024-02-25             110. \n6 2024-03-03              92.8\n7 2024-03-10              90.3\n8 2024-03-17              82.6\n9 2024-03-24              65.4"
  },
  {
    "objectID": "slides/day1-afternoon.html#visualize-nowcast-real-time-and-finalized-values",
    "href": "slides/day1-afternoon.html#visualize-nowcast-real-time-and-finalized-values",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Visualize Nowcast, Real-time, and Finalized Values",
    "text": "Visualize Nowcast, Real-time, and Finalized Values\nFinally, we can compare these nowcast results to the real-time and finalized values:\n\nThe real-time counts tend to be biased below the finalized counts. Nowcasted values tend to provide a much better approximation of the truth (at least for these dates)."
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-moving-from-one-signal-to-two",
    "href": "slides/day1-afternoon.html#nowcasting-moving-from-one-signal-to-two",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting: Moving from One Signal to Two",
    "text": "Nowcasting: Moving from One Signal to Two\n\nRecall that in nowcasting the goal is to predict a finalized value from a provisional value.\nNow, we’ll move from one signal to two, creating a simple linear model to nowcast.\nExogenous features (predictors) could include relevant signals, such as Google symptom search trends.\nWe will use these signals to nowcast hospital admissions related to influenza."
  },
  {
    "objectID": "slides/day1-afternoon.html#data-sources-google-searches-hospital-admissions",
    "href": "slides/day1-afternoon.html#data-sources-google-searches-hospital-admissions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Data Sources: Google Searches & Hospital Admissions",
    "text": "Data Sources: Google Searches & Hospital Admissions\n\nGoogle Search Trends: Symptoms like cough, fever, and shortness of breath.\n\ns01: Cough, Phlegm, Sputum, Upper respiratory tract infection\n\ns02: Nasal congestion, Post nasal drip, Sinusitis, Common cold\n\nHospital Admissions: Data from the Department of Health & Human Services on confirmed influenza admissions.\nUsing these, we will nowcast hospital admissions by using Google symptom search trends for GA from April to June 2023.\nThe first step is to fetch this data…"
  },
  {
    "objectID": "slides/day1-afternoon.html#data-sources-google-searches-hospital-admissions-1",
    "href": "slides/day1-afternoon.html#data-sources-google-searches-hospital-admissions-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Data Sources: Google Searches & Hospital Admissions",
    "text": "Data Sources: Google Searches & Hospital Admissions\n\n# Fetch Google symptom data for s01 and s02\nx1 &lt;- pub_covidcast(\n  source = \"google-symptoms\",\n  signals = \"s01_smoothed_search\", \n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"ga\",\n  time_values = epirange(20230401, 20230701),\n  issues = \"*\"\n) |&gt;\n  select(geo_value, time_value, version = issue, avg_search_vol_s01 = value) |&gt;\n  as_epi_archive(compactify = FALSE)\n\nx2 &lt;- pub_covidcast(\n  source = \"google-symptoms\",\n  signals = \"s02_smoothed_search\",\n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"ga\",\n  time_values = epirange(20230401, 20230701),\n  issues = \"*\"\n) |&gt;\n  select(geo_value, time_value, version = issue, avg_search_vol_s02 = value) |&gt;\n  as_epi_archive(compactify = FALSE)\n\n# Fetch hospital admissions data\ny1 &lt;- pub_covidcast(\n  source = \"hhs\",\n  signals = \"confirmed_admissions_influenza_1d\",\n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"ga\",\n  time_values = epirange(20230401, 20230701),\n  issues = \"*\"\n) |&gt;\n  select(geo_value, time_value, version = issue, admissions = value) |&gt;\n  as_epi_archive(compactify = FALSE)"
  },
  {
    "objectID": "slides/day1-afternoon.html#merging-the-archives",
    "href": "slides/day1-afternoon.html#merging-the-archives",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Merging the Archives",
    "text": "Merging the Archives\n\nWe’ll merge the symptom search trends (x1, x2) with hospital admissions data (y) using epix_merge() from epiprocess.\nThis allows us to match data by time and geography, & fill any missing values with the most recent observation (LOCF)."
  },
  {
    "objectID": "slides/day1-afternoon.html#linear-model-a-simple-approach-for-nowcasting",
    "href": "slides/day1-afternoon.html#linear-model-a-simple-approach-for-nowcasting",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Linear Model: A Simple Approach for Nowcasting",
    "text": "Linear Model: A Simple Approach for Nowcasting\n\nAside from ratios, one of the simplest approach to nowcasting is to use a linear regression model.\nWe model the relationship between provisional (predictor) data and response data.\nThis model helps us make predictions for the finalized data based on the current (provisional) signals."
  },
  {
    "objectID": "slides/day1-afternoon.html#linear-regression",
    "href": "slides/day1-afternoon.html#linear-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nGoal: Estimate the coefficients \\(\\beta_0\\) and \\(\\beta_1\\) that describe the relationship between the predictor \\(x_i\\) and the outcome \\(y_i\\).\nLinear Model: The relationship is assumed to be:\n\\[y_i \\approx \\beta_0 + \\beta_1 x_i \\]\nwhere \\(\\beta_0\\) is the intercept, \\(\\beta_1\\) is the slope.\nIn R: Use lm(y ~ x) to estimate the coefficients, where y is the outcome variable and x is the predictor."
  },
  {
    "objectID": "slides/day1-afternoon.html#multiple-linear-regression",
    "href": "slides/day1-afternoon.html#multiple-linear-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\n\nGoal: Estimate coefficients \\(\\beta_0, \\beta_1, \\dots, \\beta_p\\) that describe the relationship between multiple predictors \\(x_{i1}, x_{i2}, \\dots, x_{ip}\\) and the outcome \\(y_i\\).\nModel: The relationship is assumed to be:\n\\[y_i \\approx \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip}\\]\nwhere: \\(\\beta_0\\) is the intercept, \\(\\beta_1, \\dots, \\beta_p\\) are the coefficients.\nIn R: Use lm(y ~ x1 + x2 + ... + xp) to estimate the coefficients, where y is the outcome and x1, x2, ..., xp are the predictors."
  },
  {
    "objectID": "slides/day1-afternoon.html#multiple-linear-regression-model",
    "href": "slides/day1-afternoon.html#multiple-linear-regression-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Multiple Linear Regression Model",
    "text": "Multiple Linear Regression Model\n\nA linear model is a good choice to describe the relationship between search trends and hospital admissions.\nThe model will include two predictors (s01 and s02).\nWe’ll use these two search trend signals to predict hospital admissions (response)."
  },
  {
    "objectID": "slides/day1-afternoon.html#multiple-linear-regression-model-1",
    "href": "slides/day1-afternoon.html#multiple-linear-regression-model-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Multiple Linear Regression Model",
    "text": "Multiple Linear Regression Model\n\n# Define the function for lm model fit and prediction\nlm_mod_pred &lt;- function(data, gk, rtv, ...) {\n  \n  # Fit the linear model\n  model &lt;- lm(admissions ~ avg_search_vol_s01 + avg_search_vol_s02, data = data)\n  \n  # Make predictions\n  predictions = predict(model,\n                        newdata = data |&gt;\n                          # Use tidyr::fill() for LOCF if predictor data is incomplete \n                          fill(avg_search_vol_s01, .direction = \"down\") |&gt; \n                          fill(avg_search_vol_s02, .direction = \"down\") |&gt;\n                          filter(time_value == max(time_value)),\n                        interval = \"prediction\", level = 0.9\n  )\n\n  # Pull off true time value for comparison to target\n  real_time_val = data |&gt; filter(time_value == max(time_value)) |&gt; pull(admissions)\n\n  return(data.frame(predictions, actual_nowcast_date = max(data$time_value), real_time_val = real_time_val))\n}\n\nNote that this code is intentionally simple; while it can be refined to handle cases like negatives or other boundary conditions, we aim to avoid unnecessary complexity."
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-with-epix_slide",
    "href": "slides/day1-afternoon.html#nowcasting-with-epix_slide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting with epix_slide()",
    "text": "Nowcasting with epix_slide()\n\nWe will use epix_slide() to create a sliding window of training data.\nThe model will be trained on a 14-day window before the target date, and predictions will be made for the target date.\nThe beauty of this function is that it is version-aware - the sliding computation at any given reference time t is performed on data that would have been available as of t automatically."
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-with-epix_slide-1",
    "href": "slides/day1-afternoon.html#nowcasting-with-epix_slide-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting with epix_slide()",
    "text": "Nowcasting with epix_slide()\n\n# Define the reference time points for nowcasting\ntargeted_nowcast_dates &lt;- seq(as.Date(\"2023-04-15\"), as.Date(\"2023-06-15\"), by = \"1 week\")\nref_time_values = targeted_nowcast_dates + 2  # Adjust for the systematic 2-day latency in the response\n# Determine this from revision_summary(y1, print_inform = TRUE) \n\n# Perform nowcasting using epix_slide\nnowcast_res &lt;- archive |&gt;\n  group_by(geo_value) |&gt;\n  epix_slide(\n    .f = lm_mod_pred,\n    .before = 14,  # 14-day training period\n    .versions = ref_time_values, \n    .new_col_name = \"res\"\n  ) |&gt;\n  unnest() |&gt; # Nesting creates a list-column of data frames; unnesting flattens it back out into regular columns. \n  mutate(targeted_nowcast_date = targeted_nowcast_dates, time_value = actual_nowcast_date) |&gt;\n  ungroup()\n\n# View results\nhead(nowcast_res, n=2)\n\n# A tibble: 2 × 9\n  geo_value version      fit    lwr   upr actual_nowcast_date real_time_val\n  &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;                      &lt;dbl&gt;\n1 ga        2023-04-17  4.64 -0.122  9.39 2023-04-15                      4\n2 ga        2023-04-24  7.36  1.56  13.2  2023-04-22                      4\n# ℹ 2 more variables: targeted_nowcast_date &lt;date&gt;, time_value &lt;date&gt;"
  },
  {
    "objectID": "slides/day1-afternoon.html#compare-with-the-actual-admissions",
    "href": "slides/day1-afternoon.html#compare-with-the-actual-admissions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Compare with the Actual Admissions",
    "text": "Compare with the Actual Admissions\n\nAfter making predictions, we compare them to the actual hospital admissions.\n\n\n# Left join with latest results \n# Latest snapshot of data (with the latest/finalized admissions)\nx_latest &lt;- epix_as_of(archive, max_version = max(archive$DT$version)) |&gt; select(-c(avg_search_vol_s01, avg_search_vol_s02))\n\nres &lt;- nowcast_res |&gt; left_join(x_latest, by = c(\"geo_value\", \"time_value\"))\nhead(res)\n\n# A tibble: 6 × 10\n  geo_value version      fit    lwr   upr actual_nowcast_date real_time_val\n  &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;                      &lt;dbl&gt;\n1 ga        2023-04-17  4.64 -0.122  9.39 2023-04-15                      4\n2 ga        2023-04-24  7.36  1.56  13.2  2023-04-22                      4\n3 ga        2023-05-01  6.06  1.57  10.5  2023-04-29                      5\n4 ga        2023-05-08  5.01  1.28   8.74 2023-05-06                      6\n5 ga        2023-05-15  8.14  5.69  10.6  2023-05-11                      8\n6 ga        2023-05-22  3.43 -2.35   9.21 2023-05-20                      4\n# ℹ 3 more variables: targeted_nowcast_date &lt;date&gt;, time_value &lt;date&gt;,\n#   admissions &lt;dbl&gt;"
  },
  {
    "objectID": "slides/day1-afternoon.html#visualizing-the-nowcast-results",
    "href": "slides/day1-afternoon.html#visualizing-the-nowcast-results",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Visualizing the Nowcast Results",
    "text": "Visualizing the Nowcast Results\n\nWe can then visualize the nowcast results alongside the true values using ggplot2:"
  },
  {
    "objectID": "slides/day1-afternoon.html#key-takeaways-linear-regression-nowcasting-example",
    "href": "slides/day1-afternoon.html#key-takeaways-linear-regression-nowcasting-example",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Key Takeaways: Linear Regression Nowcasting Example",
    "text": "Key Takeaways: Linear Regression Nowcasting Example\n\nProvisional Data as Predictors: Using Google symptom search trends to predict influenza hospital admissions.\nSimple Linear Model: A linear regression model captures the relationship between symptom searches and hospital admissions.\nActionable Predictions: Nowcasts provide timely insights for hospital admissions, even before data is finalized.\nSliding Window Approach: Predictions are based on data up to the current time, ensuring no future information influences the nowcast.\nEvaluation: Predictions are compared with actual admissions visually."
  },
  {
    "objectID": "slides/day1-afternoon.html#goal-of-this-case-study",
    "href": "slides/day1-afternoon.html#goal-of-this-case-study",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Goal of this Case Study",
    "text": "Goal of this Case Study\nGoal: Nowcast COVID-19 Case Rates using %CLI for Massachusetts.\n\n%CLI is contained in the Epidata API.\nCase rates by specimen collection date are not. They are from the MA gov website.\nCase rates in the API (JHU) are aligned by report date, not specimen collection/test date.\nWorking with cases aligned by test date allows us to avoid the more unpredictable delays introduced by the report date."
  },
  {
    "objectID": "slides/day1-afternoon.html#summary-of-main-steps",
    "href": "slides/day1-afternoon.html#summary-of-main-steps",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Summary of Main Steps",
    "text": "Summary of Main Steps\n\nThe workflow is similar to the previous example where we nowcasted using two variables, only more involved. The main steps are…\n\nFetch Data: Retrieve %CLI and COVID-19 case data (by specimen collection date) for MA.\nMerge Data: Align %CLI and case rate data using epix_merge, filling missing values via last observation carried forward (LOCF).\nModel & Prediction: Fit a linear model to predict case rates based on %CLI, trained on a 30-day rolling window.\nNowcast Execution: Use epix_slide to nowcast the case rates dynamically.\nVisualization: Plot actual vs. nowcasted case rates with confidence intervals to assess model accuracy.\n\nSo the first step is to fetch the data…"
  },
  {
    "objectID": "slides/day1-afternoon.html#construct-an-epi_archive-from-scratch",
    "href": "slides/day1-afternoon.html#construct-an-epi_archive-from-scratch",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Construct an epi_archive from Scratch",
    "text": "Construct an epi_archive from Scratch\n\nHere’s the archive of COVID-19 case excel files from the MA gov website, which we’ll use to construct our own epi_archive.  Brief summary of this data:\n\nFirst release: Raw .xlsx data was first released early January 2021.\nChange in reporting: Starting July 1, 2021, the dashboard shifted from 7 days/week to 5 days/week (Monday-Friday).\nFriday, Saturday, and Sunday data is included in the Monday dashboard.\nWhen Monday is a holiday, the Friday through Monday data is posted on Tuesday."
  },
  {
    "objectID": "slides/day1-afternoon.html#construct-an-epi_archive-from-scratch-1",
    "href": "slides/day1-afternoon.html#construct-an-epi_archive-from-scratch-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Construct an epi_archive from Scratch",
    "text": "Construct an epi_archive from Scratch\n\n\nPurpose: To create an epi_archive object for storing versioned time series data.\nRequired Columns:\n\ngeo_value: Geographic data (e.g., region).\ntime_value: Time-related data (e.g., date, time).\nversion: Tracks when the data was available (enables version-aware forecasting).\n\nConstructor:\n\nnew_epi_archive(): For manual construction of epi_archive (assumes validation of inputs).\n\nRecommended Method:\n\nas_epi_archive(): Simplifies the creation process, ensuring proper formatting and validation. We’ll use this one when we download some data from the MA gov website!"
  },
  {
    "objectID": "slides/day1-afternoon.html#main-steps-to-construct-the-epi_archive",
    "href": "slides/day1-afternoon.html#main-steps-to-construct-the-epi_archive",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Main Steps to Construct the epi_archive",
    "text": "Main Steps to Construct the epi_archive\n\n\nLoad necessary Libraries: Such as tidyverse, readxl, epiprocess.\nProcess Each Date’s Data:\n\nA function we’ll make (process_covid_data) downloads and processes daily COVID-19 data from the MA gov Excel files on their website.\nThe data is cleaned and formatted with columns: geo_value, time_value, version, and values.\n\nHandle Missing Data: Checks if a date’s data is available (handle 404 errors).\nCreate epi_archive:\n\nCombine processed data into a tibble.\nConvert the tibble to an epi_archive object using as_epi_archive()."
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---code-for-one-date",
    "href": "slides/day1-afternoon.html#fetch-data---code-for-one-date",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - Code for One Date",
    "text": "Fetch Data - Code for One Date\n\n# Load required libraries\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(httr)\nlibrary(tibble)\nlibrary(epiprocess)\n\n# Function to download and process each Excel file for a given date\nprocess_covid_data &lt;- function(Date) {\n  # Generate the URL for the given date\n  url &lt;- paste0(\"https://www.mass.gov/doc/covid-19-raw-data-\", tolower(gsub(\"-0\", \"-\", format(Date, \"%B-%d-%Y\"))), \"/download\") \n  # Applies gsub(\"-0\", \"-\", ...) to replace any occurrence of -0 (such as in \"April-01\") with just - (resulting in \"April-1\").\n  \n  # Check if the URL exists (handle the 404 error by skipping that date)\n  response &lt;- GET(url)\n  \n  if (status_code(response) != 200) {\n    return(NULL)  # Skip if URL doesn't exist (404)\n  }\n  \n  # Define the destination file path for the Excel file\n  file_path &lt;- tempfile(fileext = \".xlsx\")\n  \n  # Download the Excel file\n  GET(url, write_disk(file_path, overwrite = TRUE))\n  \n  # Read the relevant sheet from the Excel file\n  data &lt;- read_excel(file_path, sheet = \"CasesByDate (Test Date)\")\n  \n  # Process the data: rename columns and convert Date\n  data &lt;- data |&gt;\n    rename(\n      Date = `Date`,\n      Positive_Total = `Positive Total`,\n      Positive_New = `Positive New`,\n      Case_Average_7day = `7-day confirmed case average`\n    ) |&gt;\n    mutate(Date = as.Date(Date))  # Convert to Date class\n  \n  # Create a tibble with the required columns for the epi_archive\n  tib &lt;- tibble(\n    geo_value = \"ma\",  # Massachusetts (geo_value)\n    time_value = data$Date,  # Date from the data\n    version = Date,  # The extracted version date\n    case_rate_7d_av = data$Case_Average_7day  # 7-day average case value\n  )\n  \n  return(tib)\n}"
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---code-breakdown",
    "href": "slides/day1-afternoon.html#fetch-data---code-breakdown",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - Code Breakdown",
    "text": "Fetch Data - Code Breakdown\n\n\nThis purpose of this function is to download and process each Excel file as of a date.\nURL Creation: Dynamically generates the URL based on the date, removing leading zeros in day values (e.g., “April-01” → “April-1”).\nCheck URL: Sends a request (GET(url)) and skips the date if the URL returns a non-200 status (e.g., 404 error).\nDownload File: Saves the Excel file to a temporary path using tempfile() and GET().\nRead Data: Loads the relevant sheet (“CasesByDate”) from the Excel file using read_excel().\nTibble Creation: Constructs a tibble with geo_value, time_value, version, and case_rate_7d_av to later compile into an epi_archive (you can think of an epi_archive as being a comprised of many epi_dfs)."
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---process-range-of-dates",
    "href": "slides/day1-afternoon.html#fetch-data---process-range-of-dates",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - Process Range of Dates",
    "text": "Fetch Data - Process Range of Dates\n\nNote that process_covid_data() works on one date at a time.\nSo now, we need a function that iterates over a date range and applies process_covid_data() to each date & combines the resulting tibbles into an epi_archive.\nWe call this function process_data_for_date_range()…"
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---process-range-of-dates-1",
    "href": "slides/day1-afternoon.html#fetch-data---process-range-of-dates-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - Process Range of Dates",
    "text": "Fetch Data - Process Range of Dates\n\n# Function to process data for a range of dates\nprocess_data_for_date_range &lt;- function(start_date, end_date) {\n  # Generate a sequence of dates between start_date and end_date\n  date_sequence &lt;- seq(as.Date(start_date), as.Date(end_date), by = \"day\")\n  \n  # Process data for each date and combine results\n  covid_data_list &lt;- lapply(date_sequence, function(Date) {\n    process_covid_data(Date)  # Skip over dates with no data (NULLs will be ignored)\n  })\n  \n  # Combine all non-null individual tibbles into one data frame\n  combined_data &lt;- bind_rows(covid_data_list[!sapply(covid_data_list, is.null)])\n  \n  # Convert the combined data into an epi_archive object\n  if (nrow(combined_data) &gt; 0) {\n    epi_archive_data &lt;- combined_data |&gt;\n      as_epi_archive(compactify = FALSE)\n    \n    return(epi_archive_data)\n  } else {\n    message(\"No valid data available for the given date range.\")\n    return(NULL)\n  }\n}"
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---code-breakdown-1",
    "href": "slides/day1-afternoon.html#fetch-data---code-breakdown-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - Code Breakdown",
    "text": "Fetch Data - Code Breakdown\nHere’s a summary of what process_data_for_date_range() does: 1. Generates Date Range: Creates a sequence of dates between start_date and end_date.\n\nProcesses Data: Applies the process_covid_data function to each date in the range (skip over dates with no data).\nCombines Results: Combines all valid (non-NULL) tibbles into one single data frame.\nCreates epi_archive: Converts the combined data into an epi_archive object."
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---run-the-function-inspect-archive",
    "href": "slides/day1-afternoon.html#fetch-data---run-the-function-inspect-archive",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - Run the Function & Inspect Archive",
    "text": "Fetch Data - Run the Function & Inspect Archive\n\n\nNow, let’s run the function & inspect the resulting epi_archive of 7-day averaged COVID-19 case counts:\nExpect building the archive to take a nontrivial amount of time (enough for a cup of coffee or to meditate on life).\n\n\n\n\n# Example usage: process data between Jan. 10, 2021, and Dec. 1, 2021\ny &lt;- process_data_for_date_range(\"2021-01-10\", \"2021-12-01\")  # Raw .xlsx data is first released on Jan. 4, 2021\ny\n\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-01-29 / 2021-11-30\nℹ First/last version with update: 2021-01-10 / 2021-12-01\nℹ Versions end: 2021-12-01\nℹ A preview of the table (135549 rows x 4 columns):\nKey: &lt;geo_value, time_value, version&gt;\n        geo_value time_value    version case_rate_7d_av\n           &lt;char&gt;     &lt;Date&gt;     &lt;Date&gt;           &lt;num&gt;\n     1:        ma 2020-01-29 2021-01-10              NA\n     2:        ma 2020-01-29 2021-01-11              NA\n     3:        ma 2020-01-29 2021-01-12              NA\n     4:        ma 2020-01-29 2021-01-13              NA\n     5:        ma 2020-01-29 2021-01-14              NA\n    ---                                                \n135545:        ma 2021-11-28 2021-11-30        2196.000\n135546:        ma 2021-11-28 2021-12-01        2352.286\n135547:        ma 2021-11-29 2021-11-30        1735.714\n135548:        ma 2021-11-29 2021-12-01        2371.286\n135549:        ma 2021-11-30 2021-12-01        1972.143"
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---outpatient-doctors-visits-for-cli",
    "href": "slides/day1-afternoon.html#fetch-data---outpatient-doctors-visits-for-cli",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - % Outpatient Doctors Visits for CLI",
    "text": "Fetch Data - % Outpatient Doctors Visits for CLI\n\n\nNow, from the Epidata API, let’s download the estimated percentage of outpatient doctor visits primarily for COVID-related symptoms, based on health system data.\nComes pre-smoothed in time using a Gaussian linear smoother\nThis will be the predictor when we nowcast COVID-19 Case Rates in MA.\n\n\n\n# Step 1: Fetch Versioned Data \nx &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"ma\", # Just for MA to keep it simple (& to go with the case data by test date for that state)\n  time_value = epirange(20210301, 20212101), \n  issues = epirange(20210301, 20212101)\n) |&gt;\n  select(geo_value, time_value,\n         version = issue,\n         percent_cli = value\n  ) |&gt;\n  as_epi_archive(compactify = FALSE)"
  },
  {
    "objectID": "slides/day1-afternoon.html#use-epix_merge-to-merge-the-two-archives",
    "href": "slides/day1-afternoon.html#use-epix_merge-to-merge-the-two-archives",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Use epix_merge() to Merge the Two Archives",
    "text": "Use epix_merge() to Merge the Two Archives\nNow we’ll use epix_merge() to combine the two epi_archives that share the same geo_value & time_value.\n\n\narchive &lt;- epix_merge(\n  x, y,\n  sync = \"locf\",\n  compactify = FALSE\n)\narchive\n\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-01-29 / 2021-12-13\nℹ First/last version with update: 2021-01-10 / 2021-12-17\nℹ Versions end: 2021-12-17\nℹ A preview of the table (139190 rows x 5 columns):\nKey: &lt;geo_value, time_value, version&gt;\n        geo_value time_value    version percent_cli case_rate_7d_av\n           &lt;char&gt;     &lt;Date&gt;     &lt;Date&gt;       &lt;num&gt;           &lt;num&gt;\n     1:        ma 2020-01-29 2021-01-10          NA              NA\n     2:        ma 2020-01-29 2021-01-11          NA              NA\n     3:        ma 2020-01-29 2021-01-12          NA              NA\n     4:        ma 2020-01-29 2021-01-13          NA              NA\n     5:        ma 2020-01-29 2021-01-14          NA              NA\n    ---                                                            \n139186:        ma 2021-12-11 2021-12-16    2.306966              NA\n139187:        ma 2021-12-11 2021-12-17    2.281141              NA\n139188:        ma 2021-12-12 2021-12-16    2.333759              NA\n139189:        ma 2021-12-12 2021-12-17    2.369756              NA\n139190:        ma 2021-12-13 2021-12-17    2.256551              NA"
  },
  {
    "objectID": "slides/day1-afternoon.html#fitting-and-predicting-with-linear-model",
    "href": "slides/day1-afternoon.html#fitting-and-predicting-with-linear-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fitting and Predicting with Linear Model",
    "text": "Fitting and Predicting with Linear Model\n\n\nDefine lm_mod_pred(): A function that fits a linear model to forecast case rates based on the percent_cli predictor.\nUse predict() with a 90% prediction interval.\nSave the actual case rates to compare to the nowcasts later.\n\n\n\nlm_mod_pred &lt;- function(data, ...) {\n  # Linear model\n  model &lt;- lm(case_rate_7d_av ~ percent_cli, data = data)\n\n  # Make predictions\n  predictions = predict(model,\n                        newdata = data |&gt;\n                          fill(percent_cli, .direction = \"down\") |&gt; \n                          filter(time_value == max(time_value)),\n                        interval = \"prediction\", level = 0.9)\n  \n  # Pull off real-time value for later comparison to the nowcast value\n  real_time_val = data |&gt; filter(time_value == max(time_value)) |&gt; pull(case_rate_7d_av)\n  \n  # Could clip predictions and bounds at 0\n  return(data.frame(predictions, actual_nowcast_date = max(data$time_value), real_time_val = real_time_val)) \n}"
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-with-epix_slide-2",
    "href": "slides/day1-afternoon.html#nowcasting-with-epix_slide-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting with epix_slide()",
    "text": "Nowcasting with epix_slide()\n\nSpecify targets: Define the target dates for nowcasting (e.g., 1st of each month) & adjust training data to include the lag for the latent case data.\nSliding window: Use epix_slide() to apply the linear model across a sliding window of data for each region.\nTraining-test split: Use the last 30 days of data to train and predict case rates for each target nowcast date."
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-with-epix_slide-3",
    "href": "slides/day1-afternoon.html#nowcasting-with-epix_slide-3",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting with epix_slide()",
    "text": "Nowcasting with epix_slide()\n\n# Define the reference time points (to give the training/test split)\ntargeted_nowcast_dates &lt;- seq(as.Date(\"2021-04-01\"), as.Date(\"2021-11-01\"), by = \"1 month\") \nref_time_values = targeted_nowcast_dates + 1 # + 1 because the case data is 1 day latent. \n# Determine this from revision_summary(y)\n\n# Use epix_slide to perform the nowcasting with a training-test split\nnowcast_res &lt;- archive |&gt;\n  group_by(geo_value) |&gt;\n  epix_slide(\n    .f = lm_mod_pred,  # Pass the function defined above\n    .before = 30,   # Training period of 30 days\n    .versions = ref_time_values, # Determines the day where training data goes up to (not inclusive)\n    .new_col_name = \"res\"\n  ) |&gt;\n  unnest() |&gt;\n  mutate(targeted_nowcast_date = targeted_nowcast_dates,\n         time_value = actual_nowcast_date)\n\n# Take a peek at the results\nhead(nowcast_res, n = 1)\n\n# A tibble: 1 × 9\n# Groups:   geo_value [1]\n  geo_value version      fit   lwr   upr actual_nowcast_date real_time_val\n  &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;                      &lt;dbl&gt;\n1 ma        2021-04-02 2114. 1975. 2254. 2021-04-01                  1556.\n# ℹ 2 more variables: targeted_nowcast_date &lt;date&gt;, time_value &lt;date&gt;"
  },
  {
    "objectID": "slides/day1-afternoon.html#visualizing-nowcasts-vs.-actual-values",
    "href": "slides/day1-afternoon.html#visualizing-nowcasts-vs.-actual-values",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Visualizing Nowcasts vs. Actual Values",
    "text": "Visualizing Nowcasts vs. Actual Values\nMerge the nowcast results with the latest data for more direct comparison:\n\nx_latest &lt;- epix_as_of(archive, max_version = max(archive$DT$version)) |&gt;\n  select(-percent_cli) \n\nres &lt;- nowcast_res |&gt; left_join(x_latest, by = c(\"geo_value\", \"time_value\"))\n\nres\n\n# A tibble: 8 × 10\n# Groups:   geo_value [1]\n  geo_value version       fit    lwr   upr actual_nowcast_date real_time_val\n  &lt;chr&gt;     &lt;date&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;                      &lt;dbl&gt;\n1 ma        2021-04-02 2114.  1975.  2254. 2021-04-01                  1556.\n2 ma        2021-05-02 1083.   851.  1316. 2021-05-01                   869.\n3 ma        2021-06-02  353.   164.   541. 2021-06-01                   117.\n4 ma        2021-07-02   57.1   11.3  103. 2021-07-01                    59 \n5 ma        2021-08-02  513.   284.   742. 2021-08-01                   572.\n6 ma        2021-09-02 1207.   888.  1527. 2021-09-01                  1099.\n7 ma        2021-10-02 1575.  1357.  1793. 2021-09-30                  1069 \n8 ma        2021-11-02 1299.  1257.  1340. 2021-11-01                   891.\n# ℹ 3 more variables: targeted_nowcast_date &lt;date&gt;, time_value &lt;date&gt;,\n#   case_rate_7d_av &lt;dbl&gt;"
  },
  {
    "objectID": "slides/day1-afternoon.html#visualizing-nowcasts-vs.-actual-values-1",
    "href": "slides/day1-afternoon.html#visualizing-nowcasts-vs.-actual-values-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Visualizing Nowcasts vs. Actual Values",
    "text": "Visualizing Nowcasts vs. Actual Values\n\nFinally, plot the predictions & real-time values on top of latest COVID-19 case rates using ggplot2:"
  },
  {
    "objectID": "slides/day1-afternoon.html#takeaways",
    "href": "slides/day1-afternoon.html#takeaways",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Takeaways",
    "text": "Takeaways\nGoal: Predict COVID-19 case rates using %CLI, overcoming delays in report data.\nMain Steps:\n\nFetch Data: Collect case rates and %CLI data.\nMerge Data: Align datasets with epix_merge() and fill missing values.\nModel: Fit a linear model to predict case rates.\nNowcast: Apply dynamic forecasting with epix_slide().\nVisualize: Plot nowcasts vs. actual case rates with confidence intervals.\n\nOverall, nowcasting, based on the linear model, provided a closer approximation of true case rates compared to the real-time values."
  },
  {
    "objectID": "slides/day1-afternoon.html#final-slide",
    "href": "slides/day1-afternoon.html#final-slide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Final slide",
    "text": "Final slide\nThanks:\n\nThe whole CMU Delphi Team (across many institutions)\nOptum/UnitedHealthcare, Change Healthcare.\nGoogle, Facebook, Amazon Web Services.\nQuidel, SafeGraph, Qualtrics.\nCenters for Disease Control and Prevention.\nCouncil of State and Territorial Epidemiologists\n\n\n    \n\n\n\n\n\nExplore, clean & transform data — cmu-delphi/insightnet-workshop-2024"
  },
  {
    "objectID": "slides/day1-morning.html#section",
    "href": "slides/day1-morning.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Signal Discovery & Data Fetching",
    "text": "Signal Discovery & Data Fetching"
  },
  {
    "objectID": "slides/day1-morning.html#outline",
    "href": "slides/day1-morning.html#outline",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Outline",
    "text": "Outline\n\nAbout Delphi\nGoals of Delphi Epidata platform\nEpidata API\nFinding data sources and signals\nVersioned data"
  },
  {
    "objectID": "slides/day1-morning.html#about-delphi",
    "href": "slides/day1-morning.html#about-delphi",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "About Delphi",
    "text": "About Delphi\n\nFounded in 2012 at Carnegie Mellon University, now expanded to UC Berkeley, and University of British Columbia.\nCurrently 5 faculty, ~10 PhD students, ~15 staff (mostly software engineers).\nEasy to join us from anywhere (lots of volunteers during Covid-19 pandemic).\nWe are:\n\nCDC Center of Excellence for Influenza and Covid-19 Forecasting (2019-24).\nCDC Innovation Center for Outbreak Analytics and Disease Modeling (2024-29).\n\n\nOur mission: To develop the theory and practice of epidemic detection, tracking and forecasting, and their use in decision making, both public and private."
  },
  {
    "objectID": "slides/day1-morning.html#what-does-delphi-do",
    "href": "slides/day1-morning.html#what-does-delphi-do",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What does Delphi do?",
    "text": "What does Delphi do?\n\nProcure real-time, aggregated data streams informative of infectious diseases and syndromes, in collaboration with partners in industry and government.\nExtract signals and make them widely available via the Epidata platform & API.\nDevelop and deploy algorithms for epidemic detection, tracking, forecasting.\nDevelop and maintain statistical software packages for these tasks.\nMake it all production-grade, maximally-accessible, and open-source (to serve CDC, state and local public health agencies, epi-forecasting researchers, data journalists, the public)"
  },
  {
    "objectID": "slides/day1-morning.html#what-we-provide",
    "href": "slides/day1-morning.html#what-we-provide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What we provide",
    "text": "What we provide"
  },
  {
    "objectID": "slides/day1-morning.html#goals-of-delphi-epidata-platform-and-repository",
    "href": "slides/day1-morning.html#goals-of-delphi-epidata-platform-and-repository",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Goals of Delphi Epidata platform and repository",
    "text": "Goals of Delphi Epidata platform and repository\n\n\nBe the one-stop shop for aggregated epi-surveillance time-series (“epi-signals”)\n\nHence: include also signals available elsewhere, especially if they don’t keep data revisions - E.g. CDC’s own NSSP, NWSS\nBe the national historical repository of record & preserve the raw data\n\nBe the national clearinghouse for epi-signals, including those held elsewhere\n\nThe go-to place for signal discovery\n\nAdd value to existing signals and synthesize new ones\n\nAdded value: see next slide\nSynthesize new: via signal fusion, e.g. nowcasting\n\nBe the focal point for community-wide efforts to open up privately held data\n\nBetter positioned than government or industry"
  },
  {
    "objectID": "slides/day1-morning.html#the-bigger-goal",
    "href": "slides/day1-morning.html#the-bigger-goal",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "The bigger goal",
    "text": "The bigger goal\nThe goal is to make epi-surveillance more nimble, complete, standardized, robust, and real-time; and less burdensome on the health system itself. Epidata is not the solution; but we hope it is a blueprint towards such a solution."
  },
  {
    "objectID": "slides/day1-morning.html#what-is-the-epidata-repository",
    "href": "slides/day1-morning.html#what-is-the-epidata-repository",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What is the Epidata repository",
    "text": "What is the Epidata repository\nEpidata is a repository of aggregated epi-surveillance time series. To the full extent we can, we make everything free and open-source.\n\nTo date, it has accumulated over 5 billion records (each record is the value of a signal, at a particular date, and a particular location).\nAt the peak of the pandemic, we were receiving millions of API queries per day.\nData comes from: public health reporting, medical insurance claims, medical device data, Google search queries, wastewater, app-based mobility patterns.\nMany of our data streams simply aren’t available anywhere else.\nAdded value we provide: revision tracking, anomaly detection, trend detection, smoothing, imputation, geo-temporal-demographic disaggregation"
  },
  {
    "objectID": "slides/day1-morning.html#features-of-delphi-epidata",
    "href": "slides/day1-morning.html#features-of-delphi-epidata",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Features of Delphi Epidata",
    "text": "Features of Delphi Epidata\n\n\nBuilt-in support for:\n\nData revisions (“backfill”). Concepts of “reporting date” and “as of”.\nBackfill projection and alerting to changes in backfill dynamics\nGeo levels w/ auto-aggregation: county, MSA, HRR, state, HHS region, nation\n\nAlso esoteric ones: DMA, sewer sheds\n\nDemographic breakdown\nRepresentation for missingness and censoring\nPopulation sizes and fine-grained population density\n\nPre-computed smoothing and normalization (customization planned)\nAccess control\nCode is Open Source. Signals are as accessible (w/ API, SDK) as allowed by DUAs"
  },
  {
    "objectID": "slides/day1-morning.html#epidata-api-1",
    "href": "slides/day1-morning.html#epidata-api-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Epidata API",
    "text": "Epidata API\n\nDelphi’s Epidata API provides real-time access to epidemiological surveillance data.\nThe main endpoint (covidcast) providing daily updates about current COVID-19 and influenza activity across the United States.\nA variety of other endpoints, providing primarily historical data about various diseases including COVID-19, influenza, dengue fever, and norovirus in several countries.\nA full-featured R client is available for quick access to all data.\nA Legacy Python client is available, full-featured Python client in development."
  },
  {
    "objectID": "slides/day1-morning.html#some-of-our-data-sources",
    "href": "slides/day1-morning.html#some-of-our-data-sources",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Some of our data sources",
    "text": "Some of our data sources\nOngoing Sources:\n\nInsurance claims: %Covid {inpatient, outpatient}, by {county x day}\nGoogle Symptom searches: 7 symptoms groups, by {county x day}\nQuidel/Ortho antigen tests: %Covid by age group, by {county x day}\nNCHS Deaths: all-cause, pneumonia, flu, Covid, by {state x week}\nNSSP ED visits: %Covid, %flu, %RSV, by {county x week} (new!)\nNWSS Covid, by {sampling-site x day} (in progress)"
  },
  {
    "objectID": "slides/day1-morning.html#some-of-our-data-sources-1",
    "href": "slides/day1-morning.html#some-of-our-data-sources-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Some of our data sources",
    "text": "Some of our data sources\nActive during pandemic, could be restarted for the next PHE**:\n\nHHS Hosp/ICU beds: Covid, flu, by age-group, by {state x day}, {facility x week}\nCTIS (“Delphi Facebook Survey”): many dozens of questions, by (county x day)\nSTLT-reported: {cases, deaths} via {JHU, USAFacts}, by (country x day)\nSafegraph mobility: misc measures by {county x day},{county x week}"
  },
  {
    "objectID": "slides/day1-morning.html#some-of-our-pre-pandemic-data-sources",
    "href": "slides/day1-morning.html#some-of-our-pre-pandemic-data-sources",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Some of our Pre-Pandemic Data Sources",
    "text": "Some of our Pre-Pandemic Data Sources\n\n\nFluView ILINet, by {state x week}\nFluView Clinical (% positive flu, PH and clinical labs)\nGoogle Health Trends (GHT), precursor to Google Symptoms\nGoogle Flu Trends (GFT), precursor to to GHT\nTwitter flu\nAccess counts for flu-related CDC pages, by {city x week}\nAccess counts for flu-related Wikipedia entries by {day x hour}\nFlu-surv (flu hosp rates, now expanded to RESP-NET)\nMisc signals for dengue, norovirus\nMisc signals for PAHO countries, ECDC, KCDC, Taiwan,…\nDelphi ILI nowcasts, by {state x week}, visualized in “ILI Nearby” website\nDelphi ILI forecasts, by {state x week}"
  },
  {
    "objectID": "slides/day1-morning.html#severity-pyramid",
    "href": "slides/day1-morning.html#severity-pyramid",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Severity pyramid",
    "text": "Severity pyramid"
  },
  {
    "objectID": "slides/day1-morning.html#installing-epidatr",
    "href": "slides/day1-morning.html#installing-epidatr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Installing epidatr",
    "text": "Installing epidatr\nInstalling the package in R is straightforward…\nInstall the CRAN version\n\n# Install the CRAN version\npak::pkg_install(\"epidatr\")\n\nor the development version\n\n# Install the development version from the GitHub dev branch\n# pak::pkg_install(\"cmu-delphi/epidatr@dev\")\n\nThe CRAN listing is here."
  },
  {
    "objectID": "slides/day1-morning.html#python",
    "href": "slides/day1-morning.html#python",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Python",
    "text": "Python\nIn Python, install delphi-epidata from PyPI with\npip install delphi-epidata\n\ndelphi-epidata is soon to be replaced with epidatpy.\n\n# Latest dev version\npip install -e \"git+https://github.com/cmu-delphi/epidatpy.git#egg=epidatpy\"\n\n# PyPI version (not yet available)\npip install epidatpy"
  },
  {
    "objectID": "slides/day1-morning.html#using-epidatr-and-epidatpy",
    "href": "slides/day1-morning.html#using-epidatr-and-epidatpy",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using epidatr and epidatpy",
    "text": "Using epidatr and epidatpy\n\nThe following shows how to import the library and fetch all confirmed influenza hospital admissions occurring each day for North Carolina:\n\n\nlibrary(epidatr)\nres &lt;- pub_covidcast('hhs', 'confirmed_admissions_influenza_1d', 'state', 'day', geo_values = 'nc',\n                     time_values = c(20240401, 20240405:20240414))\nhead(res, n = 3)\n\n# A tibble: 3 × 15\n  geo_value signal     source geo_type time_type time_value direction issue     \n  &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;date&gt;         &lt;dbl&gt; &lt;date&gt;    \n1 nc        confirmed… hhs    state    day       2024-04-01        NA 2024-04-22\n2 nc        confirmed… hhs    state    day       2024-04-05        NA 2024-04-22\n3 nc        confirmed… hhs    state    day       2024-04-06        NA 2024-04-22\n# ℹ 7 more variables: lag &lt;dbl&gt;, missing_value &lt;dbl&gt;, missing_stderr &lt;dbl&gt;,\n#   missing_sample_size &lt;dbl&gt;, value &lt;dbl&gt;, stderr &lt;dbl&gt;, sample_size &lt;dbl&gt;\n\n\nPython equivalent:\nres = Epidata.covidcast('hhs', 'confirmed_admissions_influenza_1d', 'day', 'state', [20240401, Epidata.range(20240405, 20240414)], 'nc')\nprint(res['result'], res['message'], len(res['epidata']))"
  },
  {
    "objectID": "slides/day1-morning.html#api-keys",
    "href": "slides/day1-morning.html#api-keys",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "API keys",
    "text": "API keys\n\n\nAnyone may access the Epidata API anonymously without providing any personal data.\nAnonymous API access is subject to the following restrictions:\n\npublic datasets only; 2) rate limited to 60 requests per hour; 3) only two parameters may have multiple selections\n\nAn API key grants priviledged access to the API and can be obtained by registering with us.\nPrivileges of registration:\n\nno rate limit; 2) no limit on multiple selections\n\n\n\n\n\n\n\n\n\nTip\n\n\nThe epidatr client automatically searches for the key in the DELPHI_EPIDATA_KEY environment variable. We recommend storing it in your .Renviron file, which R reads by default. More on setting your API key here."
  },
  {
    "objectID": "slides/day1-morning.html#finding-data-sources-and-signals-of-interest",
    "href": "slides/day1-morning.html#finding-data-sources-and-signals-of-interest",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Finding data sources and signals of interest",
    "text": "Finding data sources and signals of interest\n\n\nDiverse Data Streams\n\nVariety of Data: Access to medical claims data, cases and deaths, mobility data, and more.\nGeographic Coverage: Includes multiple regions, making it comprehensive yet complex.\nChallenge: Difficulty in pinpointing the specific data stream of interest.\n\nUsing the Documentation\n\nComprehensive Listings: Documentation details all available data sources and signals for both COVID-19 and other endpoints.\n\nDocs are great for a deep dive into the data, whereas the apps & tools are useful to see what is available…"
  },
  {
    "objectID": "slides/day1-morning.html#cheatsheet-of-web-based-apps-we-provide",
    "href": "slides/day1-morning.html#cheatsheet-of-web-based-apps-we-provide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Cheatsheet of web-based apps we provide",
    "text": "Cheatsheet of web-based apps we provide\nWe provide…\n\nA signal discovery app, to explore what epi-signals are available in Delphi Epidata and elsewhere in the community.\nA general signal visualization tool.\nA signal dashboard and a “classic” map-based version to visualize a core set of COVID-19 and flu indicators.\nA COVID-19 signal export app, a dashboard builder, and more!"
  },
  {
    "objectID": "slides/day1-morning.html#signal-dashboard---for-covid-19-flu-data",
    "href": "slides/day1-morning.html#signal-dashboard---for-covid-19-flu-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Signal dashboard - For COVID-19 & flu data",
    "text": "Signal dashboard - For COVID-19 & flu data\n\n\n\nThe signal dashboard displays a selection of signals for COVID-19 & flu.\nBrowse by location or indicator to choose which signal you are interested in & then export the data for analysis.\nExample: Symptom searches on Google in NC"
  },
  {
    "objectID": "slides/day1-morning.html#signal-discovery-app---browse-for-more-data",
    "href": "slides/day1-morning.html#signal-discovery-app---browse-for-more-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Signal discovery app - Browse for more data",
    "text": "Signal discovery app - Browse for more data\n\nSignal discovery app: An easy way to find data sources and signals (no programming required).\n\nSearch tool that is a good to browse & find data.\n\nLet’s try it out together!"
  },
  {
    "objectID": "slides/day1-morning.html#example---nchs-weekly-flu-mortality-data-in-states",
    "href": "slides/day1-morning.html#example---nchs-weekly-flu-mortality-data-in-states",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example - NCHS Weekly Flu Mortality Data in States",
    "text": "Example - NCHS Weekly Flu Mortality Data in States"
  },
  {
    "objectID": "slides/day1-morning.html#interactive-tooling-in-r",
    "href": "slides/day1-morning.html#interactive-tooling-in-r",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Interactive tooling in R",
    "text": "Interactive tooling in R\n\nMoving from initial web-based browsing to programming, how do we find sources and signals in R?\nFunctions to enhance data discovery in epidatr:\n\navail_endpoints() Function:\n\nLists all endpoints with brief descriptions.\nHighlights specific endpoints that cover non-US locations, facilitating targeted searches.\n\nOutput Format: Returns a tibble for easy viewing and analysis of available data sources.\n\n\n\navail_endpoints()"
  },
  {
    "objectID": "slides/day1-morning.html#using-the-covidcast_epidata-function",
    "href": "slides/day1-morning.html#using-the-covidcast_epidata-function",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using the covidcast_epidata() function",
    "text": "Using the covidcast_epidata() function\n\n\nIn-Depth Data Exploration\n\nFunction Overview: covidcast_epidata() provides detailed insights into data sources from the COVIDcast endpoint.\nSource List: Each data source is listed in covid_sources$sources, with associated tibbles describing included signals.\n\nTab Completion for Ease of Use\n\nEditor Support: In RStudio or similar editors, use tab completion to explore:\n\nData Sources: Type covid_sources$source$ to view available data sources.\nSignals: Type covid_sources$signals$ to see signal options with autocomplete assistance.\n\n\nFiltering Convenience: Signal names are prefixed with their respective data source for easier navigation.\n\n\n\ncovid_sources &lt;- covidcast_epidata()\nhead(covid_sources$sources, n = 2) # head(list, n = 2) will print the first two elements of the list"
  },
  {
    "objectID": "slides/day1-morning.html#fetching-data---covidcast-main-endpoint",
    "href": "slides/day1-morning.html#fetching-data---covidcast-main-endpoint",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetching data - COVIDcast main endpoint",
    "text": "Fetching data - COVIDcast main endpoint\n\n\nFetching data from the Delphi Epidata API is simple.\nThe pub_covidcast() function lets us access the covidcast endpoint.\nWe need to specify the following six arguments…\n\nsource: Data source name\nsignals: Signal name\ngeo_type: Geographic level\ntime_type: Time resolution\ngeo_values: Location(s)\ntime_values: times of interest\n\nLet’s give this a try!"
  },
  {
    "objectID": "slides/day1-morning.html#fetching-data---covidcast-main-endpoint-1",
    "href": "slides/day1-morning.html#fetching-data---covidcast-main-endpoint-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetching data - COVIDcast main endpoint",
    "text": "Fetching data - COVIDcast main endpoint\n\n\nlibrary(epidatr)\nlibrary(dplyr)\n\n\n# Obtain the most up-to-date version of the daily new \n# confirmed COVID cases, 7-day average, per 100k people for the US\nepidata &lt;- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_7dav_incidence_prop\", \n  geo_type = \"nation\",\n  time_type = \"day\",\n  geo_values = \"us\",\n  time_values = epirange(20210101, 20210401)\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal             source geo_type time_value issue        lag value\n  &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;  &lt;fct&gt;    &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 us        confirmed_7dav_in… jhu-c… nation   2021-01-01 2023-03-10   798  61.9\n2 us        confirmed_7dav_in… jhu-c… nation   2021-01-02 2023-03-10   797  64.2\n3 us        confirmed_7dav_in… jhu-c… nation   2021-01-03 2023-03-10   796  67.1\n4 us        confirmed_7dav_in… jhu-c… nation   2021-01-04 2023-03-10   795  67.6\n5 us        confirmed_7dav_in… jhu-c… nation   2021-01-05 2023-03-10   794  68.7\n6 us        confirmed_7dav_in… jhu-c… nation   2021-01-06 2023-03-10   793  70.4\n\n\nHere value is the requested signal – in this case, the number of daily new confirmed COVID-19 cases per 100,000 population from January to April 2021."
  },
  {
    "objectID": "slides/day1-morning.html#returned-data---covidcast-main-endpoint",
    "href": "slides/day1-morning.html#returned-data---covidcast-main-endpoint",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Returned data - COVIDcast main endpoint",
    "text": "Returned data - COVIDcast main endpoint\n\n\npub_covidcast() outputs a tibble, where each row represents one observation.\nEach observation covers a set of events aggregated by time and by geographic region is a record in our database. Each such record includes:\ntime_value: time period when the events occurred.\ngeo_value: geographic region where the events occurred.\nvalue: estimated value.\nstderr: standard error of the estimate, usually referring to the sampling error.\nsample_size: number of events used in the estimation."
  },
  {
    "objectID": "slides/day1-morning.html#returned-data---covidcast-main-endpoint-1",
    "href": "slides/day1-morning.html#returned-data---covidcast-main-endpoint-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Returned data - COVIDcast main endpoint",
    "text": "Returned data - COVIDcast main endpoint\nCrucially—and unlike most other sources of COVID-19 data—our API reports two additional fields with each record:\n\nissue: The time period when this observation was published.\nlag: The time delay between when the events occurred and when this observation was published.\nMeaning that unlike most other sources of COVID data, it tracks the complete revision history of every signal.\nThis allows for historical reconstructions of what information was available at specific times. More on this soon!"
  },
  {
    "objectID": "slides/day1-morning.html#geographic-levels",
    "href": "slides/day1-morning.html#geographic-levels",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Geographic levels",
    "text": "Geographic levels\n\n\nThe Epidata API makes signals available at different geographic levels, depending on the endpoint.\nFor the confirmed_7dav_incidence_prop signal, we can obtain values for each state.\nSimply change geo_type and geo_values in the previous example to get…\n\n\n# Obtain the most up-to-date version of the smoothed covid-like illness (CLI)\n# signal from the COVID-19 Trends and Impact survey for all states\nstate_epidata &lt;- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_7dav_incidence_prop\",\n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"*\",\n  time_values = epirange(20210101, 20210401)\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal             source geo_type time_value issue        lag value\n  &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;  &lt;fct&gt;    &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 ak        confirmed_7dav_in… jhu-c… state    2021-01-01 2023-03-03   791  35.9\n2 al        confirmed_7dav_in… jhu-c… state    2021-01-01 2023-03-03   791  67.7\n3 ar        confirmed_7dav_in… jhu-c… state    2021-01-01 2023-03-03   791  76.2\n4 as        confirmed_7dav_in… jhu-c… state    2021-01-01 2023-03-03   791   0  \n5 az        confirmed_7dav_in… jhu-c… state    2021-01-01 2023-03-03   791  83.4\n6 ca        confirmed_7dav_in… jhu-c… state    2021-01-01 2023-03-10   798 104."
  },
  {
    "objectID": "slides/day1-morning.html#covidcast-main-endpoint---example-query",
    "href": "slides/day1-morning.html#covidcast-main-endpoint---example-query",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "COVIDcast main endpoint - Example query",
    "text": "COVIDcast main endpoint - Example query\n\nCounty geo_values are FIPS codes and are discussed in the API docs here. The example below is for Orange County, California.\n\nfb_county_data &lt;- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_7dav_incidence_prop\",\n  geo_type = \"county\",\n  time_type = \"day\",\n  time_values = epirange(20210101, 20210401),\n  geo_values = \"06059\"\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal             source geo_type time_value issue        lag value\n  &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;  &lt;fct&gt;    &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 06059     confirmed_7dav_in… jhu-c… county   2021-01-01 2023-03-03   791  105.\n2 06059     confirmed_7dav_in… jhu-c… county   2021-01-02 2023-03-03   790  107.\n3 06059     confirmed_7dav_in… jhu-c… county   2021-01-03 2023-03-03   789  108.\n4 06059     confirmed_7dav_in… jhu-c… county   2021-01-04 2023-03-03   788  107.\n5 06059     confirmed_7dav_in… jhu-c… county   2021-01-05 2023-03-03   787  105.\n6 06059     confirmed_7dav_in… jhu-c… county   2021-01-06 2023-03-03   786  104.\n\n\n\n\n\n\nNote\n\n\nThe covidcast endpoint supports * in its time and geo fields. Try to obtain the signal values for all available counties by replacing geo_values = \"06059\" with geo_values = \"*\"."
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints  Hospitalizations",
    "text": "Example queries - Other endpoints  Hospitalizations\nCOVID-19 Hospitalization: Facility Lookup\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp_facility_lookup.html \n\npub_covid_hosp_facility_lookup(city = \"southlake\")\n\n# A tibble: 2 × 10\n  hospital_pk state ccn    hospital_name    address city  zip   hospital_subtype\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           \n1 450888      TX    450888 TEXAS HEALTH HA… 1545 E… SOUT… 76092 Short Term      \n2 670132      TX    670132 METHODIST SOUTH… 421 E … SOUT… 76092 Short Term      \n# ℹ 2 more variables: fips_code &lt;chr&gt;, is_metro_micro &lt;dbl&gt;\n\n# pub_covid_hosp_facility_lookup(state = \"WY\")\n# A non-example (there is no city called New York in Wyoming)\n# pub_covid_hosp_facility_lookup(state = \"WY\", city = \"New York\")"
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations-1",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints  Hospitalizations",
    "text": "Example queries - Other endpoints  Hospitalizations\nCOVID-19 Hospitalization by Facility\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp_facility.html \n\npub_covid_hosp_facility(\n  hospital_pks = \"100075\",\n  collection_weeks = epirange(20200101, 20200501)\n)\n\nCOVID-19 Hospitalization by State\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp.html \n\npub_covid_hosp_state_timeseries(states = \"MA\", dates = \"20200510\")"
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-flu-endpoints",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-flu-endpoints",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints  Flu endpoints",
    "text": "Example queries - Other endpoints  Flu endpoints\nFluSurv hospitalization data\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/flusurv.html \n\npub_flusurv(locations = \"ca\", epiweeks = 202001)\n\nFluview data\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/fluview.html \n\npub_fluview(regions = \"nat\", epiweeks = epirange(201201, 202001))\n\nNIDSS Flu\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/nidss_flu.html \n\npub_nidss_flu(regions = \"taipei\", epiweeks = epirange(200901, 201301))"
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-dengue-endpoints",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-dengue-endpoints",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints  Dengue endpoints",
    "text": "Example queries - Other endpoints  Dengue endpoints\nDelphi’s Dengue Nowcast\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/dengue_nowcast.html \n\npub_dengue_nowcast(locations = \"pr\", epiweeks = epirange(201401, 202301))\n\nNIDSS dengue\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/nidss_dengue.html \n\npub_nidss_dengue(locations = \"taipei\", epiweeks = epirange(200301, 201301))\n\nPAHO Dengue\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/paho_dengue.html \n\npub_paho_dengue(regions = \"ca\", epiweeks = epirange(200201, 202319))"
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-wikipedia",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-wikipedia",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints  Wikipedia",
    "text": "Example queries - Other endpoints  Wikipedia\nWikipedia access\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/wiki.html \n\npub_wiki(\n  language = \"en\",\n  articles = \"influenza\",\n  time_type = \"week\",\n  time_values = epirange(202001, 202319)\n)\n\n# A tibble: 64 × 6\n   article   count     total  hour epiweek     value\n   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;      &lt;dbl&gt;\n 1 influenza  6516 663604044    -1 2019-12-29   9.82\n 2 influenza 10244 789885521    -1 2020-01-05  13.0 \n 3 influenza 10728 783760384    -1 2020-01-12  13.7 \n 4 influenza 24843 785222292    -1 2020-01-19  31.6 \n 5 influenza 62850 780291898    -1 2020-01-26  80.5 \n 6 influenza 41768 778222703    -1 2020-02-02  53.7 \n 7 influenza 29434 767244708    -1 2020-02-09  38.4 \n 8 influenza 22714 764074572    -1 2020-02-16  29.7 \n 9 influenza 88758 767718009    -1 2020-02-23 116.  \n10 influenza 62433 759825311    -1 2020-03-01  82.2 \n# ℹ 54 more rows\n\n\n\n\n\n\n\n\nTip - public vs private methods\n\n\nAside from these public methods we’ve gone through (these start with pub_), there are private methods (these start with pvt_ when you type avail_endpoints()). These require private access keys to use (separate from the Delphi Epidata API key). To run these locally, you will need to store these secrets in your .Reviron file, or set them as environmental variables. See Private methods for examples of using private endpoints."
  },
  {
    "objectID": "slides/day1-morning.html#signal-metadata",
    "href": "slides/day1-morning.html#signal-metadata",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Signal metadata",
    "text": "Signal metadata\n\nSome endpoints provide additional metadata for signals.\n\nTime Information: Details on available time frames and last update times.\nGeography Information: Details on available geography types.\n\nKey Endpoints for Metadata\n\npub_covidcast_meta(): Access metadata for the COVIDcast endpoint.\npub_fluview_meta(): Get metadata for the FluView endpoint.\npub_meta(): General metadata for the Delphi Epidata API."
  },
  {
    "objectID": "slides/day1-morning.html#panel-data-1",
    "href": "slides/day1-morning.html#panel-data-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Panel data",
    "text": "Panel data\n\n\nPanel data or longitudinal data, contain cross-sectional measurements of subjects over time.\nSince we’re working with aggregated data, the subjects are geographic units (e.g. counties, states) and not individuals.\nIn table form, panel data is a time index + one or more locations/keys.\nFor example: The estimated percentage of outpatient doctor visits that are COVID-related in WA from Dec. 2021 to Feb. 2022 (docs):\n\n\n\nAn `epi_df` object, 6 x 3 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2022-02-01\n\n# A tibble: 6 × 3\n  geo_value time_value percent_cli\n* &lt;chr&gt;     &lt;date&gt;           &lt;dbl&gt;\n1 wa        2021-12-01        4.70\n2 wa        2021-12-02        4.60\n3 wa        2021-12-03        4.56\n4 wa        2021-12-04        4.93\n5 wa        2021-12-05        4.17\n6 wa        2021-12-06        4.12"
  },
  {
    "objectID": "slides/day1-morning.html#examples-of-panel-data---covid-19-cases",
    "href": "slides/day1-morning.html#examples-of-panel-data---covid-19-cases",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of panel data - COVID-19 cases",
    "text": "Examples of panel data - COVID-19 cases\nJHU CSSE COVID cases per 100k  estimates the daily number of new confirmed COVID-19 cases per 100,000 population, averaged over the past 7 days.\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/jhu-csse.html"
  },
  {
    "objectID": "slides/day1-morning.html#examples-of-panel-data---chng-cli",
    "href": "slides/day1-morning.html#examples-of-panel-data---chng-cli",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of panel data - CHNG-CLI",
    "text": "Examples of panel data - CHNG-CLI\nChange Healthcare COVID-like illness (CHNG-CLI) reports the percentage of outpatient visits for COVID-related symptoms, based on deidentified Change Healthcare claims data.\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/chng.html"
  },
  {
    "objectID": "slides/day1-morning.html#examples-of-panel-data---chng-covid",
    "href": "slides/day1-morning.html#examples-of-panel-data---chng-covid",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of panel data - CHNG-COVID",
    "text": "Examples of panel data - CHNG-COVID\nChange Healthcare COVID (CHNG-COVID) reports the percentage of outpatient visits with confirmed COVID-19, based on Change Healthcare claims data.\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/chng.html"
  },
  {
    "objectID": "slides/day1-morning.html#examples-of-panel-data---hhs-admissions",
    "href": "slides/day1-morning.html#examples-of-panel-data---hhs-admissions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of panel data - HHS Admissions",
    "text": "Examples of panel data - HHS Admissions\nConfirmed COVID-19 Hospital Admissions per 100k estimates the daily sum of adult and pediatric confirmed COVID-19 hospital admissions, per 100,000 population, averaged over the past 7 days.\nAPI docs: https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/hhs.html"
  },
  {
    "objectID": "slides/day1-morning.html#examples-of-panel-data---covid-19-cases-and-deaths-in-ca",
    "href": "slides/day1-morning.html#examples-of-panel-data---covid-19-cases-and-deaths-in-ca",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of panel data - COVID-19 cases and deaths in CA",
    "text": "Examples of panel data - COVID-19 cases and deaths in CA\n\nTakeaway: Cases appear to strongly correlate with deaths several weeks later.\nWe’ll see this again in an upcoming session…"
  },
  {
    "objectID": "slides/day1-morning.html#intro-to-versioned-data",
    "href": "slides/day1-morning.html#intro-to-versioned-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Intro to versioned data",
    "text": "Intro to versioned data\n\nIn panel data, we’ve seen that time is indicated by time_value.\nNow, we add a second time index to indicate the data version…\n\n\n\n# A tibble: 6 × 4\n  geo_value time_value version    percent_cli\n  &lt;chr&gt;     &lt;date&gt;     &lt;date&gt;           &lt;dbl&gt;\n1 wa        2021-12-01 2021-12-05       0.884\n2 wa        2021-12-01 2021-12-06       0.917\n3 wa        2021-12-01 2021-12-07       0.896\n4 wa        2021-12-01 2021-12-08       0.985\n5 wa        2021-12-01 2021-12-09       1.03 \n6 wa        2021-12-01 2021-12-10       1.00 \n\n\n\nNote that this feature can be indicated in different ways (ex. version, issue, release, as_of)."
  },
  {
    "objectID": "slides/day1-morning.html#versioned-panel-data",
    "href": "slides/day1-morning.html#versioned-panel-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Versioned panel data",
    "text": "Versioned panel data\nEstimated percentage of outpatient (DV-CLI) data across multiple issue dates, with updates and revisions to past data as new issue dates are released:\n\n\nFigure 5 from Reinhart et al. (2021)"
  },
  {
    "objectID": "slides/day1-morning.html#latency-and-revision-in-signals",
    "href": "slides/day1-morning.html#latency-and-revision-in-signals",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Latency and revision in signals",
    "text": "Latency and revision in signals\n\nLatency refers to the delay between data collection and availability.\n\nExample: A signal based on medical insurance claims may take several days to appear but is subject to delays as claims are processed over weeks.\n\nRevision occurs when data is updated or corrected after initial publication, often due to new information or late reporting.\n\nExample: COVID-19 case reports are revised frequently after initial publication as new data comes in or reporting backlogs are cleared."
  },
  {
    "objectID": "slides/day1-morning.html#latency-and-revision-in-signals---example",
    "href": "slides/day1-morning.html#latency-and-revision-in-signals---example",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Latency and revision in signals - Example",
    "text": "Latency and revision in signals - Example\n\n\nRecall the first example of panel & versioned data we’ve seen…\nThis signal is 4 days latent (min(version - time_value))\n\n\n\n# A tibble: 6 × 5\n  geo_value time_value version    percent_cli version_time_diff\n  &lt;chr&gt;     &lt;date&gt;     &lt;date&gt;           &lt;dbl&gt; &lt;drtn&gt;           \n1 wa        2021-12-01 2021-12-05       0.884 4 days           \n2 wa        2021-12-02 2021-12-06       0.737 4 days           \n3 wa        2021-12-03 2021-12-07       0.662 4 days           \n4 wa        2021-12-04 2021-12-08       0.663 4 days           \n5 wa        2021-12-05 2021-12-09       0.872 4 days           \n6 wa        2021-12-06 2021-12-10       0.642 4 days           \n\n\n\nAnd clearly undergoes revision over time (ex. consider Dec. 1’s percent_cli across version):\n\n\n\n# A tibble: 6 × 5\n  geo_value time_value version    percent_cli version_time_diff\n  &lt;chr&gt;     &lt;date&gt;     &lt;date&gt;           &lt;dbl&gt; &lt;drtn&gt;           \n1 wa        2021-12-01 2021-12-05       0.884 4 days           \n2 wa        2021-12-01 2021-12-06       0.917 5 days           \n3 wa        2021-12-01 2021-12-07       0.896 6 days           \n4 wa        2021-12-01 2021-12-08       0.985 7 days           \n5 wa        2021-12-01 2021-12-09       1.03  8 days           \n6 wa        2021-12-01 2021-12-10       1.00  9 days"
  },
  {
    "objectID": "slides/day1-morning.html#revision-triangle-outpatient-visits-in-wa-2022",
    "href": "slides/day1-morning.html#revision-triangle-outpatient-visits-in-wa-2022",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Revision triangle, Outpatient visits in WA 2022",
    "text": "Revision triangle, Outpatient visits in WA 2022"
  },
  {
    "objectID": "slides/day1-morning.html#revisions",
    "href": "slides/day1-morning.html#revisions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Revisions",
    "text": "Revisions\nMany data sources are subject to revisions:\n\nCase and death counts are frequently corrected or adjusted by authorities.\nMedical claims data can take weeks to be submitted and processed.\n\n\n\nLab tests and medical records can be backlogged for a variety of reasons.\nSurveys are not always completed promptly.\nKey: An accurate revision log is crucial for researchers building forecasts.\n\nA forecast that is made today can should rely on information we have access to today."
  },
  {
    "objectID": "slides/day1-morning.html#three-types-of-revisions",
    "href": "slides/day1-morning.html#three-types-of-revisions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Three types of revisions",
    "text": "Three types of revisions\n\nSources that don’t revise - Ex. Facebook or Google symptoms (provisional and final are the same)\nPredictable revisions - Ex. Claims data (CHNG) and public health reports aligned by test, hosp., or death date\nRevisions that are large and erratic to predict - Ex. COVID cases and deaths, especially when aligned by report date (which can be highly variable & less predictable compared to test data)."
  },
  {
    "objectID": "slides/day1-morning.html#types-of-revisions---comparison-between-2.-and-3.",
    "href": "slides/day1-morning.html#types-of-revisions---comparison-between-2.-and-3.",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Types of revisions - Comparison between 2. and 3.",
    "text": "Types of revisions - Comparison between 2. and 3.\n\n\nRevision behavior for two indicators in the HRR containing Charlotte, NC.\n\n\n\nDV-CLI signal (left)  was regularly revised throughout the period, although effects fade farther back.\nJHU CSSE cases (right)  remain “as reported” on Sept. 28, with a spike toward the end of this period, until a major correction is made on Oct. 19, which brings this down & affects prior data.\n\n\n\n\nFigure 1 from McDonald et al. (2021)"
  },
  {
    "objectID": "slides/day1-morning.html#key-takeaways",
    "href": "slides/day1-morning.html#key-takeaways",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nMedical claims revisions: More systematic and predictable.\nCOVID-19 case report revisions: Erratic and often unpredictable.\nLarge spikes or anomalies can occur as:\n\nReporting backlogs are cleared.\nChanges in case definitions are implemented."
  },
  {
    "objectID": "slides/day1-morning.html#reporting-backlogs---example",
    "href": "slides/day1-morning.html#reporting-backlogs---example",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Reporting backlogs - Example",
    "text": "Reporting backlogs - Example\n\n\nLeft: Reported cases per day in Bexar County, Texas, during the summer of 2020. On July 16, 4,810 backlogged cases were reported, reflecting a 2-week delay. This caused a prolonged spike due to the 7-day trailing average applied to the counts.\nRight: CTIS estimates of CLI-in-community showed more stable underlying trends.\n\n\n\n\nFigure 4 from Reinhart et al. (2021)"
  },
  {
    "objectID": "slides/day1-morning.html#reporting-backlogs---key-takeaways",
    "href": "slides/day1-morning.html#reporting-backlogs---key-takeaways",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Reporting backlogs - Key takeaways",
    "text": "Reporting backlogs - Key takeaways\n\nReporting issues been common across U.S. jurisdictions.\nFor example, audits have regularly discovered misclassified or unreported cases and deaths.\nThis underscores the value of cross-checking data with external sources not part of the same reporting systems."
  },
  {
    "objectID": "slides/day1-morning.html#versioned-data-in-epidatr",
    "href": "slides/day1-morning.html#versioned-data-in-epidatr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Versioned data in epidatr",
    "text": "Versioned data in epidatr\n\nEpidata API contains comprehensive data record, capturing each signal’s estimate, location, date, and update timeline.\nRequesting Specific Data Versions:\n\nUse as_of or issues arguments to specify data availability.\nUse as_of to fetch one version and issues to fetch multiple.\nOnly one argument can be used at a time; not all endpoints support both\n\nLet’s start with fetching one version…"
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-data-as-of-a-specific-date",
    "href": "slides/day1-morning.html#obtaining-data-as-of-a-specific-date",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining data “as of” a specific date",
    "text": "Obtaining data “as of” a specific date\n\n\nExample: Doctor Visits Signal (from the covidcast endpoint)\n\nEstimates the percentage of outpatient doctor visits that are COVID-related. To give a specific example, let’s consider the estimate for PA on May 1, 2020:\n\n\n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-01\"),\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  as_of = \"2020-05-07\"\n)\n\n\n\n# A tibble: 1 × 7\n  geo_value signal           source        time_value issue        lag value\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-visits 2020-05-01 2020-05-07     6  2.58\n\n\n\nInitial estimate was issued on May 7, 2020 (due to delay from aggregation and ingestion by the API)."
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-data-as-of-a-specific-date-1",
    "href": "slides/day1-morning.html#obtaining-data-as-of-a-specific-date-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining data “as of” a specific date",
    "text": "Obtaining data “as of” a specific date\n\nDefault behaviour: If we don’t specify as_of, we get the most recent estimate:\n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-01\"),\n  geo_type = \"state\",\n  geo_values = \"pa\"\n)\n\n\n\n# A tibble: 1 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  5.97     NA\n\n\n\nSubstantial Estimate Change:\n\nEstimate increased from &lt;3% to almost 6% after May 7, reflecting new data on visits from May 1.\n\nVersioning is Important in Forecasting:\n\nAccurate backtesting requires using data available at the time of model fitting, not later updates, for accurate forecasting results."
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-multiple-specific-issues-for-one-state",
    "href": "slides/day1-morning.html#obtaining-multiple-specific-issues-for-one-state",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining multiple specific issues for one state",
    "text": "Obtaining multiple specific issues for one state\nBy using the issues argument, we can request all issues in a certain time period:\n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-01\"),\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  issues = epirange(\"2020-05-01\", \"2020-05-15\")\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-07     6  2.58     NA\n2 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-08     7  3.28     NA\n3 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-09     8  3.32     NA\n4 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-12    11  3.59     NA\n5 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-13    12  3.63     NA\n6 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-14    13  3.66     NA"
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-multiple-issues-for-one-state",
    "href": "slides/day1-morning.html#obtaining-multiple-issues-for-one-state",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining multiple issues for one state",
    "text": "Obtaining multiple issues for one state\n\nTo ensure that you’ve captured all issues up to a specific date (e.g., “2020-05-15”), set an extreme lower bound: issues = epirange(\"1900-01-01\", \"2020-05-15\").\n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-01\"),\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  issues = epirange(\"1900-01-01\", \"2020-05-15\")\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-07     6  2.58     NA\n2 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-08     7  3.28     NA\n3 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-09     8  3.32     NA\n4 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-12    11  3.59     NA\n5 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-13    12  3.63     NA\n6 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-14    13  3.66     NA\n\n\n\nThis doesn’t change anything here, but it may matter for other types of data where you don’t know the latency or reporting lag.\nWhen in doubt, refer to the signal’s API documentation to find the earliest date available."
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-multiple-issues-for-one-state-1",
    "href": "slides/day1-morning.html#obtaining-multiple-issues-for-one-state-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining multiple issues for one state",
    "text": "Obtaining multiple issues for one state\n\n\nOnce the maximum issue is reached and there are no more issues to come, the data is considered finalized, regardless of the maximum issue you requested.\nFor example, the last issue in July 2020 and so the data is finalized as of July 2020, even though we requested issues up to today.\n\n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-01\"),\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  issues = epirange(\"1900-01-01\", \"2024-12-11\") # From the 1900s to today\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-06-29    59  5.99     NA\n2 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-06-30    60  5.99     NA\n3 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-01    61  5.95     NA\n4 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-02    62  5.97     NA\n5 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-03    63  5.97     NA\n6 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  5.97     NA\n\n\n\nWe caution against starting queries with too late a minimum issue or setting a late maximum issue, as it could lead to incorrect and/or misleading results.\nYou’re safest bet to capture all issues is what we’ll talk about next…"
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-all-issues-for-one-state",
    "href": "slides/day1-morning.html#obtaining-all-issues-for-one-state",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining all issues for one state",
    "text": "Obtaining all issues for one state\n\nThe fast way to obtain all available issues for PA, set issues to be *:\n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-07\"),\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  issues = \"*\"\n)\n\n\n\n# A tibble: 8 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-07     6  2.58     NA\n2 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-08     7  3.28     NA\n3 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-09     8  3.32     NA\n4 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-12    11  3.59     NA\n5 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-13    12  3.63     NA\n6 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-14    13  3.66     NA\n7 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-15    14  3.66     NA\n8 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-16    15  3.61     NA"
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-all-issues-for-all-states",
    "href": "slides/day1-morning.html#obtaining-all-issues-for-all-states",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining all issues for all states",
    "text": "Obtaining all issues for all states\n\nA very useful feature is the ability to extract all geo_values and issues by using * in both.\n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-07\"),\n  geo_type = \"state\",\n  geo_values = \"*\",\n  issues = \"*\"\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-07     6  1.61     NA\n2 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-08     7  2.40     NA\n3 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-09     8  2.38     NA\n4 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-12    11  2.38     NA\n5 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-13    12  2.36     NA\n6 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-14    13  2.36     NA\n\n\nSo, now we obtain all available issues for all states (not just PA) for the specified date range. Neat!\n\nLast but not least… The do nothing approach\n\n\n\nLast but not least… The do nothing approach\nFinal question: What do you think happens when we adopt a “do nothing” approach to geo_values and issues (take both of them out) for this example?\n Hint: remember a couple slides ago, when we removed as_of, we got the most recent estimate for PA. \n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-07\"),\n  geo_type = \"state\"\n)\n\n\n\nObtaining one issue for all states\nFinal question: What do you think happens when we adopt a “do nothing” approach to geo_values and issues (take both of them out)?\n Hint: remember a couple slides ago, when we removed as_of, we got the most recent estimate for PA. \n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-07\"),\n  geo_type = \"state\"\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  5.72     NA\n2 al        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  2.74     NA\n3 ar        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  4.23     NA\n4 az        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  2.78     NA\n5 ca        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  4.25     NA\n6 co        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  8.77     NA\n\n\nWe get the most recent issue for all states!\n\n\n\nMain takeaways\n\n\nDelphi Epidata: A one-stop platform for real-time epidemic data, providing aggregated signals for disease tracking and forecasting from diverse sources like health records, mobility patterns, and more.\nEpidata API: Open-access API delivering up-to-date, granular epidemiological data + makes all historical versions available.\nEpidatr: Enables you to access Delphi’s epidemiological data through R and Python, offering easy installation, powerful API functions, and interactive tools for discovering and analyzing health signals.\nVersioned Data and Latency: Panel data captures time-series trends, which are often subject to revision. A standout feature of this API is its inclusion of two critical fields…\n\nas_of: One version of the data, and referring to the specific date when the data was last update (i.e. the data was updated as_of this date)\nissues: Multiple versions of the data, each corresponding to different as_of dates, capturing revisions and updates over time.\n\nto manage latency and revisions for transparency and accuracy in data analysis.\n\n\n\n\nFinal slide\nThanks:\n\nThe whole CMU Delphi Team (across many institutions)\nOptum/UnitedHealthcare, Change Healthcare.\nGoogle, Facebook, Amazon Web Services.\nQuidel, SafeGraph, Qualtrics.\nCenters for Disease Control and Prevention.\nCouncil of State and Territorial Epidemiologists\n\n\n    \n\n\n\n\n\nDay 1 Morning — cmu-delphi/insightnet-workshop-2024"
  },
  {
    "objectID": "slides/day1-morning.html#last-but-not-least-the-do-nothing-approach",
    "href": "slides/day1-morning.html#last-but-not-least-the-do-nothing-approach",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Last but not least… The do nothing approach",
    "text": "Last but not least… The do nothing approach"
  },
  {
    "objectID": "slides/day1-morning.html#last-but-not-least-the-do-nothing-approach-1",
    "href": "slides/day1-morning.html#last-but-not-least-the-do-nothing-approach-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Last but not least… The do nothing approach",
    "text": "Last but not least… The do nothing approach\nFinal question: What do you think happens when we adopt a “do nothing” approach to geo_values and issues (take both of them out) for this example?\n Hint: remember a couple slides ago, when we removed as_of, we got the most recent estimate for PA. \n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-07\"),\n  geo_type = \"state\"\n)"
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-one-issue-for-all-states",
    "href": "slides/day1-morning.html#obtaining-one-issue-for-all-states",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining one issue for all states",
    "text": "Obtaining one issue for all states\nFinal question: What do you think happens when we adopt a “do nothing” approach to geo_values and issues (take both of them out)?\n Hint: remember a couple slides ago, when we removed as_of, we got the most recent estimate for PA. \n\nepidata &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-07\"),\n  geo_type = \"state\"\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  5.72     NA\n2 al        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  2.74     NA\n3 ar        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  4.23     NA\n4 az        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  2.78     NA\n5 ca        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  4.25     NA\n6 co        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  8.77     NA\n\n\nWe get the most recent issue for all states!"
  },
  {
    "objectID": "slides/day1-morning.html#main-takeaways",
    "href": "slides/day1-morning.html#main-takeaways",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Main takeaways",
    "text": "Main takeaways\n\n\nDelphi Epidata: A one-stop platform for real-time epidemic data, providing aggregated signals for disease tracking and forecasting from diverse sources like health records, mobility patterns, and more.\nEpidata API: Open-access API delivering up-to-date, granular epidemiological data + makes all historical versions available.\nEpidatr: Enables you to access Delphi’s epidemiological data through R and Python, offering easy installation, powerful API functions, and interactive tools for discovering and analyzing health signals.\nVersioned Data and Latency: Panel data captures time-series trends, which are often subject to revision. A standout feature of this API is its inclusion of two critical fields…\n\nas_of: One version of the data, and referring to the specific date when the data was last update (i.e. the data was updated as_of this date)\nissues: Multiple versions of the data, each corresponding to different as_of dates, capturing revisions and updates over time.\n\nto manage latency and revisions for transparency and accuracy in data analysis."
  },
  {
    "objectID": "slides/day1-morning.html#final-slide",
    "href": "slides/day1-morning.html#final-slide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Final slide",
    "text": "Final slide\nThanks:\n\nThe whole CMU Delphi Team (across many institutions)\nOptum/UnitedHealthcare, Change Healthcare.\nGoogle, Facebook, Amazon Web Services.\nQuidel, SafeGraph, Qualtrics.\nCenters for Disease Control and Prevention.\nCouncil of State and Territorial Epidemiologists\n\n\n    \n\n\n\n\n\nDay 1 Morning — cmu-delphi/insightnet-workshop-2024"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Schedule",
    "text": "Schedule\nShort description\n\nDay 1 Morning\nDay 1 Afternoon\nDay 2 Morning\nDay 2 Afternoon"
  },
  {
    "objectID": "index.html#instructors",
    "href": "index.html#instructors",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Instructors",
    "text": "Instructors\n\nRyan J. Tibshirani\nDaniel J. McDonald\nAlice Cima\nRachel Lobay"
  },
  {
    "objectID": "slides/day2-afternoon.html#section",
    "href": "slides/day2-afternoon.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Forecasting with {epipredict}",
    "text": "Forecasting with {epipredict}\n\n\n\n\nVenue – dd Somemonth yyyy"
  },
  {
    "objectID": "slides/day2-afternoon.html#outline",
    "href": "slides/day2-afternoon.html#outline",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Outline",
    "text": "Outline\n\n{epipredict}\nFit and Predict with arx_forecaster\nCustomizing arx_forecaster\nForecasting with Versioned Data\nBuilding a Forecaster"
  },
  {
    "objectID": "slides/day2-afternoon.html#epipredict-1",
    "href": "slides/day2-afternoon.html#epipredict-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "{epipredict}",
    "text": "{epipredict}\nhttps://cmu-delphi.github.io/epipredict\nInstallation\n\n# Stable version\npak::pkg_install(\"cmu-delphi/epipredict@main\")\n# Development version\n# pak::pkg_install(\"cmu-delphi/epipredict@dev\")"
  },
  {
    "objectID": "slides/day2-afternoon.html#what-epipredict-provides-i",
    "href": "slides/day2-afternoon.html#what-epipredict-provides-i",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What {epipredict} provides (i)",
    "text": "What {epipredict} provides (i)\nBasic and easy to use “canned” forecasters:\n\nBaseline flat forecaster\nAutoregressive forecaster (ARX)\nAutoregressive classifier\nCDC FluSight flatline forecaster"
  },
  {
    "objectID": "slides/day2-afternoon.html#what-epipredict-provides-ii",
    "href": "slides/day2-afternoon.html#what-epipredict-provides-ii",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What {epipredict} provides (ii)",
    "text": "What {epipredict} provides (ii)\n\nA framework for creating custom forecasters out of modular components.\nThere are four types of components:\n\nPreprocessor: do things to the data before model training\nTrainer: train a model on data, resulting in a fitted model object\nPredictor: make predictions, using a fitted model object\nPostprocessor: do things to the predictions before returning"
  },
  {
    "objectID": "slides/day2-afternoon.html#fit-arx-on-training-set",
    "href": "slides/day2-afternoon.html#fit-arx-on-training-set",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fit ARX on training set",
    "text": "Fit ARX on training set\n\nBack to the ARX model for COVID deaths: \\(\\quad \\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\beta_0 x_{t}\\)\nUsing {epipredict}\n\n\nlibrary(epipredict)\n\n# split into train and test \nt0_date &lt;- as.Date('2021-04-01')\ntrain &lt;- ca |&gt; filter(time_value &lt;= t0_date)\ntest &lt;- ca |&gt; filter(time_value &gt; t0_date)\n\n# fit ARX\nepi_arx &lt;- arx_forecaster(epi_data = train |&gt; as_epi_df(), \n                          outcome = \"deaths\", \n                          predictors = c(\"cases\", \"deaths\"),\n                          trainer = linear_reg() |&gt; set_engine(\"lm\"),\n                          args_list = arx_args_list(lags = 0, ahead = 28,\n                                                    quantile_levels = c(0.1, 0.9)))"
  },
  {
    "objectID": "slides/day2-afternoon.html#arx_forecaster-output",
    "href": "slides/day2-afternoon.html#arx_forecaster-output",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "arx_forecaster output",
    "text": "arx_forecaster output\n\nA fitted model object which can be used any time in the future to create forecasts ($epi_workflows).\nA forecast (point prediction + interval) for 28 days after the last available time value in the data ($predictions)."
  },
  {
    "objectID": "slides/day2-afternoon.html#arx_forecaster-output-1",
    "href": "slides/day2-afternoon.html#arx_forecaster-output-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "arx_forecaster output",
    "text": "arx_forecaster output\n\nepi_arx \n\n══ A basic forecaster of type ARX Forecaster ═══════════════════════════════════\n\n\n\n\n\nThis forecaster was fit on 2024-11-12 08:50:39.\n\n\n\n\n\nTraining data was an &lt;epi_df&gt; with:\n\n\n• Geography: state,\n\n\n• Other keys: ,\n\n\n• Time type: day,\n\n\n• Using data up-to-date as of: 2024-11-06 08:50:44.\n\n\n• With the last data available on 2021-04-01\n\n\n\n\n\n── Predictions ─────────────────────────────────────────────────────────────────\n\n\n\n\n\nA total of 1 prediction is available for\n\n\n• 1 unique geographic region,\n\n\n• At forecast date: 2021-04-01,\n\n\n• For target date: 2021-04-29,"
  },
  {
    "objectID": "slides/day2-afternoon.html#extract-fitted-object",
    "href": "slides/day2-afternoon.html#extract-fitted-object",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extract fitted object",
    "text": "Extract fitted object\n\n\nepi_arx$epi_workflow\n\n\n\n\n══ Epi Workflow [trained] ══════════════════════════════════════════════════════\n\n\nPreprocessor: Recipe\n\n\nModel: linear_reg()\n\n\nPostprocessor: Frosting\n\n\n\n\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n\n\n\n\n\n6 Recipe steps.\n\n\n1. step_epi_lag()\n\n\n2. step_epi_lag()\n\n\n3. step_epi_ahead()\n\n\n4. step_naomit()\n\n\n5. step_naomit()\n\n\n6. step_training_window()\n\n\n\n\n\n── Model ───────────────────────────────────────────────────────────────────────\n\n\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n (Intercept)   lag_0_cases  lag_0_deaths  \n    0.076884      0.009858      0.200700  \n\n\n\n\n\n── Postprocessor ───────────────────────────────────────────────────────────────\n\n\n\n\n\n5 Frosting layers.\n\n\n1. layer_predict()\n\n\n2. layer_residual_quantiles()\n\n\n3. layer_add_forecast_date()\n\n\n4. layer_add_target_date()\n\n\n5. layer_threshold()"
  },
  {
    "objectID": "slides/day2-afternoon.html#extract-predictions",
    "href": "slides/day2-afternoon.html#extract-predictions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extract predictions",
    "text": "Extract predictions\n\nepi_arx$predictions\n\n# A tibble: 1 × 5\n  geo_value .pred        .pred_distn forecast_date target_date\n  &lt;chr&gt;     &lt;dbl&gt;             &lt;dist&gt; &lt;date&gt;        &lt;date&gt;     \n1 ca        0.219 quantiles(0.22)[2] 2021-04-01    2021-04-29 \n\n\n\n\n\nNote\n\n\n.pred_dstn is actually a “distribution”, parameterized by its quantiles."
  },
  {
    "objectID": "slides/day2-afternoon.html#extract-predictions-1",
    "href": "slides/day2-afternoon.html#extract-predictions-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extract predictions",
    "text": "Extract predictions\nWe can extract the distribution into a “long” epi_df:\n\n one row per quantile \nvalues = value associated to that quantile\n\n\nepi_arx$predictions |&gt;\n  mutate(.pred_distn = nested_quantiles(.pred_distn)) |&gt;  # create a \"nested\" list-column\n  unnest(.pred_distn)                                     # then unnest it\n\n# A tibble: 2 × 6\n  geo_value .pred values quantile_levels forecast_date target_date\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;           &lt;dbl&gt; &lt;date&gt;        &lt;date&gt;     \n1 ca        0.219 0.0133           0.025 2021-04-01    2021-04-29 \n2 ca        0.219 0.425            0.975 2021-04-01    2021-04-29"
  },
  {
    "objectID": "slides/day2-afternoon.html#predict-with-fitted-arx-split-sample",
    "href": "slides/day2-afternoon.html#predict-with-fitted-arx-split-sample",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predict with fitted ARX (split-sample)",
    "text": "Predict with fitted ARX (split-sample)\n\narx_forecaster fits a model to the training set, and outputs only one prediction (for time \\(t_0+h\\)).\nTo get predictions for the test set:\n\n\npredict(epi_arx$epi_workflow, test)\n\nAn `epi_df` object, 707 x 6 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-11-06 08:50:44.00687\n\n# A tibble: 707 × 6\n   geo_value time_value .pred        .pred_distn forecast_date target_date\n * &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;             &lt;dist&gt; &lt;date&gt;        &lt;date&gt;     \n 1 ca        2021-04-02 0.217 quantiles(0.22)[2] 2021-04-01    2021-04-29 \n 2 ca        2021-04-03 0.203  quantiles(0.2)[2] 2021-04-01    2021-04-29 \n 3 ca        2021-04-04 0.197  quantiles(0.2)[2] 2021-04-01    2021-04-29 \n 4 ca        2021-04-05 0.202  quantiles(0.2)[2] 2021-04-01    2021-04-29 \n 5 ca        2021-04-06 0.199  quantiles(0.2)[2] 2021-04-01    2021-04-29 \n 6 ca        2021-04-07 0.196  quantiles(0.2)[2] 2021-04-01    2021-04-29 \n 7 ca        2021-04-08 0.193 quantiles(0.19)[2] 2021-04-01    2021-04-29 \n 8 ca        2021-04-09 0.195  quantiles(0.2)[2] 2021-04-01    2021-04-29 \n 9 ca        2021-04-10 0.209 quantiles(0.21)[2] 2021-04-01    2021-04-29 \n10 ca        2021-04-11 0.214 quantiles(0.21)[2] 2021-04-01    2021-04-29 \n# ℹ 697 more rows"
  },
  {
    "objectID": "slides/day2-afternoon.html#predict-with-arx-when-re-fitting",
    "href": "slides/day2-afternoon.html#predict-with-arx-when-re-fitting",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predict with ARX (when re-fitting)",
    "text": "Predict with ARX (when re-fitting)\nIn practice, if we want to re-train the forecasters as new data arrive, we fit and predict combining arx_forecaster with epi_slide."
  },
  {
    "objectID": "slides/day2-afternoon.html#predict-with-arx-re-fitting-on-trailing-window",
    "href": "slides/day2-afternoon.html#predict-with-arx-re-fitting-on-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predict with ARX (re-fitting on trailing window)",
    "text": "Predict with ARX (re-fitting on trailing window)\n\nh &lt;- 28         #horizon\nw &lt;- 120 + h    #trailing window length\nn &lt;- nrow(ca)   #time-series length\n\n# Specify the forecast dates\nfc_time_values &lt;- seq(from = t0_date, to = ca$time_value[n]-h, by = \"1 day\")\n\n# Slide the arx_forecaster \nepi_pred_trailing &lt;- ca |&gt;\n  epi_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"cases\", \"deaths\"), \n                     trainer = linear_reg() |&gt; set_engine(\"lm\"),\n                     args_list = arx_args_list(lags = 0, ahead = h,\n                                               quantile_levels = c(0.01, 0.9))\n                     )$predictions |&gt;\n        pivot_quantiles_wider(.pred_distn),\n  .window_size = w, \n  .ref_time_values = fc_time_values\n)"
  },
  {
    "objectID": "slides/day2-afternoon.html#predict-with-arx",
    "href": "slides/day2-afternoon.html#predict-with-arx",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predict with ARX",
    "text": "Predict with ARX\n\n\n\nNote (window length)\n\n\nWe set \\(w = 120 + h\\) to match the window size of the ARX model we fitted manually. Previously, when considering a window from \\(t-w\\) to \\(t\\), we had access to all outcomes in that window, and to all predictors between \\(t-w-h\\) and \\(t-h\\). (That’s because we lagged \\(x\\) before applying the window.) So we were “cheating” by saying that the trailing window had length \\(w=120\\), as its actual size was \\(120+h\\)!\n\n\n\n\n\n\nNote (all past)\n\n\nThe method fitting on all past data up to the forecasting date can be implemented by setting:\n.window_size = Inf in epi_slide."
  },
  {
    "objectID": "slides/day2-afternoon.html#predict-with-arx-re-fitting-on-trailing-window-1",
    "href": "slides/day2-afternoon.html#predict-with-arx-re-fitting-on-trailing-window-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predict with ARX (re-fitting on trailing window)",
    "text": "Predict with ARX (re-fitting on trailing window)\n\n\nepi_pred_trailing \n\nAn `epi_df` object, 680 x 9 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-11-06 08:50:44.00687\n\n# A tibble: 680 × 9\n# Groups:   geo_value [1]\n   geo_value time_value cases deaths .pred forecast_date target_date `0.025`\n * &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;        &lt;date&gt;        &lt;dbl&gt;\n 1 ca        2021-04-01  6.77  0.375 0.337 2021-04-01    2021-04-29   0.0996\n 2 ca        2021-04-02  7.27  0.340 0.340 2021-04-02    2021-04-30   0.104 \n 3 ca        2021-04-03  6.79  0.293 0.331 2021-04-03    2021-05-01   0.0960\n 4 ca        2021-04-04  6.51  0.281 0.327 2021-04-04    2021-05-02   0.0919\n 5 ca        2021-04-05  6.87  0.284 0.330 2021-04-05    2021-05-03   0.0934\n 6 ca        2021-04-06  6.97  0.267 0.329 2021-04-06    2021-05-04   0.0900\n 7 ca        2021-04-07  6.92  0.253 0.326 2021-04-07    2021-05-05   0.0850\n 8 ca        2021-04-08  6.97  0.234 0.322 2021-04-08    2021-05-06   0.0795\n 9 ca        2021-04-09  7.07  0.243 0.322 2021-04-09    2021-05-07   0.0784\n10 ca        2021-04-10  8.33  0.249 0.332 2021-04-10    2021-05-08   0.0878\n# ℹ 670 more rows\n# ℹ 1 more variable: `0.975` &lt;dbl&gt;"
  },
  {
    "objectID": "slides/day2-afternoon.html#predict-with-arx-re-fitting-on-trailing-window-2",
    "href": "slides/day2-afternoon.html#predict-with-arx-re-fitting-on-trailing-window-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predict with ARX (re-fitting on trailing window)",
    "text": "Predict with ARX (re-fitting on trailing window)\n\n\n\n                                 MAE     MASE\ntime series CV + trailing 0.07852942 731.6178"
  },
  {
    "objectID": "slides/day2-afternoon.html#simple-adjustments",
    "href": "slides/day2-afternoon.html#simple-adjustments",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Simple adjustments",
    "text": "Simple adjustments\n\narx_forecaster(epi_data = train |&gt; as_epi_df(), \n               outcome = \"deaths\", \n               predictors = c(\"cases\", \"deaths\"),\n               trainer = linear_reg() |&gt; set_engine(\"lm\"),\n               args_list = arx_args_list(lags = 0, ahead = 28,\n                                         quantile_levels = c(0.01, 0.9)))\n\n\n\nModify predictors to add/drop predictors\n\ne.g. drop deaths for regression with a lagged predictor, or drop cases to get AR model\ndefault: predictors = outcome"
  },
  {
    "objectID": "slides/day2-afternoon.html#simple-adjustments-1",
    "href": "slides/day2-afternoon.html#simple-adjustments-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Simple adjustments",
    "text": "Simple adjustments\n\narx_forecaster(epi_data = train |&gt; as_epi_df(), \n               outcome = \"deaths\", \n               predictors = c(\"cases\", \"deaths\"),\n               trainer = linear_reg() |&gt; set_engine(\"lm\"),\n               args_list = arx_args_list(lags = 0, ahead = 28,\n                                         quantile_levels = c(0.01, 0.9)))\n\n\nModify trainer to use a model that is not lm (default)\n\n e.g. trainer = quantile_reg()\ncan use any {parsnip} models, see list"
  },
  {
    "objectID": "slides/day2-afternoon.html#simple-adjustments-2",
    "href": "slides/day2-afternoon.html#simple-adjustments-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Simple adjustments",
    "text": "Simple adjustments\n\narx_forecaster(epi_data = train |&gt; as_epi_df(), \n               outcome = \"deaths\", \n               predictors = c(\"cases\", \"deaths\"),\n               trainer = linear_reg() |&gt; set_engine(\"lm\"),\n               args_list = arx_args_list(lags = 0, ahead = 28,\n                                         quantile_levels = c(0.01, 0.9)))\n\n\nModify arx_args_list to change lags, horizon, quantile levels, …\n\n\n\narx_args_list(\n  lags = c(0L, 7L, 14L),\n  ahead = 7L,\n  n_training = Inf,\n  forecast_date = NULL,\n  target_date = NULL,\n  adjust_latency = c(\"none\", \"extend_ahead\", \"extend_lags\", \"locf\"),\n  warn_latency = TRUE,\n  quantile_levels = c(0.05, 0.95),\n  symmetrize = TRUE,\n  nonneg = TRUE,\n  quantile_by_key = character(0L),\n  check_enough_data_n = NULL,\n  check_enough_data_epi_keys = NULL,\n  ...\n)"
  },
  {
    "objectID": "slides/day2-afternoon.html#versioned-data",
    "href": "slides/day2-afternoon.html#versioned-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Versioned data",
    "text": "Versioned data\n\nus_data\n\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-04-01 / 2023-01-31\nℹ First/last version with update: 2021-04-01 / 2023-02-01\nℹ Versions end: 2023-02-01\nℹ A preview of the table (92197 rows x 5 columns):\n          version time_value geo_value     cases     deaths\n    1: 2021-04-01 2020-04-01        ak        NA         NA\n    2: 2021-04-01 2020-04-02        ak        NA         NA\n    3: 2021-04-01 2020-04-03        ak        NA         NA\n    4: 2021-04-01 2020-04-04        ak        NA         NA\n    5: 2021-04-01 2020-04-05        ak        NA         NA\n   ---                                                     \n92193: 2023-02-01 2023-01-27        wy   4.61203 0.17172453\n92194: 2023-02-01 2023-01-28        wy   4.61203 0.17172453\n92195: 2023-02-01 2023-01-29        wy   4.61203 0.17172453\n92196: 2023-02-01 2023-01-30        wy   4.61203 0.17172453\n92197: 2023-02-01 2023-01-31        wy -14.74378 0.04906416"
  },
  {
    "objectID": "slides/day2-afternoon.html#version-aware-forecasting-with-geo-pooling",
    "href": "slides/day2-afternoon.html#version-aware-forecasting-with-geo-pooling",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version-aware forecasting with geo-pooling",
    "text": "Version-aware forecasting with geo-pooling\n\nforecast_dates &lt;- seq(from = t0_date, to = as.Date(\"2023-02-01\"), by = \"1 month\")\nh &lt;- c(7, 14, 21, 28)\n\nforecast_k_days_ahead &lt;- function(epi_archive, forecast_dates, ahead = 7) {\n  epi_archive |&gt;\n    epix_slide(\n      ~ arx_forecaster(\n        .x, \n        outcome = \"deaths\", \n        predictors = c(\"cases\", \"deaths\"),\n        trainer = linear_reg() |&gt; set_engine(\"lm\"),\n        args_list = arx_args_list(lags = 0, ahead = ahead,\n                                  quantile_levels = c(0.01, 0.9))\n      )$predictions |&gt; pivot_quantiles_wider(.pred_distn),\n      .before = 120,\n      .versions = forecast_dates\n    )\n}\n\nforecasts &lt;- bind_rows(map(h, ~ forecast_k_days_ahead(us_data, forecast_dates, ahead = .x)))"
  },
  {
    "objectID": "slides/day2-afternoon.html#version-aware-forecasting-with-geo-pooling-1",
    "href": "slides/day2-afternoon.html#version-aware-forecasting-with-geo-pooling-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version-aware forecasting with geo-pooling",
    "text": "Version-aware forecasting with geo-pooling"
  },
  {
    "objectID": "slides/day2-afternoon.html#philosophy-of-forecasting",
    "href": "slides/day2-afternoon.html#philosophy-of-forecasting",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Philosophy of forecasting",
    "text": "Philosophy of forecasting\n\nWe should build up modular components\nBe able to add/remove layers of complexity sequentially\n\n\n\nPreprocessor: do things to the data before model training\nTrainer: train a model on data, resulting in a fitted model object\nPredictor: make predictions, using a fitted model object\nPostprocessor: do things to the predictions before returning"
  },
  {
    "objectID": "slides/day2-afternoon.html#examples-of-preprocessing",
    "href": "slides/day2-afternoon.html#examples-of-preprocessing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of preprocessing",
    "text": "Examples of preprocessing\n\n\nEDA type stuff\n\nMaking locations/signals commensurate (scaling)\nDealing with revisions\nDetecting and removing outliers\nImputing or removing missing data\n\n\n\n\nFeature engineering\n\nCreating lagged predictors\nDay of Week effects\nRolling averages for smoothing\nLagged differences\nGrowth rates instead of raw signals\nThe sky’s the limit"
  },
  {
    "objectID": "slides/day2-afternoon.html#examples-of-postprocessing",
    "href": "slides/day2-afternoon.html#examples-of-postprocessing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of postprocessing",
    "text": "Examples of postprocessing\n\nImpute missing features\nNowcast current values of features\nBootstrap to get predictive intervals\nInvert scaling or other transforms\nThreshold predictions, [0, max_population]"
  },
  {
    "objectID": "slides/day2-afternoon.html#fit-a-forecaster",
    "href": "slides/day2-afternoon.html#fit-a-forecaster",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fit a forecaster",
    "text": "Fit a forecaster\n\n# A preprocessing \"recipe\" that turns raw data into features / response\nr &lt;- epi_recipe(ca) |&gt;\n  step_epi_lag(cases, lag = c(0, 7, 14)) |&gt;\n  step_epi_lag(deaths, lag = c(0, 7, 14)) |&gt;\n  step_epi_ahead(deaths, ahead = 28) |&gt;\n  step_epi_naomit()\n\n# Training engine\ne &lt;- quantile_reg(quantile_levels = c(.1, .5, .9))\n\n# A postprocessing routine describing what to do to the predictions\nf &lt;- frosting() |&gt;\n  layer_predict() |&gt;\n  layer_threshold(.pred, lower = 0) |&gt; # predictions / intervals should be non-negative\n  layer_add_target_date() |&gt;\n  layer_add_forecast_date()\n\n# Bundle up the preprocessor, training engine, and postprocessor\n# We use quantile regression\newf &lt;- epi_workflow(r, e, f)\n\n# Fit it to data (we could fit this to ANY data that has the same format)\ntrained_ewf &lt;- ewf |&gt; fit(ca)\n\n# examines the recipe to determine what we need to make the prediction\nlatest &lt;- get_test_data(r, ca)\n\n# we could make predictions using the same model on ANY test data\npreds &lt;- trained_ewf |&gt; predict(new_data = latest)"
  },
  {
    "objectID": "slides/day2-afternoon.html#thanks",
    "href": "slides/day2-afternoon.html#thanks",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Thanks:",
    "text": "Thanks:\n\nThe whole CMU Delphi Team (across many institutions)\nOptum/UnitedHealthcare, Change Healthcare.\nGoogle, Facebook, Amazon Web Services.\nQuidel, SafeGraph, Qualtrics.\nCenters for Disease Control and Prevention.\nCouncil of State and Territorial Epidemiologists\n\n\n    \n\n\n\n\n\nForecasting with {epipredict} — cmu-delphi/insightnet-workshop-2024"
  },
  {
    "objectID": "slides/day2-morning.html#section",
    "href": "slides/day2-morning.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Forecasting and Time-Series Models",
    "text": "Forecasting and Time-Series Models\n\n\n\n\nVenue – dd Somemonth yyyy"
  },
  {
    "objectID": "slides/day2-morning.html#outline",
    "href": "slides/day2-morning.html#outline",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Outline",
    "text": "Outline\n\nLinear Regression for Time Series Data\nEvaluation Methods\nARX Models\nOverfitting and Regularization\nPrediction Intervals\nForecasting with Versioned Data\nModeling Multiple Time Series"
  },
  {
    "objectID": "slides/day2-morning.html#basics-of-linear-regression",
    "href": "slides/day2-morning.html#basics-of-linear-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Basics of linear regression",
    "text": "Basics of linear regression\n\nAssume we observe a predictor \\(x_i\\) and an outcome \\(y_i\\) for \\(i = 1, \\dots, n\\).\nLinear regression seeks coefficients \\(\\beta_0\\) and \\(\\beta_1\\) such that\n\n\\[y_i \\approx \\beta_0 + \\beta_1 x_i\\]\nis a good approximation for every \\(i = 1, \\dots, n\\).\n\nIn R, the coefficients are found by running lm(y ~ x), where y is the vector of responses and x the vector of predictors."
  },
  {
    "objectID": "slides/day2-morning.html#multiple-linear-regression",
    "href": "slides/day2-morning.html#multiple-linear-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nGiven \\(p\\) different predictors, we seek \\((p+1)\\) coefficients such that\n\n\\[y_i \\approx \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip}\\] is a good approximation for every \\(i = 1, \\dots, n\\)."
  },
  {
    "objectID": "slides/day2-morning.html#linear-regression-with-lagged-predictor",
    "href": "slides/day2-morning.html#linear-regression-with-lagged-predictor",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Linear regression with lagged predictor",
    "text": "Linear regression with lagged predictor\n\nIn time series, outcomes and predictors are usually indexed by time \\(t\\).\n\n\n\nGoal: predicting future \\(y\\), given present \\(x\\).\n\n\n\n\nModel: linear regression with lagged predictor\n\n\\[\\hat y_t = \\hat \\beta + \\hat \\beta_0 x_{t-k}\\]\ni.e. regress the outcome \\(y\\) at time \\(t\\) on the predictor \\(x\\) at time \\(t-k\\).\n\n\n\nEquivalent way to write the model:\n\n\\[\\hat y_{t+k} = \\hat \\beta + \\hat \\beta_0 x_t\\]"
  },
  {
    "objectID": "slides/day2-morning.html#example-predicting-covid-deaths",
    "href": "slides/day2-morning.html#example-predicting-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example: predicting COVID deaths",
    "text": "Example: predicting COVID deaths\n\nDuring the pandemic, interest in predicting COVID deaths 7, 14, 21, 28 days ahead.\nCan we reasonably predict COVID deaths 28 days ahead by just using cases today?\n\n\n\nIf we let\n\n\\[y_{t+28} = \\text{deaths at time } t+28 \\quad\\quad x_{t} = \\text{cases at time } t\\] is the following a good model?\n\\[\\hat y_{t+28} = \\hat\\beta_0 + \\hat\\beta_1 x_{t}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#example-covid-cases-and-deaths-in-california",
    "href": "slides/day2-morning.html#example-covid-cases-and-deaths-in-california",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example: COVID cases and deaths in California",
    "text": "Example: COVID cases and deaths in California\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhead(ca)\n\nAn `epi_df` object, 6 x 4 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-11-06 08:50:44.00687\n\n# A tibble: 6 × 4\n# Groups:   geo_value [1]\n  geo_value time_value cases deaths\n* &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 ca        2020-04-01  3.17 0.0734\n2 ca        2020-04-02  3.48 0.0835\n3 ca        2020-04-03  3.44 0.0894\n4 ca        2020-04-04  3.05 0.0778\n5 ca        2020-04-05  3.28 0.0876\n6 ca        2020-04-06  3.37 0.0848\n\n\n\n\n\n\n\nNote\n\n\nCases seem highly correlated with deaths several weeks later (but relation cases-deaths changes over time)."
  },
  {
    "objectID": "slides/day2-morning.html#checking-correlation",
    "href": "slides/day2-morning.html#checking-correlation",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Checking correlation",
    "text": "Checking correlation\n\nLet’s split the data into a training and a test set (before/after 2021-04-01).\nOn training set: large correlation between cases and deaths 28 days ahead (&gt; 0.95).\n\n\n\n\nLet’s use (base) R to prepare the data and fit\n\n\\[\\hat y_{t+28} = \\hat\\beta + \\hat\\beta_0 x_{t}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#preparing-the-data",
    "href": "slides/day2-morning.html#preparing-the-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Preparing the data",
    "text": "Preparing the data\n\n# Add column with cases lagged by k\nca$lagged_cases &lt;- dplyr::lag(ca$cases, n = k)\n\n# Split into train and test (before/after t0_date)\nt0_date &lt;- as.Date('2021-04-01')\ntrain &lt;- ca |&gt; filter(time_value &lt;= t0_date)\ntest &lt;- ca |&gt; filter(time_value &gt; t0_date)\n\nCheck if deaths is approximately linear in lagged_cases:"
  },
  {
    "objectID": "slides/day2-morning.html#fitting-lagged-linear-regression-in-r",
    "href": "slides/day2-morning.html#fitting-lagged-linear-regression-in-r",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fitting lagged linear regression in R",
    "text": "Fitting lagged linear regression in R\n\nreg_lagged = lm(deaths ~ lagged_cases, data = train)\ncoef(reg_lagged)\n\n (Intercept) lagged_cases \n   0.1171839    0.0112714"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics",
    "href": "slides/day2-morning.html#error-metrics",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics",
    "text": "Error metrics\n\nAssume we have predictions \\(\\hat y_{new, t}\\) for the unseen observations \\(y_{new,t}\\) over times \\(t = 1, \\dots, N\\).\nFour commonly used error metrics are:\n\nmean squared error (MSE)\nmean absolute error (MAE)\nmean absolute percentage error (MAPE)\nmean absolute scaled error (MASE)"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics-mse-and-mae",
    "href": "slides/day2-morning.html#error-metrics-mse-and-mae",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics: MSE and MAE",
    "text": "Error metrics: MSE and MAE\n\\[MSE = \\frac{1}{N} \\sum_{t=1}^N (y_{new, t}- \\hat y_{new, t})^2\\] \\[MAE = \\frac{1}{N} \\sum_{t=1}^N |y_{new, t}- \\hat y_{new, t}|\\]\n\nMAE gives less importance to extreme errors than MSE.\nDrawback: both metrics are scale-dependent, so they are not universally interpretable. (For example, if \\(y\\) captures height, MSE and MAE will vary depending on whether we measure in feet or meters.)"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics-mape",
    "href": "slides/day2-morning.html#error-metrics-mape",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics: MAPE",
    "text": "Error metrics: MAPE\n\nFixing scale-dependence:\n\n\\[MAPE = 100 \\times \\frac{1}{N} \\sum_{t=1}^N\n\\left|\\frac{y_{new, t}- \\hat y_{new, t}}{y_{new, t}}\\right|\\]\n\nDrawbacks:\n\nErratic behavior when \\(y_{new, t}\\) is close to zero\nIt assumes the unit of measurement has a meaningful zero (e.g. using Fahrenheit or Celsius to measure temperature will lead to different MAPE)"
  },
  {
    "objectID": "slides/day2-morning.html#comparing-mae-and-mape",
    "href": "slides/day2-morning.html#comparing-mae-and-mape",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Comparing MAE and MAPE",
    "text": "Comparing MAE and MAPE\n\n\n\nNote\n\n\nThere are situations when MAPE is problematic!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n           MAE     MAPE\nyhat1 2.873328 43.14008\nyhat2 5.382247 36.08279"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics-mase",
    "href": "slides/day2-morning.html#error-metrics-mase",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics: MASE",
    "text": "Error metrics: MASE\n\\[MASE = 100 \\times \\frac{\\frac{1}{N} \\sum_{t=1}^N\n|y_{new, t}- \\hat y_{new, t}|}\n{\\frac{1}{N-1} \\sum_{t=2}^N\n|y_{new, t}- y_{new, t-1}|}\\]\n\nAdvantages:\n\nis universally interpretable (not scale dependent)\navoids the zero-pitfall\n\nMASE in words: we normalize the error of our forecasts by that of a naive method which always predicts the last observation."
  },
  {
    "objectID": "slides/day2-morning.html#comparing-mae-mape-and-mase",
    "href": "slides/day2-morning.html#comparing-mae-mape-and-mase",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Comparing MAE, MAPE and MASE",
    "text": "Comparing MAE, MAPE and MASE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n           MAE     MAPE      MASE\nyhat1 2.873328 43.14008  66.10004\nyhat2 5.382247 36.08279 123.81696"
  },
  {
    "objectID": "slides/day2-morning.html#defining-the-error-metrics-in-r",
    "href": "slides/day2-morning.html#defining-the-error-metrics-in-r",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Defining the error metrics in R",
    "text": "Defining the error metrics in R\n\nMSE &lt;- function(truth, prediction) {\n  mean((truth - prediction)^2)}\n\nMAE &lt;- function(truth, prediction) {\n  mean(abs(truth - prediction))}\n\nMAPE &lt;- function(truth, prediction) {\n  100 * mean(abs(truth - prediction) / truth)}\n\nMASE &lt;- function(truth, prediction) {\n  100 * MAE(truth, prediction) / mean(abs(diff(truth)))}"
  },
  {
    "objectID": "slides/day2-morning.html#estimating-the-prediction-error",
    "href": "slides/day2-morning.html#estimating-the-prediction-error",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Estimating the prediction error",
    "text": "Estimating the prediction error\n\nGiven an error metric, we want to estimate the prediction error under that metric.\nThis can be accomplished in different ways, using the\n\nTraining error\nSplit-sample error\nTime series cross-validation error (using all past data or a trailing window)"
  },
  {
    "objectID": "slides/day2-morning.html#training-error",
    "href": "slides/day2-morning.html#training-error",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Training error",
    "text": "Training error\n\nThe easiest but worst approach to estimate the prediction error is to use the training error, i.e. the average error on the training set that was used to fit the model.\nThe training error is\n\ngenerally too optimistic as an estimate of prediction error\nmore optimistic the more complex the model!1\n\n\nMore on this when we talk about overfitting."
  },
  {
    "objectID": "slides/day2-morning.html#training-error-1",
    "href": "slides/day2-morning.html#training-error-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Training error",
    "text": "Training error\nLinear regression of COVID deaths on lagged cases\n\n# Getting the predictions for the training set\npred_train &lt;- predict(reg_lagged)\n\n\n\n\n               MAE     MASE\ntraining 0.0740177 380.9996"
  },
  {
    "objectID": "slides/day2-morning.html#split-sample-error",
    "href": "slides/day2-morning.html#split-sample-error",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Split-sample error",
    "text": "Split-sample error\nTo compute the split-sample error\n\nSplit data into training (up to time \\(t_0\\)), and test set (after \\(t_0\\))\nFit the model to the training data only\nMake predictions for the test set\nCompute the selected error metric on the test set only\n\n\n\n\nNote\n\n\nSplit-sample estimates of prediction error don’t mimic a situation where we would refit the model in the future. They are pessimistic if the relation between outcome and predictors changes over time."
  },
  {
    "objectID": "slides/day2-morning.html#split-sample-mse",
    "href": "slides/day2-morning.html#split-sample-mse",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Split-sample MSE",
    "text": "Split-sample MSE\nAssume we want to make \\(h\\)-step ahead predictions, i.e. at time \\(t\\) we want to make a forecast for \\(t+h\\). Then, the split-sample MSE is\n\\[\\text{SplitMSE} = \\frac{1}{n-h-t_0} \\sum_{t = t_0}^{n-h} (\\hat y_{t+h|t_0} - y_{t+h})^2\\]\nwhere \\(\\hat y_{t+h|t_0}\\) indicates a prediction for \\(y\\) at time \\(t+h\\) that was made with a model that was fit on data up to time \\(t_0\\)."
  },
  {
    "objectID": "slides/day2-morning.html#split-sample-error-1",
    "href": "slides/day2-morning.html#split-sample-error-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Split-sample error",
    "text": "Split-sample error\nLinear regression of COVID deaths on lagged cases\n\n# Getting h-step ahead predictions for the test set\nh &lt;- k\ntest_h &lt;- test[-(1:h-1), ] # drop first h-1 rows to avoid data leakage\npred_test &lt;- predict(reg_lagged, newdata = test_h)\n\n\n\n\n                   MAE      MASE\ntraining     0.0740177  380.9996\nsplit-sample 0.3116854 2914.4575\n\n\n\nNote that we are overestimating the peak due to the changed relationship between cases - deaths over time.\nTalk about data leakage."
  },
  {
    "objectID": "slides/day2-morning.html#warning",
    "href": "slides/day2-morning.html#warning",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Warning!",
    "text": "Warning!\n\nPredictions are overshooting the target, especially in early 2022 (Omicron phase).\nThis is because we are predicting deaths using lagged cases, but the relation between the two changes over time."
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cross-validation-cv",
    "href": "slides/day2-morning.html#time-series-cross-validation-cv",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series cross-validation (CV)",
    "text": "Time-series cross-validation (CV)\n\\(h\\)-step ahead predictions\n\nIf we refit in the future once new data are available, a more appropriate way to estimate the prediction error is time-series cross-validation.\nTo get \\(h\\)-step ahead predictions, for each time \\(t = t_0, t_0+1, \\dots\\),\n\nFit the model using data up to time \\(t\\)\nMake a prediction for \\(t+h\\)\nRecord the prediction error\n\nThe cross-validation MSE is then\n\n\\[CVMSE = \\frac{1}{n-h-t_0} \\sum_{t = t_0}^{n-h} (\\hat y_{t+h|t} - y_{t+h})^2\\]\nwhere \\(\\hat y_{t+h|t}\\) indicates a prediction for \\(y\\) at time \\(t+h\\) that was made with data available up to time \\(t\\)."
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cross-validation-cv-1",
    "href": "slides/day2-morning.html#time-series-cross-validation-cv-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series cross-validation (CV)",
    "text": "Time-series cross-validation (CV)\nLinear regression of COVID deaths on lagged cases\n\nn &lt;- nrow(ca)                               #length of time series\nh &lt;- k                                      #number of days ahead for which prediction is wanted\npred_all_past &lt;- rep(NA, length = n)        #initialize vector of predictions\n\nfor (t in t0:(n-h)) {\n  # fit to all past data and make h-step ahead prediction\n  reg_all_past = lm(deaths ~ lagged_cases, data = ca, subset = (1:n) &lt;= t) \n  pred_all_past[t+h] = predict(reg_all_past, newdata = data.frame(ca[t+h, ]))\n}\n\n\n\n\nNote\n\n\nWith the current model, we can only predict \\(k\\) days ahead (where \\(k\\) = number of days by which predictor is lagged)!"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cross-validation-cv-2",
    "href": "slides/day2-morning.html#time-series-cross-validation-cv-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series cross-validation (CV)",
    "text": "Time-series cross-validation (CV)\nLinear regression of COVID deaths on lagged cases\n\n\n\n                     MAE      MASE\ntraining       0.0740177  380.9996\nsplit-sample   0.3116854 2914.4575\ntime series CV 0.2374931 2212.5992\n\n\n\nSome improvement wrt split-sample, but still overestimating peak."
  },
  {
    "objectID": "slides/day2-morning.html#warning-1",
    "href": "slides/day2-morning.html#warning-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Warning!",
    "text": "Warning!\n\nPredictions are still overshooting the target, but error is smaller than split-sample.\nWhy?\n\n 👍 Forecaster is partially learning the change in cases-deaths relation (especially in late 2022)\n👎 We refit on all past data, so predictions are still influenced by old cases-deaths relation\n\n\n\n\n\nIdea 💡\n\n\nIgnore old data when refitting?"
  },
  {
    "objectID": "slides/day2-morning.html#regression-on-a-trailing-window",
    "href": "slides/day2-morning.html#regression-on-a-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Regression on a trailing window",
    "text": "Regression on a trailing window\n\nFit the model on a window of data of length \\(w\\), starting at \\(t-w\\) and ending at \\(t\\).\nAdvantage: if the predictors-outcome relation changes over time, training the forecaster on a window of recent data can better capture the recent relation which might be more relevant to predict the outcome in the near future.\nWindow length \\(w\\) considerations:\n\nif \\(w\\) is too big, the model can’t adapt to the recent predictors-outcome relation \nif \\(w\\) is too small, the fitted model may be too volatile (trained on too little data)"
  },
  {
    "objectID": "slides/day2-morning.html#trailing-window",
    "href": "slides/day2-morning.html#trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Trailing window",
    "text": "Trailing window\nLinear regression of COVID deaths on lagged cases\n\n# Getting the predictions through CV with trailing window\nw &lt;- 120                                    #trailing window size\nh &lt;- k                                      #number of days ahead for which prediction is wanted\npred_trailing &lt;- rep(NA, length = n)        #initialize vector of predictions\n\nfor (t in t0:(n-h)) {\n  # fit to a trailing window of size w and make h-step ahead prediction\n  reg_trailing = lm(deaths ~ lagged_cases, data = ca, \n                    subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n  pred_trailing[t+h] = predict(reg_trailing, newdata = data.frame(ca[t+h, ]))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-all-past-vs-trailing-window",
    "href": "slides/day2-morning.html#time-series-cv-all-past-vs-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series CV: all past vs trailing window",
    "text": "Time-series CV: all past vs trailing window\nLinear regression of COVID deaths on lagged cases\n\n\n\n                                 MAE      MASE\ntraining                  0.07401770  380.9996\nsplit-sample              0.31168536 2914.4575\ntime series CV            0.23749306 2212.5992\ntime series CV + trailing 0.09932651  925.3734\n\n\n\nA lot of improvement: trailing window allows to adapt to the change in relationship between cases and deaths over time."
  },
  {
    "objectID": "slides/day2-morning.html#autoregressive-exogenous-input-arx-model",
    "href": "slides/day2-morning.html#autoregressive-exogenous-input-arx-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Autoregressive exogenous input (ARX) model",
    "text": "Autoregressive exogenous input (ARX) model\n\nIdea: predicting the outcome via a linear combination of its lags and a set of exogenous (i.e. external) input variables\nExample:\n\n\\[\\hat y_{t+h} = \\hat\\phi + \\sum_{i=0}^p \\hat\\phi_i y_{t-i} + \\sum_{j=0}^q \\hat\\beta_j x_{t-j}\\]\n\nNotice: we don’t need to include all contiguous lags, and we could fit e.g.\n\n\\[\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} + \\hat\\phi_2 y_{t-14} +\n\\hat\\beta_0 x_{t} + \\hat\\beta_1 x_{t-7} + \\hat\\beta_2 x_{t-14}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#arx-model-for-covid-deaths",
    "href": "slides/day2-morning.html#arx-model-for-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX model for COVID deaths",
    "text": "ARX model for COVID deaths\n\nLet’s add lagged deaths as a predictor to our previous forecaster:\n\n\\[\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\beta_0 x_{t}\\]\n\n# Prepare data: add column with deaths lagged by 28\nca$lagged_deaths &lt;- dplyr::lag(ca$deaths, n = k)\n\n\nHow does it compare to the previous model in terms of time-series CV?"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-all-past-and-trailing-arx-model",
    "href": "slides/day2-morning.html#time-series-cv-all-past-and-trailing-arx-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-Series CV: all past and trailing (ARX model)",
    "text": "Time-Series CV: all past and trailing (ARX model)\n\n\n\n                                 MAE      MASE\ntime series CV            0.16204381 1509.6779\ntime series CV + trailing 0.07872895  733.4767\n\n\n\nErrors under both metrics are smaller than with previous model."
  },
  {
    "objectID": "slides/day2-morning.html#warning-2",
    "href": "slides/day2-morning.html#warning-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Warning!",
    "text": "Warning!\nRegression on a trailing window can be quite sensitive to data issues."
  },
  {
    "objectID": "slides/day2-morning.html#predictions-for-different-h",
    "href": "slides/day2-morning.html#predictions-for-different-h",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions for different \\(h\\)",
    "text": "Predictions for different \\(h\\)\n\nSo far we only focused on COVID death predictions 28 days ahead.\nWe will now compare the first model\n\n\\[\\hat y_{t+h} = \\hat\\beta + \\hat\\beta_0 x_t\\]\nto the second model\n\\[\\hat y_{t+h} = \\hat\\phi + \\hat\\phi_0 y_t + \\hat\\beta_0 x_t\\]\nfor horizons \\(h = 7, 14, 21, 28\\).\n\nWe will only make forecasts on the \\(1^{st}\\) day of each month, and use a trailing window with \\(w = 120\\)."
  },
  {
    "objectID": "slides/day2-morning.html#predictions-for-different-h-1",
    "href": "slides/day2-morning.html#predictions-for-different-h-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions for different \\(h\\)",
    "text": "Predictions for different \\(h\\)\n\nh_vals &lt;- c(7, 14, 21, 28)  #horizons \npred_m1 = pred_m2 &lt;- data.frame(matrix(NA, nrow = 0, ncol = 3))  #initialize df for predictions\ncolnames(pred_m1) = colnames(pred_m2) = c(\"forecast_date\", \"target_date\", \"prediction\")\nw &lt;- 120    #trailing window size\n\nca_lags &lt;- ca |&gt; select(!c(lagged_cases, lagged_deaths))\n\n# Create lagged predictors \nfor (i in seq_along(h_vals)) {\n  ca_lags[[paste0(\"lagged_deaths_\", h_vals[i])]] &lt;- dplyr::lag(ca_lags$deaths, n = h_vals[i])\n  ca_lags[[paste0(\"lagged_cases_\", h_vals[i])]] &lt;- dplyr::lag(ca_lags$cases, n = h_vals[i])\n}\n\n# Only forecast on 1st day of the months\nforecast_time &lt;- which(ca_lags$time_value &gt;= t0_date & \n                         ca_lags$time_value &lt; ca_lags$time_value[n-max(h_vals)] &\n                         day(ca_lags$time_value) == 1)\n\nfor (t in forecast_time) {\n  for (i in seq_along(h_vals)) {\n    h = h_vals[i]\n    # formulas including h-lagged variables\n    m1_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h))\n    m2_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h, \" + lagged_deaths_\", h))\n    # fit to trailing window of data\n    m1_fit = lm(m1_formula, data = ca_lags, subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n    m2_fit = lm(m2_formula, data = ca_lags, subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n    # make h-step ahead predictions\n    pred_m1 = rbind(pred_m1, \n                    data.frame(forecast_date = ca_lags$time_value[t],\n                               target_date = ca_lags$time_value[t+h],\n                               prediction = predict(m1_fit, newdata = data.frame(ca_lags[t+h, ]))))\n    pred_m2 = rbind(pred_m2, \n                    data.frame(forecast_date = ca_lags$time_value[t],\n                               target_date = ca_lags$time_value[t+h],\n                               prediction = predict(m2_fit, newdata = data.frame(ca_lags[t+h, ]))))\n    }\n}"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-for-different-h-model-1",
    "href": "slides/day2-morning.html#predictions-for-different-h-model-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions for different \\(h\\) (Model 1)",
    "text": "Predictions for different \\(h\\) (Model 1)\n\n\n\n              MAE    MASE\nModel 1 0.1049742 304.007"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-for-different-h-model-2",
    "href": "slides/day2-morning.html#predictions-for-different-h-model-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions for different \\(h\\) (Model 2)",
    "text": "Predictions for different \\(h\\) (Model 2)\n\n\n\n               MAE     MASE\nModel 2 0.04463132 129.2531"
  },
  {
    "objectID": "slides/day2-morning.html#visualizing-predictions-for-multiple-horizons",
    "href": "slides/day2-morning.html#visualizing-predictions-for-multiple-horizons",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Visualizing predictions for multiple horizons",
    "text": "Visualizing predictions for multiple horizons\nDifferent ways to visualize predictions for multiple \\(h\\)\n\nLast slides: group by forecast date, and show prediction “trajectories”\nOther approach: one line and color per horizon \\(h\\)"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-by-horizon-model-2",
    "href": "slides/day2-morning.html#predictions-by-horizon-model-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions by horizon (Model 2)",
    "text": "Predictions by horizon (Model 2)"
  },
  {
    "objectID": "slides/day2-morning.html#too-many-predictors",
    "href": "slides/day2-morning.html#too-many-predictors",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Too many predictors",
    "text": "Too many predictors\nWhat if we try to incorporate past information extensively by fitting a model with a very large number of predictors?\n\nThe estimated coefficients will be chosen to mimic the observed data very closely on the training set, leading to small training error\nThe predictive performance on the test set might be very poor, producing large split-sample and CV error\n\n\n\n\nOverfitting!"
  },
  {
    "objectID": "slides/day2-morning.html#arx-model-for-covid-deaths-with-many-predictors",
    "href": "slides/day2-morning.html#arx-model-for-covid-deaths-with-many-predictors",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX model for COVID deaths with many predictors",
    "text": "ARX model for COVID deaths with many predictors\nWhen predicting COVID deaths 28 days ahead, we can use more past information and fit a model that includes the past two months of deaths and cases as predictors\n\\[\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-1} + \\dots +\n\\hat\\phi_{59} y_{t-59} +\n\\hat\\beta_0 x_{t} + \\dots + \\hat\\beta_{t-59} x_{t-59}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#preparing-the-data-1",
    "href": "slides/day2-morning.html#preparing-the-data-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Preparing the data",
    "text": "Preparing the data\n\ny &lt;- ca$deaths  #outcome\nlags &lt;- 28:87   #lags used for predictors (deaths and cases)\nh &lt;- 28\n\n# Build predictor matrix with 60 columns\nX &lt;- data.frame(matrix(NA, nrow = length(y), ncol = 2*length(lags)))\ncolnames(X) &lt;- paste('X', 1:ncol(X), sep = '')\n\nfor (j in 1:length(lags)) {\n  # first 60 columns contain deaths lagged by 28, 29, ..., 87\n  X[, j] = dplyr::lag(ca$deaths, lags[j])\n  # last 60 columns contain cases lagged by 28, 29, ..., 87\n  X[, length(lags) + j] = dplyr::lag(ca$cases, lags[j])\n}"
  },
  {
    "objectID": "slides/day2-morning.html#fitting-the-arx-model",
    "href": "slides/day2-morning.html#fitting-the-arx-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fitting the ARX model",
    "text": "Fitting the ARX model\n\n# Train/test split\ny_train &lt;- y[1:t0]\nX_train &lt;- X[1:t0, ]\ny_test &lt;- y[(t0+h):length(y)]\nX_test &lt;- X[(t0+h):length(y), ]\n\n# Fitting the ARX model\nreg = lm(y_train ~ ., data = X_train)\ncoef(reg)\n\n  (Intercept)            X1            X2            X3            X4 \n 0.0775116437 -0.5593818462  0.7979659233 -0.4175920623 -0.2780809101 \n           X5            X6            X7            X8            X9 \n 0.3031742752 -0.0809244359  0.2548033065 -0.4860940499  0.1322930625 \n          X10           X11           X12           X13           X14 \n-0.2352041391 -0.1327834155  0.2155747658 -0.3380379255  0.4239820677 \n          X15           X16           X17           X18           X19 \n-0.2012041267 -0.3367851572 -0.2889890062  0.5328712849  0.5388650654 \n          X20           X21           X22           X23           X24 \n-0.3065835983  0.0724595436 -0.0168042757 -0.1171985635  0.2046513639 \n          X25           X26           X27           X28           X29 \n 0.1810480128  0.1213875691  0.0230516587  0.0196208441  0.0397085778 \n          X30           X31           X32           X33           X34 \n-0.3884271784  0.2088690345  0.1248242133  0.0706165553 -0.4882035875 \n          X35           X36           X37           X38           X39 \n 0.3609708771 -0.3169047917  0.4216666798  0.1891753615 -0.1106475626 \n          X40           X41           X42           X43           X44 \n 0.1498605000 -0.0692090064  0.1336287081 -0.1875462008 -0.2449003857 \n          X45           X46           X47           X48           X49 \n-0.0001337325 -0.5738823399  0.0695056705 -0.2460256934  1.0173509442 \n          X50           X51           X52           X53           X54 \n-0.1853591480 -0.5428279059  0.2678983608 -0.6935743948  0.3829408389 \n          X55           X56           X57           X58           X59 \n 0.1088530454  0.9466159031 -0.5618240450 -0.4660113206  0.6102916420 \n          X60           X61           X62           X63           X64 \n-0.2859449807  0.0283237204 -0.0099051792 -0.0070208086  0.0021192306 \n          X65           X66           X67           X68           X69 \n-0.0047341417 -0.0111532015  0.0038542335  0.0184565802 -0.0060684485 \n          X70           X71           X72           X73           X74 \n-0.0005801373  0.0048246180 -0.0061516656 -0.0066597399  0.0039021597 \n          X75           X76           X77           X78           X79 \n 0.0126296042 -0.0080708988 -0.0027091539  0.0052517573 -0.0052000323 \n          X80           X81           X82           X83           X84 \n 0.0029961750  0.0013593227  0.0083628716 -0.0063778828 -0.0018882435 \n          X85           X86           X87           X88           X89 \n-0.0097221295  0.0003314155 -0.0013911110  0.0066935430  0.0107961484 \n          X90           X91           X92           X93           X94 \n-0.0052473765 -0.0057177036  0.0023462634 -0.0112827594  0.0008517257 \n          X95           X96           X97           X98           X99 \n-0.0004388072  0.0231342674 -0.0056794349 -0.0046693142 -0.0061536587 \n         X100          X101          X102          X103          X104 \n-0.0094880392  0.0071605921  0.0021423255  0.0108738290 -0.0015420116 \n         X105          X106          X107          X108          X109 \n 0.0015155025  0.0022482275 -0.0148197121  0.0129113709  0.0009150566 \n         X110          X111          X112          X113          X114 \n 0.0021338029 -0.0019029077 -0.0040171812 -0.0025674957 -0.0069761237 \n         X115          X116          X117          X118          X119 \n 0.0226899068 -0.0022271856 -0.0060651747  0.0071536700 -0.0016426930 \n         X120 \n-0.0127949778"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-on-training-and-test-set",
    "href": "slides/day2-morning.html#predictions-on-training-and-test-set",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions on training and test set",
    "text": "Predictions on training and test set\n\n\n\n                             MAE    MASE\nsplit-sample truncated 0.3978198 3706.28\n\n\n\n\n\nNote\n\n\nSome predictions were negative, which doesn’t make sense for count data, so we truncated them at 0."
  },
  {
    "objectID": "slides/day2-morning.html#arx-models-with-2-and-3-lags",
    "href": "slides/day2-morning.html#arx-models-with-2-and-3-lags",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX models with 2 and 3 lags",
    "text": "ARX models with 2 and 3 lags\n\nThe ARX model \\(\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\beta_0 x_{t}\\) predicted quite well for different \\(h\\)\nWe will now consider two extensions\n\n\\[\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} +\n\\hat\\beta_0 x_{t} + \\hat\\beta_1 x_{t-7}\\]\nand\n\\[\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} + \\hat\\phi_2 y_{t-14} +\n\\hat\\beta_0 x_{t} + \\hat\\beta_1 x_{t-7} + \\hat\\beta_2 x_{t-14}\\]\nand fit them using a trailing window with \\(w = 120\\)."
  },
  {
    "objectID": "slides/day2-morning.html#fit-arx-with-2-and-3-lags-on-trailing-window",
    "href": "slides/day2-morning.html#fit-arx-with-2-and-3-lags-on-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fit ARX with 2 and 3 lags on trailing window",
    "text": "Fit ARX with 2 and 3 lags on trailing window\n\npred_m3 = pred_m4 &lt;- data.frame(matrix(NA, nrow = 0, ncol = 3))  #initialize df for predictions\ncolnames(pred_m3) = colnames(pred_m4) = c(\"forecast_date\", \"target_date\", \"prediction\")\nw &lt;- 120     #trailing window size\n\nca_lags$lagged_deaths_35 &lt;- dplyr::lag(ca_lags$deaths, n = 35)\nca_lags$lagged_deaths_42 &lt;- dplyr::lag(ca_lags$deaths, n = 42)\nca_lags$lagged_cases_35 &lt;- dplyr::lag(ca_lags$cases, n = 35)\nca_lags$lagged_cases_42 &lt;- dplyr::lag(ca_lags$cases, n = 42)\n\nfor (t in forecast_time) {\n  for (i in seq_along(h_vals)) {\n    h = h_vals[i]\n    # formulas including h-lagged variables\n    m3_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h, \" + lagged_deaths_\", h,\n                                   \" + lagged_cases_\", h+7, \" + lagged_deaths_\", h+7))\n    m4_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h, \" + lagged_deaths_\", h,\n                                   \" + lagged_cases_\", h+7, \" + lagged_deaths_\", h+7,\n                                   \" + lagged_cases_\", h+14, \" + lagged_deaths_\", h+14))\n    # fit to trailing window of data\n    m3_fit = lm(m3_formula, data = ca_lags, subset = (1:n) &lt;= t & (1:n) &gt; (t-w-7)) \n    m4_fit = lm(m4_formula, data = ca_lags, subset = (1:n) &lt;= t & (1:n) &gt; (t-w-14)) \n    # make h-step ahead predictions\n    pred_m3 = rbind(pred_m3, \n                    data.frame(forecast_date = ca_lags$time_value[t],\n                               target_date = ca_lags$time_value[t+h],\n                               prediction = max(0, predict(m3_fit, newdata = data.frame(ca_lags[t+h, ])))))\n    pred_m4 = rbind(pred_m4, \n                    data.frame(forecast_date = ca_lags$time_value[t],\n                               target_date = ca_lags$time_value[t+h],\n                               prediction = max(0, predict(m4_fit, newdata = data.frame(ca_lags[t+h, ])))))\n  }\n}"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-using-arx-with-2-lags",
    "href": "slides/day2-morning.html#predictions-using-arx-with-2-lags",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions using ARX with 2 lags",
    "text": "Predictions using ARX with 2 lags\n\n\n\n       MAE     MASE\n 0.0495936 143.6239"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-using-arx-with-3-lags",
    "href": "slides/day2-morning.html#predictions-using-arx-with-3-lags",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions using ARX with 3 lags",
    "text": "Predictions using ARX with 3 lags\n\n\n\n        MAE     MASE\n 0.05800799 167.9921"
  },
  {
    "objectID": "slides/day2-morning.html#warning-3",
    "href": "slides/day2-morning.html#warning-3",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Warning!",
    "text": "Warning!\n\nAs we add more predictors, forecasts seem more volatile and errors increase.\nHow can we\n\nselect the “right” number of lags to include?\navoid overfitting, while considering a large number of predictors?"
  },
  {
    "objectID": "slides/day2-morning.html#regularization",
    "href": "slides/day2-morning.html#regularization",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Regularization",
    "text": "Regularization\n\nIdea: introduce a regularization parameter \\(\\lambda\\) that shrinks or sets some of the estimated coefficients to zero, i.e. some predictors are estimated to have limited or no predictive power\nMost common regularization methods\n\nRidge: shrinks coefficients to zero\nLasso: sets some coefficients to zero\n\nLet’s predict \\(h=28\\) days ahead by regularizing\n\n\\[\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} + \\hat\\phi_2 y_{t-14} +\n\\hat\\beta_0 x_{t} + \\hat\\beta_1 x_{t-7} + \\hat\\beta_2 x_{t-14}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#fit-arx-3-lags-ridgelasso-for-covid-deaths",
    "href": "slides/day2-morning.html#fit-arx-3-lags-ridgelasso-for-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fit ARX (3 lags) + ridge/lasso for COVID deaths",
    "text": "Fit ARX (3 lags) + ridge/lasso for COVID deaths\n\nlibrary(glmnet) # Implements ridge and lasso\n\nh &lt;- 28\nX &lt;- as_tibble(ca_lags) |&gt; select(ends_with(\"_28\"), ends_with(\"_35\"), ends_with(\"_42\"))\ny &lt;- ca_lags$deaths\n\n# We'll need to omit NA values explicitly, as otherwise glmnet will complain\nX_train &lt;- X[43:t0, ]\ny_train &lt;- y[43:t0]\n\n# Ridge regression: set alpha = 0, lambda sequence will be chosen automatically\nridge &lt;- glmnet(X_train, y_train, alpha = 0)\nbeta_ridge &lt;- coef(ridge)       # matrix of estimated coefficients \nlambda_ridge &lt;- ridge$lambda    # sequence of lambdas used to fit ridge \n\n# Lasso regression: set alpha = 1, lambda sequence will be chosen automatically\nlasso &lt;- glmnet(X_train, y_train, alpha = 1)\nbeta_lasso &lt;- coef(lasso)       # matrix of estimated coefficients \nlambda_lasso &lt;- lasso$lambda    # sequence of lambdas used to fit lasso \n\ndim(beta_lasso)                 # One row per coefficient, one column per lambda value\n\n[1]  7 85"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-on-test-set-and-best-lambda",
    "href": "slides/day2-morning.html#predictions-on-test-set-and-best-lambda",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions on test set and best \\(\\lambda\\)",
    "text": "Predictions on test set and best \\(\\lambda\\)\n\nX_test &lt;- X[(t0+h):n, ]\ny_test &lt;- y[(t0+h):n]\n\n# Predict values for second half of the time series\nyhat_ridge &lt;- predict(ridge, newx = as.matrix(X_test))\nyhat_lasso &lt;- predict(lasso, newx = as.matrix(X_test))\n\n# Compute MAE \nmae_ridge &lt;- colMeans(abs(yhat_ridge - y_test))\nmae_lasso &lt;- colMeans(abs(yhat_lasso - y_test))\n\n# Select index of lambda vector which gives lowest MAE\nmin_ridge &lt;- which.min(mae_ridge)\nmin_lasso &lt;- which.min(mae_lasso)\n\n# Get corresponding predictions for train and test sets\npred_train_ridge &lt;- predict(ridge, newx = as.matrix(X_train))[, min_ridge] \npred_test_ridge &lt;- yhat_ridge[, min_ridge]\npred_train_lasso &lt;- predict(lasso, newx = as.matrix(X_train))[, min_lasso] \npred_test_lasso &lt;- yhat_lasso[, min_lasso]"
  },
  {
    "objectID": "slides/day2-morning.html#estimated-coefficients-shrinkage-vs-sparsity",
    "href": "slides/day2-morning.html#estimated-coefficients-shrinkage-vs-sparsity",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Estimated coefficients: shrinkage vs sparsity",
    "text": "Estimated coefficients: shrinkage vs sparsity\n\n\n\n\n                    ridge       lasso\n(Intercept)  0.2978514823 0.124915807\nX1           0.0433892112 0.069300307\nX2           0.0292256563 0.000000000\nX3           0.0179647838 0.000000000\nX4           0.0083918680 0.000000000\nX5          -0.0015177021 0.000000000\nX6          -0.0125786976 0.000000000\nX7          -0.0191532557 0.000000000\nX8           0.0010586265 0.008320956\nX9           0.0009417383 0.000000000\nX10          0.0008208805 0.001690258\nX11          0.0006535137 0.000000000\nX12          0.0004488789 0.000000000\nX13          0.0002816751 0.000000000\nX14          0.0001839354 0.000000000"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-arx-ridgelasso-train-and-test-set",
    "href": "slides/day2-morning.html#predictions-arx-ridgelasso-train-and-test-set",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions: ARX + ridge/lasso (train and test set)",
    "text": "Predictions: ARX + ridge/lasso (train and test set)\n\n\n\n                         MAE      MASE\nridge training     0.1975073  924.4584\nridge split-sample 0.2923452 2723.6281\nlasso training     0.0790951  370.2149\nlasso split-sample 0.2945295 2743.9784"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-for-arx-ridgelasso-trailing",
    "href": "slides/day2-morning.html#time-series-cv-for-arx-ridgelasso-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series CV for ARX + ridge/lasso (trailing)",
    "text": "Time-series CV for ARX + ridge/lasso (trailing)\n\nh &lt;- 28  # number of days ahead \nw &lt;- 120 # window length\n\n# Initialize matrices for predictions (one column per lambda value)\nyhat_ridge_mat &lt;- matrix(NA, nrow = n, ncol = length(lambda_ridge))\nyhat_lasso_mat &lt;- matrix(NA, nrow = n, ncol = length(lambda_lasso)) \nyhat_ridge = yhat_lasso &lt;- rep(NA, length = n)\n\n# Select index of best lambda value on training set\nridge_index = cv.glmnet(as.matrix(X_train), y_train, alpha = 0, lambda = lambda_ridge)$index[1]\nlasso_index = cv.glmnet(as.matrix(X_train), y_train, alpha = 1, lambda = lambda_lasso)$index[1]\n\nfor (t in t0:(n-h)) {\n  # Indices of data within window\n  inds = t-w &lt; 1:n & 1:n &lt;= t\n  # Fit ARX + ridge/lasso for each lambda value\n  ridge_trail = glmnet(X[inds, ], y[inds], alpha = 0, lambda = lambda_ridge)\n  lasso_trail = glmnet(X[inds, ], y[inds], alpha = 1, lambda = lambda_lasso)\n  # Predict for each lambda value\n  yhat_ridge_mat[t+h, ] = predict(ridge_trail, newx = as.matrix(X[(t+h), ]))\n  yhat_lasso_mat[t+h, ] = predict(lasso_trail, newx = as.matrix(X[(t+h), ]))\n  # Save prediction corresponding to best lambda so far\n  yhat_ridge[t+h] = max(0, yhat_ridge_mat[t+h, ridge_index])\n  yhat_lasso[t+h] = max(0, yhat_lasso_mat[t+h, lasso_index])\n  if (t &gt;= t0+h) {\n    # Prediction error\n    mae_ridge = colMeans(abs(yhat_ridge_mat[1:(t+1), ] - y[1:(t+1)]), na.rm = T)\n    mae_lasso = colMeans(abs(yhat_lasso_mat[1:(t+1), ] - y[1:(t+1)]), na.rm = T)\n    # Select index of lambda vector which gives lowest MAE so far\n    ridge_index &lt;- which.min(mae_ridge)\n    lasso_index &lt;- which.min(mae_lasso)\n  }\n}"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-time-series-cv-for-arx-ridgelasso-trailing",
    "href": "slides/day2-morning.html#predictions-time-series-cv-for-arx-ridgelasso-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions: time-series CV for ARX + ridge/lasso (trailing)",
    "text": "Predictions: time-series CV for ARX + ridge/lasso (trailing)\n\n\n\n                           MAE      MASE\nridge CV + trailing 0.09264327  863.1092\nlasso CV + trailing 0.12042184 1121.9076"
  },
  {
    "objectID": "slides/day2-morning.html#point-predictions-vs-intervals",
    "href": "slides/day2-morning.html#point-predictions-vs-intervals",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Point predictions vs intervals",
    "text": "Point predictions vs intervals\n\nSo far, we have only considered point predictions, i.e.  we have fitted models to provide our best guess on the outcome at time \\(t+h\\).\n\n\n\n\nImportant\n\n\nWhat if we want to provide a measure of uncertainty around the point prediction or a likely range of values for the outcome at time \\(t+h\\)?\n\n\n\n\nFor each target time \\(t+h\\), we can construct prediction intervals, i.e. provide ranges of values that are expected to cover the true outcome value a fixed fraction of times."
  },
  {
    "objectID": "slides/day2-morning.html#prediction-intervals-for-lm-fits",
    "href": "slides/day2-morning.html#prediction-intervals-for-lm-fits",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Prediction intervals for lm fits",
    "text": "Prediction intervals for lm fits\n\nTo get prediction intervals for the models we previously fitted, we only need to tweak our call to predict by adding as an input:\ninterval = \"prediction\", level = p\nwhere \\(p \\in (0, 1)\\) is the desired coverage.\nThe output from predict will then be a matrix with\n\nfirst column a point estimate\nsecond column the lower limit of the interval\nthird column the upper limit of the interval"
  },
  {
    "objectID": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window",
    "href": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Prediction intervals for ARX (CV, trailing window)",
    "text": "Prediction intervals for ARX (CV, trailing window)\n\n# Initialize matrices to store predictions \n# 3 columns: point estimate, lower limit, and upper limit\npred_trailing &lt;- matrix(NA, nrow = n, ncol = 3)\ncolnames(pred_trailing) &lt;- c('prediction', 'lower', 'upper')\n\nfor (t in t0:(n-h)) {\n  # Fit ARX and predict\n  arx_trailing = lm(deaths ~ lagged_deaths + lagged_cases, data = ca, \n                    subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n  pred_trailing[t+h, ] = pmax(0, \n                              predict(arx_trailing, newdata = data.frame(ca[t+h, ]),\n                                      interval = \"prediction\", level = 0.8))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window-1",
    "href": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Prediction intervals for ARX (CV, trailing window)",
    "text": "Prediction intervals for ARX (CV, trailing window)\n\n\n\n                 MAE     MASE\nlm.trailing 0.104397 972.6125"
  },
  {
    "objectID": "slides/day2-morning.html#quantile-regression",
    "href": "slides/day2-morning.html#quantile-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Quantile regression",
    "text": "Quantile regression\n\nSo far we only considered different ways to apply linear regression.\nQuantile regression is a different estimation method, and it directly targets conditional quantiles of the outcome over time.\n\n\n\n\n\n\n\nDefinition\n\n\nConditional quantile = value below which a given percentage (e.g. 25%, 50%, 75%) of observations fall, given specific values of the predictor variables.\n\n\n\n\nAdvantage: it provides a more complete picture of the outcome distribution."
  },
  {
    "objectID": "slides/day2-morning.html#arx-model-for-covid-deaths-via-quantile-regression",
    "href": "slides/day2-morning.html#arx-model-for-covid-deaths-via-quantile-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX model for COVID deaths via quantile regression",
    "text": "ARX model for COVID deaths via quantile regression\n\n#install.packages(\"quantreg\")\nlibrary(quantreg)  #library to perform quantile regression\n\n# Set quantiles of interest: we will focus on 10%, 50% (i.e. median), and 90% quantiles\nquantiles &lt;- c(0.1, 0.5, 0.9)  \n\n# Fit quantile regression to training set\nq_reg &lt;- rq(deaths ~ lagged_deaths + lagged_cases, data = train, tau = quantiles)\n\n# Sort estimated coefficients \ncoefs_sorted &lt;- t(apply(coef(q_reg), 1, sort))\ncolnames(coefs_sorted) &lt;- colnames(coef(q_reg))\nq_reg$coefficients &lt;- coefs_sorted\ncoefs_sorted\n\n                 tau= 0.1   tau= 0.5   tau= 0.9\n(Intercept)   0.023886410 0.06896010 0.11680538\nlagged_deaths 0.173198197 0.19821254 0.30706290\nlagged_cases  0.008602685 0.01022547 0.01135643"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-via-quantile-regression-cv-trailing",
    "href": "slides/day2-morning.html#predictions-via-quantile-regression-cv-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions via quantile regression (CV, trailing)",
    "text": "Predictions via quantile regression (CV, trailing)\n\n# Initialize matrix to store predictions \n# 3 columns: lower limit, median, and upper limit\npred_trailing &lt;- matrix(NA, nrow = n, ncol = 3)\ncolnames(pred_trailing) &lt;- c('lower', 'median', 'upper')\n\nfor (t in t0:(n-h)) {\n  # Fit quantile regression\n  rq_trailing = rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles,\n                   data = ca, subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n  \n  # Sort estimated coefficients \n  coefs_sorted &lt;- t(apply(coef(rq_trailing), 1, sort))\n  rq_trailing$coefficients &lt;- coefs_sorted\n  \n  # Predict\n  pred_trailing[t+h, ] = pmax(0, predict(rq_trailing, newdata = data.frame(ca[t+h, ])))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-via-quantile-regression-cv-trailing-1",
    "href": "slides/day2-morning.html#predictions-via-quantile-regression-cv-trailing-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions via quantile regression (CV, trailing)",
    "text": "Predictions via quantile regression (CV, trailing)\n\n\n\n                  MAE     MASE\nrq.trailing 0.1244401 1159.343"
  },
  {
    "objectID": "slides/day2-morning.html#actual-coverage",
    "href": "slides/day2-morning.html#actual-coverage",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Actual Coverage",
    "text": "Actual Coverage\n\nWe would expect the ARX model fitted via lm and via rq to cover the truth about 80% of the times. Is this actually true in practice?\nThe actual coverage of each predictive interval is lower:\n\n\n\n         lm.trailing rq.trailing\nCoverage   0.8294118   0.8117647"
  },
  {
    "objectID": "slides/day2-morning.html#evaluation-1",
    "href": "slides/day2-morning.html#evaluation-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Evaluation",
    "text": "Evaluation\n\nPrediction intervals are “good” if they\n\ncover the truth most of the time\nare not too wide\n\nError metric that captures both desiderata: Weighted Interval Score (WIS)\n\\(F\\) = forecast composed of predicted quantiles \\(q_{\\tau}\\) for the set of quantile levels \\(\\tau\\). The WIS for target variable \\(Y\\) is represented as (McDonald et al., 2021):\n\n\\[WIS(F, Y) = 2\\sum_{\\tau} \\phi_{\\tau} (Y - q_{\\tau})\\]\nwhere \\(\\phi_{\\tau}(x) = \\tau |x|\\) for \\(x \\geq 0\\) and \\(\\phi_{\\tau}(x) = (1-\\tau) |x|\\) for \\(x &lt; 0\\)."
  },
  {
    "objectID": "slides/day2-morning.html#computing-the-wis",
    "href": "slides/day2-morning.html#computing-the-wis",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Computing the WIS",
    "text": "Computing the WIS\n\nWIS &lt;- function(truth, estimates, quantiles) {\n  2 * sum(pmax(\n    quantiles * (truth - estimates),\n    (1 - quantiles) * (estimates - truth),\n    na.rm = TRUE\n  ))\n}\n\n\n\n\nNote\n\n\nWIS tends to prioritize sharpness (how wide the interval is) relative to coverage (if the interval contains the truth)."
  },
  {
    "objectID": "slides/day2-morning.html#wis-for-arx-fitted-via-lm-and-rq",
    "href": "slides/day2-morning.html#wis-for-arx-fitted-via-lm-and-rq",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "WIS for ARX fitted via lm and rq",
    "text": "WIS for ARX fitted via lm and rq\nThe lowest mean WIS is attained by quantile regression.\n\n\n  Mean WIS lm Mean WIS rq\n1   0.1335326   0.1056215"
  },
  {
    "objectID": "slides/day2-morning.html#versioned-data",
    "href": "slides/day2-morning.html#versioned-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Versioned data",
    "text": "Versioned data\nSo far: data never revised (or simply ignored revisions, as_of today)\n\n\n\nImportant\n\n\nHow can we train forecasters when dealing with versioned data?\n\n\n\n\ndata_archive\n\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-04-01 / 2023-03-09\nℹ First/last version with update: 2020-04-02 / 2023-03-10\nℹ Versions end: 2023-03-10\nℹ A preview of the table (148820 rows x 5 columns):\n        geo_value time_value    version case_rate death_rate\n     1:        ak 2020-04-01 2020-04-02  1.797489  0.0000000\n     2:        ak 2020-04-01 2020-05-07  1.777061  0.0000000\n     3:        ak 2020-04-01 2020-10-28  1.106147  0.0000000\n     4:        ak 2020-04-01 2020-10-29  1.797489  0.0000000\n     5:        ak 2020-04-01 2020-10-30  1.797489  0.0000000\n    ---                                                     \n148816:        wy 2023-03-05 2023-03-06  0.000000  0.0000000\n148817:        wy 2023-03-06 2023-03-07  0.000000  0.0000000\n148818:        wy 2023-03-07 2023-03-08 38.809743  0.3434491\n148819:        wy 2023-03-08 2023-03-09  0.000000  0.0000000\n148820:        wy 2023-03-09 2023-03-10  0.000000  0.0000000"
  },
  {
    "objectID": "slides/day2-morning.html#version-aware-forecasting",
    "href": "slides/day2-morning.html#version-aware-forecasting",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version aware-forecasting",
    "text": "Version aware-forecasting\nImportant: when fitting and predicting, only use data in the latest version available at the forecast date!"
  },
  {
    "objectID": "slides/day2-morning.html#version-aware-forecasting-1",
    "href": "slides/day2-morning.html#version-aware-forecasting-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version-aware forecasting",
    "text": "Version-aware forecasting\n\n# initialize dataframe for predictions\n# 5 columns: forecast date, target date, 10%, 50%, and 90% quantiles\npred_trailing &lt;- data.frame(matrix(NA, ncol = 5, nrow = 0))\ncolnames(pred_trailing) &lt;- c(\"forecast_date\", \"target_date\", 'tau..0.1', 'tau..0.5', 'tau..0.9')\n\nw &lt;- 120         #trailing window size\nh &lt;- 28          #number of days ahead\n\n# dates when predictions are made (set to be 1 month apart)\nfc_time_values &lt;- seq(from = t0_date, to = as.Date(\"2023-02-01\"), by = \"1 month\")\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data &lt;- epix_as_of(ca_archive, max_version = as.Date(fc_date))\n  # create lagged predictors\n  data$lagged_deaths &lt;- dplyr::lag(data$deaths, h) \n  data$lagged_cases &lt;- dplyr::lag(data$cases, h)\n  # perform quantile regression\n  rq_trailing &lt;- rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles, \n                    # only consider window of data\n                    data = data |&gt; filter(time_value &gt; (max(time_value) - w))) \n  # sort estimated coefficients \n  coefs_sorted &lt;- t(apply(coef(rq_trailing), 1, sort))\n  colnames(coefs_sorted) &lt;- c('tau..0.1', 'tau..0.5', 'tau..0.9')\n  rq_trailing$coefficients &lt;- coefs_sorted\n  # construct data.frame with the right predictors for the target date\n  predictors &lt;- data.frame(lagged_deaths = tail(data$deaths, 1), \n                           lagged_cases = tail(data$cases, 1))\n  # make predictions for target date and add them to matrix of predictions\n  pred_trailing &lt;- rbind(pred_trailing, \n                         data.frame('forecast_date' = max(data$time_value),\n                                    'target_date' = max(data$time_value) + h, \n                                    predict(rq_trailing, newdata = predictors)))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#version-aware-predictions-cv-trailing",
    "href": "slides/day2-morning.html#version-aware-predictions-cv-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version-aware predictions (CV, trailing)",
    "text": "Version-aware predictions (CV, trailing)"
  },
  {
    "objectID": "slides/day2-morning.html#using-geo-information",
    "href": "slides/day2-morning.html#using-geo-information",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using geo information",
    "text": "Using geo information\n\nAssume we observe data over time from multiple locations (e.g. states or counties).\nWe could\n\nEstimate coefficients separately for each location (as we have done so far).\nFit one model using all locations together at each time point (geo-pooling). Estimated coefficients will not be location specific.\nEstimate coefficients separately for each location, but include predictors capturing averages across locations (partial geo-pooling)."
  },
  {
    "objectID": "slides/day2-morning.html#geo-pooling-trailing-window",
    "href": "slides/day2-morning.html#geo-pooling-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Geo-pooling (trailing window)",
    "text": "Geo-pooling (trailing window)\n\nusa_archive &lt;- data_archive$DT |&gt; \n  as_epi_archive()\n\n# initialize dataframe for predictions\n# 6 columns: geo value, forecast date, target date, 10%, 50%, and 90% quantiles\npred_trailing &lt;- data.frame(matrix(NA, ncol = 6, nrow = 0))\ncolnames(pred_trailing) &lt;- c('geo_value', 'forecast_date', 'target_date',\n                             'tau..0.1', 'tau..0.5', 'tau..0.9')\n\nw &lt;- 120         #trailing window size\nh &lt;- 28          #number of days ahead\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data &lt;- epix_as_of(usa_archive, max_version = as.Date(fc_date))\n  \n  # create lagged predictors for each state \n  data &lt;- data |&gt;\n    arrange(geo_value, time_value) |&gt;  \n    group_by(geo_value) |&gt;\n    mutate(lagged_deaths = dplyr::lag(deaths, h),\n           lagged_cases = dplyr::lag(cases, h)) |&gt;\n    ungroup()\n  \n  # perform quantile regression\n  rq_trailing &lt;- rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles, \n                    # only consider window of data\n                    data = data |&gt; filter(time_value &gt; (max(time_value) - w))) \n  # sort estimated coefficients \n  coefs_sorted &lt;- t(apply(coef(rq_trailing), 1, sort))\n  colnames(coefs_sorted) &lt;- c('tau..0.1', 'tau..0.5', 'tau..0.9')\n  rq_trailing$coefficients &lt;- coefs_sorted\n  \n  # construct dataframe with the right predictors for the target date\n  new_lagged_deaths &lt;- data |&gt; \n    filter(time_value == max(time_value)) |&gt;\n    select(geo_value, deaths)\n  \n  new_lagged_cases &lt;- data |&gt; \n    filter(time_value == max(time_value)) |&gt;\n    select(geo_value, cases)\n  \n  predictors &lt;- new_lagged_deaths |&gt;\n    inner_join(new_lagged_cases, join_by(geo_value)) |&gt;\n    rename(lagged_deaths = deaths,\n           lagged_cases = cases)\n  \n  # make predictions for target date and add them to matrix of predictions\n  pred_trailing &lt;- rbind(pred_trailing, \n                         data.frame(\n                           'geo_value' = predictors$geo_value,\n                           'forecast_date' = max(data$time_value),\n                           'target_date' = max(data$time_value) + h, \n                           predict(rq_trailing, newdata = predictors)))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#geo-pooled-predictions-for-california",
    "href": "slides/day2-morning.html#geo-pooled-predictions-for-california",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Geo-pooled predictions for California",
    "text": "Geo-pooled predictions for California"
  },
  {
    "objectID": "slides/day2-morning.html#partial-geo-pooling-trailing-window",
    "href": "slides/day2-morning.html#partial-geo-pooling-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Partial geo-pooling (trailing window)",
    "text": "Partial geo-pooling (trailing window)\n\n# initialize dataframe for predictions\n# 6 columns: geo value, forecast date, target date, 10%, 50%, and 90% quantiles\npred_trailing &lt;- data.frame(matrix(NA, ncol = 6, nrow = 0))\ncolnames(pred_trailing) &lt;- c('geo_value', 'forecast_date', 'target_date',\n                             'tau..0.1', 'tau..0.5', 'tau..0.9')\n\nw &lt;- 120         #trailing window size\nh &lt;- 28          #number of days ahead\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data &lt;- epix_as_of(usa_archive, max_version = as.Date(fc_date))\n  \n  # create lagged predictors \n  data &lt;- data |&gt;\n    arrange(geo_value, time_value) |&gt;  \n    group_by(geo_value) |&gt;\n    mutate(lagged_deaths = dplyr::lag(deaths, h),\n           lagged_cases = dplyr::lag(cases, h)) |&gt;\n    ungroup() |&gt;\n    group_by(time_value) |&gt;\n    mutate(avg_lagged_deaths = mean(lagged_deaths, na.rm = T),\n           avg_lagged_cases = mean(lagged_cases, na.rm = T)) |&gt;\n    ungroup() \n  \n  # perform quantile regression\n  rq_trailing &lt;- rq(deaths ~ lagged_deaths + lagged_cases + avg_lagged_deaths +\n                      avg_lagged_cases, tau = quantiles, \n                    data = (data |&gt; filter(geo_value == 'ca'))) \n  \n  # sort estimated coefficients \n  coefs_sorted &lt;- t(apply(coef(rq_trailing), 1, sort))\n  colnames(coefs_sorted) &lt;- c('tau..0.1', 'tau..0.5', 'tau..0.9')\n  rq_trailing$coefficients &lt;- coefs_sorted\n  \n  # construct data.frame with the right predictors for the target date\n  new_lagged_deaths &lt;- data |&gt; \n    filter(time_value == max(time_value)) |&gt;\n    select(geo_value, deaths) |&gt;\n    mutate(avg_lagged_deaths = mean(deaths, na.rm = T)) |&gt;\n    filter(geo_value == 'ca')\n  \n  new_lagged_cases &lt;- data |&gt; \n    filter(time_value == max(time_value)) |&gt;\n    select(geo_value, cases) |&gt;\n    mutate(avg_lagged_cases = mean(cases, na.rm = T)) |&gt;\n    filter(geo_value == 'ca')\n  \n  predictors &lt;- new_lagged_deaths |&gt;\n    inner_join(new_lagged_cases, join_by(geo_value)) |&gt;\n    rename(lagged_deaths = deaths,\n           lagged_cases = cases)\n  \n  # make predictions for target date and add them to matrix of predictions\n  pred_trailing &lt;- rbind(pred_trailing, \n                         data.frame(\n                           'geo_value' = predictors$geo_value,\n                           'forecast_date' = max(data$time_value),\n                           'target_date' = max(data$time_value) + h, \n                           predict(rq_trailing, newdata = predictors)))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#partially-geo-pooled-predictions-for-california",
    "href": "slides/day2-morning.html#partially-geo-pooled-predictions-for-california",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Partially geo-pooled predictions for California",
    "text": "Partially geo-pooled predictions for California"
  },
  {
    "objectID": "slides/day2-morning.html#final-slide",
    "href": "slides/day2-morning.html#final-slide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Final slide",
    "text": "Final slide\nThanks:\n\nThe whole CMU Delphi Team (across many institutions)\nOptum/UnitedHealthcare, Change Healthcare.\nGoogle, Facebook, Amazon Web Services.\nQuidel, SafeGraph, Qualtrics.\nCenters for Disease Control and Prevention.\nCouncil of State and Territorial Epidemiologists\n\n\n    \n\n\n\n\n\nForecasting and Time-Series Models — cmu-delphi/insightnet-workshop-2024"
  }
]