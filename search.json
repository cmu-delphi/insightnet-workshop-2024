[
  {
    "objectID": "slides/day2-morning.html#section",
    "href": "slides/day2-morning.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Forecasting and Time-Series Models",
    "text": "Forecasting and Time-Series Models\n\n\n\n\nVenue – dd Somemonth yyyy"
  },
  {
    "objectID": "slides/day2-morning.html#outline",
    "href": "slides/day2-morning.html#outline",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Outline",
    "text": "Outline\n\nLinear Regression for Time Series Data\nEvaluation Methods\nARX Models\nConsiderations for Different Horizons\nOverfitting and Regularization\nPrediction Intervals\nForecasting with Versioned Data\nModeling Multiple Time Series"
  },
  {
    "objectID": "slides/day2-morning.html#basics-of-linear-regression",
    "href": "slides/day2-morning.html#basics-of-linear-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Basics of linear regression",
    "text": "Basics of linear regression\n\nAssume we observe a predictor \\(x_i\\) and an outcome \\(y_i\\) for \\(i = 1, \\dots, n\\).\nLinear regression seeks coefficients \\(\\beta_0\\) and \\(\\beta_1\\) such that\n\n\\[y_i \\approx \\beta_0 + \\beta_1 x_i\\]\nis a good approximation for every \\(i = 1, \\dots, n\\).\n\nIn R, the coefficients are found by running lm(y ~ x), where y is the vector of responses and x the vector of predictors."
  },
  {
    "objectID": "slides/day2-morning.html#multiple-linear-regression",
    "href": "slides/day2-morning.html#multiple-linear-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nGiven \\(p\\) different predictors, we seek \\((p+1)\\) coefficients such that\n\n\\[y_i \\approx \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip}\\] is a good approximation for every \\(i = 1, \\dots, n\\)."
  },
  {
    "objectID": "slides/day2-morning.html#linear-regression-with-lagged-predictor",
    "href": "slides/day2-morning.html#linear-regression-with-lagged-predictor",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Linear regression with lagged predictor",
    "text": "Linear regression with lagged predictor\n\nIn time series, outcomes and predictors are usually indexed by time \\(t\\).\nGoal: predicting future \\(y\\), given present \\(x\\).\nModel: linear regression with lagged predictor\n\n\\[\\hat y_t = \\hat \\beta + \\hat \\beta_0 x_{t-k}\\]\ni.e. regress the outcome \\(y\\) at time \\(t\\) on the predictor \\(x\\) at time \\(t-k\\).\n\nEquivalent way to write the model:\n\n\\[\\hat y_{t+k} = \\hat \\beta + \\hat \\beta_0 x_t\\]"
  },
  {
    "objectID": "slides/day2-morning.html#example-predicting-covid-deaths",
    "href": "slides/day2-morning.html#example-predicting-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example: predicting COVID deaths",
    "text": "Example: predicting COVID deaths\n\nDuring the pandemic, interest in predicting COVID deaths 7, 14, 21, 28 days ahead.\nCan we reasonably predict COVID deaths 28 days ahead by just using cases today?\nIf we let\n\n\\[y_{t+28} = \\text{deaths at time } t+28 \\quad\\quad x_{t} = \\text{cases at time } t\\] is the following a good model?\n\\[\\hat y_{t+28} = \\hat\\beta_0 + \\hat\\beta_1 x_{t}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#example-covid-cases-and-deaths-in-california",
    "href": "slides/day2-morning.html#example-covid-cases-and-deaths-in-california",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example: COVID cases and deaths in California",
    "text": "Example: COVID cases and deaths in California\n\nLet’s focus on California.\nCases seem highly correlated with deaths several weeks later.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhead(ca)\n\nAn `epi_df` object, 6 x 4 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-10-23 20:07:29.405142\n\n# A tibble: 6 × 4\n  geo_value time_value cases deaths\n* &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 ca        2020-04-01  3.17 0.0734\n2 ca        2020-04-02  3.48 0.0835\n3 ca        2020-04-03  3.44 0.0894\n4 ca        2020-04-04  3.05 0.0778\n5 ca        2020-04-05  3.28 0.0876\n6 ca        2020-04-06  3.37 0.0848"
  },
  {
    "objectID": "slides/day2-morning.html#checking-correlation",
    "href": "slides/day2-morning.html#checking-correlation",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Checking correlation",
    "text": "Checking correlation\n\nLet’s split the data into a training and a test set (before/after 2021-03-01).\nOn training set: large correlation between cases and deaths 28 days ahead (&gt; 0.95).\n\n\n\nLet’s use (base) R to prepare the data and fit\n\n\\[\\hat y_{t+28} = \\hat\\beta + \\hat\\beta_0 x_{t}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#preparing-the-data",
    "href": "slides/day2-morning.html#preparing-the-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Preparing the data",
    "text": "Preparing the data\n\n# Add column with cases lagged by k\nca$lagged_cases &lt;- dplyr::lag(ca$cases, n = k)\n\n# Split into train and test (before/after t0_date)\nt0_date &lt;- as.Date('2021-03-01')\ntrain &lt;- ca %&gt;% filter(time_value &lt;= t0_date)\ntest &lt;- ca %&gt;% filter(time_value &gt; t0_date)\n\n\nCheck if deaths is approximately linear in lagged_cases:"
  },
  {
    "objectID": "slides/day2-morning.html#fitting-lagged-linear-regression-in-r",
    "href": "slides/day2-morning.html#fitting-lagged-linear-regression-in-r",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fitting lagged linear regression in R",
    "text": "Fitting lagged linear regression in R\n\nreg_lagged = lm(deaths ~ lagged_cases, data = train)\ncoef(reg_lagged)\n\n (Intercept) lagged_cases \n  0.09853776   0.01132312"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics",
    "href": "slides/day2-morning.html#error-metrics",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics",
    "text": "Error metrics\n\nAssume we have predictions \\(\\hat y_{new, t}\\) for the unseen observations \\(y_{new,t}\\) over times \\(t = 1, \\dots, N\\).\nFour commonly used error metrics are:\n\nmean squared error (MSE)\nmean absolute error (MAE)\nmean absolute percentage error (MAPE)\nmean absolute scaled error (MASE)"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics-mse-and-mae",
    "href": "slides/day2-morning.html#error-metrics-mse-and-mae",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics: MSE and MAE",
    "text": "Error metrics: MSE and MAE\n\\[MSE = \\frac{1}{N} \\sum_{t=1}^N (y_{new, t}- \\hat y_{new, t})^2\\] \\[MAE = \\frac{1}{N} \\sum_{t=1}^N |y_{new, t}- \\hat y_{new, t}|\\]\n\nMAE gives less importance to extreme errors than MSE.\nDrawback: both metrics are scale-dependent, so they are not universally interpretable. (For example, if \\(y\\) captures height, MSE and MAE will vary depending on whether we measure in feet or meters.)"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics-mape",
    "href": "slides/day2-morning.html#error-metrics-mape",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics: MAPE",
    "text": "Error metrics: MAPE\n\nFixing scale-dependence:\n\n\\[MAPE = 100 \\times \\frac{1}{N} \\sum_{t=1}^N\n\\left|\\frac{y_{new, t}- \\hat y_{new, t}}{y_{new, t}}\\right|\\]\n\nDrawbacks:\n\nErratic behavior when \\(y_{new, t}\\) is close to zero\nIt assumes the unit of measurement has a meaningful zero (e.g. using Fahrenheit or Celsius to measure temperature will lead to different MAPE)"
  },
  {
    "objectID": "slides/day2-morning.html#comparing-mae-and-mape",
    "href": "slides/day2-morning.html#comparing-mae-and-mape",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Comparing MAE and MAPE",
    "text": "Comparing MAE and MAPE\n\n\n\nNote\n\n\nThere are situations when MAPE is problematic!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n           MAE     MAPE\nyhat1 2.873328 43.14008\nyhat2 5.382247 36.08279"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics-mase",
    "href": "slides/day2-morning.html#error-metrics-mase",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics: MASE",
    "text": "Error metrics: MASE\n\\[MASE = 100 \\times \\frac{\\frac{1}{N} \\sum_{t=1}^N\n|y_{new, t}- \\hat y_{new, t}|}\n{\\frac{1}{N-1} \\sum_{t=2}^N\n|y_{new, t}- y_{new, t-1}|}\\]\n\nAdvantages:\n\nis universally interpretable (not scale dependent)\navoids the zero-pitfall\n\nMASE in words: we normalize the error of our forecasts by that of a naive method which always predicts the last observation."
  },
  {
    "objectID": "slides/day2-morning.html#comparing-mae-mape-and-mase",
    "href": "slides/day2-morning.html#comparing-mae-mape-and-mase",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Comparing MAE, MAPE and MASE",
    "text": "Comparing MAE, MAPE and MASE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n           MAE     MAPE      MASE\nyhat1 2.873328 43.14008  66.10004\nyhat2 5.382247 36.08279 123.81696"
  },
  {
    "objectID": "slides/day2-morning.html#defining-the-error-metrics-in-r",
    "href": "slides/day2-morning.html#defining-the-error-metrics-in-r",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Defining the error metrics in R",
    "text": "Defining the error metrics in R\n\nMSE &lt;- function(truth, prediction) {\n  mean((truth - prediction)^2)}\n\nMAE &lt;- function(truth, prediction) {\n  mean(abs(truth - prediction))}\n\nMAPE &lt;- function(truth, prediction) {\n  100 * mean(abs(truth - prediction) / truth)}\n\nMASE &lt;- function(truth, prediction) {\n  100 * MAE(truth, prediction) / mean(abs(diff(truth)))}"
  },
  {
    "objectID": "slides/day2-morning.html#estimating-the-prediction-error",
    "href": "slides/day2-morning.html#estimating-the-prediction-error",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Estimating the prediction error",
    "text": "Estimating the prediction error\n\nGiven an error metric, we want to estimate the prediction error under that metric.\nThis can be accomplished in different ways, using the\n\nTraining error\nSplit-sample error\nTime series cross-validation error (using all past data or a trailing window)"
  },
  {
    "objectID": "slides/day2-morning.html#training-error",
    "href": "slides/day2-morning.html#training-error",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Training error",
    "text": "Training error\n\nThe easiest but worst approach to estimate the prediction error is to use the training error, i.e. the average error on the training set that was used to fit the model.\nThe training error is\n\ngenerally too optimistic as an estimate of prediction error\nmore optimistic the more complex the model!1\n\n\nMore on this when we talk about overfitting."
  },
  {
    "objectID": "slides/day2-morning.html#training-error-1",
    "href": "slides/day2-morning.html#training-error-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Training error",
    "text": "Training error\nLinear regression of COVID deaths on lagged cases\n\n# Getting the predictions for the training set\npred_train &lt;- predict(reg_lagged)\n\n\n\n\n                MAE     MASE\ntraining 0.05985631 351.4848"
  },
  {
    "objectID": "slides/day2-morning.html#split-sample-error",
    "href": "slides/day2-morning.html#split-sample-error",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Split-sample error",
    "text": "Split-sample error\n\nTo compute the split-sample error\n\nSplit data into training (up to time \\(t_0\\)), and test set (after \\(t_0\\))\nFit the model to the training data only\nMake predictions for the test set\nCompute the selected error metric on the test set only\n\nFormally, the split-sample MSE is\n\n\\[\\text{SplitMSE} = \\frac{1}{n-t_0} \\sum_{t = t_0 +1}^n (\\hat y_t - y_t)^2\\]\n\nSplit-sample estimates of prediction error don’t mimic a situation where we would refit the model in the future. They are pessimistic if the relation between outcome and predictors changes over time."
  },
  {
    "objectID": "slides/day2-morning.html#split-sample-error-1",
    "href": "slides/day2-morning.html#split-sample-error-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Split-sample error",
    "text": "Split-sample error\nLinear regression of COVID deaths on lagged cases\n\n# Getting the predictions for the test set\npred_test &lt;- predict(reg_lagged, newdata = test)\n\n\n\n\n                    MAE     MASE\ntraining     0.05985631 351.4848\nsplit-sample 0.10005007 659.8971"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cross-validation-cv",
    "href": "slides/day2-morning.html#time-series-cross-validation-cv",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series cross-validation (CV)",
    "text": "Time-series cross-validation (CV)\n1-step ahead predictions\n\nIf we refit in the future once new data are available, a more appropriate way to estimate the prediction error is time-series cross-validation.\nTo get 1-step ahead predictions (i.e. at time \\(t\\) we forecast for \\(t+1\\)) we proceed as follows, for \\(t = t_0, t_0+1, \\dots\\)\n\nFit the model using data up to time \\(t\\)\nMake a prediction for \\(t+1\\)\nRecord the prediction error\n\n\nThe cross-validation MSE is then\n\\[CVMSE = \\frac{1}{n-t_0} \\sum_{t = t_0}^{n-1} (\\hat y_{t+1|t} - y_{t+1})^2\\]\nwhere \\(\\hat y_{t+1|t}\\) indicates a prediction for \\(y\\) at time \\(t+1\\) that was made with data available up to time \\(t\\)."
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cross-validation-cv-1",
    "href": "slides/day2-morning.html#time-series-cross-validation-cv-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series cross-validation (CV)",
    "text": "Time-series cross-validation (CV)\n\\(h\\)-step ahead predictions\n\nIn general, if we want to make \\(h\\)-step ahead predictions (i.e. at time \\(t\\) we forecast for \\(t+h\\)), we proceed as follows for \\(t = t_0, t_0+1, \\dots\\)\n\nFit the model using data up to time \\(t\\)\nMake a prediction for \\(t+h\\)\nRecord the prediction error\n\nThe cross-validation MSE is then\n\n\\[CVMSE = \\frac{1}{n-t_0} \\sum_{t = t_0}^{n-h} (\\hat y_{t+h|t} - y_{t+h})^2\\]\nwhere \\(\\hat y_{t+h|t}\\) indicates a prediction for \\(y\\) at time \\(t+h\\) that was made with data available up to time \\(t\\)."
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cross-validation-cv-2",
    "href": "slides/day2-morning.html#time-series-cross-validation-cv-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series cross-validation (CV)",
    "text": "Time-series cross-validation (CV)\nLinear regression of COVID deaths on lagged cases\nGetting the predictions requires slightly more code:\n\nn &lt;- nrow(ca)                               #length of time series\nh &lt;- k                                      #number of days ahead for which prediction is wanted\npred_all_past &lt;- rep(NA, length = n-h-t0+1) #initialize vector of predictions\n\nfor (t in t0:(n-h)) {\n  # fit to all past data and make 1-step ahead prediction\n  reg_all_past = lm(deaths ~ lagged_cases, data = ca, subset = (1:n) &lt;= t) \n  pred_all_past[t-t0+1] = predict(reg_all_past, newdata = data.frame(ca[t+h, ]))\n}\n\n\n\n\nNote\n\n\nWith the current model, we can only predict \\(k\\) days ahead (where \\(k\\) = number of days by which predictor is lagged)!"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cross-validation-cv-3",
    "href": "slides/day2-morning.html#time-series-cross-validation-cv-3",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series cross-validation (CV)",
    "text": "Time-series cross-validation (CV)\nLinear regression of COVID deaths on lagged cases\n\n\n\n                      MAE     MASE\ntraining       0.05985631 351.4848\nsplit-sample   0.10005007 659.8971\ntime series CV 0.08973951 732.5769"
  },
  {
    "objectID": "slides/day2-morning.html#regression-on-a-trailing-window",
    "href": "slides/day2-morning.html#regression-on-a-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Regression on a trailing window",
    "text": "Regression on a trailing window\n\nSo far, to get \\(h\\)-step ahead predictions for time \\(t+h\\), we have fitted the model on all data available up to time \\(t\\). We can instead use a trailing window, i.e. fit the model on a window of data of length \\(w\\), starting at time \\(t-w\\) and ending at \\(t\\).\nAdvantage: if the predictors-outcome relation changes over time, training the forecaster on a window of recent data can better capture the recent relation which might be more relevant to predict the outcome in the near future.\nWindow length \\(w\\) considerations:\n\nif \\(w\\) is too big, the model can’t adapt to the recent predictors-outcome relation\nif \\(w\\) is too small, the fitted model may be too volatile (trained on too little data)"
  },
  {
    "objectID": "slides/day2-morning.html#trailing-window",
    "href": "slides/day2-morning.html#trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Trailing window",
    "text": "Trailing window\nLinear regression of COVID deaths on lagged cases\n\n# Getting the predictions through CV with trailing window\nw &lt;- 200                                    #trailing window size\nh &lt;- k                                      #number of days ahead for which prediction is wanted\npred_trailing &lt;- rep(NA, length = n-h-t0+1) #initialize vector of predictions\n\nfor (t in t0:(n-h)) {\n  # fit to a trailing window of size w and make 1-step ahead prediction\n  reg_trailing = lm(deaths ~ lagged_cases, data = ca, \n                    subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n  pred_trailing[t-t0+1] = predict(reg_trailing, newdata = data.frame(ca[t+h, ]))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-all-past-vs-trailing-window",
    "href": "slides/day2-morning.html#time-series-cv-all-past-vs-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series CV: all past vs trailing window",
    "text": "Time-series CV: all past vs trailing window\nLinear regression of COVID deaths on lagged cases\n\n\n\n                                 MAE     MASE\ntraining                  0.05985631 351.4848\nsplit-sample              0.10005007 659.8971\ntime series CV            0.08973951 732.5769\ntime series CV + trailing 0.10270064 838.3834"
  },
  {
    "objectID": "slides/day2-morning.html#autoregressive-ar-model",
    "href": "slides/day2-morning.html#autoregressive-ar-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Autoregressive (AR) model",
    "text": "Autoregressive (AR) model\n\nIdea: predicting the outcome via a linear combination of (some of) its lags\n\n\\[\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-1} + \\dots + \\hat\\phi_p y_{t-p}\\]\n\nNotice: we don’t need to include all contiguous lags1.\nFor example, we could fit\n\n\\[\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} + \\hat\\phi_2 y_{t-14}\\]\nHere we depart from traditional AR models, which do include all contiguous lags."
  },
  {
    "objectID": "slides/day2-morning.html#ar-model-for-covid-deaths",
    "href": "slides/day2-morning.html#ar-model-for-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "AR model for COVID deaths",
    "text": "AR model for COVID deaths\n\nLet’s disregard cases, and only use COVID deaths to predict deaths 28 days ahead.\nWe will fit the model:\n\n\\[\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t}\\]\n\nWould this be a good forecaster?"
  },
  {
    "objectID": "slides/day2-morning.html#preparing-the-data-and-checking-correlation",
    "href": "slides/day2-morning.html#preparing-the-data-and-checking-correlation",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Preparing the data and checking correlation",
    "text": "Preparing the data and checking correlation\n\n# Add column with deaths lagged by 28\nca$lagged_deaths &lt;- dplyr::lag(ca$deaths, n = k)\n\n# Split into train and test (before/after t0_date)\ntrain &lt;- ca %&gt;% filter(time_value &lt;= t0_date)\ntest &lt;- ca %&gt;% filter(time_value &gt; t0_date)"
  },
  {
    "objectID": "slides/day2-morning.html#fitting-the-ar-model-for-covid-deaths",
    "href": "slides/day2-morning.html#fitting-the-ar-model-for-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fitting the AR model for COVID deaths",
    "text": "Fitting the AR model for COVID deaths\n\nar_fit = lm(deaths ~ lagged_deaths, data = train)\ncoef(ar_fit)\n\n  (Intercept) lagged_deaths \n    0.1023887     0.9523213 \n\n\n\n\n\nNote\n\n\nThe intercept is close to 0, and the coefficient is close to 1. This means that we are naively predicting the number of deaths in 28 days with (approximately) the number of deaths observed today."
  },
  {
    "objectID": "slides/day2-morning.html#predictions-on-training-and-test-sets-ar-model",
    "href": "slides/day2-morning.html#predictions-on-training-and-test-sets-ar-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions on training and test sets (AR model)",
    "text": "Predictions on training and test sets (AR model)\n\n\n\n                   MAE      MASE\ntraining     0.1469711  902.8794\nsplit-sample 0.1899489 1252.8397"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-all-past-and-trailing-ar-model",
    "href": "slides/day2-morning.html#time-series-cv-all-past-and-trailing-ar-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-Series CV: all past and trailing (AR model)",
    "text": "Time-Series CV: all past and trailing (AR model)\n\n\n\n                                MAE      MASE\ntraining                  0.1469711  902.8794\nsplit-sample              0.1899489 1252.8397\ntime series CV            0.1242872 1014.6024\ntime series CV + trailing 0.1646065 1343.7439"
  },
  {
    "objectID": "slides/day2-morning.html#autoregressive-exogenous-input-arx-model",
    "href": "slides/day2-morning.html#autoregressive-exogenous-input-arx-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Autoregressive exogenous input (ARX) model",
    "text": "Autoregressive exogenous input (ARX) model\n\nIdea: predicting the outcome via a linear combination of its lags and a set of exogenous (i.e. external) input variables\nExample:\n\n\\[\\hat y_{t+h} = \\hat\\phi + \\sum_{i=0}^p \\hat\\phi_i y_{t-i} + \\sum_{j=0}^q \\hat\\beta_j x_{t-j}\\]\n\nWe can construct more complex ARX models with multiple lags of several exogenous variables"
  },
  {
    "objectID": "slides/day2-morning.html#arx-model-for-covid-deaths",
    "href": "slides/day2-morning.html#arx-model-for-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX model for COVID deaths",
    "text": "ARX model for COVID deaths\n\nTo improve our predictions for COVID deaths 28 days ahead, we could merge the two models considered so far.\nThis leads us to the ARX model\n\n\\[\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\beta_0 x_{t}\\]\n\nWe can fit it on the training set by running\n\n\narx_fit = lm(deaths ~ lagged_deaths + lagged_cases, data = train)\ncoef(arx_fit)\n\n  (Intercept) lagged_deaths  lagged_cases \n   0.08133189    0.14010549    0.01030239"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-on-training-and-test-sets-arx-model",
    "href": "slides/day2-morning.html#predictions-on-training-and-test-sets-arx-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions on training and test sets (ARX model)",
    "text": "Predictions on training and test sets (ARX model)\n\n\n\n                    MAE     MASE\ntraining     0.06268428 368.0910\nsplit-sample 0.08227714 542.6727"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-all-past-and-trailing-arx-model",
    "href": "slides/day2-morning.html#time-series-cv-all-past-and-trailing-arx-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-Series CV: all past and trailing (ARX model)",
    "text": "Time-Series CV: all past and trailing (ARX model)\n\n\n\n                                 MAE     MASE\ntraining                  0.06268428 368.0910\nsplit-sample              0.08227714 542.6727\ntime series CV            0.06739289 550.1531\ntime series CV + trailing 0.04757330 388.3585"
  },
  {
    "objectID": "slides/day2-morning.html#changing-h",
    "href": "slides/day2-morning.html#changing-h",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Changing \\(h\\)",
    "text": "Changing \\(h\\)\n\nSo far we focused on COVID deaths prediction 28 days ahead.\nThe ARX model we fitted had much better performance than the AR model.\nWe will next compare the AR model\n\n\\[\\hat y_{t+h} = \\hat\\phi + \\hat\\phi_0 y_t\\]\nto the ARX model\n\\[\\hat y_{t+h} = \\hat\\phi + \\hat\\phi_0 y_t + \\hat\\beta_0 x_t\\]\nfor horizons \\(h = 7, 14, 21, 28\\) (using a trailing window of size 200)."
  },
  {
    "objectID": "slides/day2-morning.html#predicting-7-days-ahead",
    "href": "slides/day2-morning.html#predicting-7-days-ahead",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predicting 7 days ahead",
    "text": "Predicting 7 days ahead\n\n\n\n           MAE     MASE\nAR  0.12989192 934.5696\nARX 0.09713393 698.8765"
  },
  {
    "objectID": "slides/day2-morning.html#predicting-14-days-ahead",
    "href": "slides/day2-morning.html#predicting-14-days-ahead",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predicting 14 days ahead",
    "text": "Predicting 14 days ahead\n\n\n\n           MAE     MASE\nAR  0.13037989 956.0440\nARX 0.06348795 465.5417"
  },
  {
    "objectID": "slides/day2-morning.html#predicting-21-days-ahead",
    "href": "slides/day2-morning.html#predicting-21-days-ahead",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predicting 21 days ahead",
    "text": "Predicting 21 days ahead\n\n\n\n          MAE      MASE\nAR  0.1702452 1312.0747\nARX 0.0488983  376.8577"
  },
  {
    "objectID": "slides/day2-morning.html#predicting-28-days-ahead",
    "href": "slides/day2-morning.html#predicting-28-days-ahead",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predicting 28 days ahead",
    "text": "Predicting 28 days ahead\n\n\n\n          MAE      MASE\nAR  0.1646065 1343.7439\nARX 0.0475733  388.3585"
  },
  {
    "objectID": "slides/day2-morning.html#observations",
    "href": "slides/day2-morning.html#observations",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Observations",
    "text": "Observations\n\nFor each horizon \\(h\\), the ARX model has always smaller error than the AR model.\nThe benefit of including cases as a predictor increases with \\(h\\).\nThe error of the AR model increases with \\(h\\), while the error of the ARX model decreases with \\(h\\)."
  },
  {
    "objectID": "slides/day2-morning.html#too-many-predictors",
    "href": "slides/day2-morning.html#too-many-predictors",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Too many predictors",
    "text": "Too many predictors\n\nWhat if we try to incorporate past information extensively by fitting a model with a very large number of predictors?\n\nThe estimated coefficients will be chosen to mimic the observed data very closely on the training set, leading to small training error\nThe predictive performance on the test set might be very poor, producing large split-sample and CV error\n\n\n\n\n\nIssue\n\n\nOverfitting!"
  },
  {
    "objectID": "slides/day2-morning.html#arx-model-for-covid-deaths-with-many-predictors",
    "href": "slides/day2-morning.html#arx-model-for-covid-deaths-with-many-predictors",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX model for COVID deaths with many predictors",
    "text": "ARX model for COVID deaths with many predictors\n\nWhen predicting COVID deaths 28 days ahead, we can try to use more past information by fitting a model that includes the past two months of COVID deaths and cases as predictors\n\n\\[\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-1} + \\dots +\n\\hat\\phi_{59} y_{t-59} +\n\\hat\\beta_0 x_{t} + \\dots + \\hat\\beta_{t-59} x_{t-59}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#preparing-the-data-1",
    "href": "slides/day2-morning.html#preparing-the-data-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Preparing the data",
    "text": "Preparing the data\n\ny &lt;- ca$deaths  #outcome\nlags &lt;- 28:87   #lags used for predictors (deaths and cases)\n\n# Build predictor matrix with 60 columns\nX &lt;- data.frame(matrix(NA, nrow = length(y), ncol = 2*length(lags)))\ncolnames(X) &lt;- paste('X', 1:ncol(X), sep = '')\n\nfor (j in 1:length(lags)) {\n  # first 60 columns contain deaths lagged by 28, 29, ..., 87\n  X[, j] = dplyr::lag(ca$deaths, lags[j])\n  # last 60 columns contain cases lagged by 28, 29, ..., 87\n  X[, length(lags) + j] = dplyr::lag(ca$cases, lags[j])\n}"
  },
  {
    "objectID": "slides/day2-morning.html#fitting-the-arx-model",
    "href": "slides/day2-morning.html#fitting-the-arx-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fitting the ARX model",
    "text": "Fitting the ARX model\n\n# Train/test split\ny_train &lt;- y[1:t0]\nX_train &lt;- X[1:t0, ]\ny_test &lt;- y[(t0+1):length(y)]\nX_test &lt;- X[(t0+1):length(y), ]\n\n# Fitting the ARX model\nreg = lm(y_train ~ ., data = X_train)\ncoef(reg)\n\n  (Intercept)            X1            X2            X3            X4 \n 0.2758283711  0.2457314327  0.2225988768 -0.4559613879 -0.4731427507 \n           X5            X6            X7            X8            X9 \n 0.4570192882 -0.0829030158  0.0087610368 -0.1277561418 -0.0930270533 \n          X10           X11           X12           X13           X14 \n 0.2880726732 -0.8396082213  0.5525681932 -0.6656058745 -0.1372663639 \n          X15           X16           X17           X18           X19 \n 0.2441111445 -0.5549887598 -0.1984910609 -0.4381802967  0.9748005886 \n          X20           X21           X22           X23           X24 \n-0.2252872009 -0.3603010052 -0.1484425645 -0.2629114744  0.6481906782 \n          X25           X26           X27           X28           X29 \n-0.4386397760  0.2287881141 -0.4141878941  0.1538387231  0.0016914281 \n          X30           X31           X32           X33           X34 \n-0.1675549452  0.1862035471 -0.7604163647  0.7661301939 -0.3567175136 \n          X35           X36           X37           X38           X39 \n-0.6461899753  0.2820547532  0.3658805915 -0.1036095025  0.3168098103 \n          X40           X41           X42           X43           X44 \n 0.4270049404 -0.3861653324  0.1887767107  0.2446997478  0.0406226039 \n          X45           X46           X47           X48           X49 \n 0.3290951846 -0.4657697117  0.1271299593  0.3931515677  0.2836116580 \n          X50           X51           X52           X53           X54 \n-0.3674019667 -0.4491442210  0.4524243063 -0.3428030503  0.4292019510 \n          X55           X56           X57           X58           X59 \n 0.4096633980 -0.5462527325  0.4501163940 -0.3929646040 -0.2112561496 \n          X60           X61           X62           X63           X64 \n-0.3326657892  0.0175419874 -0.0077855053 -0.0024976868  0.0014263572 \n          X65           X66           X67           X68           X69 \n-0.0048785301  0.0013524131 -0.0022148536  0.0065944994  0.0023437318 \n          X70           X71           X72           X73           X74 \n-0.0040292424  0.0136591034 -0.0086165459 -0.0059687437 -0.0069756592 \n          X75           X76           X77           X78           X79 \n 0.0145125287 -0.0021987656 -0.0018740932  0.0043662687  0.0019855230 \n          X80           X81           X82           X83           X84 \n 0.0005040760 -0.0021147396  0.0030569084 -0.0043404977 -0.0081888972 \n          X85           X86           X87           X88           X89 \n 0.0124142487 -0.0019007422 -0.0091802229  0.0090002190  0.0096226370 \n          X90           X91           X92           X93           X94 \n-0.0033216356 -0.0040088540  0.0006876339 -0.0152565542 -0.0112099615 \n          X95           X96           X97           X98           X99 \n 0.0289012311  0.0084111577 -0.0134474728  0.0083765726 -0.0089290862 \n         X100          X101          X102          X103          X104 \n 0.0069254713 -0.0178761659  0.0191826013  0.0011505708  0.0071752544 \n         X105          X106          X107          X108          X109 \n 0.0127445467 -0.0133315137 -0.0022960536 -0.0031951107  0.0102816246 \n         X110          X111          X112          X113          X114 \n-0.0028098154  0.0092476436 -0.0120237253 -0.0079725070  0.0194764427 \n         X115          X116          X117          X118          X119 \n-0.0170893902  0.0232396558 -0.0175601245  0.0002431107  0.0129597132 \n         X120 \n-0.0196106522"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-on-training-and-test-set",
    "href": "slides/day2-morning.html#predictions-on-training-and-test-set",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions on training and test set",
    "text": "Predictions on training and test set\n\npred_train &lt;- predict(reg)                    #get training predictions\npred_test &lt;- predict(reg, newdata = X_test)   #get test predictions\n\n\n\n\n                    MAE      MASE\ntraining     0.02888549  146.9367\nsplit-sample 0.35664868 2352.3364"
  },
  {
    "objectID": "slides/day2-morning.html#regularization",
    "href": "slides/day2-morning.html#regularization",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Regularization",
    "text": "Regularization\n\nIf we want to consider a large number of predictors, how can we avoid overfitting?\nIdea: introduce a regularization parameter \\(\\lambda\\) that shrinks or sets some of the estimated coefficients to zero, i.e. some predictors are estimated to have limited or no predictive power\nMost common regularization methods\n\nRidge: shrinks coefficients to zero\nLasso: sets some coefficients to zero"
  },
  {
    "objectID": "slides/day2-morning.html#choosing-lambda",
    "href": "slides/day2-morning.html#choosing-lambda",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Choosing \\(\\lambda\\)",
    "text": "Choosing \\(\\lambda\\)\n\nThe regularization parameter \\(\\lambda\\) can be selected by cross-validation:\n\nSelect a sequence of \\(\\lambda\\)’s\nFit and predict for each such \\(\\lambda\\)\nSelect the \\(\\lambda\\) that leads to smaller error\n\nThe R library glmnet implements ridge and lasso regression, and can perform step 1. automatically."
  },
  {
    "objectID": "slides/day2-morning.html#fit-arx-ridgelasso-for-covid-deaths",
    "href": "slides/day2-morning.html#fit-arx-ridgelasso-for-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fit ARX + ridge/lasso for COVID deaths",
    "text": "Fit ARX + ridge/lasso for COVID deaths\n\nlibrary(glmnet) # Implements ridge and lasso\n\n# We'll need to omit NA values explicitly, as otherwise glmnet will complain\nna_obs &lt;- 1:max(lags)\nX_train &lt;- X_train[-na_obs, ]\ny_train &lt;- y_train[-na_obs]\n\n# Ridge regression: set alpha = 0, lambda sequence will be chosen automatically\nridge &lt;- glmnet(X_train, y_train, alpha = 0)\nbeta_ridge &lt;- coef(ridge)       # matrix of estimated coefficients \nlambda_ridge &lt;- ridge$lambda    # sequence of lambdas used to fit ridge \n\n# Lasso regression: set alpha = 1, lambda sequence will be chosen automatically\nlasso &lt;- glmnet(X_train, y_train, alpha = 1)\nbeta_lasso &lt;- coef(lasso)       # matrix of estimated coefficients \nlambda_lasso &lt;- lasso$lambda    # sequence of lambdas used to fit lasso \n\ndim(beta_lasso)      # One row per coefficient, one column per lambda value\n\n[1] 121 100"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-on-test-set-and-selection-of-lambda",
    "href": "slides/day2-morning.html#predictions-on-test-set-and-selection-of-lambda",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions on test set and selection of \\(\\lambda\\)",
    "text": "Predictions on test set and selection of \\(\\lambda\\)\n\n# Predict values for second half of the time series\nyhat_ridge &lt;- predict(ridge, newx = as.matrix(X_test))\nyhat_lasso &lt;- predict(lasso, newx = as.matrix(X_test))\n\n# Compute MAE \nmae_ridge &lt;- colMeans(abs(yhat_ridge - y_test))\nmae_lasso &lt;- colMeans(abs(yhat_lasso - y_test))\n\n# Select index of lambda vector which gives lowest MAE\nmin_ridge &lt;- which.min(mae_ridge)\nmin_lasso &lt;- which.min(mae_lasso)\npaste('Best MAE ridge:', round(min(mae_ridge), 3),\n      '; Best MAE lasso:', round(min(mae_lasso), 3))\n\n[1] \"Best MAE ridge: 0.196 ; Best MAE lasso: 0.092\"\n\n# Get predictions for train and test sets\npred_train_ridge &lt;- predict(ridge, newx = as.matrix(X_train))[, min_ridge] \npred_test_ridge &lt;- yhat_ridge[, min_ridge]\npred_train_lasso &lt;- predict(lasso, newx = as.matrix(X_train))[, min_lasso] \npred_test_lasso &lt;- yhat_lasso[, min_lasso]"
  },
  {
    "objectID": "slides/day2-morning.html#estimated-coefficients-shrinkage-vs-sparsity",
    "href": "slides/day2-morning.html#estimated-coefficients-shrinkage-vs-sparsity",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Estimated coefficients: shrinkage vs sparsity",
    "text": "Estimated coefficients: shrinkage vs sparsity\n\n\n\n\n                    ridge         lasso\n(Intercept)  4.112256e-01  0.1027530670\nX1           5.497463e-03  0.0000000000\nX2           5.443749e-03  0.0000000000\nX3           5.385490e-03  0.0000000000\nX4           5.313227e-03  0.0000000000\nX5           5.258979e-03  0.0000000000\nX6           5.188803e-03  0.0000000000\nX7           5.139054e-03  0.0000000000\nX8           5.076501e-03  0.0000000000\nX9           4.981253e-03  0.0000000000\nX10          4.886178e-03  0.0000000000\nX11          4.809706e-03  0.0000000000\nX12          4.729025e-03  0.0000000000\nX13          4.667905e-03  0.0000000000\nX14          4.583550e-03  0.0000000000\nX15          4.499529e-03  0.0000000000\nX16          4.448547e-03  0.0000000000\nX17          4.397032e-03  0.0000000000\nX18          4.368272e-03  0.0000000000\nX19          4.316661e-03  0.0000000000\nX20          4.249886e-03  0.0000000000\nX21          4.183664e-03  0.0000000000\nX22          4.127680e-03  0.0000000000\nX23          4.050602e-03  0.0000000000\nX24          3.988909e-03  0.0000000000\nX25          3.822127e-03  0.0000000000\nX26          3.584918e-03  0.0000000000\nX27          3.283302e-03  0.0000000000\nX28          2.888911e-03  0.0000000000\nX29          2.415738e-03  0.0000000000\nX30          1.824392e-03  0.0000000000\nX31          1.152044e-03  0.0000000000\nX32          3.881764e-04  0.0000000000\nX33         -4.546563e-04  0.0000000000\nX34         -1.293969e-03  0.0000000000\nX35         -2.117525e-03  0.0000000000\nX36         -2.801391e-03  0.0000000000\nX37         -3.394630e-03  0.0000000000\nX38         -4.006729e-03  0.0000000000\nX39         -4.662078e-03  0.0000000000\nX40         -5.354854e-03  0.0000000000\nX41         -6.265590e-03  0.0000000000\nX42         -7.230297e-03  0.0000000000\nX43         -8.508468e-03  0.0000000000\nX44         -9.918750e-03  0.0000000000\nX45         -1.149602e-02  0.0000000000\nX46         -1.319458e-02  0.0000000000\nX47         -1.481247e-02  0.0000000000\nX48         -1.630315e-02  0.0000000000\nX49         -1.753316e-02  0.0000000000\nX50         -1.813929e-02  0.0000000000\nX51         -1.857362e-02  0.0000000000\nX52         -1.893093e-02  0.0000000000\nX53         -1.933053e-02  0.0000000000\nX54         -1.957672e-02  0.0000000000\nX55         -1.975165e-02  0.0000000000\nX56         -2.012127e-02  0.0000000000\nX57         -2.030953e-02  0.0000000000\nX58         -2.037081e-02  0.0000000000\nX59         -2.021378e-02  0.0000000000\nX60         -1.976317e-02 -0.0345707637\nX61          8.242683e-05  0.0095304559\nX62          8.132113e-05  0.0000000000\nX63          8.018020e-05  0.0000000000\nX64          7.901220e-05  0.0000000000\nX65          7.779561e-05  0.0000000000\nX66          7.664052e-05  0.0000000000\nX67          7.551905e-05  0.0000000000\nX68          7.444242e-05  0.0000000000\nX69          7.340449e-05  0.0000000000\nX70          7.236918e-05  0.0000000000\nX71          7.136972e-05  0.0000000000\nX72          7.037117e-05  0.0000000000\nX73          6.943229e-05  0.0000000000\nX74          6.860455e-05  0.0000000000\nX75          6.787924e-05  0.0000000000\nX76          6.722652e-05  0.0015360023\nX77          6.661688e-05  0.0000000000\nX78          6.601493e-05  0.0000000000\nX79          6.545565e-05  0.0000000000\nX80          6.496923e-05  0.0000000000\nX81          6.451692e-05  0.0000000000\nX82          6.407003e-05  0.0000000000\nX83          6.345530e-05  0.0000000000\nX84          6.276881e-05  0.0000000000\nX85          6.192521e-05  0.0000000000\nX86          6.101792e-05  0.0000000000\nX87          6.003796e-05  0.0000000000\nX88          5.900856e-05  0.0000000000\nX89          5.766256e-05  0.0000000000\nX90          5.640154e-05  0.0000000000\nX91          5.521221e-05  0.0000000000\nX92          5.410753e-05  0.0000000000\nX93          5.310748e-05  0.0000000000\nX94          5.191454e-05  0.0000000000\nX95          5.078166e-05  0.0000000000\nX96          4.995013e-05  0.0000000000\nX97          4.934901e-05  0.0000000000\nX98          4.892197e-05  0.0000000000\nX99          4.863106e-05  0.0000000000\nX100         4.829392e-05  0.0000000000\nX101         4.816553e-05  0.0000000000\nX102         4.810093e-05  0.0000000000\nX103         4.841180e-05  0.0000000000\nX104         4.912355e-05  0.0005895771\nX105         4.985320e-05  0.0000000000\nX106         5.066950e-05  0.0000000000\nX107         5.150530e-05  0.0000000000\nX108         5.258211e-05  0.0000000000\nX109         5.387059e-05  0.0000000000\nX110         5.451414e-05  0.0000000000\nX111         5.443739e-05  0.0000000000\nX112         5.410652e-05  0.0000000000\nX113         5.355103e-05  0.0000000000\nX114         5.275985e-05  0.0000000000\nX115         5.111364e-05  0.0000000000\nX116         4.828218e-05  0.0000000000\nX117         4.455698e-05  0.0000000000\nX118         4.029228e-05  0.0000000000\nX119         3.539927e-05  0.0000000000\nX120         3.020232e-05  0.0000000000"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-arx-ridgelasso-train-and-test-set",
    "href": "slides/day2-morning.html#predictions-arx-ridgelasso-train-and-test-set",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions: ARX + ridge/lasso (train and test set)",
    "text": "Predictions: ARX + ridge/lasso (train and test set)\n\n\n\n                          MAE      MASE\nridge training     0.25271764 1285.5412\nridge split-sample 0.19616116 1293.8139\nlasso training     0.06984086  355.2712\nlasso split-sample 0.09163079  604.3663"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-for-arx-ridgelasso-trailing",
    "href": "slides/day2-morning.html#time-series-cv-for-arx-ridgelasso-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time-series CV for ARX + ridge/lasso (trailing)",
    "text": "Time-series CV for ARX + ridge/lasso (trailing)\n\nh &lt;- 28  # number of days ahead \nw &lt;- 200 # window length\n\n# Initialize matrices for predictions (one column per lambda value)\nyhat_ridge &lt;- matrix(NA, ncol = length(lambda_ridge), nrow = n-h-t0+1) \nyhat_lasso &lt;- matrix(NA, ncol = length(lambda_lasso), nrow = n-h-t0+1) \n\nfor (t in t0:(n-h)) {\n  # Indices of data within window\n  inds = t-w &lt; 1:n & 1:n &lt;= t\n  # Fit ARX + ridge/lasso\n  ridge_trail = glmnet(X[inds, ], y[inds], alpha = 0, lambda = lambda_ridge)\n  lasso_trail = glmnet(X[inds, ], y[inds], alpha = 1, lambda = lambda_lasso)\n  # Predict\n  yhat_ridge[t-t0+1, ] = predict(ridge_trail, newx = as.matrix(X[(t+h), ]))\n  yhat_lasso[t-t0+1, ] = predict(lasso_trail, newx = as.matrix(X[(t+h), ]))\n}\n\n# MAE values for each lambda\nmae_ridge &lt;- colMeans(abs(yhat_ridge - y_test[-c(1:(k-1))]))\nmae_lasso &lt;- colMeans(abs(yhat_lasso - y_test[-c(1:(k-1))]))\n\n# Select lambda that minimizes MAE and save corresponding predictions\nmin_ridge &lt;- which.min(mae_ridge)\nmin_lasso &lt;- which.min(mae_lasso)\npred_cv_ridge &lt;- yhat_ridge[, min_ridge]\npred_cv_lasso &lt;- yhat_lasso[, min_lasso]\n\npaste('Best MAE ridge:', round(min(mae_ridge), 3))\n\n[1] \"Best MAE ridge: 0.12\"\n\npaste('Best MAE lasso:', round(min(mae_lasso), 3))\n\n[1] \"Best MAE lasso: 0.062\""
  },
  {
    "objectID": "slides/day2-morning.html#predictions-time-series-cv-for-arx-ridgelasso-trailing",
    "href": "slides/day2-morning.html#predictions-time-series-cv-for-arx-ridgelasso-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions: time-series CV for ARX + ridge/lasso (trailing)",
    "text": "Predictions: time-series CV for ARX + ridge/lasso (trailing)\n\n\n\n                           MAE     MASE\nridge CV + trailing 0.11964733 976.7255\nlasso CV + trailing 0.06243937 509.7157"
  },
  {
    "objectID": "slides/day2-morning.html#point-predictions-vs-intervals",
    "href": "slides/day2-morning.html#point-predictions-vs-intervals",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Point predictions vs intervals",
    "text": "Point predictions vs intervals\n\nSo far, we have only considered point predictions, i.e.  we have fitted models to provide our best guess on the outcome at time \\(t+h\\).\n\n\n\n\nImportant\n\n\nWhat if we want to provide a measure of uncertainty around the point prediction or a likely range of values for the outcome at time \\(t+h\\)?\n\n\n\n\nFor each target time \\(t+h\\), we can construct prediction intervals, i.e. provide ranges of values that are expected to cover the true outcome value a fixed fraction of times."
  },
  {
    "objectID": "slides/day2-morning.html#prediction-intervals-for-lm-fits",
    "href": "slides/day2-morning.html#prediction-intervals-for-lm-fits",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Prediction intervals for lm fits",
    "text": "Prediction intervals for lm fits\n\nTo get prediction intervals for the models we previously fitted, we only need to tweak our call to predict by adding as an input:\ninterval = \"prediction\", level = p\nwhere \\(p \\in (0, 1)\\) is the desired coverage.\nThe output from predict will then be a matrix with\n\nfirst column a point estimate\nsecond column the lower limit of the interval\nthird column the upper limit of the interval"
  },
  {
    "objectID": "slides/day2-morning.html#prediction-intervals-for-arx-test",
    "href": "slides/day2-morning.html#prediction-intervals-for-arx-test",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Prediction intervals for ARX (test)",
    "text": "Prediction intervals for ARX (test)\n\n\npred_test_ci &lt;- predict(arx_fit, \n                        newdata = test, \n                        interval = \"prediction\", \n                        level = 0.95)\n\nhead(pred_test_ci)\n\n\n        fit       lwr       upr\n1 0.7093207 0.5286159 0.8900255\n2 0.6908382 0.5104118 0.8712647\n3 0.6768019 0.4955346 0.8580692\n4 0.6527938 0.4714708 0.8341169\n5 0.6276180 0.4468436 0.8083924\n6 0.6062234 0.4255984 0.7868483"
  },
  {
    "objectID": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window",
    "href": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Prediction intervals for ARX (CV, trailing window)",
    "text": "Prediction intervals for ARX (CV, trailing window)"
  },
  {
    "objectID": "slides/day2-morning.html#quantile-regression",
    "href": "slides/day2-morning.html#quantile-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Quantile regression",
    "text": "Quantile regression\n\nSo far we only considered different ways to apply linear regression.\nQuantile regression is a different estimation method, and it directly targets conditional quantiles of the outcome over time.\n\n\n\n\n\n\n\nDefinition\n\n\nConditional quantile = value below which a given percentage (e.g. 25%, 50%, 75%) of observations fall, given specific values of the predictor variables.\n\n\n\n\nAdvantage: it provides a more complete picture of the outcome distribution."
  },
  {
    "objectID": "slides/day2-morning.html#arx-model-for-covid-deaths-via-quantile-regression",
    "href": "slides/day2-morning.html#arx-model-for-covid-deaths-via-quantile-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX model for COVID deaths via quantile regression",
    "text": "ARX model for COVID deaths via quantile regression\n\n#install.packages(\"quantreg\")\nlibrary(quantreg)  #library to perform quantile regression\n\n# Set quantiles of interest: we will focus on 2.5%, 50% (i.e. median), and 97.5% quantiles\nquantiles &lt;- c(0.025, 0.5, 0.975)  \n\n# Fit quantile regression on training set\nq_reg &lt;- rq(deaths ~ lagged_deaths + lagged_cases, data = train, tau = quantiles)\n\n# Estimated coefficients\ncoef(q_reg)\n\n               tau= 0.025  tau= 0.500 tau= 0.975\n(Intercept)   0.021903320  0.10599167 0.12247490\nlagged_deaths 0.037881788 -0.08804903 0.26866227\nlagged_cases  0.009539598  0.01167695 0.01301036"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-via-quantile-regression-cv-trailing",
    "href": "slides/day2-morning.html#predictions-via-quantile-regression-cv-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions via quantile regression (CV, trailing)",
    "text": "Predictions via quantile regression (CV, trailing)\n\n# Initialize matrix to store predictions \n# 3 columns: lower limit, median, and upper limit\npred_trailing &lt;- matrix(NA, nrow = n-h-t0+1, ncol = 3)\ncolnames(pred_trailing) &lt;- c('lower', 'median', 'upper')\n\nfor (t in t0:(n-h)) {\n  # Fit quantile regression\n  rq_trailing = rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles,\n                   data = ca, subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n  # Predict\n  pred_trailing[t-t0+1, ] = predict(rq_trailing, newdata = data.frame(ca[t+h, ]))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-via-quantile-regression-cv-trailing-1",
    "href": "slides/day2-morning.html#predictions-via-quantile-regression-cv-trailing-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions via quantile regression (CV, trailing)",
    "text": "Predictions via quantile regression (CV, trailing)"
  },
  {
    "objectID": "slides/day2-morning.html#actual-coverage",
    "href": "slides/day2-morning.html#actual-coverage",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Actual Coverage",
    "text": "Actual Coverage\n\nWe would expect the ARX model fitted via lm and via rq to cover the truth about 95% of the times. Is this actually true in practice?\nThe actual coverage of each predictive interval is\n\n\n\n         lm.trailing rq.trailing\nCoverage   0.9749104   0.8566308\n\n\n\nNotice that the coverage of lm is close to 95%, while rq has lower coverage."
  },
  {
    "objectID": "slides/day2-morning.html#evaluation-1",
    "href": "slides/day2-morning.html#evaluation-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Evaluation",
    "text": "Evaluation\n\nPrediction intervals are “good” if they\n\ncover the truth most of the time\nare not too wide\n\nError metric that captures both desiderata: Weighted Interval Score (WIS)\n\\(F\\) = forecast composed of predicted quantiles \\(q_{\\tau}\\) for the set of quantile levels \\(\\tau\\). The WIS for target variable \\(Y\\) is represented as (McDonald et al., 2021):\n\n\\[WIS(F, Y) = 2\\sum_{\\tau} \\phi_{\\tau} (Y - q_{\\tau})\\]\nwhere \\(\\phi_{\\tau}(x) = \\tau |x|\\) for \\(x \\geq 0\\) and \\(\\phi_{\\tau}(x) = (1-\\tau) |x|\\) for \\(x &lt; 0\\)."
  },
  {
    "objectID": "slides/day2-morning.html#computing-the-wis",
    "href": "slides/day2-morning.html#computing-the-wis",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Computing the WIS",
    "text": "Computing the WIS\n\nWIS &lt;- function(truth, estimates, quantiles) {\n  2 * sum(pmax(\n    quantiles * (truth - estimates),\n    (1 - quantiles) * (estimates - truth),\n    na.rm = TRUE\n  ))\n}\n\n\n\n\nNote\n\n\nWIS tends to prioritize sharpness (how wide the interval is) relative to coverage (if the interval contains the truth)."
  },
  {
    "objectID": "slides/day2-morning.html#wis-for-arx-fitted-via-lm-and-rq",
    "href": "slides/day2-morning.html#wis-for-arx-fitted-via-lm-and-rq",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "WIS for ARX fitted via lm and rq",
    "text": "WIS for ARX fitted via lm and rq\n\nThe lowest mean WIS is attained by quantile regression.\nNotice: this method has coverage below 95% but is still preferred under WIS because its intervals are narrower than for linear regression.\n\n\n\n  Mean WIS lm Mean WIS rq\n1  0.06534014  0.05733309"
  },
  {
    "objectID": "slides/day2-morning.html#versioned-data",
    "href": "slides/day2-morning.html#versioned-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Versioned data",
    "text": "Versioned data\n\nIn our forecasting examples, we have assumed the data are never revised (or have simply ignored revisions, and used data as_of today)\n\n\n\n\nImportant\n\n\nHow can we train forecasters when dealing with versioned data?\n\n\n\n\ndata_archive\n\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-04-01 / 2021-12-31\nℹ First/last version with update: 2020-04-02 / 2022-01-01\nℹ Versions end: 2022-01-01\nℹ A preview of the table (93566 rows x 5 columns):\n       geo_value time_value    version case_rate death_rate\n    1:        ak 2020-04-01 2020-04-02  1.797489          0\n    2:        ak 2020-04-01 2020-05-07  1.777061          0\n    3:        ak 2020-04-01 2020-10-28  1.106147          0\n    4:        ak 2020-04-01 2020-10-29  1.797489          0\n    5:        ak 2020-04-01 2020-10-30  1.797489          0\n   ---                                                     \n93562:        wy 2021-12-27 2021-12-28 65.598769          0\n93563:        wy 2021-12-28 2021-12-29 50.315286          0\n93564:        wy 2021-12-29 2021-12-30 55.810471          0\n93565:        wy 2021-12-30 2021-12-31 68.002912          0\n93566:        wy 2021-12-31 2022-01-01  0.000000          0"
  },
  {
    "objectID": "slides/day2-morning.html#version-aware-forecasting",
    "href": "slides/day2-morning.html#version-aware-forecasting",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version-aware forecasting",
    "text": "Version-aware forecasting\n\n# initialize dataframe for predictions\n# 5 columns: forecast date, target date, 2.5%, 50%, and 97.5% quantiles\npred_trailing &lt;- data.frame(matrix(NA, ncol = 5, nrow = 0))\ncolnames(pred_trailing) &lt;- c(\"forecast_date\", \"target_date\", 'tau..0.025', 'tau..0.500', 'tau..0.975')\n\nw &lt;- 200         #trailing window size\nh &lt;- 28          #number of days ahead\n\n# dates when predictions are made (set to be 1 month apart)\nfc_time_values &lt;- seq(from = t0_date, to = as.Date(\"2021-12-31\"), by = \"1 month\")\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data &lt;- epix_as_of(ca_archive, max_version = as.Date(fc_date))\n  # create lagged predictors\n  data$lagged_deaths &lt;- dplyr::lag(data$deaths, h) \n                                                  \n  data$lagged_cases &lt;- dplyr::lag(data$cases, h)\n  # perform quantile regression\n  rq_trailing &lt;- rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles, \n                    # only consider window of data\n                    data = data %&gt;% filter(time_value &gt; (max(time_value) - w))) \n  # construct data.frame with the right predictors for the target date\n  predictors &lt;- data.frame(lagged_deaths = tail(data$deaths, 1), \n                           lagged_cases = tail(data$cases, 1))\n  # make predictions for target date and add them to matrix of predictions\n  pred_trailing &lt;- rbind(pred_trailing, \n                         data.frame('forecast_date' = max(data$time_value),\n                                    'target_date' = max(data$time_value) + h, \n                                    predict(rq_trailing, newdata = predictors)))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#version-aware-predictions-cv-trailing",
    "href": "slides/day2-morning.html#version-aware-predictions-cv-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version-aware predictions (CV, trailing)",
    "text": "Version-aware predictions (CV, trailing)"
  },
  {
    "objectID": "slides/day2-morning.html#using-geo-information",
    "href": "slides/day2-morning.html#using-geo-information",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using geo information",
    "text": "Using geo information\n\nAssume we observe data over time from multiple locations (e.g. states or counties).\nWe could\n\nEstimate coefficients separately for each location (as we have done so far).\nFit one model using all locations together at each time point (geo-pooling). Estimated coefficients will not be location specific.\nEstimate coefficients separately for each location, but include predictors capturing averages across locations (partial geo-pooling)."
  },
  {
    "objectID": "slides/day2-morning.html#geo-pooling-trailing-window",
    "href": "slides/day2-morning.html#geo-pooling-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Geo-pooling (trailing window)",
    "text": "Geo-pooling (trailing window)\n\nusa_archive &lt;- data_archive$DT %&gt;% \n  as_epi_archive()\n\n# initialize dataframe for predictions\n# 6 columns: geo value, forecast date, target date, 2.5%, 50%, and 97.5% quantiles\npred_trailing &lt;- data.frame(matrix(NA, ncol = 6, nrow = 0))\ncolnames(pred_trailing) &lt;- c('geo_value', 'forecast_date', 'target_date',\n                             'tau..0.025', 'tau..0.500', 'tau..0.975')\n\nw &lt;- 200         #trailing window size\nh &lt;- 28          #number of days ahead\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data &lt;- epix_as_of(usa_archive, max_version = as.Date(fc_date))\n  \n  # create lagged predictors for each state \n  data &lt;- data %&gt;%\n    arrange(geo_value, time_value) %&gt;%  \n    group_by(geo_value) %&gt;%\n    mutate(lagged_deaths = dplyr::lag(deaths, h),\n           lagged_cases = dplyr::lag(cases, h)) %&gt;%\n    ungroup()\n  \n  # perform quantile regression\n  rq_trailing &lt;- rq(deaths ~ lagged_deaths + lagged_cases, tau = quantiles, \n                    # only consider window of data\n                    data = data %&gt;% filter(time_value &gt; (max(time_value) - w))) \n  \n  # construct dataframe with the right predictors for the target date\n  new_lagged_deaths &lt;- data %&gt;% \n    filter(time_value == max(time_value)) %&gt;%\n    select(geo_value, deaths)\n  \n  new_lagged_cases &lt;- data %&gt;% \n    filter(time_value == max(time_value)) %&gt;%\n    select(geo_value, cases)\n  \n  predictors &lt;- new_lagged_deaths %&gt;%\n    inner_join(new_lagged_cases, join_by(geo_value)) %&gt;%\n    rename(lagged_deaths = deaths,\n           lagged_cases = cases)\n  \n  # make predictions for target date and add them to matrix of predictions\n  pred_trailing &lt;- rbind(pred_trailing, \n                         data.frame(\n                           'geo_value' = predictors$geo_value,\n                           'forecast_date' = max(data$time_value),\n                           'target_date' = max(data$time_value) + h, \n                           predict(rq_trailing, newdata = predictors)))\n}\n\n# geo-pooled predictions for California\npred_ca &lt;- pred_trailing %&gt;%\n  filter(geo_value == 'ca') %&gt;%\n  rename(median = `tau..0.500`,\n         lower = `tau..0.025`,\n         upper = `tau..0.975`) %&gt;%\n  full_join(ca %&gt;% select(time_value, deaths), join_by(target_date == time_value)) %&gt;%\n  arrange(target_date)"
  },
  {
    "objectID": "slides/day2-morning.html#geo-pooled-predictions-for-california",
    "href": "slides/day2-morning.html#geo-pooled-predictions-for-california",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Geo-pooled predictions for California",
    "text": "Geo-pooled predictions for California"
  },
  {
    "objectID": "slides/day2-morning.html#partial-geo-pooling-trailing-window",
    "href": "slides/day2-morning.html#partial-geo-pooling-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Partial geo-pooling (trailing window)",
    "text": "Partial geo-pooling (trailing window)\n\n# initialize dataframe for predictions\n# 6 columns: geo value, forecast date, target date, 2.5%, 50%, and 97.5% quantiles\npred_trailing &lt;- data.frame(matrix(NA, ncol = 6, nrow = 0))\ncolnames(pred_trailing) &lt;- c('geo_value', 'forecast_date', 'target_date',\n                             'tau..0.025', 'tau..0.500', 'tau..0.975')\n\nw &lt;- 200         #trailing window size\nh &lt;- 28          #number of days ahead\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data &lt;- epix_as_of(usa_archive, max_version = as.Date(fc_date))\n  \n  # create lagged predictors \n  data &lt;- data %&gt;%\n    arrange(geo_value, time_value) %&gt;%  \n    group_by(geo_value) %&gt;%\n    mutate(lagged_deaths = dplyr::lag(deaths, h),\n           lagged_cases = dplyr::lag(cases, h)) %&gt;%\n    ungroup() %&gt;%\n    group_by(time_value) %&gt;%\n    mutate(avg_lagged_deaths = mean(lagged_deaths, na.rm = T),\n           avg_lagged_cases = mean(lagged_cases, na.rm = T)) %&gt;%\n    ungroup() \n  \n  # perform quantile regression\n  rq_trailing &lt;- rq(deaths ~ lagged_deaths + lagged_cases + avg_lagged_deaths +\n                      avg_lagged_cases, tau = quantiles, \n                    data = (data %&gt;% filter(geo_value == 'ca'))) \n  \n  # construct data.frame with the right predictors for the target date\n  new_lagged_deaths &lt;- data %&gt;% \n    filter(time_value == max(time_value)) %&gt;%\n    select(geo_value, deaths) %&gt;%\n    mutate(avg_lagged_deaths = mean(deaths, na.rm = T)) %&gt;%\n    filter(geo_value == 'ca')\n  \n  new_lagged_cases &lt;- data %&gt;% \n    filter(time_value == max(time_value)) %&gt;%\n    select(geo_value, cases) %&gt;%\n    mutate(avg_lagged_cases = mean(cases, na.rm = T)) %&gt;%\n    filter(geo_value == 'ca')\n  \n  predictors &lt;- new_lagged_deaths %&gt;%\n    inner_join(new_lagged_cases, join_by(geo_value)) %&gt;%\n    rename(lagged_deaths = deaths,\n           lagged_cases = cases)\n  \n  # make predictions for target date and add them to matrix of predictions\n  pred_trailing &lt;- rbind(pred_trailing, \n                         data.frame(\n                           'geo_value' = predictors$geo_value,\n                           'forecast_date' = max(data$time_value),\n                           'target_date' = max(data$time_value) + h, \n                           predict(rq_trailing, newdata = predictors)))\n}\n\n# partially geo-pooled predictions for California\npred_ca &lt;- pred_trailing %&gt;%\n  filter(geo_value == 'ca') %&gt;%\n  rename(median = `tau..0.500`,\n         lower = `tau..0.025`,\n         upper = `tau..0.975`) %&gt;%\n  full_join(ca %&gt;% select(time_value, deaths), join_by(target_date == time_value)) %&gt;%\n  arrange(target_date)"
  },
  {
    "objectID": "slides/day2-morning.html#partially-geo-pooled-predictions-for-california",
    "href": "slides/day2-morning.html#partially-geo-pooled-predictions-for-california",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Partially geo-pooled predictions for California",
    "text": "Partially geo-pooled predictions for California"
  },
  {
    "objectID": "slides/day2-morning.html#final-slide",
    "href": "slides/day2-morning.html#final-slide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Final slide",
    "text": "Final slide\nThanks:\n\nThe whole CMU Delphi Team (across many institutions)\nOptum/UnitedHealthcare, Change Healthcare.\nGoogle, Facebook, Amazon Web Services.\nQuidel, SafeGraph, Qualtrics.\nCenters for Disease Control and Prevention.\nCouncil of State and Territorial Epidemiologists\n\n\n    \n\n\n\n\n\nForecasting and Time-Series Models — cmu-delphi/insightnet-workshop-2024"
  },
  {
    "objectID": "slides/day1-morning.html#section",
    "href": "slides/day1-morning.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Title",
    "text": "Title\nSubtitle\n\nDaniel J. McDonald\n\nVenue – dd Somemonth yyyy"
  },
  {
    "objectID": "slides/day1-morning.html#slides-begin",
    "href": "slides/day1-morning.html#slides-begin",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Slides begin",
    "text": "Slides begin"
  },
  {
    "objectID": "slides/day1-morning.html#callouts",
    "href": "slides/day1-morning.html#callouts",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Callouts",
    "text": "Callouts\n\n\n\n\n\n\nNote\n\n\nYou can use these. See https://quarto.org/docs/authoring/callouts.html"
  },
  {
    "objectID": "slides/day1-morning.html#final-slide",
    "href": "slides/day1-morning.html#final-slide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Final slide",
    "text": "Final slide\nThanks:\n\nThe whole CMU Delphi Team (across many institutions)\nOptum/UnitedHealthcare, Change Healthcare.\nGoogle, Facebook, Amazon Web Services.\nQuidel, SafeGraph, Qualtrics.\nCenters for Disease Control and Prevention.\nCouncil of State and Territorial Epidemiologists\n\n\n    \n\n\n\n\n\nTitle — cmu-delphi/insightnet-workshop-2024"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "",
    "text": "Short description\n\nDay 1 Morning\nDay 1 Afternoon\nDay 2 Morning\nDay 2 Afternoon\n\n\n\n\n\nRyan J. Tibshirani\nDaniel J. McDonald\nAlice Cima\nRachel Lobay"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "",
    "text": "Short description\n\nDay 1 Morning\nDay 1 Afternoon\nDay 2 Morning\nDay 2 Afternoon"
  },
  {
    "objectID": "index.html#instructors",
    "href": "index.html#instructors",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "",
    "text": "Ryan J. Tibshirani\nDaniel J. McDonald\nAlice Cima\nRachel Lobay"
  },
  {
    "objectID": "slides/day2-afternoon.html#section",
    "href": "slides/day2-afternoon.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Forecasting with {epipredict}",
    "text": "Forecasting with {epipredict}\n\n\n\n\nVenue – dd Somemonth yyyy"
  },
  {
    "objectID": "slides/day2-afternoon.html#outline",
    "href": "slides/day2-afternoon.html#outline",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Outline",
    "text": "Outline\n\n{epipredict}\nARX Models\nForecasting with Versioned Data"
  },
  {
    "objectID": "slides/day2-afternoon.html#fit-arx-on-training-set",
    "href": "slides/day2-afternoon.html#fit-arx-on-training-set",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fit ARX on training set",
    "text": "Fit ARX on training set\n\n# Split into train and test (before/after t0_date)\nt0_date &lt;- as.Date('2021-03-01')\ntrain &lt;- ca %&gt;% filter(time_value &lt;= t0_date)\ntest &lt;- ca %&gt;% filter(time_value &gt; t0_date)\n\nh &lt;- 28 \n\nepi_arx &lt;- arx_forecaster(epi_data = train %&gt;% as_epi_df(), \n                          outcome = \"deaths\", \n                          predictors = c(\"cases\", \"deaths\"),\n                          trainer = linear_reg() %&gt;% set_engine(\"lm\"),\n                          args_list = arx_args_list(lags = 0, \n                                                    ahead = h))\nepi_arx"
  },
  {
    "objectID": "slides/day2-afternoon.html#extract-workflow",
    "href": "slides/day2-afternoon.html#extract-workflow",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extract workflow",
    "text": "Extract workflow\n\nepi_arx$epi_workflow\n\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n (Intercept)   lag_0_cases  lag_0_deaths  \n     0.08133       0.01030       0.14011"
  },
  {
    "objectID": "slides/day2-afternoon.html#extract-prediction",
    "href": "slides/day2-afternoon.html#extract-prediction",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extract prediction",
    "text": "Extract prediction\n\nepi_arx$predictions\n\n# A tibble: 1 × 5\n  geo_value .pred        .pred_distn forecast_date target_date\n  &lt;chr&gt;     &lt;dbl&gt;             &lt;dist&gt; &lt;date&gt;        &lt;date&gt;     \n1 ca        0.368 quantiles(0.37)[2] 2021-03-01    2021-03-29 \n\n\n\nepi_arx$predictions %&gt;%\n  # first create a \"nested\" list-column\n  mutate(.pred_distn = nested_quantiles(.pred_distn)) %&gt;%\n  unnest(.pred_distn) # then unnest it\n\n# A tibble: 2 × 6\n  geo_value .pred values quantile_levels forecast_date target_date\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;           &lt;dbl&gt; &lt;date&gt;        &lt;date&gt;     \n1 ca        0.368  0.224            0.05 2021-03-01    2021-03-29 \n2 ca        0.368  0.513            0.95 2021-03-01    2021-03-29"
  },
  {
    "objectID": "slides/day2-afternoon.html#arx-on-trailing-window",
    "href": "slides/day2-afternoon.html#arx-on-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX on trailing window",
    "text": "ARX on trailing window\n\n# Specify the forecast dates\nfc_time_values &lt;- seq(\n  from = t0_date,\n  to = tail(ca$time_value, 1) - h,\n  by = \"1 day\"\n)\n\nw &lt;- 200  # trailing window length\n\n# Slide an arx_forecaster with appropriate outcome, predictions, lags, and trailing window\nepi_pred_cv_trailing &lt;- ca %&gt;%\n  epi_slide(\n    ~ arx_forecaster(epi_data = .x,\n                   outcome = \"deaths\", \n                   predictors = c(\"cases\", \"deaths\"), \n                   trainer = linear_reg() %&gt;% set_engine(\"lm\"),\n                   args_list = arx_args_list(lags = 0, ahead = h)\n                   )$predictions %&gt;%\n      pivot_quantiles_wider(.pred_distn),\n  # notice that `before` is not simply equal to w-1. That's because previously, \n  # when considering a window from t to t+w, we had access to y_t, ..., y_{t+w} \n  # and also to x_{t-h}, ..., x_{t+w-h}. (That's because of how we structured \n  # the dataframe after manually lagging x.) So we were \"cheating\" by saying that \n  # the trailing window had length w, as its actual size was w+h! \n  .window_size = (w+h-1), \n  .ref_time_values = fc_time_values,\n  .new_col_name = \"fc\"\n)\n\n# they match exactly\nhead(epi_pred_cv_trailing %&gt;% select(fc))\nhead(test %&gt;% select(pred_trailing_cv, time_value))\n\nThe method fitting on all past data up to the forecasting date can be implemented by changing before = Inf in epi_slide."
  },
  {
    "objectID": "slides/day2-afternoon.html#thanks",
    "href": "slides/day2-afternoon.html#thanks",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Thanks:",
    "text": "Thanks:\n\nThe whole CMU Delphi Team (across many institutions)\nOptum/UnitedHealthcare, Change Healthcare.\nGoogle, Facebook, Amazon Web Services.\nQuidel, SafeGraph, Qualtrics.\nCenters for Disease Control and Prevention.\nCouncil of State and Territorial Epidemiologists\n\n\n    \n\n\n\n\n\nForecasting with {epipredict} — cmu-delphi/insightnet-workshop-2024"
  }
]