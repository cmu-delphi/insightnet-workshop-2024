[
  {
    "objectID": "slides/day2-morning.html#section",
    "href": "slides/day2-morning.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Quick Tour of Time Series Forecasting",
    "text": "Quick Tour of Time Series Forecasting\nInsightNet Forecasting Workshop 2024\n\nAlice Cima, Rachel Lobay, Daniel McDonald, Ryan Tibshirani\nwith huge thanks to Logan Brooks, Xueda Shen, and also to Nat DeFries, Dmitry Shemetov, and David Weber\n12 December – Morning"
  },
  {
    "objectID": "slides/day2-morning.html#outline",
    "href": "slides/day2-morning.html#outline",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Outline",
    "text": "Outline\n\nSome Words About Forecasting\nLinear Regression for Time Series\nEvaluation Methods\nARX Models\nOverfitting and Regularization\nPrediction Intervals\nForecasting with Versioned Data\nTraditional Approaches to Time Series"
  },
  {
    "objectID": "slides/day2-morning.html#forecasting-is-not-magic",
    "href": "slides/day2-morning.html#forecasting-is-not-magic",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Forecasting is not magic",
    "text": "Forecasting is not magic\n\nForecasts are generally comprised of two parts: trend and seasonality\nMethods for detecting and projecting trends are not magic; in general they’re not qualitatively that different from what you can do with your eyeballs\nThat said, assimilating information from exogenous features (ideally, leading indicators) can lead highly nontrivial gains, beyond the eyeballs\nRemember … good data is just as (more?) important as a good model!\nSeasonality can help short-term forecasts. Long-term forecasts, absent of strong seasonality, are generally not very tractable"
  },
  {
    "objectID": "slides/day2-morning.html#basics-of-linear-regression",
    "href": "slides/day2-morning.html#basics-of-linear-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Basics of linear regression",
    "text": "Basics of linear regression\n\nAssume we observe a predictor \\(x_i\\) and an outcome \\(y_i\\) for \\(i = 1, \\dots, n\\).\nLinear regression seeks coefficients \\(\\beta_0\\) and \\(\\beta_1\\) such that\n\n\\[y_i \\approx \\beta_0 + \\beta_1 x_i\\]\nis a good approximation for every \\(i = 1, \\dots, n\\).\n\nIn R, the coefficients are found by running lm(y ~ x), where y is the vector of responses and x the vector of predictors."
  },
  {
    "objectID": "slides/day2-morning.html#multiple-linear-regression",
    "href": "slides/day2-morning.html#multiple-linear-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nGiven \\(p\\) different predictors, we seek \\((p+1)\\) coefficients such that\n\n\\[y_i \\approx \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip}\\] is a good approximation for every \\(i = 1, \\dots, n\\)."
  },
  {
    "objectID": "slides/day2-morning.html#linear-regression-with-lagged-predictor",
    "href": "slides/day2-morning.html#linear-regression-with-lagged-predictor",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Linear regression with lagged predictor",
    "text": "Linear regression with lagged predictor\n\nIn time series, outcomes and predictors are usually indexed by time \\(t\\).\n\n\n\nGoal: predicting future \\(y\\), given present \\(x\\).\n\n\n\n\nModel: linear regression with lagged predictor\n\n\\[\\hat y_t = \\hat \\beta + \\hat \\beta_0 x_{t-k}\\]\ni.e. regress the outcome \\(y\\) at time \\(t\\) on the predictor \\(x\\) at time \\(t-k\\).\n\n\n\nEquivalent way to write the model:\n\n\\[\\hat y_{t+k} = \\hat \\beta + \\hat \\beta_0 x_t\\]"
  },
  {
    "objectID": "slides/day2-morning.html#example-predicting-covid-deaths",
    "href": "slides/day2-morning.html#example-predicting-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example: predicting COVID deaths",
    "text": "Example: predicting COVID deaths\n\nDuring the pandemic, interest in predicting COVID deaths 7, 14, 21, 28 days ahead.\nCan we reasonably predict COVID deaths 28 days ahead by just using cases today?\n\n\n\nIf we let\n\n\\[y_{t+28} = \\text{deaths at time } t+28 \\quad\\quad x_{t} = \\text{cases at time } t\\] is the following a good model?\n\\[\\hat y_{t+28} = \\hat\\beta_0 + \\hat\\beta_1 x_{t}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#example-covid-cases-and-deaths-in-california",
    "href": "slides/day2-morning.html#example-covid-cases-and-deaths-in-california",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example: COVID cases and deaths in California",
    "text": "Example: COVID cases and deaths in California\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhead(ca)\n\nAn `epi_df` object, 6 x 4 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-11-05 23:50:44.00687\n\n# A tibble: 6 × 4\n# Groups:   geo_value [1]\n  geo_value time_value cases deaths\n* &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 ca        2020-04-01  3.17 0.0734\n2 ca        2020-04-02  3.48 0.0835\n3 ca        2020-04-03  3.44 0.0894\n4 ca        2020-04-04  3.05 0.0778\n5 ca        2020-04-05  3.28 0.0876\n6 ca        2020-04-06  3.37 0.0848\n\n\n\n\n\n\n\nNote\n\n\nCases seem highly correlated with deaths several weeks later (but relation cases-deaths changes over time)."
  },
  {
    "objectID": "slides/day2-morning.html#checking-correlation",
    "href": "slides/day2-morning.html#checking-correlation",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Checking correlation",
    "text": "Checking correlation\n\nLet’s split the data into a training and a test set (before/after 2021-04-01).\nOn training set: large correlation between cases and deaths 28 days ahead (&gt; 0.95).\n\n\n\n\nLet’s use (base) R to prepare the data and fit\n\n\\[\\hat y_{t+28} = \\hat\\beta + \\hat\\beta_0 x_{t}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#preparing-the-data",
    "href": "slides/day2-morning.html#preparing-the-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Preparing the data",
    "text": "Preparing the data\n\nca$lagged_cases &lt;- dplyr::lag(ca$cases, n = k)     # Add column with cases lagged by k\nt0_date &lt;- as.Date('2021-04-01')                   # Split into train and test (before/after t0_date)\ntrain &lt;- ca |&gt; filter(time_value &lt;= t0_date)\ntest &lt;- ca |&gt; filter(time_value &gt; t0_date)\n\nCheck if deaths is approximately linear in lagged_cases:"
  },
  {
    "objectID": "slides/day2-morning.html#fitting-lagged-linear-regression-in-r",
    "href": "slides/day2-morning.html#fitting-lagged-linear-regression-in-r",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fitting lagged linear regression in R",
    "text": "Fitting lagged linear regression in R\n\nreg_lagged = lm(deaths ~ lagged_cases, data = train)\ncoef(reg_lagged)\n\n (Intercept) lagged_cases \n   0.1171839    0.0112714"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics",
    "href": "slides/day2-morning.html#error-metrics",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics",
    "text": "Error metrics\n\nAssume we have predictions \\(\\hat y_{new, t}\\) for the unseen observations \\(y_{new,t}\\) over times \\(t = 1, \\dots, N\\).\nFour commonly used error metrics are:\n\nmean squared error (MSE)\nmean absolute error (MAE)\nmean absolute percentage error (MAPE)\nmean absolute scaled error (MASE)"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics-mse-and-mae",
    "href": "slides/day2-morning.html#error-metrics-mse-and-mae",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics: MSE and MAE",
    "text": "Error metrics: MSE and MAE\n\\[MSE = \\frac{1}{N} \\sum_{t=1}^N (y_{new, t}- \\hat y_{new, t})^2\\] \\[MAE = \\frac{1}{N} \\sum_{t=1}^N |y_{new, t}- \\hat y_{new, t}|\\]\n\nMAE gives less importance to extreme errors than MSE.\nDrawback: both metrics are scale-dependent, so they are not universally interpretable. (For example, if \\(y\\) captures height, MSE and MAE will vary depending on whether we measure in feet or meters.)"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics-mape",
    "href": "slides/day2-morning.html#error-metrics-mape",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics: MAPE",
    "text": "Error metrics: MAPE\n\nFixing scale-dependence:\n\n\\[MAPE = 100 \\times \\frac{1}{N} \\sum_{t=1}^N\n\\left|\\frac{y_{new, t}- \\hat y_{new, t}}{y_{new, t}}\\right|\\]\n\nDrawbacks:\n\nErratic behavior when \\(y_{new, t}\\) is close to zero\nIt assumes the unit of measurement has a meaningful zero (e.g. using Fahrenheit or Celsius to measure temperature will lead to different MAPE)"
  },
  {
    "objectID": "slides/day2-morning.html#comparing-mae-and-mape",
    "href": "slides/day2-morning.html#comparing-mae-and-mape",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Comparing MAE and MAPE",
    "text": "Comparing MAE and MAPE\n\n\n\n\n\n\nImportant\n\n\nThere are situations when MAPE is problematic!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMAE\nMAPE\n\n\n\n\nyhat1\n2.873\n43.140\n\n\nyhat2\n5.382\n36.083"
  },
  {
    "objectID": "slides/day2-morning.html#error-metrics-mase",
    "href": "slides/day2-morning.html#error-metrics-mase",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Error metrics: MASE",
    "text": "Error metrics: MASE\n\\[MASE = 100 \\times \\frac{\\frac{1}{N} \\sum_{t=1}^N\n|y_{new, t}- \\hat y_{new, t}|}\n{\\frac{1}{N-1} \\sum_{t=2}^N\n|y_{new, t}- y_{new, t-1}|}\\]\n\nAdvantages:\n\nis universally interpretable (not scale dependent)\navoids the zero-pitfall\n\nMASE in words: we normalize the error of our forecasts by that of a naive method which always predicts the last observation."
  },
  {
    "objectID": "slides/day2-morning.html#comparing-mae-mape-and-mase",
    "href": "slides/day2-morning.html#comparing-mae-mape-and-mase",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Comparing MAE, MAPE and MASE",
    "text": "Comparing MAE, MAPE and MASE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMAE\nMAPE\nMASE\n\n\n\n\nyhat1\n2.873\n43.140\n66.100\n\n\nyhat2\n5.382\n36.083\n123.817"
  },
  {
    "objectID": "slides/day2-morning.html#defining-the-error-metrics-in-r",
    "href": "slides/day2-morning.html#defining-the-error-metrics-in-r",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Defining the error metrics in R",
    "text": "Defining the error metrics in R\n\nMSE &lt;- function(truth, prediction) {\n  mean((truth - prediction)^2)}\n\nMAE &lt;- function(truth, prediction) {\n  mean(abs(truth - prediction))}\n\nMAPE &lt;- function(truth, prediction) {\n  100 * mean(abs(truth - prediction) / truth)}\n\nMASE &lt;- function(truth, prediction) {\n  100 * MAE(truth, prediction) / mean(abs(diff(truth)))}"
  },
  {
    "objectID": "slides/day2-morning.html#estimating-the-prediction-error",
    "href": "slides/day2-morning.html#estimating-the-prediction-error",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Estimating the prediction error",
    "text": "Estimating the prediction error\n\nGiven an error metric, we want to estimate the prediction error under that metric.\nThis can be accomplished in different ways, using the\n\nTraining error\nSplit-sample error\nTime series cross-validation error (using all past data or a trailing window)"
  },
  {
    "objectID": "slides/day2-morning.html#training-error",
    "href": "slides/day2-morning.html#training-error",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Training error",
    "text": "Training error\n\nThe easiest but worst approach to estimate the prediction error is to use the training error, i.e. the average error on the training set that was used to fit the model.\nThe training error is\n\ngenerally too optimistic as an estimate of prediction error\nmore optimistic the more complex the model!1\n\n\nMore on this when we talk about overfitting."
  },
  {
    "objectID": "slides/day2-morning.html#training-error-1",
    "href": "slides/day2-morning.html#training-error-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Training error",
    "text": "Training error\nLinear regression of COVID deaths on lagged cases\n\n# Getting the predictions for the training set\npred_train &lt;- predict(reg_lagged)\n\n\n\n\n               MAE     MASE\ntraining 0.0740177 380.9996"
  },
  {
    "objectID": "slides/day2-morning.html#split-sample-error",
    "href": "slides/day2-morning.html#split-sample-error",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Split-sample error",
    "text": "Split-sample error\nTo compute the split-sample error\n\nSplit data into training (up to time \\(t_0\\)), and test set (after \\(t_0\\))\nFit the model to the training data only\nMake predictions for the test set\nCompute the selected error metric on the test set only\n\n\n\n\nNote\n\n\nSplit-sample estimates of prediction error don’t mimic a situation where we would refit the model in the future. They are pessimistic if the relation between outcome and predictors changes over time."
  },
  {
    "objectID": "slides/day2-morning.html#split-sample-mse",
    "href": "slides/day2-morning.html#split-sample-mse",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Split-sample MSE",
    "text": "Split-sample MSE\nAssume we want to make \\(h\\)-step ahead predictions, i.e. at time \\(t\\) we want to make a forecast for \\(t+h\\). Then, the split-sample MSE is\n\\[\\text{SplitMSE} = \\frac{1}{n-h-t_0} \\sum_{t = t_0}^{n-h} (\\hat y_{t+h|t_0} - y_{t+h})^2\\]\nwhere \\(\\hat y_{t+h|t_0}\\) indicates a prediction for \\(y\\) at time \\(t+h\\) that was made with a model that was fit on data up to time \\(t_0\\)."
  },
  {
    "objectID": "slides/day2-morning.html#split-sample-error-1",
    "href": "slides/day2-morning.html#split-sample-error-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Split-sample error",
    "text": "Split-sample error\nLinear regression of COVID deaths on lagged cases\n\n# Getting h-step ahead predictions for the test set\nh &lt;- k\ntest_h &lt;- test[-(1:h-1), ] # drop first h-1 rows to avoid data leakage\npred_test &lt;- predict(reg_lagged, newdata = test_h)\n\n\n\n\n                   MAE      MASE\ntraining     0.0740177  380.9996\nsplit-sample 0.3116854 2914.4575\n\n\n\nNote that we are overestimating the peak due to the changed relationship between cases - deaths over time.\nTalk about data leakage."
  },
  {
    "objectID": "slides/day2-morning.html#warning",
    "href": "slides/day2-morning.html#warning",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Warning!",
    "text": "Warning!\n\nPredictions are overshooting the target, especially in early 2022 (Omicron phase).\nThis is because we are predicting deaths using lagged cases, but the relation between the two changes over time."
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cross-validation-cv",
    "href": "slides/day2-morning.html#time-series-cross-validation-cv",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time series cross-validation (CV)",
    "text": "Time series cross-validation (CV)\n\\(h\\)-step ahead predictions\n\nIf we refit in the future once new data are available, a more appropriate way to estimate the prediction error is time series cross-validation.\nTo get \\(h\\)-step ahead predictions, for each time \\(t = t_0, t_0+1, \\dots\\),\n\nFit the model using data up to time \\(t\\)\nMake a prediction for \\(t+h\\)\nRecord the prediction error\n\nThe cross-validation MSE is then\n\n\\[CVMSE = \\frac{1}{n-h-t_0} \\sum_{t = t_0}^{n-h} (\\hat y_{t+h|t} - y_{t+h})^2\\]\nwhere \\(\\hat y_{t+h|t}\\) indicates a prediction for \\(y\\) at time \\(t+h\\) that was made with data available up to time \\(t\\)."
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cross-validation-cv-1",
    "href": "slides/day2-morning.html#time-series-cross-validation-cv-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time series cross-validation (CV)",
    "text": "Time series cross-validation (CV)\nLinear regression of COVID deaths on lagged cases\n\nn &lt;- nrow(ca)                               #length of time series\nh &lt;- k                                      #number of days ahead for which prediction is wanted\npred_all_past &lt;- rep(NA, length = n)        #initialize vector of predictions\n\nfor (t in t0:(n-h)) {\n  # fit to all past data and make h-step ahead prediction\n  reg_all_past = lm(deaths ~ lagged_cases, data = ca, subset = (1:n) &lt;= t) \n  pred_all_past[t+h] = predict(reg_all_past, newdata = data.frame(ca[t+h, ]))\n}\n\n\n\n\nNote\n\n\nWith the current model, we can only predict \\(k\\) days ahead (where \\(k\\) = number of days by which predictor is lagged)!"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cross-validation-cv-2",
    "href": "slides/day2-morning.html#time-series-cross-validation-cv-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time series cross-validation (CV)",
    "text": "Time series cross-validation (CV)\nLinear regression of COVID deaths on lagged cases\n\n\n\n                     MAE      MASE\ntraining       0.0740177  380.9996\nsplit-sample   0.3116854 2914.4575\ntime series CV 0.2374931 2212.5992\n\n\n\nSome improvement wrt split-sample, but still overestimating peak."
  },
  {
    "objectID": "slides/day2-morning.html#warning-1",
    "href": "slides/day2-morning.html#warning-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Warning!",
    "text": "Warning!\n\nPredictions are still overshooting the target, but error is smaller than split-sample.\nWhy?\n\n 👍 Forecaster is partially learning the change in cases-deaths relation (especially in late 2022)\n👎 We refit on all past data, so predictions are still influenced by old cases-deaths relation\n\n\n\n\n\nIdea 💡\n\n\nIgnore old data when refitting?"
  },
  {
    "objectID": "slides/day2-morning.html#regression-on-a-trailing-window",
    "href": "slides/day2-morning.html#regression-on-a-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Regression on a trailing window",
    "text": "Regression on a trailing window\n\nFit the model on a window of data of length \\(w\\), starting at \\(t-w\\) and ending at \\(t\\).\nAdvantage: if the predictors-outcome relation changes over time, training the forecaster on a window of recent data can better capture the recent relation which might be more relevant to predict the outcome in the near future.\nWindow length \\(w\\) considerations:\n\nif \\(w\\) is too big, the model can’t adapt to the recent predictors-outcome relation \nif \\(w\\) is too small, the fitted model may be too volatile (trained on too little data)"
  },
  {
    "objectID": "slides/day2-morning.html#trailing-window",
    "href": "slides/day2-morning.html#trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Trailing window",
    "text": "Trailing window\nLinear regression of COVID deaths on lagged cases\n\n# Getting the predictions through CV with trailing window\nw &lt;- 120                                    #trailing window size\nh &lt;- k                                      #number of days ahead for which prediction is wanted\npred_trailing &lt;- rep(NA, length = n)        #initialize vector of predictions\n\nfor (t in t0:(n-h)) {\n  # fit to a trailing window of size w and make h-step ahead prediction\n  reg_trailing = lm(deaths ~ lagged_cases, data = ca, \n                    subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n  pred_trailing[t+h] = predict(reg_trailing, newdata = data.frame(ca[t+h, ]))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-all-past-vs-trailing-window",
    "href": "slides/day2-morning.html#time-series-cv-all-past-vs-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time series CV: all past vs trailing window",
    "text": "Time series CV: all past vs trailing window\nLinear regression of COVID deaths on lagged cases\n\n\n\n                                 MAE      MASE\ntraining                  0.07401770  380.9996\nsplit-sample              0.31168536 2914.4575\ntime series CV            0.23749306 2212.5992\ntime series CV + trailing 0.09932651  925.3734\n\n\n\nA lot of improvement: trailing window allows to adapt to the change in relationship between cases and deaths over time."
  },
  {
    "objectID": "slides/day2-morning.html#autoregressive-exogenous-input-arx-model",
    "href": "slides/day2-morning.html#autoregressive-exogenous-input-arx-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Autoregressive exogenous input (ARX) model",
    "text": "Autoregressive exogenous input (ARX) model\n\nIdea: predicting the outcome via a linear combination of its lags and a set of exogenous (i.e. external) input variables\nExample:\n\n\\[\\hat y_{t+h} = \\hat\\phi + \\sum_{i=0}^p \\hat\\phi_i y_{t-i} + \\sum_{j=0}^q \\hat\\beta_j x_{t-j}\\]\n\nNotice: we don’t need to include all contiguous lags, and we could fit e.g.\n\n\\[\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} + \\hat\\phi_2 y_{t-14} +\n\\hat\\beta_0 x_{t} + \\hat\\beta_1 x_{t-7} + \\hat\\beta_2 x_{t-14}\\]"
  },
  {
    "objectID": "slides/day2-morning.html#arx-model-for-covid-deaths",
    "href": "slides/day2-morning.html#arx-model-for-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX model for COVID deaths",
    "text": "ARX model for COVID deaths\n\nLet’s add lagged deaths as a predictor to our previous forecaster:\n\n\\[\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\beta_0 x_{t}\\]\n\nWe will refer to this model as ARX(1), as it only includes one lag for each predictor.\n\n\n# Prepare data: add column with deaths lagged by 28\nca$lagged_deaths &lt;- dplyr::lag(ca$deaths, n = k)\n\n\nHow does it compare to the previous model in terms of time series CV?\n\n\n\n\nNote\n\n\nFrom now on, we will only consider regression on a trailing window, since regression on all past data leads to overshooting during Omicron."
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-trailing-arx1-vs-lm-on-lagged-cases",
    "href": "slides/day2-morning.html#time-series-cv-trailing-arx1-vs-lm-on-lagged-cases",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time series CV (trailing): ARX(1) vs lm on lagged cases",
    "text": "Time series CV (trailing): ARX(1) vs lm on lagged cases\n\n\n\n                          MAE     MASE\nARX(1)             0.07852942 731.6178\nlm on lagged cases 0.09932651 925.3734\n\n\n\nErrors under both metrics are smaller than with previous model."
  },
  {
    "objectID": "slides/day2-morning.html#warning-2",
    "href": "slides/day2-morning.html#warning-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Warning!",
    "text": "Warning!\nRegression on a trailing window can be quite sensitive to data issues."
  },
  {
    "objectID": "slides/day2-morning.html#warning-3",
    "href": "slides/day2-morning.html#warning-3",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Warning!",
    "text": "Warning!\n\nAt the forecast date when the downward dip in deaths is predicted, the coefficients estimated by ARX(1) are\n\n\n\n  (Intercept) lagged_deaths  lagged_cases \n  0.067259206   0.304075294  -0.004285251 \n\n\n\nThe downward dip is explained by the negative coefficient on lagged_cases, and by the fact that at the forecast date\n\nobserved deaths are exactly equal to 0 (data issue)\nobserved cases are increasing"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-for-different-h",
    "href": "slides/day2-morning.html#predictions-for-different-h",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions for different \\(h\\)",
    "text": "Predictions for different \\(h\\)\n\nSo far we only focused on COVID death predictions 28 days ahead.\nWe will now compare the model with lagged cases as predictor\n\n\\[\\hat y_{t+h} = \\hat\\beta + \\hat\\beta_0 x_t\\]\nto the ARX(1) model\n\\[\\hat y_{t+h} = \\hat\\phi + \\hat\\phi_0 y_t + \\hat\\beta_0 x_t\\]\nfor horizons \\(h = 7, 14, 21, 28\\).\n\nWe will only make forecasts on the \\(1^{st}\\) day of each month, and use a trailing window with \\(w = 120\\)."
  },
  {
    "objectID": "slides/day2-morning.html#predictions-for-different-h-1",
    "href": "slides/day2-morning.html#predictions-for-different-h-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions for different \\(h\\)",
    "text": "Predictions for different \\(h\\)\n\nh_vals &lt;- c(7, 14, 21, 28)  #horizons \npred_m1 = pred_m2 &lt;- data.frame(matrix(NA, nrow = 0, ncol = 3))  #initialize df for predictions\ncolnames(pred_m1) = colnames(pred_m2) = c(\"forecast_date\", \"target_date\", \"prediction\")\nw &lt;- 120    #trailing window size\n\nca_lags &lt;- ca |&gt; select(!c(lagged_cases, lagged_deaths))\n\n# Create lagged predictors \nfor (i in seq_along(h_vals)) {\n  ca_lags[[paste0(\"lagged_deaths_\", h_vals[i])]] &lt;- dplyr::lag(ca_lags$deaths, n = h_vals[i])\n  ca_lags[[paste0(\"lagged_cases_\", h_vals[i])]] &lt;- dplyr::lag(ca_lags$cases, n = h_vals[i])\n}\n\n# Only forecast on 1st day of the months\nforecast_time &lt;- which(ca_lags$time_value &gt;= t0_date & \n                         ca_lags$time_value &lt; ca_lags$time_value[n-max(h_vals)] &\n                         day(ca_lags$time_value) == 1)\n\nfor (t in forecast_time) {\n  for (i in seq_along(h_vals)) {\n    h = h_vals[i]\n    # formulas including h-lagged variables\n    m1_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h))\n    m2_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h, \" + lagged_deaths_\", h))\n    # fit to trailing window of data\n    m1_fit = lm(m1_formula, data = ca_lags, subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n    m2_fit = lm(m2_formula, data = ca_lags, subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n    # make h-step ahead predictions\n    pred_m1 = rbind(pred_m1, \n                    data.frame(forecast_date = ca_lags$time_value[t],\n                               target_date = ca_lags$time_value[t+h],\n                               prediction = predict(m1_fit, newdata = data.frame(ca_lags[t+h, ]))))\n    pred_m2 = rbind(pred_m2, \n                    data.frame(forecast_date = ca_lags$time_value[t],\n                               target_date = ca_lags$time_value[t+h],\n                               prediction = predict(m2_fit, newdata = data.frame(ca_lags[t+h, ]))))\n    }\n}"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-for-different-h-lm-on-lagged-cases",
    "href": "slides/day2-morning.html#predictions-for-different-h-lm-on-lagged-cases",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions for different \\(h\\), lm on lagged cases",
    "text": "Predictions for different \\(h\\), lm on lagged cases\n\n\n\n                         MAE    MASE\nlm on lagged cases 0.1049742 304.007"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-for-different-h-arx1",
    "href": "slides/day2-morning.html#predictions-for-different-h-arx1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions for different \\(h\\), ARX(1)",
    "text": "Predictions for different \\(h\\), ARX(1)\n\n\n\n              MAE     MASE\nARX(1) 0.04463132 129.2531"
  },
  {
    "objectID": "slides/day2-morning.html#visualizing-predictions-for-multiple-horizons",
    "href": "slides/day2-morning.html#visualizing-predictions-for-multiple-horizons",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Visualizing predictions for multiple horizons",
    "text": "Visualizing predictions for multiple horizons\nDifferent ways to visualize predictions for multiple \\(h\\)\n\nLast slides: group by forecast date, and show prediction “trajectories”\nOther approach: one line and color per horizon \\(h\\)"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-by-horizon-arx1",
    "href": "slides/day2-morning.html#predictions-by-horizon-arx1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions by horizon, ARX(1)",
    "text": "Predictions by horizon, ARX(1)"
  },
  {
    "objectID": "slides/day2-morning.html#arx-models-with-2-and-3-lags",
    "href": "slides/day2-morning.html#arx-models-with-2-and-3-lags",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "ARX models with 2 and 3 lags",
    "text": "ARX models with 2 and 3 lags\n\nThe ARX(1) model \\(\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\beta_0 x_{t}\\) has good predictive performance\nWe will now try to improve the ARX(1) model by including more lags in the set of predictors\nLet’s consider two extensions: the ARX(2) model\n\n\\[\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} +\n\\hat\\beta_0 x_{t} + \\hat\\beta_1 x_{t-7}\\]\nand the ARX(3) model\n\\[\\hat y_{t+h} = \\hat \\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-7} + \\hat\\phi_2 y_{t-14} +\n\\hat\\beta_0 x_{t} + \\hat\\beta_1 x_{t-7} + \\hat\\beta_2 x_{t-14}\\]\nand fit them using a trailing window with \\(w = 120\\)."
  },
  {
    "objectID": "slides/day2-morning.html#fit-arx2-and-arx3-on-trailing-window",
    "href": "slides/day2-morning.html#fit-arx2-and-arx3-on-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fit ARX(2) and ARX(3) on trailing window",
    "text": "Fit ARX(2) and ARX(3) on trailing window\n\npred_arx2 = pred_arx3 &lt;- rep(NA, length = n)  \nw &lt;- 120     #trailing window size\nh &lt;- 28      #number of days ahead\n\n# create lagged predictors\nca_lags$lagged_deaths_35 &lt;- dplyr::lag(ca_lags$deaths, n = 35)\nca_lags$lagged_deaths_42 &lt;- dplyr::lag(ca_lags$deaths, n = 42)\nca_lags$lagged_cases_35 &lt;- dplyr::lag(ca_lags$cases, n = 35)\nca_lags$lagged_cases_42 &lt;- dplyr::lag(ca_lags$cases, n = 42)\n\nfor (t in t0:(n-h)) {\n  arx2_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h, \" + lagged_deaths_\", h,\n                                  \" + lagged_cases_\", h+7, \" + lagged_deaths_\", h+7))\n  arx3_formula = as.formula(paste0(\"deaths ~ lagged_cases_\", h, \" + lagged_deaths_\", h,\n                                  \" + lagged_cases_\", h+7, \" + lagged_deaths_\", h+7,\n                                  \" + lagged_cases_\", h+14, \" + lagged_deaths_\", h+14))\n  # fit to trailing window of data\n  arx2_fit = lm(arx2_formula, data = ca_lags, subset = (1:n) &lt;= t & (1:n) &gt; (t-w-7)) \n  arx3_fit = lm(arx3_formula, data = ca_lags, subset = (1:n) &lt;= t & (1:n) &gt; (t-w-14)) \n  # make h-step ahead predictions\n  pred_arx2[t+h] &lt;- max(0, predict(arx2_fit, newdata = data.frame(ca_lags[t+h, ])))\n  pred_arx3[t+h] &lt;- max(0, predict(arx3_fit, newdata = data.frame(ca_lags[t+h, ])))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-trailing-arx1-arx2-and-arx3",
    "href": "slides/day2-morning.html#time-series-cv-trailing-arx1-arx2-and-arx3",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time series CV (trailing): ARX(1), ARX(2), and ARX(3)",
    "text": "Time series CV (trailing): ARX(1), ARX(2), and ARX(3)\n\n\n\n              MAE      MASE\nARX(1) 0.07852942  731.6178\nARX(2) 0.08716160  812.0393\nARX(3) 0.12487694 1163.4135"
  },
  {
    "objectID": "slides/day2-morning.html#warning-4",
    "href": "slides/day2-morning.html#warning-4",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Warning!",
    "text": "Warning!\nAs we add more predictors, forecasts seem more volatile and errors increase.\n\n\n\nOverfitting"
  },
  {
    "objectID": "slides/day2-morning.html#overfitting-1",
    "href": "slides/day2-morning.html#overfitting-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Overfitting",
    "text": "Overfitting\nWhen we introduce too many predictors in the model\n\nThe estimated coefficients will be chosen to mimic the observed data very closely on the training set, leading to small training error\nThe predictive performance on the test set might be very poor, producing large split-sample and CV error"
  },
  {
    "objectID": "slides/day2-morning.html#extreme-case-arx-model-with-120-predictors",
    "href": "slides/day2-morning.html#extreme-case-arx-model-with-120-predictors",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extreme case: ARX model with 120 predictors",
    "text": "Extreme case: ARX model with 120 predictors\n\nWhat happens if we increase the number of predictors to 120?\nLet’s fit\n\n\\[\\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\phi_1 y_{t-1} + \\dots +\n\\hat\\phi_{59} y_{t-59} +\n\\hat\\beta_0 x_{t} + \\dots + \\hat\\beta_{t-59} x_{t-59}\\]\nand compare training vs split-sample errors"
  },
  {
    "objectID": "slides/day2-morning.html#extreme-case-predictions-on-training-and-test-set",
    "href": "slides/day2-morning.html#extreme-case-predictions-on-training-and-test-set",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extreme case: predictions on training and test set",
    "text": "Extreme case: predictions on training and test set\n\n\n\n                   MAE    MASE\nsplit-sample 0.3978198 3706.28\n\n\n\n\n\nNote\n\n\nSome predictions were negative, which doesn’t make sense for count data, so we truncated them at 0."
  },
  {
    "objectID": "slides/day2-morning.html#back-to-arx1-arx2-and-arx3",
    "href": "slides/day2-morning.html#back-to-arx1-arx2-and-arx3",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Back to ARX(1), ARX(2), and ARX(3)",
    "text": "Back to ARX(1), ARX(2), and ARX(3)\nHow can we\n\nselect the “right” number of lags to include?\navoid overfitting, while considering a large number of predictors?"
  },
  {
    "objectID": "slides/day2-morning.html#regularization",
    "href": "slides/day2-morning.html#regularization",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Regularization",
    "text": "Regularization\n\nIdea: introduce a regularization parameter \\(\\lambda\\) that shrinks or sets some of the estimated coefficients to zero, i.e. some predictors are estimated to have limited or no predictive power\nMost common regularization methods\n\nRidge: shrinks coefficients to zero\nLasso: sets some coefficients to zero\n\nLet’s predict \\(h=28\\) days ahead by regularizing\n\nARX(1)\nARX(2)\nARX(3)"
  },
  {
    "objectID": "slides/day2-morning.html#fit-arx3-ridgelasso-for-covid-deaths",
    "href": "slides/day2-morning.html#fit-arx3-ridgelasso-for-covid-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fit ARX(3) + ridge/lasso for COVID deaths",
    "text": "Fit ARX(3) + ridge/lasso for COVID deaths\n\nlibrary(glmnet) # Implements ridge and lasso\n\nh &lt;- 28\nX &lt;- as_tibble(ca_lags) |&gt; select(ends_with(\"_28\"), ends_with(\"_35\"), ends_with(\"_42\"))\ny &lt;- ca_lags$deaths\n\n# We'll need to omit NA values explicitly, as otherwise glmnet will complain\nX_train &lt;- X[43:t0, ]\ny_train &lt;- y[43:t0]\n\n# Ridge regression: set alpha = 0, lambda sequence will be chosen automatically\nridge &lt;- glmnet(X_train, y_train, alpha = 0)\nbeta_ridge &lt;- coef(ridge)       # matrix of estimated coefficients \nlambda_ridge &lt;- ridge$lambda    # sequence of lambdas used to fit ridge \n\n# Lasso regression: set alpha = 1, lambda sequence will be chosen automatically\nlasso &lt;- glmnet(X_train, y_train, alpha = 1)\nbeta_lasso &lt;- coef(lasso)       # matrix of estimated coefficients \nlambda_lasso &lt;- lasso$lambda    # sequence of lambdas used to fit lasso \n\ndim(beta_lasso)                 # One row per coefficient, one column per lambda value\n\n[1]  8 85"
  },
  {
    "objectID": "slides/day2-morning.html#time-series-cv-trailing-for-arx3-ridgelasso",
    "href": "slides/day2-morning.html#time-series-cv-trailing-for-arx3-ridgelasso",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Time series CV (trailing) for ARX(3) + ridge/lasso",
    "text": "Time series CV (trailing) for ARX(3) + ridge/lasso\n\nh &lt;- 28  # number of days ahead \nw &lt;- 120 # window length\n\n# Initialize matrices for predictions (one column per lambda value)\nyhat_ridge_mat &lt;- matrix(NA, nrow = n, ncol = length(lambda_ridge))\nyhat_lasso_mat &lt;- matrix(NA, nrow = n, ncol = length(lambda_lasso)) \nyhat_ridge = yhat_lasso &lt;- rep(NA, length = n)\n\n# Select index of best lambda value on training set\nridge_index = cv.glmnet(as.matrix(X_train), y_train, alpha = 0, lambda = lambda_ridge)$index[1]\nlasso_index = cv.glmnet(as.matrix(X_train), y_train, alpha = 1, lambda = lambda_lasso)$index[1]\n\nfor (t in t0:(n-h)) {\n  # Indices of data within window\n  inds = t-w &lt; 1:n & 1:n &lt;= t\n  # Fit ARX + ridge/lasso for each lambda value\n  ridge_trail = glmnet(X[inds, ], y[inds], alpha = 0, lambda = lambda_ridge)\n  lasso_trail = glmnet(X[inds, ], y[inds], alpha = 1, lambda = lambda_lasso)\n  # Predict for each lambda value\n  yhat_ridge_mat[t+h, ] = predict(ridge_trail, newx = as.matrix(X[(t+h), ]))\n  yhat_lasso_mat[t+h, ] = predict(lasso_trail, newx = as.matrix(X[(t+h), ]))\n  # Save prediction corresponding to best lambda so far\n  yhat_ridge[t+h] = max(0, yhat_ridge_mat[t+h, ridge_index])\n  yhat_lasso[t+h] = max(0, yhat_lasso_mat[t+h, lasso_index])\n  if (t &gt;= t0+h) {\n    # Prediction error\n    mae_ridge = colMeans(abs(yhat_ridge_mat[1:(t+1), ] - y[1:(t+1)]), na.rm = T)\n    mae_lasso = colMeans(abs(yhat_lasso_mat[1:(t+1), ] - y[1:(t+1)]), na.rm = T)\n    # Select index of lambda vector which gives lowest MAE so far\n    ridge_index &lt;- which.min(mae_ridge)\n    lasso_index &lt;- which.min(mae_lasso)\n  }\n}"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-time-series-cv-trailing-for-arx1-ridgelasso",
    "href": "slides/day2-morning.html#predictions-time-series-cv-trailing-for-arx1-ridgelasso",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions: time series CV (trailing) for ARX(1) + ridge/lasso",
    "text": "Predictions: time series CV (trailing) for ARX(1) + ridge/lasso\n\n\n\n                      MAE     MASE\nARX(1)         0.07852942 731.6178\nARX(1) + ridge 0.07004585 652.5808\nARX(1) + lasso 0.07887651 734.8514"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-time-series-cv-trailing-for-arx2-ridgelasso",
    "href": "slides/day2-morning.html#predictions-time-series-cv-trailing-for-arx2-ridgelasso",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions: time series CV (trailing) for ARX(2) + ridge/lasso",
    "text": "Predictions: time series CV (trailing) for ARX(2) + ridge/lasso\n\n\n\n                      MAE     MASE\nARX(2)         0.08716160 812.0393\nARX(2) + ridge 0.08143228 758.6622\nARX(2) + lasso 0.07807801 727.4122"
  },
  {
    "objectID": "slides/day2-morning.html#predictions-time-series-cv-trailing-for-arx3-ridgelasso",
    "href": "slides/day2-morning.html#predictions-time-series-cv-trailing-for-arx3-ridgelasso",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions: time series CV (trailing) for ARX(3) + ridge/lasso",
    "text": "Predictions: time series CV (trailing) for ARX(3) + ridge/lasso\n\n\n\n                      MAE      MASE\nARX(3)         0.12487694 1163.4135\nARX(3) + ridge 0.08555066  797.0310\nARX(3) + lasso 0.07633053  711.1318"
  },
  {
    "objectID": "slides/day2-morning.html#comparison-of-regularized-arx1-arx2-and-arx3",
    "href": "slides/day2-morning.html#comparison-of-regularized-arx1-arx2-and-arx3",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Comparison of regularized ARX(1), ARX(2), and ARX(3)",
    "text": "Comparison of regularized ARX(1), ARX(2), and ARX(3)\n\nBest model: ARX(1) + ridge\nSecond best: ARX(3) + lasso\nRidge worsens as more predictors are included\nLasso improves as more predictors are included"
  },
  {
    "objectID": "slides/day2-morning.html#point-predictions-vs-intervals",
    "href": "slides/day2-morning.html#point-predictions-vs-intervals",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Point predictions vs intervals",
    "text": "Point predictions vs intervals\n\nSo far, we have only considered point predictions, i.e.  we have fitted models to provide our best guess on the outcome at time \\(t+h\\).\n\n\n\n\nImportant\n\n\nWhat if we want to provide a measure of uncertainty around the point prediction or a likely range of values for the outcome at time \\(t+h\\)?\n\n\n\n\nFor each target time \\(t+h\\), we can construct prediction intervals, i.e. provide ranges of values that are expected to cover the true outcome value a fixed fraction of times."
  },
  {
    "objectID": "slides/day2-morning.html#prediction-intervals-for-lm-fits",
    "href": "slides/day2-morning.html#prediction-intervals-for-lm-fits",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Prediction intervals for lm fits",
    "text": "Prediction intervals for lm fits\n\nTo get prediction intervals for the models we previously fitted, we only need to tweak our call to predict by adding as an input:\ninterval = \"prediction\", level = p\nwhere \\(p \\in (0, 1)\\) is the desired coverage.\nThe output from predict will then be a matrix with\n\nfirst column a point estimate\nsecond column the lower limit of the interval\nthird column the upper limit of the interval"
  },
  {
    "objectID": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window",
    "href": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Prediction intervals for ARX (CV, trailing window)",
    "text": "Prediction intervals for ARX (CV, trailing window)\n\n# Initialize matrices to store predictions \n# 3 columns: point estimate, lower limit, and upper limit\npred_interval_lm &lt;- matrix(NA, nrow = n, ncol = 3)\ncolnames(pred_interval_lm) &lt;- c('prediction', 'lower', 'upper')\n\nfor (t in t0:(n-h)) {\n  # Fit ARX and predict\n  arx_trailing = lm(deaths ~ lagged_deaths + lagged_cases, data = ca, \n                    subset = (1:n) &lt;= t & (1:n) &gt; (t-w)) \n  pred_interval_lm[t+h, ] = pmax(0, \n                              predict(arx_trailing, newdata = data.frame(ca[t+h, ]),\n                                      interval = \"prediction\", level = 0.8))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window-1",
    "href": "slides/day2-morning.html#prediction-intervals-for-arx-cv-trailing-window-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Prediction intervals for ARX (CV, trailing window)",
    "text": "Prediction intervals for ARX (CV, trailing window)\n\n\n\n                   MAE     MASE\nlm.trailing 0.08932857 832.2278"
  },
  {
    "objectID": "slides/day2-morning.html#expected-vs-actual-coverage",
    "href": "slides/day2-morning.html#expected-vs-actual-coverage",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Expected vs actual coverage",
    "text": "Expected vs actual coverage\n\nWe would expect the ARX model to cover the truth about 80% of the times. Is this actually true in practice?\nThe actual coverage of the predictive intervals is lower:\n\n\n\n         Actual Expected\nCoverage    0.6      0.8\n\n\n\nWe can use calibration to handle under-covering (more on this in the afternoon)"
  },
  {
    "objectID": "slides/day2-morning.html#versioned-data",
    "href": "slides/day2-morning.html#versioned-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Versioned data",
    "text": "Versioned data\nSo far: data never revised (or simply ignored revisions, as_of today)\n\n\n\nImportant\n\n\nHow can we train forecasters when dealing with versioned data?\n\n\n\n\nca_archive\n\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-04-01 / 2023-03-09\nℹ First/last version with update: 2020-04-02 / 2023-03-10\nℹ Versions end: 2023-03-10\nℹ A preview of the table (24953 rows x 5 columns):\nKey: &lt;geo_value, time_value, version&gt;\n       geo_value time_value    version case_rate death_rate\n          &lt;char&gt;     &lt;Date&gt;     &lt;Date&gt;     &lt;num&gt;      &lt;num&gt;\n    1:        ca 2020-04-01 2020-04-02  3.009195 0.06580240\n    2:        ca 2020-04-01 2020-05-07  3.009195 0.06327156\n    3:        ca 2020-04-01 2020-06-21  3.009195 0.06580242\n    4:        ca 2020-04-01 2020-07-02  2.978825 0.06580242\n    5:        ca 2020-04-01 2020-07-03  2.978825 0.06580242\n   ---                                                     \n24949:        ca 2023-03-07 2023-03-08  0.000000 0.00000000\n24950:        ca 2023-03-07 2023-03-10 27.397832 0.00000000\n24951:        ca 2023-03-08 2023-03-09 21.083071 0.00000000\n24952:        ca 2023-03-08 2023-03-10  0.000000 0.00000000\n24953:        ca 2023-03-09 2023-03-10 22.185487 0.52072650"
  },
  {
    "objectID": "slides/day2-morning.html#version-aware-forecasting",
    "href": "slides/day2-morning.html#version-aware-forecasting",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version-aware forecasting",
    "text": "Version-aware forecasting\nImportant: when fitting and predicting, only use data in the latest version available at the forecast date!"
  },
  {
    "objectID": "slides/day2-morning.html#version-aware-forecasting-1",
    "href": "slides/day2-morning.html#version-aware-forecasting-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version-aware forecasting",
    "text": "Version-aware forecasting\n\n# initialize dataframe for predictions\n# 5 columns: forecast date, target date, 10%, 50%, and 90% quantiles\npred_aware &lt;- data.frame(matrix(NA, ncol = 5, nrow = 0))\n\nw &lt;- 120         #trailing window size\nh &lt;- 28          #number of days ahead\n\n# forecast once a week\nfc_time_values &lt;- seq(from = t0_date, to = as.Date(\"2023-02-09\"), by = \"1 week\")\n\nfor (fc_date in fc_time_values) {\n  # get data version as_of forecast date\n  data &lt;- epix_as_of(ca_archive, version = as.Date(fc_date))\n  # create lagged predictors\n  data$lagged_deaths &lt;- dplyr::lag(data$deaths, h) \n  data$lagged_cases &lt;- dplyr::lag(data$cases, h)\n  # perform regression\n  lm_weekly &lt;- lm(deaths ~ lagged_deaths + lagged_cases, \n                  # only consider window of data\n                  data = data |&gt; filter(time_value &gt; (max(time_value) - w))) \n  # construct data.frame with the right predictors for the target date\n  predictors &lt;- data.frame(lagged_deaths = tail(data$deaths, 1), \n                           lagged_cases = tail(data$cases, 1))\n  # make predictions for target date and add them to dataframe of predictions\n  pred_aware &lt;- rbind(pred_aware, \n                      data.frame('forecast_date' = max(data$time_value),\n                                 'target_date' = max(data$time_value) + h, \n                                 t(pmax(0, predict(lm_weekly, newdata = predictors,\n                                                   interval = \"prediction\", level = 0.8)))))\n}"
  },
  {
    "objectID": "slides/day2-morning.html#version-aware-predictions-cv-trailing",
    "href": "slides/day2-morning.html#version-aware-predictions-cv-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version-aware predictions (CV, trailing)",
    "text": "Version-aware predictions (CV, trailing)\n\n\n\n                     MAE     MASE\nversion-aware 0.08001814 224.2782"
  },
  {
    "objectID": "slides/day2-morning.html#version-unaware-predictions-cv-trailing",
    "href": "slides/day2-morning.html#version-unaware-predictions-cv-trailing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version-unaware predictions (CV, trailing)",
    "text": "Version-unaware predictions (CV, trailing)\n\n\n\n                       MAE     MASE\nversion-unaware 0.07934554 200.4657"
  },
  {
    "objectID": "slides/day2-morning.html#popular-forecasting-frameworks",
    "href": "slides/day2-morning.html#popular-forecasting-frameworks",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Popular forecasting frameworks",
    "text": "Popular forecasting frameworks\n\nAutoregressive integrated model average (ARIMA) models\nExponential smoothing with trend and seasonality (ETS)\nProphet forecaster\nDeepAR (neural network)\n\nFirst two here are classic and standard, second two are more recent. None are particularly well-suited for epi forecasting out-of-the-box, ask us about them if you’re curious. We’ll discuss ARIMA as it’s closest to what we’ve seen."
  },
  {
    "objectID": "slides/day2-morning.html#dissecting-arima",
    "href": "slides/day2-morning.html#dissecting-arima",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Dissecting ARIMA",
    "text": "Dissecting ARIMA\n\nAR = autoregressive, include lags of response itself as features\nMA = moving average, include lags of noise terms (correlated noise model)\nI = integrated, we model and forecast differences between observations"
  },
  {
    "objectID": "slides/day2-morning.html#discussion",
    "href": "slides/day2-morning.html#discussion",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Discussion",
    "text": "Discussion\nWorth comparing and discussing ARIMA versus the kind of autoregressive models you’ve just seen:\n\nThe way lags are handled:\n\nIn what you’ve seen, we can include arbitrary lags (and regularize)\nTraditional AR models require lags to be contiguous (e.g., all of 0-17, instead of 0, 7, 14)\n\nThe way multi-step forecasts are made:\n\nIn what you’ve seen, we model h-step ahead directly\nTraditional AR models only do 1-step ahead prediction, and iterate this to get forecasts at longer horizons"
  },
  {
    "objectID": "slides/day2-morning.html#discussion-1",
    "href": "slides/day2-morning.html#discussion-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Discussion",
    "text": "Discussion\n\nThe way nonstationarity is handled:\n\nIn what you’ve seen, we address nonstationarity via trailing training windows (or observation weights more generally)\nTraditional ARIMA models use the I component for this: remove linear or quadratic trends by differences, add them back in at prediction time\n\nThe way exogenous features are included:\n\nIn what you’ve seen, they appear directly as an exogenous predictor\nTraditional ARIMA models (software, such as fable()) includes them in a different manner; they are effectively subject to the same lags as the AR and MA terms"
  },
  {
    "objectID": "slides/day2-morning.html#supplementary-resources",
    "href": "slides/day2-morning.html#supplementary-resources",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Supplementary resources",
    "text": "Supplementary resources\n\nHyndman and Athanasopoulos, Forecasting: Principles and Practice\nRyan’s course notes, Introduction to Time Series"
  },
  {
    "objectID": "slides/day1-morning.html#section",
    "href": "slides/day1-morning.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Introduction to Panel Data in Epidemiology",
    "text": "Introduction to Panel Data in Epidemiology\nInsightNet Forecasting Workshop 2024\n\nAlice Cima, Rachel Lobay, Daniel McDonald, Ryan Tibshirani\nwith huge thanks to Logan Brooks, Xueda Shen, and also to Nat DeFries, Dmitry Shemetov, and David Weber\n11 December – Morning"
  },
  {
    "objectID": "slides/day1-morning.html#outline",
    "href": "slides/day1-morning.html#outline",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Outline",
    "text": "Outline\n\nThe Delphi Research Group\nWorkshop Overview and System Setup\nPanel Data\nVersioned Data\nEpidata Repository and API\nFind Data Sources and Signals\n{epidatr}\nVersioning in {epidatr}"
  },
  {
    "objectID": "slides/day1-morning.html#about-delphi",
    "href": "slides/day1-morning.html#about-delphi",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "About Delphi",
    "text": "About Delphi\n\nFounded in 2012 at Carnegie Mellon University, now expanded to UC Berkeley, and University of British Columbia.\nCurrently 5 faculty, ~10 PhD students, ~15 staff (mostly software engineers).\nEasy to join us from anywhere (lots of volunteers during Covid-19 pandemic).\nWe are:\n\nCDC Center of Excellence for Influenza and Covid-19 Forecasting (2019-24).\nCDC Innovation Center for Outbreak Analytics and Disease Modeling (2024-29).\n\n\nOur mission: To develop the theory and practice of epidemic detection, tracking and forecasting, and their use in decision making, both public and private."
  },
  {
    "objectID": "slides/day1-morning.html#what-does-delphi-do",
    "href": "slides/day1-morning.html#what-does-delphi-do",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What does Delphi do?",
    "text": "What does Delphi do?\n\nProcure real-time, aggregated data streams informative of infectious diseases and syndromes, in collaboration with partners in industry and government.\nExtract signals and make them widely available via the Epidata platform & API.\nDevelop and deploy algorithms for epidemic detection, tracking, forecasting.\nDevelop and maintain statistical software packages for these tasks.\nMake it all production-grade, maximally-accessible, and open-source (to serve CDC, state and local public health agencies, epi-forecasting researchers, data journalists, the public)"
  },
  {
    "objectID": "slides/day1-morning.html#what-we-provide",
    "href": "slides/day1-morning.html#what-we-provide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What we provide",
    "text": "What we provide"
  },
  {
    "objectID": "slides/day1-morning.html#what-we-will-cover",
    "href": "slides/day1-morning.html#what-we-will-cover",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What we will cover",
    "text": "What we will cover\n\nCharacteristics of panel data in epidemiology\nTools for processing and plotting panel data\nStatistical background on nowcasting and forecasting\nTools for building nowcasting and forecasting models\nPlenty of examples throughout of real case studies"
  },
  {
    "objectID": "slides/day1-morning.html#goals-part-i",
    "href": "slides/day1-morning.html#goals-part-i",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Goals part I",
    "text": "Goals part I\n\nExpose you to a statistical way of thinking about now/forecasting\nCertain basic mindsets (e.g., the importance of empirical validation using techniques like time series cross-validation) are ubiquitous\nCertain basic modeling considerations (e.g., starting simple and building up complexity, taming variance through regularization, addressing nonstationarity with trailing training windows) are also ubiquitous"
  },
  {
    "objectID": "slides/day1-morning.html#goals-part-ii",
    "href": "slides/day1-morning.html#goals-part-ii",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Goals part II",
    "text": "Goals part II\n\nExpose you to software packages which aid processing, tracking, nowcasting, and forecasting with panel data\nThese tools are still in development and we welcome your feedback\nWe have tried hard to get the framework right; but many individual pieces themselves could still be improved\nIf these aren’t working for you, then we want to hear from you!\nWe welcome collaboration, and everything we do is open source"
  },
  {
    "objectID": "slides/day1-morning.html#a-disclaimer",
    "href": "slides/day1-morning.html#a-disclaimer",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "A disclaimer",
    "text": "A disclaimer\n\nOur backgrounds are primarily in statistics and computer science\nThis obviously influences our way of thinking and our approach to nowcasting and forecasting\nWe don’t have nearly as much experience with traditional epi models but we do have opinions about the pros/cons. Ask us at any point if you have a question about why we’re doing things a certain way"
  },
  {
    "objectID": "slides/day1-morning.html#one-last-slide",
    "href": "slides/day1-morning.html#one-last-slide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "One last slide",
    "text": "One last slide\n\nThis workshop is supposed to be useful for YOU. Ask questions if you have them, don’t be shy\nWe may not (likely won’t?) cover everything. Hopefully the materials will be a resource for you beyond this workshop"
  },
  {
    "objectID": "slides/day1-morning.html#system-setup-passive-viewing",
    "href": "slides/day1-morning.html#system-setup-passive-viewing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "System setup – Passive viewing",
    "text": "System setup – Passive viewing\n\nAll of the slides are at\n\nhttps://cmu-delphi.github.io/insightnet-workshop-2024\n\nThe source code is in the Repo\n\nhttps://github.com/cmu-delphi/insightnet-workshop-2024\n\nThis is enough, but we hope you’ll want to work through the code as we go along.\n\nDetailed versions of the next few slides are shown at the Repo Link above."
  },
  {
    "objectID": "slides/day1-morning.html#system-setup-required-software",
    "href": "slides/day1-morning.html#system-setup-required-software",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "System setup – Required software",
    "text": "System setup – Required software\n\nWe assume you already have\n\n\nR\n\n\n\nAn IDE. We’ll use RStudio, but you can use VSCode or Emacs or Whatnot"
  },
  {
    "objectID": "slides/day1-morning.html#system-setup-downloading-the-materials",
    "href": "slides/day1-morning.html#system-setup-downloading-the-materials",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "System setup – Downloading the materials",
    "text": "System setup – Downloading the materials\nEasy way:\n\nClick the Big Green Button that says &lt; &gt; Code ▾\nChoose Download Zip\nOpen the Zip directory and then Open insightnet-workshop-2024.Rproj\n\nMore expert (local git user):\n\nClick the Big Green Button that says &lt; &gt; Code ▾\nCopy the URL.\nOpen RStudio, select File &gt; New Project &gt; Version Control. Paste there and proceed.\n\nEven more expert (wants github remote):\n\nClick the Grey Button that says ⑂ Fork ▾\nProceed along the same lines as above."
  },
  {
    "objectID": "slides/day1-morning.html#system-setup-installing-required-packages",
    "href": "slides/day1-morning.html#system-setup-installing-required-packages",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "System setup – Installing required packages",
    "text": "System setup – Installing required packages\nWe will use a lot of packages.\nWe’ve tried to make it so you can get them all at once (with the right versions)\n🤞 We hope this works… 🤞 Note that you can “Copy to Clipboard”\n\nIn RStudio:\ninstall.packages(\"pak\") # good for installing from non-CRAN sources\npak::pkg_install(\"cmu-delphi/InsightNetFcast24\", dependencies = TRUE)\nInsightNetFcast24::verify_setup()\n\nHopefully, you see:\n\n\n✔ You should be good to go!\n\n\nAsk for help if you see something like:\n\n\nError in `verify_setup()`:\n! The following packages do not have the correct version:\nℹ Installed: epipredict 0.2.0.\nℹ Required: epipredict == 0.1.5."
  },
  {
    "objectID": "slides/day1-morning.html#panel-data-1",
    "href": "slides/day1-morning.html#panel-data-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Panel data",
    "text": "Panel data\n\nPanel data or longitudinal data, contain cross-sectional measurements of subjects over time.\nSince we’re working with aggregated data, the subjects are geographic units (e.g. counties, states).\n\n\n\nIn table form, panel data is a time index + one or more locations/keys.\nEx: The % of outpatient doctor visits that are COVID-related in WA from Dec. 2021 to Feb. 2022 (docs):\n\n\n\nAn `epi_df` object, 6 x 3 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2022-02-01\n\n# A tibble: 6 × 3\n  geo_value time_value percent_cli\n* &lt;chr&gt;     &lt;date&gt;           &lt;dbl&gt;\n1 wa        2021-12-01        4.70\n2 wa        2021-12-02        4.60\n3 wa        2021-12-03        4.56\n4 wa        2021-12-04        4.93\n5 wa        2021-12-05        4.17\n6 wa        2021-12-06        4.12"
  },
  {
    "objectID": "slides/day1-morning.html#examples-of-panel-data---covid-19-cases",
    "href": "slides/day1-morning.html#examples-of-panel-data---covid-19-cases",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of panel data - COVID-19 cases",
    "text": "Examples of panel data - COVID-19 cases\nJHU CSSE COVID cases per 100k  estimates the daily number of new confirmed COVID-19 cases per 100,000 population, averaged over the past 7 days.\n\n\n\nWA switch to weekly reporting in 2022\nFL reports “whenever” (weekly, biweekly, three days in a row, then 4 zeros, etc.)\nAPI calculates change from cumulative, so no-report becomes a 0.\nIf state decreases total, then we see a negative."
  },
  {
    "objectID": "slides/day1-morning.html#examples-of-panel-data---hhs-admissions",
    "href": "slides/day1-morning.html#examples-of-panel-data---hhs-admissions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of panel data - HHS Admissions",
    "text": "Examples of panel data - HHS Admissions\nConfirmed COVID-19 Hospital Admissions per 100k estimates the daily sum of adult and pediatric confirmed COVID-19 hospital admissions, per 100,000 population, averaged over the past 7 days."
  },
  {
    "objectID": "slides/day1-morning.html#intro-to-versioned-data",
    "href": "slides/day1-morning.html#intro-to-versioned-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Intro to versioned data",
    "text": "Intro to versioned data\n\nMany epidemic aggregates are subject to reporting delays and revisions\nThis is because individual-level data has delayed availability:\n\nPerson comes to ER → Has some tests → Admitted → Tests come back → Entered into the system → …\n\nSo, a “Hospital admission” may not attributable to a particular condition until a few days have passed (the patient may even have been released)\nAggregated data have a longer pipeline from the incident to the report.\nSo we have to track both: when the event occurred and when it was reported\nAdditionally, various mistakes lead to revisions\nThis means there can be many different values for the same date"
  },
  {
    "objectID": "slides/day1-morning.html#versioned-data-1",
    "href": "slides/day1-morning.html#versioned-data-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Versioned data",
    "text": "Versioned data\n\nThe event time is indicated by time_value (aka reference_date)\nNow, we add a second time index to indicate the data version (aka reporting_date)\nversion = the time at which we saw a particular value associated to a time_value\n\n\n\n# A tibble: 6 × 4\n  time_value geo_value percent_cli version   \n  &lt;date&gt;     &lt;chr&gt;           &lt;dbl&gt; &lt;date&gt;    \n1 2020-06-01 ca               2.14 2020-06-06\n2 2020-06-01 ca               2.14 2020-06-08\n3 2020-06-01 ca               2.11 2020-06-09\n4 2020-06-01 ca               2.13 2020-06-10\n5 2020-06-01 ca               2.20 2020-06-11\n6 2020-06-01 ca               2.23 2020-06-12\n\n\n\nNote that this feature can be indicated in different ways (ex. version, issue, release, as_of)."
  },
  {
    "objectID": "slides/day1-morning.html#versioned-panel-data",
    "href": "slides/day1-morning.html#versioned-panel-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Versioned panel data",
    "text": "Versioned panel data\nEstimated percentage of outpatient visits due to CLI across multiple versions."
  },
  {
    "objectID": "slides/day1-morning.html#latency-and-revision-in-signals",
    "href": "slides/day1-morning.html#latency-and-revision-in-signals",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Latency and revision in signals",
    "text": "Latency and revision in signals\n\nLatency the delay between data collection and availability\n\nExample: A signal based on insurance claims may take several days to appear as claims are processed\n\nRevision data is updated or corrected after initial publication\n\nExample: COVID-19 case reports are revised reporting backlogs are cleared"
  },
  {
    "objectID": "slides/day1-morning.html#latency-and-revision-in-signals---example",
    "href": "slides/day1-morning.html#latency-and-revision-in-signals---example",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Latency and revision in signals - Example",
    "text": "Latency and revision in signals - Example\n\nRecall the first example of panel & versioned data we’ve seen…\n\n\nOn June 1, this signal is 5 days latent: min(version - time_value)\n\n\n\n# A tibble: 6 × 5\n  time_value geo_value percent_cli version    version_time_diff\n  &lt;date&gt;     &lt;chr&gt;           &lt;dbl&gt; &lt;date&gt;     &lt;drtn&gt;           \n1 2020-06-01 ca               2.14 2020-06-06 5 days           \n2 2020-06-02 ca               1.96 2020-06-06 4 days           \n3 2020-06-03 ca               1.77 2020-06-06 3 days           \n4 2020-06-04 ca               1.65 2020-06-08 4 days           \n5 2020-06-05 ca               1.60 2020-06-09 4 days           \n6 2020-06-06 ca               1.34 2020-06-10 4 days           \n\n\nand subject to revision \n\n\n# A tibble: 6 × 5\n  time_value geo_value percent_cli version    version_time_diff\n  &lt;date&gt;     &lt;chr&gt;           &lt;dbl&gt; &lt;date&gt;     &lt;drtn&gt;           \n1 2020-06-01 ca               2.14 2020-06-06  5 days          \n2 2020-06-01 ca               2.14 2020-06-08  7 days          \n3 2020-06-01 ca               2.11 2020-06-09  8 days          \n4 2020-06-01 ca               2.13 2020-06-10  9 days          \n5 2020-06-01 ca               2.20 2020-06-11 10 days          \n6 2020-06-01 ca               2.23 2020-06-12 11 days"
  },
  {
    "objectID": "slides/day1-morning.html#revision-triangle-outpatient-visits-in-wa-2022",
    "href": "slides/day1-morning.html#revision-triangle-outpatient-visits-in-wa-2022",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Revision triangle, Outpatient visits in WA 2022",
    "text": "Revision triangle, Outpatient visits in WA 2022\n\n7-day trailing average to smooth day-of-week effects"
  },
  {
    "objectID": "slides/day1-morning.html#revisions",
    "href": "slides/day1-morning.html#revisions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Revisions",
    "text": "Revisions\nMany data sources are subject to revisions:\n\nCase and death counts are frequently corrected or adjusted by authorities\nMedical claims can take weeks to be submitted and processed\n\n\n\nLab tests and medical records can be backlogged\nSurveys are not completed promptly\n\nAn accurate revision log is crucial for researchers building forecasts\n\n\n\n\n\n\nObvious but crucial\n\n\nA forecast that is made today can only use data we have access to today"
  },
  {
    "objectID": "slides/day1-morning.html#three-types-of-revisions",
    "href": "slides/day1-morning.html#three-types-of-revisions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Three types of revisions",
    "text": "Three types of revisions\n\nSources that don’t revise (provisional and final are the same)\n\nFacebook Survey and Google symptoms\n\nPredictable revisions\n\nClaims data (CHNG) and public health reports aligned by test, hospitalization, or death date\nAlmost always revised upward as additional claims enter the pipeline\n\nRevisions that are large and erratic to predict\n\nCOVID cases and deaths\nThese are aligned by report date"
  },
  {
    "objectID": "slides/day1-morning.html#types-of-revisions---comparison-between-2.-and-3.",
    "href": "slides/day1-morning.html#types-of-revisions---comparison-between-2.-and-3.",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Types of revisions - Comparison between 2. and 3.",
    "text": "Types of revisions - Comparison between 2. and 3.\n\nRevision behavior for two indicators in the HRR containing Charlotte, NC.\n\n\n\nDV-CLI signal (left): regularly revised, but effects fade\nJHU CSSE cases (right) remain “as first reported” until a major correction is made on Oct. 19"
  },
  {
    "objectID": "slides/day1-morning.html#key-takeaways",
    "href": "slides/day1-morning.html#key-takeaways",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nMedical claims revisions\n\nMore systematic and predictable\n\n\n\n\nCOVID-19 case report revisions\n\nErratic and often unpredictable\n\n\n\n\nLarge spikes or anomalies can occur as\n\nReporting backlogs are cleared\n\n\nChanges in case definitions are implemented"
  },
  {
    "objectID": "slides/day1-morning.html#reporting-backlogs---example",
    "href": "slides/day1-morning.html#reporting-backlogs---example",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Reporting backlogs - Example",
    "text": "Reporting backlogs - Example\nIn Bexar County, Texas, during the summer of 2020…\n\nLarge backlog of case reports results in a spike\nAuxilliary signals show no such dramatic increase\nReports themselves may not be trustworthy without context"
  },
  {
    "objectID": "slides/day1-morning.html#reporting-backlogs---key-takeaways",
    "href": "slides/day1-morning.html#reporting-backlogs---key-takeaways",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Reporting backlogs - Key takeaways",
    "text": "Reporting backlogs - Key takeaways\n\n\nReporting issues common across U.S. jurisdictions\n\n\n\nAudits regularly discovered misclassified or unreported cases and deaths\n\n\n\nCross-checking data with external sources from different reporting systems"
  },
  {
    "objectID": "slides/day1-morning.html#what-is-the-epidata-repository",
    "href": "slides/day1-morning.html#what-is-the-epidata-repository",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What is the Epidata repository",
    "text": "What is the Epidata repository\nEpidata: repository of aggregated epi-surveillance time series\nCode is open-source. Signals can be either public or restricted.\n\nTo date, it has accumulated over 5 billion records.\nAt the peak of the pandemic, handled millions of API queries per day.\nMany aren’t available elsewhere\n\n\nData from\n\npublic health reporting, medical insurance claims, medical device data, Google search queries, wastewater, app-based mobility patterns.\n\n\n\n\nAdded value\n\nrevision tracking, anomaly detection, trend detection, smoothing, imputation, geo-temporal-demographic disaggregation."
  },
  {
    "objectID": "slides/day1-morning.html#goals-of-delphi-epidata-platform-and-repository",
    "href": "slides/day1-morning.html#goals-of-delphi-epidata-platform-and-repository",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Goals of Delphi Epidata platform and repository",
    "text": "Goals of Delphi Epidata platform and repository\n\nProvide many aggregated epi-surveillance time-series (“epi-signals”)\n\nMirror signals from other sources, especially if revisions are not tracked \nBe the national historical repository of record & preserve the raw data\n\n\n\n\nBe the go-to place for epi-signal discovery, including those held elsewhere\nAdd value to existing signals and synthesize new ones\n\nVia signal fusion, nowcasting, smoothing\n\n\n\n\n\n\n\n\nMake epi-surveillance more nimble, complete, standardized, robust, and real-time"
  },
  {
    "objectID": "slides/day1-morning.html#features-of-delphi-epidata",
    "href": "slides/day1-morning.html#features-of-delphi-epidata",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Features of Delphi Epidata",
    "text": "Features of Delphi Epidata\n\nBuilt-in support for:\n\nData revisions (“backfill”), including reporting dates and changes\nGeo levels w/ auto-aggregation (e.g. county, state, and nation) and specialized levels (e.g., DMA, sewer sheds)\nDemographic breakdown\nRepresentation for missingness and censoring\nPopulation sizes and fine-grained population density\n\nPre-computed smoothing and normalization (customization planned)\nAccess control\nCode is Open Source.\nSignals are as accessible (w/ API, SDK) as allowed by DUAs"
  },
  {
    "objectID": "slides/day1-morning.html#epidata-documentation",
    "href": "slides/day1-morning.html#epidata-documentation",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Epidata Documentation",
    "text": "Epidata Documentation\n\nDelphi’s Epidata API real-time access to epidemiological surveillance data\n\nThe main endpoint (covidcast) daily updates about COVID-19 and influenza in the U.S.\n\nA variety of other endpoints international historical data for COVID-19, influenza, dengue, norovirus"
  },
  {
    "objectID": "slides/day1-morning.html#some-of-our-data-sources",
    "href": "slides/day1-morning.html#some-of-our-data-sources",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Some of our data sources",
    "text": "Some of our data sources\nOngoing Sources:\n\nInsurance claims\n\n%Covid {inpatient, outpatient}, by county x day\n\nGoogle Symptom searches\n\n7 symptoms groups, by county x day\n\nQuidel/Ortho antigen tests\n\n%Covid by age group x county x day\n\nNCHS Deaths\n\nall-cause, pneumonia, flu, Covid, by state x week\n\nNSSP ED visits\n\n%Covid, %flu, %RSV, by county x week (new!)\n\nNWSS Covid\n\nwastewater by sampling-site x day (in progress)"
  },
  {
    "objectID": "slides/day1-morning.html#some-of-our-data-sources-1",
    "href": "slides/day1-morning.html#some-of-our-data-sources-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Some of our data sources",
    "text": "Some of our data sources\nActive during pandemic, could be restarted for the next PHE:\n\nHHS Hosp/ICU beds\n\nCovid, flu, by {age-group x {state x day, facility x week}}\n\nCTIS (“Delphi Facebook Survey”)\n\nmany dozens of questions, by county x day\n\nSTLT-reported\n\n{cases, deaths} via {JHU, USAFacts}, by country x day\n\nSafegraph mobility\n\nmisc measures by {county x day, county x week}"
  },
  {
    "objectID": "slides/day1-morning.html#severity-pyramid",
    "href": "slides/day1-morning.html#severity-pyramid",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Severity pyramid",
    "text": "Severity pyramid"
  },
  {
    "objectID": "slides/day1-morning.html#finding-data-sources-and-signals-of-interest",
    "href": "slides/day1-morning.html#finding-data-sources-and-signals-of-interest",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Finding data sources and signals of interest",
    "text": "Finding data sources and signals of interest\nDiverse Data Streams\n\nVariety of Data: medical claims data, cases and deaths, mobility data\nGeographic Coverage: includes multiple regions, making it comprehensive yet complex\nChallenge: difficulty in pinpointing the specific data stream of interest\n\nUsing the Documentation\n\nComprehensive Listings: details on data sources and signals for various endpoints\n\nDocs are great for a deep dive into the data, while the apps & tools are useful to see what’s available…"
  },
  {
    "objectID": "slides/day1-morning.html#some-tools-to-explore-more-easily",
    "href": "slides/day1-morning.html#some-tools-to-explore-more-easily",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Some tools to explore more easily",
    "text": "Some tools to explore more easily\nSignal discovery app, find available epi-signals in Delphi Epidata and elsewhere in the community\n\nSignal visualization tool\n Signal dashboard\n “classic” map-based version visualize a core set of COVID-19 and flu indicators\n Covidcast signal export app\n Dashboard builder"
  },
  {
    "objectID": "slides/day1-morning.html#installing-epidatr",
    "href": "slides/day1-morning.html#installing-epidatr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Installing {epidatr}",
    "text": "Installing {epidatr}\n(you already did this, but just for posterity…)\nInstall the CRAN version\n\n# Install the CRAN version\npak::pkg_install(\"epidatr\")\n\n\nor the development version\n\n# Install the development version from the GitHub dev branch\npak::pkg_install(\"cmu-delphi/epidatr@dev\")\n\nThe CRAN listing is here."
  },
  {
    "objectID": "slides/day1-morning.html#python",
    "href": "slides/day1-morning.html#python",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Python",
    "text": "Python\nIn Python, install delphi-epidata from PyPI with\npip install delphi-epidata\n\ndelphi-epidata is soon to be replaced with epidatpy.\n# Latest dev version\npip install -e \"git+https://github.com/cmu-delphi/epidatpy.git#egg=epidatpy\"\n\n# PyPI version (not yet available)\npip install epidatpy"
  },
  {
    "objectID": "slides/day1-morning.html#using-epidatr-and-epidatpy",
    "href": "slides/day1-morning.html#using-epidatr-and-epidatpy",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using {epidatr} and {epidatpy}",
    "text": "Using {epidatr} and {epidatpy}\n\nlibrary(epidatr)\nhhs_flu_nc &lt;- pub_covidcast(\n  source = 'hhs', \n  signals = 'confirmed_admissions_influenza_1d', \n  geo_type = 'state', \n  time_type = 'day', \n  geo_values = 'nc',\n  time_values = c(20240401, 20240405:20240414)\n)\nhead(hhs_flu_nc, n = 3)\n\n\n\n# A tibble: 3 × 15\n  geo_value signal     source geo_type time_type time_value direction issue     \n  &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;date&gt;         &lt;dbl&gt; &lt;date&gt;    \n1 nc        confirmed… hhs    state    day       2024-04-01        NA 2024-04-22\n2 nc        confirmed… hhs    state    day       2024-04-05        NA 2024-04-22\n3 nc        confirmed… hhs    state    day       2024-04-06        NA 2024-04-22\n# ℹ 7 more variables: lag &lt;dbl&gt;, missing_value &lt;dbl&gt;, missing_stderr &lt;dbl&gt;,\n#   missing_sample_size &lt;dbl&gt;, value &lt;dbl&gt;, stderr &lt;dbl&gt;, sample_size &lt;dbl&gt;\n\n\n\nPython equivalent:\nres = Epidata.covidcast('hhs', 'confirmed_admissions_influenza_1d', 'day', 'state', [20240401, Epidata.range(20240405, 20240414)], 'nc')\nprint(res['result'], res['message'], len(res['epidata']))"
  },
  {
    "objectID": "slides/day1-morning.html#api-keys",
    "href": "slides/day1-morning.html#api-keys",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "API keys",
    "text": "API keys\n\nAnyone may access the Epidata API anonymously without providing any personal data!!\nAnonymous API access is subject to some restrictions: public datasets only; 60 requests per hour; only two parameters may have multiple selections\nAPI key grants priviledged access; can be obtained by registering with us\nPrivileges of registration: no rate limit; no limit on multiple selections\nWe just want to know which signals people care about and ensure we’re providing benefit\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe {epidatr} client automatically searches for the key in the DELPHI_EPIDATA_KEY environment variable.\nWe recommend storing it in your .Renviron file, which R reads by default.\nMore on setting your API key here."
  },
  {
    "objectID": "slides/day1-morning.html#interactive-tooling-in-r",
    "href": "slides/day1-morning.html#interactive-tooling-in-r",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Interactive tooling in R",
    "text": "Interactive tooling in R\nFind sources and signals in R?\nFunctions to enhance data discovery in {epidatr}:\n\navail_endpoints()\n\nLists all endpoints with brief descriptions\n\n\nHighlights endpoints that cover non-US locations\n\n\n\navail_endpoints()\n\n# A tibble: 28 × 2\n   Endpoint                          Description                                \n   &lt;chr&gt;                             &lt;chr&gt;                                      \n 1 pub_covid_hosp_facility()         COVID hospitalizations by facility         \n 2 pub_covid_hosp_facility_lookup()  Helper for finding COVID hospitalization f…\n 3 pub_covid_hosp_state_timeseries() COVID hospitalizations by state            \n 4 pub_covidcast()                   Various COVID and flu signals via the COVI…\n 5 pub_covidcast_meta()              Metadata for the COVIDcast endpoint        \n 6 pub_delphi()                      Delphi's ILINet outpatient doctor visits f…\n 7 pub_dengue_nowcast()              Delphi's PAHO dengue nowcasts (North and S…\n 8 pub_ecdc_ili()                    ECDC ILI incidence (Europe)                \n 9 pub_flusurv()                     CDC FluSurv flu hospitalizations           \n10 pub_fluview()                     CDC FluView ILINet outpatient doctor visits\n11 pub_fluview_clinical()            CDC FluView flu tests from clinical labs   \n12 pub_fluview_meta()                Metadata for the FluView endpoint          \n13 pub_gft()                         Google Flu Trends flu search volume        \n14 pub_kcdc_ili()                    KCDC ILI incidence (Korea)                 \n15 pub_meta()                        Metadata for the Delphi Epidata API        \n16 pub_nidss_dengue()                NIDSS dengue cases (Taiwan)                \n17 pub_nidss_flu()                   NIDSS flu doctor visits (Taiwan)           \n18 pub_nowcast()                     Delphi's ILI Nearby nowcasts               \n19 pub_paho_dengue()                 PAHO dengue data (North and South America) \n20 pub_wiki()                        Wikipedia webpage counts by article        \n21 pvt_cdc()                         CDC total and by topic webpage visits      \n22 pvt_dengue_sensors()              PAHO dengue digital surveillance sensors (…\n23 pvt_ght()                         Google Health Trends health topics search …\n24 pvt_meta_norostat()               Metadata for the NoroSTAT endpoint         \n25 pvt_norostat()                    CDC NoroSTAT norovirus outbreaks           \n26 pvt_quidel()                      Quidel COVID-19 and influenza testing data \n27 pvt_sensors()                     Influenza and dengue digital surveillance …\n28 pvt_twitter()                     HealthTweets total and influenza-related t…"
  },
  {
    "objectID": "slides/day1-morning.html#using-the-covidcast_epidata",
    "href": "slides/day1-morning.html#using-the-covidcast_epidata",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using the covidcast_epidata()",
    "text": "Using the covidcast_epidata()\ncovidcast_epidata() details for signals at the COVIDcast endpoint\n\nAssign to an object\ncc_ed &lt;- covidcast_epidata()\n\nList data sources\n\ncc_ed$sources, with tibbles describing the included signals\n\nEditor Support\n\nIn RStudio or similar editors, use tab completion to explore:\n\n\ncc_ed$source$ to view available data sources.\n\n\ncc_ed$signals$ to see signal options with autocomplete assistance.\n\nFiltering Convenience\n\nSignals are prefixed with their source for easier navigation\n\n\ncc_ed &lt;- covidcast_epidata()\nhead(cc_ed$sources, n = 2) # head(list, n = 2) will print the first two elements of the list"
  },
  {
    "objectID": "slides/day1-morning.html#fetching-data---covidcast-main-endpoint",
    "href": "slides/day1-morning.html#fetching-data---covidcast-main-endpoint",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetching data - COVIDcast main endpoint",
    "text": "Fetching data - COVIDcast main endpoint\n\npub_covidcast() accesses the covidcast endpoint\nNeed to specify the following arguments…\n\nsource: Data source name\nsignals: Signal name\ngeo_type: Geographic level\ntime_type: Time resolution\ngeo_values: Location(s)\ntime_values: times of interest"
  },
  {
    "objectID": "slides/day1-morning.html#fetching-data---covidcast-main-endpoint-1",
    "href": "slides/day1-morning.html#fetching-data---covidcast-main-endpoint-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetching data - COVIDcast main endpoint",
    "text": "Fetching data - COVIDcast main endpoint\n\nlibrary(epidatr)\nlibrary(dplyr)\n\njhu_us_cases &lt;- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_7dav_incidence_prop\", \n  geo_type = \"nation\",\n  time_type = \"day\",\n  geo_values = \"us\",\n  time_values = epirange(20210101, 20210401)\n)\n\n\n\n# A tibble: 3 × 8\n  geo_value signal             source geo_type time_value issue        lag value\n  &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;  &lt;fct&gt;    &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 us        confirmed_7dav_in… jhu-c… nation   2021-01-01 2023-03-10   798  61.9\n2 us        confirmed_7dav_in… jhu-c… nation   2021-01-02 2023-03-10   797  64.2\n3 us        confirmed_7dav_in… jhu-c… nation   2021-01-03 2023-03-10   796  67.1\n\n\nvalue is the requested signal\n\nthe number of daily new confirmed COVID-19 cases per 100,000 population\nfrom January to April 2021"
  },
  {
    "objectID": "slides/day1-morning.html#returned-data---covidcast-main-endpoint",
    "href": "slides/day1-morning.html#returned-data---covidcast-main-endpoint",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Returned data - COVIDcast main endpoint",
    "text": "Returned data - COVIDcast main endpoint\npub_covidcast() outputs a tibble, where each row represents one observation\nEach observation is aggregated by time and by geographic region\n\ntime_value: time period when the events occurred.\ngeo_value: geographic region where the events occurred.\nvalue: estimated value.\nstderr: standard error of the estimate, usually referring to the sampling error.\nsample_size: number of events used in the estimation."
  },
  {
    "objectID": "slides/day1-morning.html#returned-data---covidcast-main-endpoint-1",
    "href": "slides/day1-morning.html#returned-data---covidcast-main-endpoint-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Returned data - COVIDcast main endpoint",
    "text": "Returned data - COVIDcast main endpoint\nAlso reports\n\nissue: The time this observation was published\nlag: The period between when the events occurred and when the observation was published\n\nTracks the complete revision history of the signal\nAllows for historical reconstructions of information that was available at a specific times\nMore on this soon!"
  },
  {
    "objectID": "slides/day1-morning.html#geographic-levels",
    "href": "slides/day1-morning.html#geographic-levels",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Geographic levels",
    "text": "Geographic levels\nSignals are available at different geographic levels, depending on the endpoint\nconfirmed_7dav_incidence_prop is available by state\nChange geo_type and geo_values in the previous example\n\n# Obtain the most up-to-date version of the smoothed covid-like illness (CLI)\n# signal from the COVID-19 Trends and Impact survey for all states\njhu_state_cases &lt;- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_7dav_incidence_prop\",\n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"*\",\n  time_values = epirange(20210101, 20210401)\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal             source geo_type time_value issue        lag value\n  &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;  &lt;fct&gt;    &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 ak        confirmed_7dav_in… jhu-c… state    2021-01-01 2023-03-03   791  35.9\n2 al        confirmed_7dav_in… jhu-c… state    2021-01-01 2023-03-03   791  67.7\n3 ar        confirmed_7dav_in… jhu-c… state    2021-01-01 2023-03-03   791  76.2\n4 as        confirmed_7dav_in… jhu-c… state    2021-01-01 2023-03-03   791   0  \n5 az        confirmed_7dav_in… jhu-c… state    2021-01-01 2023-03-03   791  83.4\n6 ca        confirmed_7dav_in… jhu-c… state    2021-01-01 2023-03-10   798 104."
  },
  {
    "objectID": "slides/day1-morning.html#covidcast-main-endpoint---example-query",
    "href": "slides/day1-morning.html#covidcast-main-endpoint---example-query",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "COVIDcast main endpoint - Example query",
    "text": "COVIDcast main endpoint - Example query\nCounty geo_values are FIPS codes: Orange County, California.\n\njhu_county_cases &lt;- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_7dav_incidence_prop\",\n  geo_type = \"county\",\n  time_type = \"day\",\n  time_values = epirange(20210101, 20210401),\n  geo_values = \"06059\"\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal             source geo_type time_value issue        lag value\n  &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;  &lt;fct&gt;    &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 06059     confirmed_7dav_in… jhu-c… county   2021-01-01 2023-03-03   791  105.\n2 06059     confirmed_7dav_in… jhu-c… county   2021-01-02 2023-03-03   790  107.\n3 06059     confirmed_7dav_in… jhu-c… county   2021-01-03 2023-03-03   789  108.\n4 06059     confirmed_7dav_in… jhu-c… county   2021-01-04 2023-03-03   788  107.\n5 06059     confirmed_7dav_in… jhu-c… county   2021-01-05 2023-03-03   787  105.\n6 06059     confirmed_7dav_in… jhu-c… county   2021-01-06 2023-03-03   786  104.\n\n\n\n\n\nThe covidcast endpoint supports * in its time and geo fields.\nSignal values for all available counties: replace geo_values = \"06059\" with geo_values = \"*\"."
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints: Hospitalizations",
    "text": "Example queries - Other endpoints: Hospitalizations\nCOVID-19 Hospitalization: Facility Lookup\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp_facility_lookup.html \n\npub_covid_hosp_facility_lookup(city = \"southlake\")\n\n# A tibble: 2 × 10\n  hospital_pk state ccn    hospital_name    address city  zip   hospital_subtype\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           \n1 450888      TX    450888 TEXAS HEALTH HA… 1545 E… SOUT… 76092 Short Term      \n2 670132      TX    670132 METHODIST SOUTH… 421 E … SOUT… 76092 Short Term      \n# ℹ 2 more variables: fips_code &lt;chr&gt;, is_metro_micro &lt;dbl&gt;\n\n\n\npub_covid_hosp_facility_lookup(state = \"WY\") |&gt; head()\n\n# A tibble: 6 × 10\n  hospital_pk     state ccn   hospital_name address city  zip   hospital_subtype\n  &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           \n1 100 LANCASTER … WY    2020… 42091         &lt;NA&gt;    [C39… MAIN  390195          \n2 2333 BIDDLE AVE WY    2020… 26163         POINT … [C23… HENRY 230146          \n3 2333 BIDDLE AV… WY    2020… 26163         POINT … [C23… SELEC 232031          \n4 2752 CENTURY B… WY    2020… 42011         POINT … [C39… SURGI 390316          \n5 310 SOUTH FALL… WY    2020… 05037         POINT … [C04… CROSS 041307          \n6 5200 FAIRVIEW … WY    2020… 27025         POINT … [C24… FAIRV 240050          \n# ℹ 2 more variables: fips_code &lt;chr&gt;, is_metro_micro &lt;dbl&gt;\n\n# A non-example (there is no city called New York in Wyoming)\n# pub_covid_hosp_facility_lookup(state = \"WY\", city = \"New York\")"
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations-1",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints: Hospitalizations",
    "text": "Example queries - Other endpoints: Hospitalizations\nCOVID-19 Hospitalization by Facility\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp_facility.html \n\npub_covid_hosp_facility(\n  hospital_pks = \"100075\",\n  collection_weeks = epirange(20200101, 20200501)\n) |&gt; head()\n\n# A tibble: 6 × 113\n  hospital_pk state ccn    hospital_name    address city  zip   hospital_subtype\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           \n1 100075      FL    100075 ST JOSEPHS HOSP… 3001 W… TAMPA 33677 Short Term      \n2 100075      FL    100075 ST JOSEPHS HOSP… 3001 W… TAMPA 33677 Short Term      \n3 100075      FL    100075 ST JOSEPHS HOSP… 3001 W… TAMPA 33677 Short Term      \n4 100075      FL    100075 ST JOSEPHS HOSP… 3001 W… TAMPA 33677 Short Term      \n5 100075      FL    100075 ST JOSEPHS HOSP… 3001 W… TAMPA 33677 Short Term      \n6 100075      FL    100075 ST JOSEPHS HOSP… 3001 W… TAMPA 33677 Short Term      \n# ℹ 105 more variables: fips_code &lt;chr&gt;, geocoded_hospital_address &lt;chr&gt;,\n#   hhs_ids &lt;chr&gt;, publication_date &lt;date&gt;, collection_week &lt;date&gt;,\n#   is_metro_micro &lt;lgl&gt;, total_beds_7_day_sum &lt;dbl&gt;,\n#   all_adult_hospital_beds_7_day_sum &lt;dbl&gt;,\n#   all_adult_hospital_inpatient_beds_7_day_sum &lt;dbl&gt;,\n#   inpatient_beds_used_7_day_sum &lt;dbl&gt;,\n#   all_adult_hospital_inpatient_bed_occupied_7_day_sum &lt;dbl&gt;, …"
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations-2",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-hospitalizations-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints: Hospitalizations",
    "text": "Example queries - Other endpoints: Hospitalizations\nCOVID-19 Hospitalization by State\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp.html \n\npub_covid_hosp_state_timeseries(states = \"MA\", dates = \"20200510\")\n\n# A tibble: 1 × 118\n  state geocoded_state issue      date       critical_staffing_shortage_today_…¹\n  &lt;chr&gt; &lt;lgl&gt;          &lt;date&gt;     &lt;date&gt;     &lt;lgl&gt;                              \n1 MA    NA             2024-05-03 2020-05-10 FALSE                              \n# ℹ abbreviated name: ¹​critical_staffing_shortage_today_yes\n# ℹ 113 more variables: critical_staffing_shortage_today_no &lt;lgl&gt;,\n#   critical_staffing_shortage_today_not_reported &lt;lgl&gt;,\n#   critical_staffing_shortage_anticipated_within_week_yes &lt;lgl&gt;,\n#   critical_staffing_shortage_anticipated_within_week_no &lt;lgl&gt;,\n#   critical_staffing_shortage_anticipated_within_week_not_reported &lt;lgl&gt;,\n#   hospital_onset_covid &lt;dbl&gt;, hospital_onset_covid_coverage &lt;dbl&gt;, …"
  },
  {
    "objectID": "slides/day1-morning.html#example-queries---other-endpoints-flu-endpoints",
    "href": "slides/day1-morning.html#example-queries---other-endpoints-flu-endpoints",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example queries - Other endpoints: Flu endpoints",
    "text": "Example queries - Other endpoints: Flu endpoints\nFluSurv hospitalization data – Data ends around 2020\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/flusurv.html \n\npub_flusurv(locations = \"ca\", epiweeks = 202001) \n\nFluview data – Remains active\n API docs: https://cmu-delphi.github.io/delphi-epidata/api/fluview.html \n\npub_fluview(regions = \"nat\", epiweeks = epirange(201201, 202001))\n\n\n\n\n\n\n\nPublic vs private endpoints\n\n\nPublic endpoints are accessed with functions starting with pub_\nPrivate data can be used with pvt_ for authorized API keys\nStore the key in your .Reviron file, or set is as an environment variables\nExamples"
  },
  {
    "objectID": "slides/day1-morning.html#signal-metadata",
    "href": "slides/day1-morning.html#signal-metadata",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Signal metadata",
    "text": "Signal metadata\nSome endpoints provide additional metadata\n\nTime Information: available time frames and most recent update\nGeography Information: available geographies\n\nMetadata accessors\n\npub_covidcast_meta(): metadata for COVIDcast\npub_fluview_meta(): metadata for FluView\npub_meta(): general metadata for the Delphi Epidata API"
  },
  {
    "objectID": "slides/day1-morning.html#versioned-data-in-epidatr",
    "href": "slides/day1-morning.html#versioned-data-in-epidatr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Versioned data in {epidatr}",
    "text": "Versioned data in {epidatr}\nEpidata API contains each signal’s estimate, location, date, and update timeline\nRequesting Specific Data Versions:\n\nUse as_of or issues to specify data availability\nas_of always fetches one version\nissues can fetch multiple\nOnly one may be used at a time\nNot all endpoints support both"
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-data-as-of-a-specific-date",
    "href": "slides/day1-morning.html#obtaining-data-as-of-a-specific-date",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining data “as of” a specific date",
    "text": "Obtaining data “as of” a specific date\nDoctor Visits (from the covidcast endpoint)\n\nThe percentage of outpatient visits w/ Covid-like illness\nPennsylvania on May 1, 2020:\n\n\ndv_pa_as_of &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = \"2020-05-01\",\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  as_of = \"2020-05-07\"\n)\n\n\n\n# A tibble: 1 × 7\n  geo_value signal           source        time_value issue        lag value\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-visits 2020-05-01 2020-05-07     6  2.58\n\n\n\nInitial estimate issued on May 7, 2020\nDue to delay from reporting and ingestion by the API"
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-data-as-of-a-specific-date-1",
    "href": "slides/day1-morning.html#obtaining-data-as-of-a-specific-date-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining data “as of” a specific date",
    "text": "Obtaining data “as of” a specific date\nDefault behaviour: unspecified as_of, get the most recent data\n\ndv_pa_final &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = \"2020-05-01\",\n  geo_type = \"state\",\n  geo_values = \"pa\"\n)\n\n\n\n# A tibble: 1 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  5.97     NA\n\n\nEstimate changed substantially:\n\nIncreased to ~6% from &lt;3%"
  },
  {
    "objectID": "slides/day1-morning.html#versioning-is-important-for-forecasting",
    "href": "slides/day1-morning.html#versioning-is-important-for-forecasting",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Versioning is important for forecasting",
    "text": "Versioning is important for forecasting\n\n\nBacktesting requires using data that would have been available at the time\n\n\n\nNot later updates\n\n\n\nOverly optimistic"
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-multiple-specific-issues-for-one-state",
    "href": "slides/day1-morning.html#obtaining-multiple-specific-issues-for-one-state",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining multiple specific issues for one state",
    "text": "Obtaining multiple specific issues for one state\nRequest all issues in a certain time period\n\ndv_pa_issues &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = \"2020-05-01\",\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  issues = epirange(\"2020-05-01\", \"2020-05-15\")\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-07     6  2.58     NA\n2 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-08     7  3.28     NA\n3 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-09     8  3.32     NA\n4 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-12    11  3.59     NA\n5 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-13    12  3.63     NA\n6 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-14    13  3.66     NA"
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-multiple-issues-for-one-state",
    "href": "slides/day1-morning.html#obtaining-multiple-issues-for-one-state",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining multiple issues for one state",
    "text": "Obtaining multiple issues for one state\nTo get all issues up to a specific date, set an extreme lower bound\n\ndv_pa_issues_sub &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = \"2020-05-01\",\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  issues = epirange(\"1900-01-01\", \"2020-05-15\")\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-07     6  2.58     NA\n2 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-08     7  3.28     NA\n3 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-09     8  3.32     NA\n4 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-12    11  3.59     NA\n5 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-13    12  3.63     NA\n6 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-14    13  3.66     NA\n\n\nNo change here • Can matter if the latency or reporting lag is unknown\nAPI docs show the earliest date available."
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-multiple-issues-for-one-state-1",
    "href": "slides/day1-morning.html#obtaining-multiple-issues-for-one-state-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining multiple issues for one state",
    "text": "Obtaining multiple issues for one state\nAt some point, nothing changes • It is finalized • That will be the “last” issue\n\ndv_pa_issues_all &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = \"2020-05-01\",\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  issues = epirange(\"1900-01-01\", \"2024-12-11\") # From the 1900s to today\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-06-29    59  5.99     NA\n2 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-06-30    60  5.99     NA\n3 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-01    61  5.95     NA\n4 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-02    62  5.97     NA\n5 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-03    63  5.97     NA\n6 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  5.97     NA\n\n\n\nAvoid queries with too-late minimum too-early maximum issue\nCould be misleading results"
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-all-issues-for-one-state",
    "href": "slides/day1-morning.html#obtaining-all-issues-for-one-state",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining all issues for one state",
    "text": "Obtaining all issues for one state\n\ndv_pa_issues_star &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-07\"),\n  geo_type = \"state\",\n  geo_values = \"pa\",\n  issues = \"*\"\n)\n\n\n\n# A tibble: 8 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-07     6  2.58     NA\n2 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-08     7  3.28     NA\n3 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-09     8  3.32     NA\n4 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-12    11  3.59     NA\n5 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-13    12  3.63     NA\n6 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-14    13  3.66     NA\n7 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-15    14  3.66     NA\n8 pa        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-16    15  3.61     NA"
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-all-issues-for-all-states",
    "href": "slides/day1-morning.html#obtaining-all-issues-for-all-states",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining all issues for all states",
    "text": "Obtaining all issues for all states\nUsing * gives all available\n\ndv_state_issues_star &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-07\"),\n  geo_type = \"state\",\n  geo_values = \"*\",\n  issues = \"*\"\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-07     6  1.61     NA\n2 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-08     7  2.40     NA\n3 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-09     8  2.38     NA\n4 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-12    11  2.38     NA\n5 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-13    12  2.36     NA\n6 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-05-14    13  2.36     NA"
  },
  {
    "objectID": "slides/day1-morning.html#obtaining-one-issue-for-all-states",
    "href": "slides/day1-morning.html#obtaining-one-issue-for-all-states",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Obtaining one issue for all states",
    "text": "Obtaining one issue for all states\n\nDefaults are intended to be “what you would expect”\n\ndv_state_default &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  time_values = epirange(\"2020-05-01\", \"2020-05-07\"),\n  geo_type = \"state\"\n)\n\n\n\n# A tibble: 6 × 8\n  geo_value signal           source     time_value issue        lag value stderr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 ak        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  5.72     NA\n2 al        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  2.74     NA\n3 ar        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  4.23     NA\n4 az        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  2.78     NA\n5 ca        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  4.25     NA\n6 co        smoothed_adj_cli doctor-vi… 2020-05-01 2020-07-04    64  8.77     NA\n\n\n\n\nmost recent issue\nall states"
  },
  {
    "objectID": "slides/day1-morning.html#main-takeaways",
    "href": "slides/day1-morning.html#main-takeaways",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Main takeaways",
    "text": "Main takeaways\n\nDelphi Epidata: platform for real-time epidemic data\n\nprovides (aggregated) signals for tracking and forecasting\nsources like health records, mobility patterns, and more.\n\n\n\n\nEpidata API: delivers up-to-date, granular epidemiological data + historical versions.\n\n\n\n{epidatr}: Client package for R\n\n\n\nVersioned Data and Latency:\n\nas_of: One version; the specific date when the data was last updated\nissues: Multiple versions; with different as_of dates\n\n\nManages the record of revisions for transparency and accuracy in data analysis."
  },
  {
    "objectID": "slides/appendix-tidyverse.html#section",
    "href": "slides/appendix-tidyverse.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Background on {tidyverse}",
    "text": "Background on {tidyverse}\nInsightNet Forecasting Workshop 2024\n\nAlice Cima, Rachel Lobay, Daniel McDonald, Ryan Tibshirani\nwith thanks to Delphi Tooling & Forecasting Team: Logan Brooks, Nat DeFries, Dmitry Shemetov, David Webber\n11 December – Afternoon"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#down-with-spreadsheets-for-data-manipulation",
    "href": "slides/appendix-tidyverse.html#down-with-spreadsheets-for-data-manipulation",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Down with spreadsheets for data manipulation",
    "text": "Down with spreadsheets for data manipulation\n\nSpreadsheets make it difficult to rerun analyses consistently.\nUsing R (and {dplyr}) allows for:\n\nReproducibility\nEase of modification\n\nRecommendation: Avoid manual edits; instead, use code for transformations.\nLet’s see what we mean by this…"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#introduction-to-dplyr",
    "href": "slides/appendix-tidyverse.html#introduction-to-dplyr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Introduction to dplyr",
    "text": "Introduction to dplyr\n\ndplyr is a powerful package in R for data manipulation.\nIt is part of the tidyverse, which includes a collection of packages designed to work together… Here’s some of it’s greatest hits:\n\n\n  Source"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#introduction-to-dplyr-1",
    "href": "slides/appendix-tidyverse.html#introduction-to-dplyr-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Introduction to dplyr",
    "text": "Introduction to dplyr\n\nTo load dplyr you may simply load the tidyverse package:\n\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)  # Load tidyverse, which includes dplyr & tidyr"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#introduction-to-dplyr-2",
    "href": "slides/appendix-tidyverse.html#introduction-to-dplyr-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Introduction to dplyr",
    "text": "Introduction to dplyr\nOur focus will be on basic operations like selecting and filtering data.\n\n\nSource"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#downloading-jhu-csse-covid-19-case-data",
    "href": "slides/appendix-tidyverse.html#downloading-jhu-csse-covid-19-case-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Downloading JHU CSSE COVID-19 case data",
    "text": "Downloading JHU CSSE COVID-19 case data\n\nLet’s start with something familiar… Here’s a task for you:\nUse pub_covidcast() to download JHU CSSE COVID-19 confirmed case data (confirmed_incidence_num) for CA, NC, and NY from March 1, 2022 to March 31, 2022 as of January 1, 2024.\nTry this for yourself. Then click the dropdown on the next slide to check your work…"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#downloading-jhu-csse-covid-19-case-data-1",
    "href": "slides/appendix-tidyverse.html#downloading-jhu-csse-covid-19-case-data-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Downloading JHU CSSE COVID-19 case data",
    "text": "Downloading JHU CSSE COVID-19 case data\n\n\nCode\nlibrary(epidatr)\n\ncases_df &lt;- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_incidence_num\",\n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"ca,nc,ny\",\n  time_values = epirange(20220301, 20220331),\n  as_of = as.Date(\"2024-01-01\")\n)\n\n\nNow we only really need a few columns here…\n\ncases_df &lt;- cases_df |&gt; \n  select(geo_value, time_value, raw_cases = value) # We'll talk more about this soon :)"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#ways-to-inspect-the-dataset",
    "href": "slides/appendix-tidyverse.html#ways-to-inspect-the-dataset",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Ways to inspect the dataset",
    "text": "Ways to inspect the dataset\nUse head() to view the first six row of the data\n\nhead(cases_df)  # First 6 rows\n\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 nc        2022-03-01      1231\n3 ny        2022-03-01      1487\n4 ca        2022-03-02      7044\n5 nc        2022-03-02      2243\n6 ny        2022-03-02      1889\n\n\nand tail to view the last six\n\n\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-30      3785\n2 nc        2022-03-30      1067\n3 ny        2022-03-30      3127\n4 ca        2022-03-31      4533\n5 nc        2022-03-31      1075\n6 ny        2022-03-31      4763"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#ways-to-inspect-the-dataset-1",
    "href": "slides/appendix-tidyverse.html#ways-to-inspect-the-dataset-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Ways to inspect the dataset",
    "text": "Ways to inspect the dataset\nNow, for our first foray into the tidyverse…\nUse glimpse() to get a compact overview of the dataset.\n\nglimpse(cases_df)\n\nRows: 93\nColumns: 3\n$ geo_value  &lt;chr&gt; \"ca\", \"nc\", \"ny\", \"ca\", \"nc\", \"ny\", \"ca\", \"nc\", \"ny\", \"ca\",…\n$ time_value &lt;date&gt; 2022-03-01, 2022-03-01, 2022-03-01, 2022-03-02, 2022-03-02…\n$ raw_cases  &lt;dbl&gt; 4310, 1231, 1487, 7044, 2243, 1889, 7509, 2377, 2390, 3586,…"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#creating-tibbles",
    "href": "slides/appendix-tidyverse.html#creating-tibbles",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Creating tibbles",
    "text": "Creating tibbles\n\nTibbles: Modern data frames with enhanced features.\nRows represent observations (or cases).\nColumns represent variables (or features).\nYou can create tibbles manually using the tibble() function.\n\n\ntibble(x = letters, y = 1:26)\n\n# A tibble: 26 × 2\n   x         y\n   &lt;chr&gt; &lt;int&gt;\n 1 a         1\n 2 b         2\n 3 c         3\n 4 d         4\n 5 e         5\n 6 f         6\n 7 g         7\n 8 h         8\n 9 i         9\n10 j        10\n# ℹ 16 more rows"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#selecting-columns-with-select",
    "href": "slides/appendix-tidyverse.html#selecting-columns-with-select",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Selecting columns with select()",
    "text": "Selecting columns with select()\nThe select() function is used to pick specific columns from your dataset.\n\nselect(cases_df, geo_value, time_value)  # Select the 'geo_value' and 'time_value' columns\n\n# A tibble: 93 × 2\n   geo_value time_value\n   &lt;chr&gt;     &lt;date&gt;    \n 1 ca        2022-03-01\n 2 nc        2022-03-01\n 3 ny        2022-03-01\n 4 ca        2022-03-02\n 5 nc        2022-03-02\n 6 ny        2022-03-02\n 7 ca        2022-03-03\n 8 nc        2022-03-03\n 9 ny        2022-03-03\n10 ca        2022-03-04\n# ℹ 83 more rows"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#selecting-columns-with-select-1",
    "href": "slides/appendix-tidyverse.html#selecting-columns-with-select-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Selecting columns with select()",
    "text": "Selecting columns with select()\nYou can exclude columns by prefixing the column names with a minus sign -.\n\nselect(cases_df, -raw_cases)  # Exclude the 'raw_cases' column from the dataset\n\n# A tibble: 93 × 2\n   geo_value time_value\n   &lt;chr&gt;     &lt;date&gt;    \n 1 ca        2022-03-01\n 2 nc        2022-03-01\n 3 ny        2022-03-01\n 4 ca        2022-03-02\n 5 nc        2022-03-02\n 6 ny        2022-03-02\n 7 ca        2022-03-03\n 8 nc        2022-03-03\n 9 ny        2022-03-03\n10 ca        2022-03-04\n# ℹ 83 more rows"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#extracting-columns-with-pull",
    "href": "slides/appendix-tidyverse.html#extracting-columns-with-pull",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extracting columns with pull()",
    "text": "Extracting columns with pull()\n\npull(): Extract a column as a vector.\nLet’s try this with the cases column…\n\n\npull(cases_df, raw_cases) \n\n [1] 4310 1231 1487 7044 2243 1889 7509 2377 2390 3586 2646  350 1438    0 3372\n[16] 6465    0 2343 6690 4230 1033 3424  894 1025 4591 1833 1691 5359 1783 1747\n[31] 2713 1849 2229 1623    0 1396 5151    0 2202 4826 3130  982 1831  649 3128\n[46] 3706    0 2039 6143 2742 2356 4204 1740 2052 3256    0 2188 4659    0 2667\n[61] 5499 2508 1177 3004  819 1603 3943 1602  551 3550 1288 6596 1960 1224 3542\n[76] 1035    0    0 3384    0 5908 2811 2291 2286 1846  624 2394 3785 1067 3127\n[91] 4533 1075 4763"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#subsetting-rows-with-filter",
    "href": "slides/appendix-tidyverse.html#subsetting-rows-with-filter",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Subsetting rows with filter()",
    "text": "Subsetting rows with filter()\n\n  Artwork by @allison_horst"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#subsetting-rows-with-filter-1",
    "href": "slides/appendix-tidyverse.html#subsetting-rows-with-filter-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Subsetting rows with filter()",
    "text": "Subsetting rows with filter()\n\nThe filter() function allows you to subset rows that meet specific conditions.\nConditions regard column values, such as filtering for only NC or cases higher than some threshold.\nThis enables you to narrow down your dataset to focus on relevant data.\n\n\nfilter(cases_df, geo_value == \"nc\", raw_cases &gt; 500)  # Filter for NC with raw daily cases &gt; 500\n\n# A tibble: 22 × 3\n   geo_value time_value raw_cases\n   &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n 1 nc        2022-03-01      1231\n 2 nc        2022-03-02      2243\n 3 nc        2022-03-03      2377\n 4 nc        2022-03-04      2646\n 5 nc        2022-03-07      4230\n 6 nc        2022-03-08       894\n 7 nc        2022-03-09      1833\n 8 nc        2022-03-10      1783\n 9 nc        2022-03-11      1849\n10 nc        2022-03-14      3130\n# ℹ 12 more rows"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#combining-select-and-filter-functions",
    "href": "slides/appendix-tidyverse.html#combining-select-and-filter-functions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Combining select() and filter() functions",
    "text": "Combining select() and filter() functions\n\nYou can further combine select() and filter() to further refine the dataset.\nUse select() to choose columns and filter() to narrow down rows.\nThis helps in extracting the exact data needed for analysis.\n\n\nselect(filter(cases_df, geo_value == \"nc\", raw_cases &gt; 1000), time_value, raw_cases) |&gt; \n  head()\n\n# A tibble: 6 × 2\n  time_value raw_cases\n  &lt;date&gt;         &lt;dbl&gt;\n1 2022-03-01      1231\n2 2022-03-02      2243\n3 2022-03-03      2377\n4 2022-03-04      2646\n5 2022-03-07      4230\n6 2022-03-09      1833"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#using-the-pipe-operator",
    "href": "slides/appendix-tidyverse.html#using-the-pipe-operator",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using the pipe operator |>",
    "text": "Using the pipe operator |&gt;\n\nThe pipe operator (|&gt;) makes code more readable by chaining multiple operations together.\nThe output of one function is automatically passed to the next function.\nThis allows you to perform multiple steps (e.g., filter() followed by select()) in a clear and concise manner.\n\n\n# This code reads more like poetry!\ncases_df |&gt; \n  filter(geo_value == \"nc\", raw_cases &gt; 1000) |&gt; \n  select(time_value, raw_cases) |&gt; \n  head()\n\n# A tibble: 6 × 2\n  time_value raw_cases\n  &lt;date&gt;         &lt;dbl&gt;\n1 2022-03-01      1231\n2 2022-03-02      2243\n3 2022-03-03      2377\n4 2022-03-04      2646\n5 2022-03-07      4230\n6 2022-03-09      1833"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#key-practices-in-dplyr",
    "href": "slides/appendix-tidyverse.html#key-practices-in-dplyr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Key practices in dplyr",
    "text": "Key practices in dplyr\n\nUse tibbles for easier data handling.\nUse select() and filter() for data manipulation.\nUse pull() to extract columns as vectors.\nUse head(), tail(), and glimpse() for quick data inspection.\nChain functions with |&gt; for cleaner code."
  },
  {
    "objectID": "slides/appendix-tidyverse.html#grouping-data-with-group_by",
    "href": "slides/appendix-tidyverse.html#grouping-data-with-group_by",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Grouping data with group_by()",
    "text": "Grouping data with group_by()\n\nUse group_by() to group data by one or more columns.\nAllows performing operations on specific groups of data.\n\n\ncases_df |&gt;\n  group_by(geo_value) |&gt;\n  filter(raw_cases == max(raw_cases, na.rm = TRUE))\n\n# A tibble: 3 × 3\n# Groups:   geo_value [3]\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-03      7509\n2 nc        2022-03-07      4230\n3 ny        2022-03-24      6596"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#creating-new-columns-with-mutate",
    "href": "slides/appendix-tidyverse.html#creating-new-columns-with-mutate",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Creating new columns with mutate()",
    "text": "Creating new columns with mutate()\n\n  Artwork by @allison_horst"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#creating-new-columns-with-mutate-1",
    "href": "slides/appendix-tidyverse.html#creating-new-columns-with-mutate-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Creating new columns with mutate()",
    "text": "Creating new columns with mutate()\n\nmutate() is used to create new columns.\nPerform calculations using existing columns and assign to new columns.\n\n\nny_subset = cases_df |&gt;\n  filter(geo_value == \"ny\")\n\nny_subset |&gt; \n  mutate(cumulative_cases = cumsum(raw_cases)) |&gt; \n  head()\n\n# A tibble: 6 × 4\n  geo_value time_value raw_cases cumulative_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;            &lt;dbl&gt;\n1 ny        2022-03-01      1487             1487\n2 ny        2022-03-02      1889             3376\n3 ny        2022-03-03      2390             5766\n4 ny        2022-03-04       350             6116\n5 ny        2022-03-05      3372             9488\n6 ny        2022-03-06      2343            11831"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#creating-new-columns-with-mutate-2",
    "href": "slides/appendix-tidyverse.html#creating-new-columns-with-mutate-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Creating new columns with mutate()",
    "text": "Creating new columns with mutate()\n\nmutate() can create multiple new columns in one step.\nLogical comparisons (e.g., over_5000 = raw_cases &gt; 5000) can be used within mutate().\n\n\nny_subset |&gt; \n  mutate(over_5000 = raw_cases &gt; 5000,\n         cumulative_cases = cumsum(raw_cases)) |&gt; \n  head()\n\n# A tibble: 6 × 5\n  geo_value time_value raw_cases over_5000 cumulative_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt; &lt;lgl&gt;                &lt;dbl&gt;\n1 ny        2022-03-01      1487 FALSE                 1487\n2 ny        2022-03-02      1889 FALSE                 3376\n3 ny        2022-03-03      2390 FALSE                 5766\n4 ny        2022-03-04       350 FALSE                 6116\n5 ny        2022-03-05      3372 FALSE                 9488\n6 ny        2022-03-06      2343 FALSE                11831"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#combining-group_by-and-mutate",
    "href": "slides/appendix-tidyverse.html#combining-group_by-and-mutate",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Combining group_by() and mutate()",
    "text": "Combining group_by() and mutate()\n\nFirst, group data using group_by().\nThen, use mutate to perform the calculations for each group.\nFinally, use arrange to display the output by geo_value.\n\n\ncases_df |&gt;\n  group_by(geo_value) |&gt;\n  mutate(cumulative_cases = cumsum(raw_cases)) |&gt; \n  arrange(geo_value) |&gt; \n  head()\n\n# A tibble: 6 × 4\n# Groups:   geo_value [1]\n  geo_value time_value raw_cases cumulative_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;            &lt;dbl&gt;\n1 ca        2022-03-01      4310             4310\n2 ca        2022-03-02      7044            11354\n3 ca        2022-03-03      7509            18863\n4 ca        2022-03-04      3586            22449\n5 ca        2022-03-05      1438            23887\n6 ca        2022-03-06      6465            30352"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#conditional-calculations-with-if_else",
    "href": "slides/appendix-tidyverse.html#conditional-calculations-with-if_else",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Conditional calculations with if_else()",
    "text": "Conditional calculations with if_else()\n\nif_else() allows conditional logic within mutate().\nPerform different operations depending on conditions, like “high” or “low.”\n\n\nt &lt;- 5000\n\ncases_df |&gt;\n  mutate(high_low_cases = if_else(raw_cases &gt; t, \"high\", \"low\")) |&gt; \n  head()\n\n# A tibble: 6 × 4\n  geo_value time_value raw_cases high_low_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt; &lt;chr&gt;         \n1 ca        2022-03-01      4310 low           \n2 nc        2022-03-01      1231 low           \n3 ny        2022-03-01      1487 low           \n4 ca        2022-03-02      7044 high          \n5 nc        2022-03-02      2243 low           \n6 ny        2022-03-02      1889 low"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#summarizing-data-with-summarise",
    "href": "slides/appendix-tidyverse.html#summarizing-data-with-summarise",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Summarizing data with summarise()",
    "text": "Summarizing data with summarise()\n\nsummarise() reduces data to summary statistics (e.g., mean, median).\nTypically used after group_by() to summarize each group.\n\n\ncases_df |&gt;\n  group_by(geo_value) |&gt;\n  summarise(median_cases = median(raw_cases))\n\n# A tibble: 3 × 2\n  geo_value median_cases\n  &lt;chr&gt;            &lt;dbl&gt;\n1 ca                3785\n2 nc                1224\n3 ny                2188"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#using-count-to-aggregate-data",
    "href": "slides/appendix-tidyverse.html#using-count-to-aggregate-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using count() to aggregate data",
    "text": "Using count() to aggregate data\ncount() is a shortcut for grouping and summarizing the data.\nFor example, if we want to get the total number of complete rows for each state, then\n\ncases_count &lt;- cases_df |&gt;\n  drop_na() |&gt; # Removes rows where any value is missing (from tidyr)\n  group_by(geo_value) |&gt;\n  summarize(count = n())\n\n is equivalent to\n\ncases_count &lt;- cases_df |&gt;\n  drop_na() |&gt; \n  count(geo_value)\n\ncases_count # Let's see what the counts are.\n\n# A tibble: 3 × 2\n  geo_value     n\n  &lt;chr&gt;     &lt;int&gt;\n1 ca           31\n2 nc           31\n3 ny           31"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#key-practices-in-dplyr-round-2",
    "href": "slides/appendix-tidyverse.html#key-practices-in-dplyr-round-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Key practices in dplyr: Round 2",
    "text": "Key practices in dplyr: Round 2\n\nUse group_by() to group data by one or more variables before applying functions.\nUse mutate to create new columns or modify existing ones by applying functions to existing data.\nUse summarise to reduce data to summary statistics (e.g., mean, median).\ncount() is a convenient shortcut for counting rows by group without needing group_by() and summarise()."
  },
  {
    "objectID": "slides/appendix-tidyverse.html#tidy-data-and-tolstoy",
    "href": "slides/appendix-tidyverse.html#tidy-data-and-tolstoy",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Tidy data and Tolstoy",
    "text": "Tidy data and Tolstoy\n\n“Happy families are all alike; every unhappy family is unhappy in its own way.” — Leo Tolstoy\n\n\nTidy datasets are like happy families: consistent, standardized, and easy to work with.\n\nMessy datasets are like unhappy families: each one messy in its own unique way.\nIn this section:\nWe’ll define what makes data tidy and how to transform between the tidy and messy formats."
  },
  {
    "objectID": "slides/appendix-tidyverse.html#tidy-data-and-tolstoy-1",
    "href": "slides/appendix-tidyverse.html#tidy-data-and-tolstoy-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Tidy data and Tolstoy",
    "text": "Tidy data and Tolstoy\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#what-is-tidy-data",
    "href": "slides/appendix-tidyverse.html#what-is-tidy-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What is tidy data?",
    "text": "What is tidy data?\n\nTidy data follows a consistent structure: each row represents one observation, and each column represents one variable.\ncases_df is one classic example of tidy data.\n\n\n\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 nc        2022-03-01      1231\n3 ny        2022-03-01      1487\n4 ca        2022-03-02      7044\n5 nc        2022-03-02      2243\n6 ny        2022-03-02      1889\n\n\n\nTo convert between tidy and messy data, we can use the tidyr package in the tidyverse."
  },
  {
    "objectID": "slides/appendix-tidyverse.html#pivot_wider-and-pivot_longer",
    "href": "slides/appendix-tidyverse.html#pivot_wider-and-pivot_longer",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "pivot_wider() and pivot_longer()",
    "text": "pivot_wider() and pivot_longer()\n\n  Artwork by @allison_horst"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#making-data-wider-with-pivot_wider",
    "href": "slides/appendix-tidyverse.html#making-data-wider-with-pivot_wider",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Making data wider with pivot_wider()",
    "text": "Making data wider with pivot_wider()\n\nTo convert data from long format to wide/messy format usepivot_wider().\nFor example, let’s try creating a column for each time value in cases_df:\n\n\n\nmessy_cases_df &lt;- cases_df |&gt;\n  pivot_wider(\n    names_from = time_value,   # Create new columns for each unique date\n    values_from = raw_cases    # Fill those columns with the raw_case values\n  )\n\n# View the result\nmessy_cases_df\n\n# A tibble: 3 × 32\n  geo_value `2022-03-01` `2022-03-02` `2022-03-03` `2022-03-04` `2022-03-05`\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 ca                4310         7044         7509         3586         1438\n2 nc                1231         2243         2377         2646            0\n3 ny                1487         1889         2390          350         3372\n# ℹ 26 more variables: `2022-03-06` &lt;dbl&gt;, `2022-03-07` &lt;dbl&gt;,\n#   `2022-03-08` &lt;dbl&gt;, `2022-03-09` &lt;dbl&gt;, `2022-03-10` &lt;dbl&gt;,\n#   `2022-03-11` &lt;dbl&gt;, `2022-03-12` &lt;dbl&gt;, `2022-03-13` &lt;dbl&gt;,\n#   `2022-03-14` &lt;dbl&gt;, `2022-03-15` &lt;dbl&gt;, `2022-03-16` &lt;dbl&gt;,\n#   `2022-03-17` &lt;dbl&gt;, `2022-03-18` &lt;dbl&gt;, `2022-03-19` &lt;dbl&gt;,\n#   `2022-03-20` &lt;dbl&gt;, `2022-03-21` &lt;dbl&gt;, `2022-03-22` &lt;dbl&gt;,\n#   `2022-03-23` &lt;dbl&gt;, `2022-03-24` &lt;dbl&gt;, `2022-03-25` &lt;dbl&gt;, …"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#tidying-messy-data-with-pivot_longer",
    "href": "slides/appendix-tidyverse.html#tidying-messy-data-with-pivot_longer",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Tidying messy data with pivot_longer()",
    "text": "Tidying messy data with pivot_longer()\n\nUse pivot_longer() to convert data from wide format (multiple columns for the same variable) to long format (one column per variable).\nLet’s try turning messy_cases_df back into the original tidy cases_df!\n\n\ntidy_cases_df &lt;- messy_cases_df |&gt;\n  pivot_longer(\n    cols = -geo_value,          # Keep the 'geo_value' column as it is\n    names_to = \"time_value\",    # Create a new 'time_value' column from the column names\n    values_to = \"raw_cases\"     # Values from the wide columns should go into 'raw_cases'\n  )\n\n# View the result\nhead(tidy_cases_df, n = 3) # Notice the class of time_value here\n\n# A tibble: 3 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-03      7509"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#tidying-messy-data-with-pivot_longer-1",
    "href": "slides/appendix-tidyverse.html#tidying-messy-data-with-pivot_longer-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Tidying messy data with pivot_longer()",
    "text": "Tidying messy data with pivot_longer()\n\nWhen we used pivot_longer(), the time_value column is converted to a character class because the column names are treated as strings.\nSo, to truly get the original cases_df we need to convert time_value back to the Date class.\nThen, we can use identical() to check if the two data frames are exactly the same.\n\n\ntidy_cases_df = tidy_cases_df |&gt; mutate(time_value = as.Date(time_value))\n\nidentical(tidy_cases_df |&gt; arrange(time_value), cases_df)\n\n[1] TRUE\n\n\nGreat. That was a success!"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#missing-data",
    "href": "slides/appendix-tidyverse.html#missing-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Missing data",
    "text": "Missing data\n\nSometimes you may have missing data in your time series.\nCan be due to actual missing data, or it can be due to the fact that the data is only reported on certain days.\nLet’s create a dataset with missing data & consider each of those cases:\n\n\nca_missing &lt;- cases_df |&gt;\n  filter(geo_value == \"ca\") |&gt;\n  slice(1:2, 4:6) # Subset rows 1 to 2 and 4 to 6; ie. omit 2022-03-03\n\nca_missing\n\n# A tibble: 5 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-04      3586\n4 ca        2022-03-05      1438\n5 ca        2022-03-06      6465"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#complete-and-fill-to-handle-missing-data",
    "href": "slides/appendix-tidyverse.html#complete-and-fill-to-handle-missing-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "complete() and fill() to handle missing data",
    "text": "complete() and fill() to handle missing data\nA simple workflow to handle missing data relies on one or both of these functions:\n\ncomplete(): Adds missing rows for combinations of specified variables.\nfill(): Fills missing values in columns, typically from previous or next available values (default is LOCF)."
  },
  {
    "objectID": "slides/appendix-tidyverse.html#data-only-reported-on-certain-days",
    "href": "slides/appendix-tidyverse.html#data-only-reported-on-certain-days",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Data only reported on certain days",
    "text": "Data only reported on certain days\n\nIf the data is only reported on certain days, it is often useful to fill in the missing data with explicit zeros.\ncomplete() is enough to handle this:\n\n\n# First, use complete() to add missing time_value (2022-03-03)\nca_complete &lt;- ca_missing |&gt;\n  complete(geo_value, time_value = seq(min(time_value), max(time_value), by = \"day\"),\n           fill = list(raw_cases = 0))\nca_complete\n\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-03         0\n4 ca        2022-03-04      3586\n5 ca        2022-03-05      1438\n6 ca        2022-03-06      6465"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#data-is-genuinely-missing",
    "href": "slides/appendix-tidyverse.html#data-is-genuinely-missing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Data is genuinely missing",
    "text": "Data is genuinely missing\n\nIf the data is truly missing, then there are multiple options (ex. omission, single imputation, multiple imputation).\nA common single imputation method used to handle missing data in time series or longitudinal datasets is LOCF.\nWe can easily perform LOCF using complete() followed by fill().\nStart with complete():\n\n\n# First, use complete() to add missing time_value (2022-03-03)\nca_complete &lt;- ca_missing |&gt;\n  complete(geo_value, time_value = seq(min(time_value), max(time_value), by = \"day\"))\nhead(ca_complete, n = 4) # notice no fill with 0s this time, NA by default\n\n# A tibble: 4 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-03        NA\n4 ca        2022-03-04      3586"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#data-is-genuinely-missing-1",
    "href": "slides/appendix-tidyverse.html#data-is-genuinely-missing-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Data is genuinely missing",
    "text": "Data is genuinely missing\nThen, use fill() to fill the counts using LOCF (default):\n\nca_complete |&gt;\n  fill(raw_cases)\n\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-03      7044\n4 ca        2022-03-04      3586\n5 ca        2022-03-05      1438\n6 ca        2022-03-06      6465"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#introduction-to-joins-in-dplyr",
    "href": "slides/appendix-tidyverse.html#introduction-to-joins-in-dplyr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Introduction to joins in dplyr",
    "text": "Introduction to joins in dplyr\n\nJoining datasets is a powerful tool for combining info. from multiple sources.\nIn R, dplyr provides several functions to perform different types of joins.\nWe’ll demonstrate joining a subset of cases_df (our case counts dataset) with state_census.\nMotivation: We can scale the case counts by population to make them comparable across regions of different sizes."
  },
  {
    "objectID": "slides/appendix-tidyverse.html#subset-cases_df",
    "href": "slides/appendix-tidyverse.html#subset-cases_df",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Subset cases_df",
    "text": "Subset cases_df\nTo simplify things, let’s use filter() to only grab one date of cases_df:\n\ncases_df_sub = cases_df |&gt; filter(time_value == \"2022-03-01\") \ncases_df_sub\n\n# A tibble: 3 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 nc        2022-03-01      1231\n3 ny        2022-03-01      1487\n\n\nThough note that what we’re going to do can be applied to the entirety of cases_df."
  },
  {
    "objectID": "slides/appendix-tidyverse.html#load-state-census-data",
    "href": "slides/appendix-tidyverse.html#load-state-census-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Load state census data",
    "text": "Load state census data\nThe state_census dataset from epidatasets contains state populations from the 2019 census.\n\n# State census dataset from epidatasets\nlibrary(epidatasets)\nstate_census = state_census |&gt; select(abbr, pop) |&gt; filter(abbr != \"us\")\n\nstate_census |&gt; head()\n\n# A tibble: 6 × 2\n  abbr       pop\n  &lt;chr&gt;    &lt;dbl&gt;\n1 al     4903185\n2 ak      731545\n3 az     7278717\n4 ar     3017804\n5 ca    39512223\n6 co     5758736\n\n\nNotice that this includes many states that are not in cases_df_sub."
  },
  {
    "objectID": "slides/appendix-tidyverse.html#left-join-keep-all-rows-from-the-first-dataset",
    "href": "slides/appendix-tidyverse.html#left-join-keep-all-rows-from-the-first-dataset",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Left Join: Keep all rows from the first dataset",
    "text": "Left Join: Keep all rows from the first dataset\n\nA left join keeps all rows from the first dataset (cases_df_sub), and adds matching data from the second dataset (state_census).\nSo all rows from the first dataset (cases_df_sub) will be preserved.\nThe datasets are joined by matching the geo_value column, specified by the by argument.\n\n\n# Left join: combining March 1, 2022 state case data with the census data\ncases_left_join &lt;- cases_df_sub |&gt;\n  left_join(state_census, join_by(geo_value == abbr))\n\ncases_left_join\n\n# A tibble: 3 × 4\n  geo_value time_value raw_cases      pop\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#right-join-keep-all-rows-from-the-second-dataset",
    "href": "slides/appendix-tidyverse.html#right-join-keep-all-rows-from-the-second-dataset",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Right Join: Keep all rows from the second dataset",
    "text": "Right Join: Keep all rows from the second dataset\n\nA right join keeps all rows from the second dataset (state_census), and adds matching data from the first dataset (cases_df_sub).\nIf a row in the second dataset doesn’t have a match in the first, then the columns from the first will be filled with NA.\nFor example, can see this for the al row from state_census…\n\n\n# Right join: keep all rows from state_census\ncases_right_join &lt;- cases_df_sub |&gt;\n  right_join(state_census, join_by(geo_value == abbr))\n\nhead(cases_right_join)\n\n# A tibble: 6 × 4\n  geo_value time_value raw_cases      pop\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561\n4 al        NA                NA  4903185\n5 ak        NA                NA   731545\n6 az        NA                NA  7278717"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#inner-join-only-keeping-matching-rows",
    "href": "slides/appendix-tidyverse.html#inner-join-only-keeping-matching-rows",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Inner Join: Only keeping matching rows",
    "text": "Inner Join: Only keeping matching rows\n\nAn inner join will only keep rows where there is a match in both datasets.\nSo, if a state in state_census does not have a corresponding entry in cases_df_sub, then that row will be excluded.\n\n\n# Inner join: only matching rows are kept\ncases_inner_join &lt;- cases_df_sub |&gt;\n  inner_join(state_census, join_by(geo_value == abbr))\n\ncases_inner_join\n\n# A tibble: 3 × 4\n  geo_value time_value raw_cases      pop\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#full-join-keeping-all-rows-from-both-datasets",
    "href": "slides/appendix-tidyverse.html#full-join-keeping-all-rows-from-both-datasets",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Full Join: Keeping all rows from both datasets",
    "text": "Full Join: Keeping all rows from both datasets\n\nA full join will keep all rows from both datasets.\nIf a state in either dataset has no match in the other, the missing values will be filled with NA.\n\n\n# Full join: keep all rows from both datasets\ncases_full_join &lt;- cases_df_sub |&gt;\n  full_join(state_census, join_by(geo_value == abbr))\n\nhead(cases_full_join)\n\n# A tibble: 6 × 4\n  geo_value time_value raw_cases      pop\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561\n4 al        NA                NA  4903185\n5 ak        NA                NA   731545\n6 az        NA                NA  7278717"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#pictorial-summary-of-the-four-join-functions",
    "href": "slides/appendix-tidyverse.html#pictorial-summary-of-the-four-join-functions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Pictorial summary of the four join functions",
    "text": "Pictorial summary of the four join functions\n\n\n\nSource"
  },
  {
    "objectID": "slides/appendix-tidyverse.html#final-thoughts-on-joins",
    "href": "slides/appendix-tidyverse.html#final-thoughts-on-joins",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Final thoughts on joins",
    "text": "Final thoughts on joins\n\nJoins are an essential part of data wrangling in R.\nThe choice of join depends on the analysis you need to perform:\n\nUse left joins when you want to keep all data from the first dataset.\nUse right joins when you want to keep all data from the second dataset.\nUse inner joins when you’re only interested in matching rows.\nUse full joins when you want to preserve all information from both datasets."
  },
  {
    "objectID": "slides/appendix-tidyverse.html#three-review-questions",
    "href": "slides/appendix-tidyverse.html#three-review-questions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Three review questions",
    "text": "Three review questions\nQ1): What can we use to fill in the missing time_value for the states in cases_full_join?\n\n\nCode\ncases_full_join |&gt; \n     fill(time_value)\n\n\nQ2): Now, what join function should you use if your goal is to scale the cases by population in cases_df?\n\n\nCode\n# Either left_join\ncases_left_join &lt;- cases_df |&gt;\n  left_join(state_census, join_by(geo_value == abbr))\n\ncases_left_join\ncases_df = cases_left_join\n\n# Or inner_join\ncases_inner_join &lt;- cases_df |&gt;\n  inner_join(state_census, join_by(geo_value == abbr))\n\ncases_inner_join\n\n\nQ3): Finally, please create a new column in cases_df where you scale the cases by population and multiply by 1e5 to get cases / 100k.\n\n\nCode\ncases_df &lt;- cases_df |&gt;\n  mutate(scaled_cases = raw_cases / pop * 1e5) # cases / 100K\nhead(cases_df)"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Schedule",
    "text": "Schedule\nIn this 2-day workshop, we plan to demonstrate how to use R to load, process, inspect, and forecast aggregate epi surveillance data. We will be presenting a few case studies to motivate the entire pipeline from signal discovery to the production of nowcasts and forecasts.\n\nDay 1 Morning\nDay 1 Afternoon\nDay 2 Morning\nDay 2 Afternoon"
  },
  {
    "objectID": "index.html#instructors",
    "href": "index.html#instructors",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Instructors",
    "text": "Instructors\n\nLogan C. Brooks\nRachel Lobay\nDaniel J. McDonald\nRyan J. Tibshirani"
  },
  {
    "objectID": "slides/day1-afternoon.html#section",
    "href": "slides/day1-afternoon.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Data Cleaning, Versioning, Nowcasting With {epiprocess}",
    "text": "Data Cleaning, Versioning, Nowcasting With {epiprocess}\nInsightNet Forecasting Workshop 2024\n\nAlice Cima, Rachel Lobay, Daniel McDonald, Ryan Tibshirani\nwith huge thanks to Logan Brooks, Xueda Shen, and also to Nat DeFries, Dmitry Shemetov, and David Weber\n11 December – Afternoon"
  },
  {
    "objectID": "slides/day1-afternoon.html#outline",
    "href": "slides/day1-afternoon.html#outline",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Outline",
    "text": "Outline\n\nEssentials of {dplyr} and {tidyr}\nEpiverse Software ecosystem\nPanel and Versioned Data in the epiverse\nBasic Nowcasting using {epiprocess}\nNowcasting with One Variable\nNowcasting with Two Variables\nCase Study - Nowcasting Cases Using %CLI"
  },
  {
    "objectID": "slides/day1-afternoon.html#down-with-spreadsheets-for-data-manipulation",
    "href": "slides/day1-afternoon.html#down-with-spreadsheets-for-data-manipulation",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Down with spreadsheets for data manipulation",
    "text": "Down with spreadsheets for data manipulation\n\nSpreadsheets make it difficult to rerun analyses consistently.\nUsing R (and {dplyr}) allows for:\n\nReproducibility\nEase of modification\n\nRecommendation: Avoid manual edits; instead, use code for transformations.\nLet’s see what we mean by this…"
  },
  {
    "objectID": "slides/day1-afternoon.html#introduction-to-dplyr",
    "href": "slides/day1-afternoon.html#introduction-to-dplyr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Introduction to dplyr",
    "text": "Introduction to dplyr\n\ndplyr is a powerful package in R for data manipulation.\nIt is part of the tidyverse, which includes a collection of packages designed to work together… Here’s some of its greatest hits:\n\n\n  Source"
  },
  {
    "objectID": "slides/day1-afternoon.html#introduction-to-dplyr-1",
    "href": "slides/day1-afternoon.html#introduction-to-dplyr-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Introduction to dplyr",
    "text": "Introduction to dplyr\nTo load dplyr, you may simply load the tidyverse package:\n\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)  \n\nOur focus will be on basic operations like selecting and filtering data.\n\n\nSource"
  },
  {
    "objectID": "slides/day1-afternoon.html#downloading-jhu-csse-covid-19-case-data",
    "href": "slides/day1-afternoon.html#downloading-jhu-csse-covid-19-case-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Downloading JHU CSSE COVID-19 case data",
    "text": "Downloading JHU CSSE COVID-19 case data\n\nLet’s start with something familiar… Here’s a task for you:\nUse pub_covidcast() to download JHU CSSE COVID-19 confirmed case data (confirmed_incidence_num) for CA, NC, and NY from March 1, 2022 to March 31, 2022 as of January 1, 2024.\nTry this for yourself. Then click the dropdown on the next slide to check your work…"
  },
  {
    "objectID": "slides/day1-afternoon.html#downloading-jhu-csse-covid-19-case-data-1",
    "href": "slides/day1-afternoon.html#downloading-jhu-csse-covid-19-case-data-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Downloading JHU CSSE COVID-19 case data",
    "text": "Downloading JHU CSSE COVID-19 case data\n\n\nCode\nlibrary(epidatr)\n\ncases_df_api &lt;- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_incidence_num\",\n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"ca,nc,ny\",\n  time_values = epirange(20220301, 20220331),\n  as_of = as.Date(\"2024-01-01\")\n)\n\n\nNow we only really need a few columns here…\n\ncases_df &lt;- cases_df_api |&gt;\n  select(geo_value, time_value, raw_cases = value) # We'll talk more about this soon :)"
  },
  {
    "objectID": "slides/day1-afternoon.html#ways-to-inspect-the-dataset",
    "href": "slides/day1-afternoon.html#ways-to-inspect-the-dataset",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Ways to inspect the dataset",
    "text": "Ways to inspect the dataset\nUse head() to view the first six row of the data\n\nhead(cases_df)  # First 6 rows\n\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 nc        2022-03-01      1231\n3 ny        2022-03-01      1487\n4 ca        2022-03-02      7044\n5 nc        2022-03-02      2243\n6 ny        2022-03-02      1889\n\n\nand tail to view the last six\n\n\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-30      3785\n2 nc        2022-03-30      1067\n3 ny        2022-03-30      3127\n4 ca        2022-03-31      4533\n5 nc        2022-03-31      1075\n6 ny        2022-03-31      4763"
  },
  {
    "objectID": "slides/day1-afternoon.html#ways-to-inspect-the-dataset-1",
    "href": "slides/day1-afternoon.html#ways-to-inspect-the-dataset-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Ways to inspect the dataset",
    "text": "Ways to inspect the dataset\nNow, for our first foray into the tidyverse…\nUse glimpse() to get a compact overview of the dataset.\n\nglimpse(cases_df)\n\nRows: 93\nColumns: 3\n$ geo_value  &lt;chr&gt; \"ca\", \"nc\", \"ny\", \"ca\", \"nc\", \"ny\", \"ca\", \"nc\", \"ny\", \"ca\",…\n$ time_value &lt;date&gt; 2022-03-01, 2022-03-01, 2022-03-01, 2022-03-02, 2022-03-02…\n$ raw_cases  &lt;dbl&gt; 4310, 1231, 1487, 7044, 2243, 1889, 7509, 2377, 2390, 3586,…"
  },
  {
    "objectID": "slides/day1-afternoon.html#selecting-columns-with-select",
    "href": "slides/day1-afternoon.html#selecting-columns-with-select",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Selecting columns with select()",
    "text": "Selecting columns with select()\nThe select() function is used to pick specific columns from your dataset.\n\nselect(cases_df, geo_value, time_value)  # Select the 'geo_value' and 'time_value' columns\n\n# A tibble: 93 × 2\n   geo_value time_value\n   &lt;chr&gt;     &lt;date&gt;    \n 1 ca        2022-03-01\n 2 nc        2022-03-01\n 3 ny        2022-03-01\n 4 ca        2022-03-02\n 5 nc        2022-03-02\n 6 ny        2022-03-02\n 7 ca        2022-03-03\n 8 nc        2022-03-03\n 9 ny        2022-03-03\n10 ca        2022-03-04\n# ℹ 83 more rows"
  },
  {
    "objectID": "slides/day1-afternoon.html#selecting-columns-with-select-1",
    "href": "slides/day1-afternoon.html#selecting-columns-with-select-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Selecting columns with select()",
    "text": "Selecting columns with select()\nYou can exclude columns by prefixing the column names with a minus sign -.\n\nselect(cases_df, -raw_cases)  # Exclude the 'raw_cases' column from the dataset\n\n# A tibble: 93 × 2\n   geo_value time_value\n   &lt;chr&gt;     &lt;date&gt;    \n 1 ca        2022-03-01\n 2 nc        2022-03-01\n 3 ny        2022-03-01\n 4 ca        2022-03-02\n 5 nc        2022-03-02\n 6 ny        2022-03-02\n 7 ca        2022-03-03\n 8 nc        2022-03-03\n 9 ny        2022-03-03\n10 ca        2022-03-04\n# ℹ 83 more rows"
  },
  {
    "objectID": "slides/day1-afternoon.html#subsetting-rows-with-filter",
    "href": "slides/day1-afternoon.html#subsetting-rows-with-filter",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Subsetting rows with filter()",
    "text": "Subsetting rows with filter()\n\n  Artwork by @allison_horst"
  },
  {
    "objectID": "slides/day1-afternoon.html#subsetting-rows-with-filter-1",
    "href": "slides/day1-afternoon.html#subsetting-rows-with-filter-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Subsetting rows with filter()",
    "text": "Subsetting rows with filter()\n\nThe filter() function allows you to subset rows that meet specific conditions.\nConditions regard column values, such as filtering for only NC or cases higher than some threshold.\nThis enables you to narrow down your dataset to focus on relevant data.\n\n\nfilter(cases_df, geo_value == \"nc\", raw_cases &gt; 500)  # Filter for NC with raw daily cases &gt; 500\n\n# A tibble: 22 × 3\n   geo_value time_value raw_cases\n   &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n 1 nc        2022-03-01      1231\n 2 nc        2022-03-02      2243\n 3 nc        2022-03-03      2377\n 4 nc        2022-03-04      2646\n 5 nc        2022-03-07      4230\n 6 nc        2022-03-08       894\n 7 nc        2022-03-09      1833\n 8 nc        2022-03-10      1783\n 9 nc        2022-03-11      1849\n10 nc        2022-03-14      3130\n# ℹ 12 more rows"
  },
  {
    "objectID": "slides/day1-afternoon.html#combining-select-and-filter-functions",
    "href": "slides/day1-afternoon.html#combining-select-and-filter-functions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Combining select() and filter() functions",
    "text": "Combining select() and filter() functions\n\nYou can further combine select() and filter() to further refine the dataset.\nUse select() to choose columns and filter() to narrow down rows.\nThis helps in extracting the exact data needed for analysis.\n\n\nselect(filter(cases_df, geo_value == \"nc\", raw_cases &gt; 1000), time_value, raw_cases) |&gt; \n  head()\n\n# A tibble: 6 × 2\n  time_value raw_cases\n  &lt;date&gt;         &lt;dbl&gt;\n1 2022-03-01      1231\n2 2022-03-02      2243\n3 2022-03-03      2377\n4 2022-03-04      2646\n5 2022-03-07      4230\n6 2022-03-09      1833"
  },
  {
    "objectID": "slides/day1-afternoon.html#using-the-pipe-operator",
    "href": "slides/day1-afternoon.html#using-the-pipe-operator",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using the pipe operator |>",
    "text": "Using the pipe operator |&gt;\n\nThe pipe operator (|&gt;) makes code more readable by chaining multiple operations together.\nThe output of one function is automatically passed to the next function.\nThis allows you to perform multiple steps (e.g., filter() followed by select()) in a clear and concise manner.\n\n\n# This code reads more like poetry!\ncases_df |&gt; \n  filter(geo_value == \"nc\", raw_cases &gt; 1000) |&gt; \n  select(time_value, raw_cases) |&gt; \n  head()\n\n# A tibble: 6 × 2\n  time_value raw_cases\n  &lt;date&gt;         &lt;dbl&gt;\n1 2022-03-01      1231\n2 2022-03-02      2243\n3 2022-03-03      2377\n4 2022-03-04      2646\n5 2022-03-07      4230\n6 2022-03-09      1833"
  },
  {
    "objectID": "slides/day1-afternoon.html#key-practices-in-dplyr",
    "href": "slides/day1-afternoon.html#key-practices-in-dplyr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Key practices in dplyr",
    "text": "Key practices in dplyr\n\nUse tibbles for easier data handling.\nUse head(), tail(), and glimpse() for quick data inspection.\nUse select() and filter() for data manipulation.\nChain functions with |&gt; for cleaner code."
  },
  {
    "objectID": "slides/day1-afternoon.html#grouping-data-with-group_by",
    "href": "slides/day1-afternoon.html#grouping-data-with-group_by",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Grouping data with group_by()",
    "text": "Grouping data with group_by()\n\nUse group_by() to group data by one or more columns.\nAllows performing operations on specific groups of data.\n\n\ncases_df |&gt;\n  group_by(geo_value) |&gt;\n  filter(raw_cases == max(raw_cases, na.rm = TRUE))\n\n# A tibble: 3 × 3\n# Groups:   geo_value [3]\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-03      7509\n2 nc        2022-03-07      4230\n3 ny        2022-03-24      6596"
  },
  {
    "objectID": "slides/day1-afternoon.html#creating-new-columns-with-mutate",
    "href": "slides/day1-afternoon.html#creating-new-columns-with-mutate",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Creating new columns with mutate()",
    "text": "Creating new columns with mutate()\n\n  Artwork by @allison_horst"
  },
  {
    "objectID": "slides/day1-afternoon.html#creating-new-columns-with-mutate-1",
    "href": "slides/day1-afternoon.html#creating-new-columns-with-mutate-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Creating new columns with mutate()",
    "text": "Creating new columns with mutate()\n\nmutate() is used to create new columns.\nPerform calculations using existing columns and assign to new columns.\n\n\nny_subset = cases_df |&gt;\n  filter(geo_value == \"ny\")\n\nny_subset |&gt; \n  mutate(cumulative_cases = cumsum(raw_cases)) |&gt; \n  head()\n\n# A tibble: 6 × 4\n  geo_value time_value raw_cases cumulative_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;            &lt;dbl&gt;\n1 ny        2022-03-01      1487             1487\n2 ny        2022-03-02      1889             3376\n3 ny        2022-03-03      2390             5766\n4 ny        2022-03-04       350             6116\n5 ny        2022-03-05      3372             9488\n6 ny        2022-03-06      2343            11831"
  },
  {
    "objectID": "slides/day1-afternoon.html#combining-group_by-and-mutate",
    "href": "slides/day1-afternoon.html#combining-group_by-and-mutate",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Combining group_by() and mutate()",
    "text": "Combining group_by() and mutate()\n\nFirst, group data using group_by().\nThen, use mutate to perform the calculations for each group.\nFinally, use arrange to display the output by geo_value.\n\n\ncases_df |&gt;\n  group_by(geo_value) |&gt;\n  mutate(cumulative_cases = cumsum(raw_cases)) |&gt; \n  arrange(geo_value) |&gt; \n  head()\n\n# A tibble: 6 × 4\n# Groups:   geo_value [1]\n  geo_value time_value raw_cases cumulative_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;            &lt;dbl&gt;\n1 ca        2022-03-01      4310             4310\n2 ca        2022-03-02      7044            11354\n3 ca        2022-03-03      7509            18863\n4 ca        2022-03-04      3586            22449\n5 ca        2022-03-05      1438            23887\n6 ca        2022-03-06      6465            30352"
  },
  {
    "objectID": "slides/day1-afternoon.html#summarizing-data-with-summarise",
    "href": "slides/day1-afternoon.html#summarizing-data-with-summarise",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Summarizing data with summarise()",
    "text": "Summarizing data with summarise()\n\nsummarise() reduces data to summary statistics (e.g., mean, median).\nTypically used after group_by() to summarize each group.\n\n\ncases_df |&gt;\n  group_by(geo_value) |&gt;\n  summarise(median_cases = median(raw_cases))\n\n# A tibble: 3 × 2\n  geo_value median_cases\n  &lt;chr&gt;            &lt;dbl&gt;\n1 ca                3785\n2 nc                1224\n3 ny                2188"
  },
  {
    "objectID": "slides/day1-afternoon.html#using-count-to-aggregate-data",
    "href": "slides/day1-afternoon.html#using-count-to-aggregate-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Using count() to aggregate data",
    "text": "Using count() to aggregate data\ncount() is a shortcut for grouping and summarizing the data.\nFor example, if we want to get the total number of complete rows for each state, then\n\ncases_count &lt;- cases_df |&gt;\n  drop_na() |&gt; # Removes rows where any value is missing (from tidyr)\n  group_by(geo_value) |&gt;\n  summarize(count = n())\n\n is equivalent to\n\ncases_count &lt;- cases_df |&gt;\n  drop_na() |&gt; \n  count(geo_value)\n\ncases_count # Let's see what the counts are.\n\n# A tibble: 3 × 2\n  geo_value     n\n  &lt;chr&gt;     &lt;int&gt;\n1 ca           31\n2 nc           31\n3 ny           31"
  },
  {
    "objectID": "slides/day1-afternoon.html#key-practices-in-dplyr-round-2",
    "href": "slides/day1-afternoon.html#key-practices-in-dplyr-round-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Key practices in dplyr: Round 2",
    "text": "Key practices in dplyr: Round 2\n\nUse group_by() to group data by one or more variables before applying functions.\nUse mutate to create new columns or modify existing ones by applying functions to existing data.\nUse summarise to reduce data to summary statistics (e.g., mean, median).\ncount() is a convenient shortcut for counting rows by group without needing group_by() and summarise()."
  },
  {
    "objectID": "slides/day1-afternoon.html#tidy-data-and-tolstoy",
    "href": "slides/day1-afternoon.html#tidy-data-and-tolstoy",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Tidy data and Tolstoy",
    "text": "Tidy data and Tolstoy\n\n“Happy families are all alike; every unhappy family is unhappy in its own way.” — Leo Tolstoy\n\n\nTidy datasets are like happy families: consistent, standardized, and easy to work with.\n\nMessy datasets are like unhappy families: each one messy in its own unique way.\nIn this section:\nWe’ll define what makes data tidy and how to transform between the tidy and messy formats."
  },
  {
    "objectID": "slides/day1-afternoon.html#tidy-data-and-tolstoy-1",
    "href": "slides/day1-afternoon.html#tidy-data-and-tolstoy-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Tidy data and Tolstoy",
    "text": "Tidy data and Tolstoy\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "slides/day1-afternoon.html#what-is-tidy-data",
    "href": "slides/day1-afternoon.html#what-is-tidy-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What is tidy data?",
    "text": "What is tidy data?\n\nTidy data follows a consistent structure: each row represents one observation, and each column represents one variable.\ncases_df is one classic example of tidy data.\n\n\n\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 nc        2022-03-01      1231\n3 ny        2022-03-01      1487\n4 ca        2022-03-02      7044\n5 nc        2022-03-02      2243\n6 ny        2022-03-02      1889\n\n\n\nTo convert between tidy and messy data, we can use the tidyr package in the tidyverse."
  },
  {
    "objectID": "slides/day1-afternoon.html#pivot_wider-and-pivot_longer",
    "href": "slides/day1-afternoon.html#pivot_wider-and-pivot_longer",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "pivot_wider() and pivot_longer()",
    "text": "pivot_wider() and pivot_longer()\n\n  Artwork by @allison_horst"
  },
  {
    "objectID": "slides/day1-afternoon.html#making-data-wider-with-pivot_wider",
    "href": "slides/day1-afternoon.html#making-data-wider-with-pivot_wider",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Making data wider with pivot_wider()",
    "text": "Making data wider with pivot_wider()\n\nTo convert data from long format to wide/messy format use pivot_wider().\nFor example, let’s try creating a column for each time value in cases_df:\n\n\n\nmessy_cases_df &lt;- cases_df |&gt;\n  pivot_wider(\n    names_from = time_value,   # Create new columns for each unique date\n    values_from = raw_cases    # Fill those columns with the raw_case values\n  )\n\n# View the result\nmessy_cases_df\n\n# A tibble: 3 × 32\n  geo_value `2022-03-01` `2022-03-02` `2022-03-03` `2022-03-04` `2022-03-05`\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 ca                4310         7044         7509         3586         1438\n2 nc                1231         2243         2377         2646            0\n3 ny                1487         1889         2390          350         3372\n# ℹ 26 more variables: `2022-03-06` &lt;dbl&gt;, `2022-03-07` &lt;dbl&gt;,\n#   `2022-03-08` &lt;dbl&gt;, `2022-03-09` &lt;dbl&gt;, `2022-03-10` &lt;dbl&gt;,\n#   `2022-03-11` &lt;dbl&gt;, `2022-03-12` &lt;dbl&gt;, `2022-03-13` &lt;dbl&gt;,\n#   `2022-03-14` &lt;dbl&gt;, `2022-03-15` &lt;dbl&gt;, `2022-03-16` &lt;dbl&gt;,\n#   `2022-03-17` &lt;dbl&gt;, `2022-03-18` &lt;dbl&gt;, `2022-03-19` &lt;dbl&gt;,\n#   `2022-03-20` &lt;dbl&gt;, `2022-03-21` &lt;dbl&gt;, `2022-03-22` &lt;dbl&gt;,\n#   `2022-03-23` &lt;dbl&gt;, `2022-03-24` &lt;dbl&gt;, `2022-03-25` &lt;dbl&gt;, …"
  },
  {
    "objectID": "slides/day1-afternoon.html#tidying-messy-data-with-pivot_longer",
    "href": "slides/day1-afternoon.html#tidying-messy-data-with-pivot_longer",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Tidying messy data with pivot_longer()",
    "text": "Tidying messy data with pivot_longer()\n\nUse pivot_longer() to convert data from wide format (multiple columns for the same variable) to long format (one column per variable).\nLet’s try turning messy_cases_df back into the original tidy cases_df!\n\n\ntidy_cases_df &lt;- messy_cases_df |&gt;\n  pivot_longer(\n    cols = -geo_value,          # Keep the 'geo_value' column as it is\n    names_to = \"time_value\",    # Create a new 'time_value' column from the column names\n    values_to = \"raw_cases\"     # Values from the wide columns should go into 'raw_cases'\n  )\n\n# View the result\nhead(tidy_cases_df, n = 3) # Notice the class of time_value here\n\n# A tibble: 3 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-03      7509"
  },
  {
    "objectID": "slides/day1-afternoon.html#tidying-messy-data-with-pivot_longer-1",
    "href": "slides/day1-afternoon.html#tidying-messy-data-with-pivot_longer-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Tidying messy data with pivot_longer()",
    "text": "Tidying messy data with pivot_longer()\n\nWhen we used pivot_longer(), the time_value column is converted to a character class because the column names are treated as strings.\nSo, to truly get the original cases_df we need to convert time_value back to the Date class.\nThen, we can use identical() to check if the two data frames are exactly the same.\n\n\ntidy_cases_df = tidy_cases_df |&gt; mutate(time_value = as.Date(time_value))\n\nidentical(tidy_cases_df |&gt; arrange(time_value), cases_df)\n\n[1] TRUE\n\n\nGreat. That was a success!"
  },
  {
    "objectID": "slides/day1-afternoon.html#introduction-to-joins-in-dplyr",
    "href": "slides/day1-afternoon.html#introduction-to-joins-in-dplyr",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Introduction to joins in dplyr",
    "text": "Introduction to joins in dplyr\n\nJoining datasets is a powerful tool for combining info. from multiple sources.\nIn R, dplyr provides several functions to perform different types of joins.\nWe’ll demonstrate joining a subset of cases_df (our case counts dataset) with state_census.\nMotivation: We can scale the case counts by population to make them comparable across regions of different sizes."
  },
  {
    "objectID": "slides/day1-afternoon.html#subset-cases_df",
    "href": "slides/day1-afternoon.html#subset-cases_df",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Subset cases_df",
    "text": "Subset cases_df\nTo simplify things, let’s use filter() to only grab one date of cases_df:\n\ncases_df_sub &lt;- cases_df |&gt; filter(time_value == \"2022-03-01\")\ncases_df_sub\n\n# A tibble: 3 × 3\n  geo_value time_value raw_cases\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2022-03-01      4310\n2 nc        2022-03-01      1231\n3 ny        2022-03-01      1487\n\n\nThough note that what we’re going to do can be applied to the entirety of cases_df."
  },
  {
    "objectID": "slides/day1-afternoon.html#load-state-census-data",
    "href": "slides/day1-afternoon.html#load-state-census-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Load state census data",
    "text": "Load state census data\nThe state_census dataset from epidatasets contains state populations from the 2019 census.\n\n# State census dataset from epidatasets\nlibrary(epidatasets)\nstate_census = state_census |&gt; select(abbr, pop) |&gt; filter(abbr != \"us\")\n\nstate_census |&gt; head()\n\n# A tibble: 6 × 2\n  abbr       pop\n  &lt;chr&gt;    &lt;dbl&gt;\n1 al     4903185\n2 ak      731545\n3 az     7278717\n4 ar     3017804\n5 ca    39512223\n6 co     5758736\n\n\nNotice that this includes many states that are not in cases_df_sub."
  },
  {
    "objectID": "slides/day1-afternoon.html#left-join-keep-all-rows-from-the-first-dataset",
    "href": "slides/day1-afternoon.html#left-join-keep-all-rows-from-the-first-dataset",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Left Join: Keep all rows from the first dataset",
    "text": "Left Join: Keep all rows from the first dataset\n\nA left join keeps all rows from the first dataset (cases_df_sub), and adds matching data from the second dataset (state_census).\nSo all rows from the first dataset (cases_df_sub) will be preserved.\nThe datasets are joined by matching the geo_value column, specified by the by argument.\n\n\n# Left join: combining March 1, 2022 state case data with the census data\ncases_sub_left_join &lt;- cases_df_sub |&gt;\n  left_join(state_census, join_by(geo_value == abbr))\n\ncases_sub_left_join\n\n# A tibble: 3 × 4\n  geo_value time_value raw_cases      pop\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561"
  },
  {
    "objectID": "slides/day1-afternoon.html#right-join-keep-all-rows-from-the-second-dataset",
    "href": "slides/day1-afternoon.html#right-join-keep-all-rows-from-the-second-dataset",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Right Join: Keep all rows from the second dataset",
    "text": "Right Join: Keep all rows from the second dataset\n\nA right join keeps all rows from the second dataset (state_census), and adds matching data from the first dataset (cases_df_sub).\nIf a row in the second dataset doesn’t have a match in the first, then the columns from the first will be filled with NA.\nFor example, can see this for the al row from state_census…\n\n\n# Right join: keep all rows from state_census\ncases_sub_right_join &lt;- cases_df_sub |&gt;\n  right_join(state_census, join_by(geo_value == abbr))\n\nhead(cases_sub_right_join)\n\n# A tibble: 6 × 4\n  geo_value time_value raw_cases      pop\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561\n4 al        NA                NA  4903185\n5 ak        NA                NA   731545\n6 az        NA                NA  7278717"
  },
  {
    "objectID": "slides/day1-afternoon.html#inner-join-only-keep-matching-rows",
    "href": "slides/day1-afternoon.html#inner-join-only-keep-matching-rows",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Inner Join: Only keep matching rows",
    "text": "Inner Join: Only keep matching rows\n\nAn inner join will only keep rows where there is a match in both datasets.\nSo, if a state in state_census does not have a corresponding entry in cases_df_sub, then that row will be excluded.\n\n\n# Inner join: only matching rows are kept\ncases_sub_inner_join &lt;- cases_df_sub |&gt;\n  inner_join(state_census, join_by(geo_value == abbr))\n\ncases_sub_inner_join\n\n# A tibble: 3 × 4\n  geo_value time_value raw_cases      pop\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561"
  },
  {
    "objectID": "slides/day1-afternoon.html#full-join-keep-all-rows-from-both-datasets",
    "href": "slides/day1-afternoon.html#full-join-keep-all-rows-from-both-datasets",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Full Join: Keep all rows from both datasets",
    "text": "Full Join: Keep all rows from both datasets\n\nA full join will keep all rows from both datasets.\nIf a state in either dataset has no match in the other, the missing values will be filled with NA.\n\n\n# Full join: keep all rows from both datasets\ncases_sub_full_join &lt;- cases_df_sub |&gt;\n  full_join(state_census, join_by(geo_value == abbr))\n\nhead(cases_sub_full_join)\n\n# A tibble: 6 × 4\n  geo_value time_value raw_cases      pop\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561\n4 al        NA                NA  4903185\n5 ak        NA                NA   731545\n6 az        NA                NA  7278717"
  },
  {
    "objectID": "slides/day1-afternoon.html#pictorial-summary-of-the-four-join-functions",
    "href": "slides/day1-afternoon.html#pictorial-summary-of-the-four-join-functions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Pictorial summary of the four join functions",
    "text": "Pictorial summary of the four join functions\n\n\n\nSource"
  },
  {
    "objectID": "slides/day1-afternoon.html#two-review-questions",
    "href": "slides/day1-afternoon.html#two-review-questions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Two review questions",
    "text": "Two review questions\nQ1): What join function should you use if your goal is to scale the cases by population in cases_df?\n\n\nCode\n# Either left_join\ncases_left_join &lt;- cases_df |&gt;\n  left_join(state_census, join_by(geo_value == abbr))\n\ncases_left_join\n\n# Or inner_join\ncases_inner_join &lt;- cases_df |&gt;\n  inner_join(state_census, join_by(geo_value == abbr))\n\ncases_inner_join\n\n\nQ2): Lastly, please create a new column in cases_df where you scale the cases by population and multiply by 1e5 to get cases / 100k.\n\n\nCode\ncase_rates_df &lt;- cases_inner_join |&gt;\n  mutate(scaled_cases = raw_cases / pop * 1e5) # cases / 100K\nhead(case_rates_df)\n\n\nCongratulations for making it through this crash course! That’s all for this glimpse() into the tidyverse."
  },
  {
    "objectID": "slides/day1-afternoon.html#epi.-data-processing-with-epiprocess",
    "href": "slides/day1-afternoon.html#epi.-data-processing-with-epiprocess",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Epi. data processing with epiprocess",
    "text": "Epi. data processing with epiprocess\n\nepiprocess is a package that offers additional functionality to pre-process such epidemiological data.\nYou can work with an epi_df like you can with a tibble by using dplyr verbs.\nFor example, on cases_df, we can easily use epi_slide_mean() to calculate trailing 14 day averages of cases:\n\n\ncase_rates_df &lt;- case_rates_df |&gt;\n  as_epi_df(as_of = as.Date(\"2024-01-01\")) |&gt;\n  group_by(geo_value) |&gt;\n  epi_slide_mean(scaled_cases, .window_size = 14, na.rm = TRUE) |&gt;\n  rename(smoothed_scaled_cases = slide_value_scaled_cases)\nhead(case_rates_df)\n\nAn `epi_df` object, 6 x 6 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-01-01\n\n# A tibble: 6 × 6\n# Groups:   geo_value [1]\n  geo_value time_value raw_cases      pop scaled_cases smoothed_scaled_cases\n* &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;                 &lt;dbl&gt;\n1 ca        2022-03-01      4310 39512223        10.9                   10.9\n2 ca        2022-03-02      7044 39512223        17.8                   14.4\n3 ca        2022-03-03      7509 39512223        19.0                   15.9\n4 ca        2022-03-04      3586 39512223         9.08                  14.2\n5 ca        2022-03-05      1438 39512223         3.64                  12.1\n6 ca        2022-03-06      6465 39512223        16.4                   12.8"
  },
  {
    "objectID": "slides/day1-afternoon.html#epi.-data-processing-with-epiprocess-1",
    "href": "slides/day1-afternoon.html#epi.-data-processing-with-epiprocess-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Epi. data processing with epiprocess",
    "text": "Epi. data processing with epiprocess\nIt is easy to produce an autoplot the smoothed confirmed daily cases for each geo_value:\n\ncase_rates_df |&gt;\n  autoplot(smoothed_scaled_cases)"
  },
  {
    "objectID": "slides/day1-afternoon.html#epi.-data-processing-with-epiprocess-2",
    "href": "slides/day1-afternoon.html#epi.-data-processing-with-epiprocess-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Epi. data processing with epiprocess",
    "text": "Epi. data processing with epiprocess\nAlternatively, we can display both the smoothed and the original daily case rates:\n\nNow, before exploring some more features of epiprocess, let’s have a look at the epiverse software ecosystem it’s part of…"
  },
  {
    "objectID": "slides/day1-afternoon.html#the-epiverse-ecosystem",
    "href": "slides/day1-afternoon.html#the-epiverse-ecosystem",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "The epiverse ecosystem",
    "text": "The epiverse ecosystem\nInterworking, community-driven, packages for epi tracking & forecasting."
  },
  {
    "objectID": "slides/day1-afternoon.html#what-is-panel-data",
    "href": "slides/day1-afternoon.html#what-is-panel-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What is panel data?",
    "text": "What is panel data?\n\nRecall that panel data, or longitudinal data, contain cross-sectional measurements of subjects over time.\nBuilt-in example: covid_case_death_rates dataset, which is a snapshot as of May 31, 2022 that contains daily state-wise measures of case_rate and death_rate for COVID-19 over 2021:\n\n\n\n# A tibble: 6 × 4\n  geo_value time_value case_rate death_rate\n  &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n1 ak        2020-12-31      35.9      0.158\n2 al        2020-12-31      65.1      0.438\n3 ar        2020-12-31      66.0      1.27 \n4 az        2020-12-31      76.8      1.10 \n5 ca        2020-12-31      96.0      0.751\n6 co        2020-12-31      35.8      0.649\n\n\n\nHow do we store & work with such snapshots in the epiverse software ecosystem?"
  },
  {
    "objectID": "slides/day1-afternoon.html#epi_df-snapshot-of-a-dataset",
    "href": "slides/day1-afternoon.html#epi_df-snapshot-of-a-dataset",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "epi_df: Snapshot of a dataset",
    "text": "epi_df: Snapshot of a dataset\n\nYou can convert panel data into an epi_df with the required geo_value and time_value columns\n\nTherefore, an epi_df is…\n\na tibble that requires columns geo_value and time_value.\narbitrary additional columns containing measured values\nadditional keys to index (age_group, ethnicity, etc.)\n\n\n\n\n\n\n\nepi_df\n\n\nRepresents a snapshot that contains the most up-to-date values of the signal variables, as of a given time."
  },
  {
    "objectID": "slides/day1-afternoon.html#epi_df-snapshot-of-a-dataset-1",
    "href": "slides/day1-afternoon.html#epi_df-snapshot-of-a-dataset-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "epi_df: Snapshot of a dataset",
    "text": "epi_df: Snapshot of a dataset\n\nConsider the same dataset we just encountered on JHU daily COVID-19 cases and deaths rates from all states as of May 31, 2022.\nWe can see that it meets the criteria epi_df (has geo_value and time_value columns) and that it contains additional metadata (i.e. geo_type, time_type, as_of, and other_keys).\n\n\n\n\nedf |&gt; head()\n\nAn `epi_df` object, 6 x 4 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2022-05-31\n\n# A tibble: 6 × 4\n  geo_value time_value case_rate death_rate\n* &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n1 ak        2020-12-31      35.9      0.158\n2 al        2020-12-31      65.1      0.438\n3 ar        2020-12-31      66.0      1.27 \n4 as        2020-12-31       0        0    \n5 az        2020-12-31      76.8      1.10 \n6 ca        2020-12-31      96.0      0.751\n\n\n\n\nattr(edf, \"metadata\")\n\n$geo_type\n[1] \"state\"\n\n$time_type\n[1] \"day\"\n\n$as_of\n[1] \"2022-05-31\"\n\n$other_keys\ncharacter(0)"
  },
  {
    "objectID": "slides/day1-afternoon.html#examples-of-preprocessing",
    "href": "slides/day1-afternoon.html#examples-of-preprocessing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of preprocessing",
    "text": "Examples of preprocessing\nEDA features\n\nMaking locations commensurate (per capita scaling)\nCorrelating signals across location or time\nComputing growth rates\nDetecting and removing outliers\nDealing with revisions"
  },
  {
    "objectID": "slides/day1-afternoon.html#features---correlations-at-different-lags",
    "href": "slides/day1-afternoon.html#features---correlations-at-different-lags",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Features - Correlations at different lags",
    "text": "Features - Correlations at different lags\n\n\nThe below plot addresses the question: “For each state, are case and death rates linearly associated across all days?”\nTo explore lagged correlations and how case rates associate with future death rates, we can use the dt1 parameter in epi_cor() to shift case rates by a specified number of days.\n\n\n\ncor0 &lt;- epi_cor(edf, case_rate, death_rate, cor_by = geo_value)\ncor14 &lt;- epi_cor(edf, case_rate, death_rate, cor_by = geo_value, dt1 = -14)\n\n\n\nWe can see that, in general, lagging the case rates back by 14 days improves the correlations."
  },
  {
    "objectID": "slides/day1-afternoon.html#features---systematic-lag-analysis",
    "href": "slides/day1-afternoon.html#features---systematic-lag-analysis",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Features - Systematic lag analysis",
    "text": "Features - Systematic lag analysis\nThe analysis helps identify the lag at which case rates from the past have the strongest correlation with future death rates.\n\nThe strongest correlation occurs at a lag of about 23 days, indicating that case rates are best correlated with death rates 23 days from now."
  },
  {
    "objectID": "slides/day1-afternoon.html#features---compute-growth-rates",
    "href": "slides/day1-afternoon.html#features---compute-growth-rates",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Features - Compute growth rates",
    "text": "Features - Compute growth rates\n\nGrowth rate measures the relative change in a signal over time. \nWe can compute time-varying growth rates for the two states, and see how this cases evolves over time.\n\n\nedfg &lt;- filter(edf, geo_value %in% c(\"ut\", \"ca\")) |&gt;\n  group_by(geo_value) |&gt;\n  mutate(gr_cases = growth_rate(time_value, case_rate, method = \"trend_filter\")) |&gt;\n  ungroup()\n\n\n\nAs expected, the peak growth rates for both states occurred during the January 2022 Omicron wave, reflecting the sharp rise in cases over that period."
  },
  {
    "objectID": "slides/day1-afternoon.html#features---outlier-detection",
    "href": "slides/day1-afternoon.html#features---outlier-detection",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Features - Outlier detection",
    "text": "Features - Outlier detection\n\n\nThe detect_outlr() function offers multiple outlier detection methods on a signal.\nThe simplest is detect_outlr_rm(), which works by calculating an outlier threshold using the rolling median and the rolling Interquartile Range (IQR) for each time point:\n\nThreshold = Rolling Median ± (Detection Multiplier × Rolling IQR)\n\nNote that the default number of time steps to use in the rolling window by default is 21 and is centrally aligned.\nThe detection multiplier default is 2 and controls how far away a data point must be from the median to be considered an outlier.\n\n\nedfo &lt;- filter(edf, geo_value %in% c(\"ut\", \"ca\")) |&gt;\n  select(geo_value, time_value, case_rate) |&gt;\n  as_epi_df() |&gt;\n  group_by(geo_value) |&gt;\n  mutate(outlier_info = detect_outlr_rm(\n    x = time_value, y = case_rate\n  )) |&gt;\n  ungroup()"
  },
  {
    "objectID": "slides/day1-afternoon.html#features---outlier-detection-1",
    "href": "slides/day1-afternoon.html#features---outlier-detection-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Features - Outlier detection",
    "text": "Features - Outlier detection\n\nSeveral data points that deviate from the expected case cadence have been flagged as outliers, and may require further investigation.\nHowever, the peak in Jan. 2022 has also been flagged as an outlier. This highlights the importance of manual inspection before correcting the data, as these may represent valid events (e.g., a genuine surge in cases)."
  },
  {
    "objectID": "slides/day1-afternoon.html#epi_archive-collection-of-epi_dfs",
    "href": "slides/day1-afternoon.html#epi_archive-collection-of-epi_dfs",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "epi_archive: Collection of epi_dfs",
    "text": "epi_archive: Collection of epi_dfs\n\nfull version history of a data set\nacts like a bunch of epi_dfs — but stored compactly\nallows similar functionality as epi_df but using only data that would have been available at the time\n\n\n\n\n\n\n\nRevisions\n\n\nEpidemiology data gets revised frequently.\n\nWe may want to use the data as it looked in the past\nor we may want to examine the history of revisions."
  },
  {
    "objectID": "slides/day1-afternoon.html#epi_archive-collection-of-epi_dfs-1",
    "href": "slides/day1-afternoon.html#epi_archive-collection-of-epi_dfs-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "epi_archive: Collection of epi_dfs",
    "text": "epi_archive: Collection of epi_dfs\nSubset of daily COVID-19 doctor visits (Optum) and cases (JHU CSSE) from 6 states in archive format:\n\narchive_cases_dv_subset\n\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-06-01 / 2021-11-30\nℹ First/last version with update: 2020-06-02 / 2021-12-01\nℹ Versions end: 2021-12-01\nℹ A preview of the table (129638 rows x 5 columns):\nKey: &lt;geo_value, time_value, version&gt;\n        geo_value time_value    version percent_cli case_rate_7d_av\n           &lt;char&gt;     &lt;Date&gt;     &lt;Date&gt;       &lt;num&gt;           &lt;num&gt;\n     1:        ca 2020-06-01 2020-06-02          NA        6.628329\n     2:        ca 2020-06-01 2020-06-06    2.140116        6.628329\n     3:        ca 2020-06-01 2020-06-07    2.140116        6.628329\n     4:        ca 2020-06-01 2020-06-08    2.140379        6.628329\n     5:        ca 2020-06-01 2020-06-09    2.114430        6.628329\n    ---                                                            \n129634:        tx 2021-11-26 2021-11-29    1.858596        7.957657\n129635:        tx 2021-11-27 2021-11-28          NA        7.174299\n129636:        tx 2021-11-28 2021-11-29          NA        6.834681\n129637:        tx 2021-11-29 2021-11-30          NA        8.841247\n129638:        tx 2021-11-30 2021-12-01          NA        9.566218"
  },
  {
    "objectID": "slides/day1-afternoon.html#revision-patterns",
    "href": "slides/day1-afternoon.html#revision-patterns",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Revision patterns",
    "text": "Revision patterns"
  },
  {
    "objectID": "slides/day1-afternoon.html#finalized-data",
    "href": "slides/day1-afternoon.html#finalized-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Finalized data",
    "text": "Finalized data\n\nCounts are revised as time proceeds\nWant to know the final value\nOften not available until weeks/months later\n\nForecasting\n\nAt time \\(t\\), predict the final value for time \\(t+h\\), \\(h &gt; 0\\)\n\n\n\n\nBackcasting\n\nAt time \\(t\\), predict the final value for time \\(t-h\\), \\(h &lt; 0\\)\n\n\n\n\nNowcasting\n\nAt time \\(t\\), predict the final value for time \\(t\\)"
  },
  {
    "objectID": "slides/day1-afternoon.html#backfill-canadian-edition",
    "href": "slides/day1-afternoon.html#backfill-canadian-edition",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Backfill Canadian edition",
    "text": "Backfill Canadian edition\n\nEvery week the BC CDC releases COVID-19 hospitalization data.\nFollowing week they revise the number upward (by ~25%) due to lagged reports.\n\n \n\nTakeaway: Once the data is backfilled, hospitalizations rarely show a decline, challenging the common media narrative."
  },
  {
    "objectID": "slides/day1-afternoon.html#backfill-american-edition",
    "href": "slides/day1-afternoon.html#backfill-american-edition",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Backfill American edition",
    "text": "Backfill American edition\n\nAgain, we can see a similar systematic underestimation problem for COVID-19 morality rates in CA. \nThis plot also illustrates the revision process - how the reported mortality changes & increases across multiple updates until it stabilizes at the final value (black line).\n\n\n\nThese two examples show the problem and now we need a solution…"
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-and-its-mathematical-setup",
    "href": "slides/day1-afternoon.html#nowcasting-and-its-mathematical-setup",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting and its mathematical setup",
    "text": "Nowcasting and its mathematical setup\n\nNowcasting: Predict a finalized value from a provisional value.\nSuppose today is time \\(t\\)\nLet \\(y_i\\) denote a series of interest observed at times \\(i=1,\\ldots, t\\).\n\n\n\n\nOur goal\n\n\n\nProduce a point nowcast for the finalized values of \\(y_t\\).\nAccompany with time-varying prediction intervals\n\n\n\n\n\nWe also have access to \\(p\\) other time series \\(x_{ij},\\; i=1,\\ldots,t, \\; j = 1,\\ldots,p\\)\nAll may be subject to revisions."
  },
  {
    "objectID": "slides/day1-afternoon.html#aside-on-nowcasting",
    "href": "slides/day1-afternoon.html#aside-on-nowcasting",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Aside on nowcasting",
    "text": "Aside on nowcasting\n\nTo some Epis, “nowcasting” can be equated with “estimate the time-varying instantaneous reproduction number, \\(R_t\\)”\nEx. using the number of reported COVID-19 cases in British Columbia between Jan. 2020 and Apr. 15, 2023.\n\n\n\n\n\n\n\n\n\n\n\n\nGroup built {rtestim} doing for this nonparametrically.\nWe may come back to this later…"
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-simple-ratio-ex-nchs-mortality",
    "href": "slides/day1-afternoon.html#nowcasting-simple-ratio-ex-nchs-mortality",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting simple ratio Ex: NCHS mortality",
    "text": "Nowcasting simple ratio Ex: NCHS mortality\n\nIn this example, we’ll demonstrate the concept of nowcasting using NHCS mortality data. (the number of weekly new deaths with confirmed or presumed COVID-19, per 100,000 population).\nWe will work with provisional data (real-time reports) and compare them to finalized data (final reports).\nThe goal is to estimate or nowcast the mortality rate for weeks when only provisional data is available."
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-versioned-data",
    "href": "slides/day1-afternoon.html#fetch-versioned-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch versioned data",
    "text": "Fetch versioned data\nLet’s fetch versioned mortality data from the API (pub_covidcast) for CA (geo_values = \"ca\") and the signal of interest (deaths_covid_incidence_num) over early 2024.\n\n# Fetch the versioned NCHS mortality data (weekly)\nmortality_archive &lt;- pub_covidcast(\n  source = \"nchs-mortality\",\n  signals = \"deaths_covid_incidence_num\",\n  geo_type = \"state\",\n  time_type = \"week\",\n  geo_values = \"ca\",  # California (CA)\n  time_values = epirange(202401, 202413),  \n  issues = \"*\"\n) |&gt; \n  select(geo_value, time_value, version = issue, mortality = value) |&gt; \n  as_epi_archive(compactify = TRUE)\n\n# Set the start and end days for the analysis \n# corresponding to the weeks entered in time_values\nstart_time = as.Date(\"2023-12-31\")\nend_time = as.Date(\"2024-03-24\")"
  },
  {
    "objectID": "slides/day1-afternoon.html#latency-in-reporting---minimum-lag",
    "href": "slides/day1-afternoon.html#latency-in-reporting---minimum-lag",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Latency in reporting - Minimum lag",
    "text": "Latency in reporting - Minimum lag\n\nA quick inspection reveals that mortality rates are systematically 7 days latent (fixed lag).\n\n\nmortality_revision_inspect = mortality_archive$DT |&gt; mutate(version_time_diff = version - time_value)\n\n# Look at the first revision for each week\nmortality_revision_inspect |&gt; group_by(time_value) |&gt; slice(1) |&gt; head()\n\n# A tibble: 6 × 5\n# Groups:   time_value [6]\n  geo_value time_value version    mortality version_time_diff\n  &lt;chr&gt;     &lt;date&gt;     &lt;date&gt;         &lt;dbl&gt; &lt;drtn&gt;           \n1 ca        2023-12-31 2024-01-07        48 7 days           \n2 ca        2024-01-07 2024-01-14        28 7 days           \n3 ca        2024-01-14 2024-01-21        47 7 days           \n4 ca        2024-01-21 2024-01-28        41 7 days           \n5 ca        2024-01-28 2024-02-04        31 7 days           \n6 ca        2024-02-04 2024-02-11        47 7 days           \n\n\n\nUse revision_summary() from epiprocess to generate basic statistics about the revision behavior for the dataset."
  },
  {
    "objectID": "slides/day1-afternoon.html#latency-in-reporting---finalized-value-attainment",
    "href": "slides/day1-afternoon.html#latency-in-reporting---finalized-value-attainment",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Latency in reporting - Finalized value attainment",
    "text": "Latency in reporting - Finalized value attainment\n\nQuestion: When is the finalized value first attained for each date? Would we have access to any in real-time?\nHow fast are the final values attained & what’s the pattern for these times, if any?\n\n\n\n# A tibble: 6 × 4\n  geo_value time_value min_version diff    \n  &lt;chr&gt;     &lt;date&gt;     &lt;date&gt;      &lt;drtn&gt;  \n1 ca        2023-12-31 2024-10-13  287 days\n2 ca        2024-01-07 2024-10-27  294 days\n3 ca        2024-01-14 2024-06-09  147 days\n4 ca        2024-01-21 2024-08-11  203 days\n5 ca        2024-01-28 2024-07-07  161 days\n6 ca        2024-02-04 2024-10-13  252 days\n\n\nAnd here’s a numerical summary:\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   84.0   147.0   189.0   192.8   259.0   294.0 \n\n\n\nConclusion: Tends to take a long time & varies. Even for this relatively small time period… Goes as low as 84 days or as high as 294 days. Yikes.\nSo if we were doing this in real-time, then we wouldn’t have access to the finalized data."
  },
  {
    "objectID": "slides/day1-afternoon.html#comparison-of-final-vs.-multiple-revisions",
    "href": "slides/day1-afternoon.html#comparison-of-final-vs.-multiple-revisions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Comparison of final vs. multiple revisions",
    "text": "Comparison of final vs. multiple revisions\nThis shows the finalized rates in comparison to multiple revisions to see how the data changes over time:"
  },
  {
    "objectID": "slides/day1-afternoon.html#comparison-of-final-vs.-one-revision",
    "href": "slides/day1-afternoon.html#comparison-of-final-vs.-one-revision",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Comparison of final vs. one revision",
    "text": "Comparison of final vs. one revision\nThe below figure compares the finalized rates (in black) to one revision (in yellow) from March 3, 2024.\n\n\n\n\n\n\n\n\n\nThe real-time data is biased downwards (systematically below the true value). That is, the signal tends to get scaled up with future revisions."
  },
  {
    "objectID": "slides/day1-afternoon.html#calculate-one-ratio-provisional-vs.-finalized-data",
    "href": "slides/day1-afternoon.html#calculate-one-ratio-provisional-vs.-finalized-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Calculate one ratio: Provisional vs. finalized data",
    "text": "Calculate one ratio: Provisional vs. finalized data\n\nSuppose that the day is March 10, 2024. Then, because the data is 7 days latent, we can compute the ratio between provisional and finalized data for March 3, 2024.\n\nas_of_date = as.Date(\"2024-03-10\"); fixed_lag = 7\n\n# Load the finalized mortality data for CA\nca_finalized &lt;- mortality_latest |&gt;\n  filter(time_value == (as_of_date - fixed_lag)) |&gt;\n  dplyr::select(mortality)\n\n# Load the provisional mortality data for the same week\nmortality_old = epix_as_of(mortality_archive, as_of_date)\n\nca_provisional &lt;- mortality_old |&gt;\n  filter(time_value == (as_of_date - fixed_lag)) |&gt;\n  dplyr::select(mortality)\n\n# Calculate ratio between provisional and finalized cases for the week of interest\nratio &lt;- ca_provisional$mortality / ca_finalized$mortality\nratio\n\n[1] 0.3611111\n\n\nConclusion: The real-time rate is well below the finalized for this time (26 vs 72 here).\nQuestion: Can we generalize this over many days?"
  },
  {
    "objectID": "slides/day1-afternoon.html#calculating-the-ratio-using-multiple-dates",
    "href": "slides/day1-afternoon.html#calculating-the-ratio-using-multiple-dates",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Calculating the ratio using multiple dates",
    "text": "Calculating the ratio using multiple dates\nLet’s move from calculating the ratio by using one day to multiple days with the goal to use it to nowcast for Feb. 18, which has a provisional value of 23\n\nas_of_date = as.Date(\"2024-02-25\")\n\nprovisional &lt;- epix_as_of(mortality_archive, as_of_date) |&gt;\n  filter(time_value == as_of_date - 7) |&gt;\n  pull(mortality)\nprovisional\n\n[1] 23\n\n\n and a finalized value of 104\n\nfinalized &lt;- mortality_latest |&gt;\n  filter(time_value == as_of_date - 7) |&gt;\n  pull(mortality)\nfinalized\n\n[1] 104"
  },
  {
    "objectID": "slides/day1-afternoon.html#calculating-the-ratio-using-multiple-dates-1",
    "href": "slides/day1-afternoon.html#calculating-the-ratio-using-multiple-dates-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Calculating the ratio using multiple dates",
    "text": "Calculating the ratio using multiple dates\nFirst, let’s download the real-time rates for CA, and compare them to their finalized version.\n\ndates &lt;- seq(start_time, (as_of_date - 7), by = \"day\")\nmortality_real_time &lt;- function(date) {\n  epix_as_of(mortality_archive, date + 7) |&gt;\n    filter(time_value == date)\n}\nmortality_real_time_df &lt;- map_dfr(dates, mortality_real_time)\nhead(mortality_real_time_df)\n\nAn `epi_df` object, 6 x 3 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-01-07\n\n# A tibble: 6 × 3\n  geo_value time_value mortality\n* &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2023-12-31        48\n2 ca        2024-01-07        28\n3 ca        2024-01-14        47\n4 ca        2024-01-21        41\n5 ca        2024-01-28        31\n6 ca        2024-02-04        47"
  },
  {
    "objectID": "slides/day1-afternoon.html#calculating-the-ratio-using-multiple-dates-2",
    "href": "slides/day1-afternoon.html#calculating-the-ratio-using-multiple-dates-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Calculating the ratio using multiple dates",
    "text": "Calculating the ratio using multiple dates\nNow, let’s plot the real-time vs the finalized mortality rates:\n\n\nTakeaways: The real-time counts are biased well below the finalized counts.\nSystematic underreporting tends to lessen over time (the gap between the lines decreases)."
  },
  {
    "objectID": "slides/day1-afternoon.html#realistic-limitation-of-nowcasting---finalized-data",
    "href": "slides/day1-afternoon.html#realistic-limitation-of-nowcasting---finalized-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Realistic limitation of nowcasting - Finalized data",
    "text": "Realistic limitation of nowcasting - Finalized data\n\nRecall that real-time access to finalized data is limited as finalized values can take months to report (e.g., Jan. 7 is finalized 294 days later).\nTo nowcast accurately, we must rely on the best available approximation of finalized data at the time of estimation (Feb. 25).\n\n\nmortality_as_of_feb25 &lt;- epix_as_of(mortality_archive, as_of_date)\nhead(mortality_as_of_feb25)\n\nAn `epi_df` object, 6 x 3 with metadata:\n* geo_type  = state\n* time_type = week\n* as_of     = 2024-02-25\n\n# A tibble: 6 × 3\n  geo_value time_value mortality\n* &lt;chr&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 ca        2023-12-31       213\n2 ca        2024-01-07       183\n3 ca        2024-01-14       183\n4 ca        2024-01-21       146\n5 ca        2024-01-28       124\n6 ca        2024-02-04       120"
  },
  {
    "objectID": "slides/day1-afternoon.html#ratio-calculation-summary",
    "href": "slides/day1-afternoon.html#ratio-calculation-summary",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Ratio calculation & summary",
    "text": "Ratio calculation & summary\nWe then use these “finalized” and real-time values to compute the mean ratio:\n\n# exclude date we're nowcasting for\nmortality_real_time_df = mortality_real_time_df |&gt; filter(time_value != \"2024-02-18\") \nmortality_as_of_feb25 = mortality_as_of_feb25 |&gt; filter(time_value != \"2024-02-18\")\nratio_real_time_to_feb25 &lt;- mortality_real_time_df$mortality / mortality_as_of_feb25$mortality\nsummary(ratio_real_time_to_feb25)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.1530  0.2317  0.2500  0.2565  0.2688  0.3917 \n\n\nOn average, the real-time rates are ~25.7% of the finalized.\n\nTells us the distribution is right-skewed (mean &gt; median) and so we should opt for the median."
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-on-feb.-25",
    "href": "slides/day1-afternoon.html#nowcasting-on-feb.-25",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting on Feb. 25",
    "text": "Nowcasting on Feb. 25\n\nSince the median ratio between real-time and finalized values is 0.250 (i.e., real-time values are typically 25% of the finalized), then the nowcast is\n\n\n# Now we can nowcast properly:\nnowcast &lt;- provisional *\n  1 / median(ratio_real_time_to_feb25)\nnowcast\n\n[1] 92\n\n\n\nTo get the accompanying 95% prediction interval, calculate the 2.5th and 97.5th percentiles:\n\n\npercentile_97.5 &lt;- quantile(ratio_real_time_to_feb25, 0.975) |&gt; unname()\n\n(lower_PI &lt;- provisional * 1 / percentile_97.5)\n\n[1] 61.3268\n\n\n\npercentile_2.5 &lt;- quantile(ratio_real_time_to_feb25, 0.025) |&gt; unname()\n(upper_PI &lt;- provisional * 1 / percentile_2.5)\n\n[1] 140.3659\n\n\n\nSo, the nowcast is 92 with 95% PI: [61, 140], which is much closer to the finalized value of 104 than the provisional value of 23."
  },
  {
    "objectID": "slides/day1-afternoon.html#summary-of-three-main-steps",
    "href": "slides/day1-afternoon.html#summary-of-three-main-steps",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Summary of three main steps",
    "text": "Summary of three main steps\nSo the main steps for this type of fixed lag nowcasting are…\n\nObtain the provisional value for the target.\nEstimate the ratio using the real-time and “finalized” data (for all previous dates that follow a consistent pattern in reporting).\nProfit.\n\n\n\nExpand for the accompanying code\n# Today\nas_of_date = as.Date(\"2024-02-25\")\n\n# 1. Obtain the provisional value\nprovisional &lt;- epix_as_of(mortality_archive, as_of_date) |&gt;\n  filter(time_value == as_of_date - 7) |&gt;\n  pull(mortality)\nprovisional\n\n# 2. Estimate the ratio \nmortality_real_time_df &lt;- map_dfr(dates, mortality_real_time) |&gt; filter(time_value != \"2024-02-18\") # Real-time\nmortality_as_of_feb25 &lt;- epix_as_of(mortality_archive, as_of_date) |&gt; filter(time_value != \"2024-02-18\")  # \"Finalized\"\n\nratio_real_time_to_feb25 &lt;- mortality_real_time_df$mortality / mortality_as_of_feb25$mortality\n\n# 3. Profit.\n(nowcast &lt;- provisional * 1 / median(ratio_real_time_to_feb25))\n\n(upper_PI &lt;- provisional * 1 / quantile(ratio_real_time_to_feb25, 0.025))\n(lower_PI &lt;- provisional * 1 / quantile(ratio_real_time_to_feb25, 0.975))"
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-mortality-for-multiple-dates",
    "href": "slides/day1-afternoon.html#nowcasting-mortality-for-multiple-dates",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting mortality for multiple dates",
    "text": "Nowcasting mortality for multiple dates\n\nDefine Nowcast Function:\n\nInput: Takes in the dates to nowcast and the fixed lag\nOutput: The nowcasted mortality rates based on the ratio of real-time to finalized data.\n\n\n\n\nCode\nnowcast_function &lt;- function(nowcast_date, fixed_lag) {\n  as_of_date = nowcast_date + fixed_lag\n  \n  # 1. Obtain the provisional value for the target.\n  provisional &lt;- epix_as_of(mortality_archive, as_of_date) |&gt;\n    filter(time_value == as_of_date - fixed_lag) |&gt;\n    pull(mortality)\n  \n  #2. Estimate the ratio multiplier using\n  # real-time\n  dates_seq &lt;- seq(start_time, (nowcast_date - fixed_lag), by = \"week\")\n  mortality_real_time &lt;- map_dfr(dates_seq, mortality_real_time)\n  \n  # and \"finalized\" data\n  finalized &lt;- epix_as_of(mortality_archive, as_of_date) |&gt; filter(time_value &gt;= start_time & time_value &lt;= (nowcast_date - fixed_lag)) \n  \n  ratios &lt;- mortality_real_time$mortality / finalized$mortality\n  \n  # Remove infinite or NaN ratios (i.e., keep only finite values)\n  median_ratio &lt;- median(ratios[is.finite(ratios)])\n  \n  #3. Profit.\n  nowcast &lt;- provisional * (1 / median_ratio)\n  upper_PI &lt;- provisional * (1 / quantile(ratios[is.finite(ratios)], 0.025))\n  lower_PI &lt;- provisional * (1 / quantile(ratios[is.finite(ratios)], 0.975))\n  \n  # Return a dataframe with the nowcast and date\n  tibble(\n    time_value = nowcast_date,\n    nowcast = nowcast,\n    lower_PI = lower_PI,\n    upper_PI = upper_PI \n  )\n}"
  },
  {
    "objectID": "slides/day1-afternoon.html#map-nowcast-over-multiple-dates",
    "href": "slides/day1-afternoon.html#map-nowcast-over-multiple-dates",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Map nowcast over multiple dates",
    "text": "Map nowcast over multiple dates\n\nWe can use map2() to apply the function to a series of weeks (e.g., Jan. 28 to Mar. 24).\nReturns a dataframe with nowcasted results.\n\n\n# Apply Nowcast Function Over Multiple Dates\nnowcast_dates &lt;- seq(as.Date(\"2024-01-28\"), as.Date(\"2024-03-24\"), by = \"week\")\nfixed_lag &lt;- 7\nnowcast_results_df &lt;- map2(nowcast_dates, fixed_lag, nowcast_function) |&gt; list_rbind()\n\nLet’s smooth with a rolling trailing mean (window size 4) & see the results:\n\n\n# A tibble: 9 × 2\n  time_value nowcast_mortality\n  &lt;date&gt;                 &lt;dbl&gt;\n1 2024-01-28             116. \n2 2024-02-04             145. \n3 2024-02-11             114. \n4 2024-02-18             109. \n5 2024-02-25             110. \n6 2024-03-03              92.8\n7 2024-03-10              90.3\n8 2024-03-17              82.6\n9 2024-03-24              65.4"
  },
  {
    "objectID": "slides/day1-afternoon.html#visualize-nowcast-real-time-and-finalized-values",
    "href": "slides/day1-afternoon.html#visualize-nowcast-real-time-and-finalized-values",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Visualize nowcast, real-time, and finalized values",
    "text": "Visualize nowcast, real-time, and finalized values\nFinally, we can compare these nowcast results to the real-time and finalized values:\n\nThe real-time counts tend to be biased below the finalized counts. Nowcasted values tend to provide a much better approximation of the truth (at least for these dates)."
  },
  {
    "objectID": "slides/day1-afternoon.html#evaluation-using-mae",
    "href": "slides/day1-afternoon.html#evaluation-using-mae",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Evaluation using MAE",
    "text": "Evaluation using MAE\n\nAssume we have prediction \\(\\hat y_{t}\\) for the provisional value at time \\(t\\).\nThen for \\(y_{t}\\) over times \\(t = 1, \\dots, N\\), then we may compute error metrics like mean absolute error (MAE).\n\n\n\nMAE measures the average absolute difference between the nowcast and finalized values.\n\n\\[MAE = \\frac{1}{N} \\sum_{t=1}^N |y_{t}- \\hat y_{t}|\\]\n\nNote that it’s scale-dependent, meaning it can vary depending on the units of the data (e.g., cases, deaths, etc.)."
  },
  {
    "objectID": "slides/day1-afternoon.html#evaluation-using-mae-1",
    "href": "slides/day1-afternoon.html#evaluation-using-mae-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Evaluation using MAE",
    "text": "Evaluation using MAE\nLet’s numerically evaluate our point nowcasts for the provisional values of a time series (e.g., COVID-19 mortality) using MAE.\n\n\n# Step 1: Join the mortality data with nowcast data\nmae_data &lt;- mortality_latest |&gt; \n  filter(time_value %in% nowcast_dates) |&gt;   \n  left_join(nowcast_results_df, by = \"time_value\") |&gt; \n  left_join(map_dfr(nowcast_dates, mortality_real_time) |&gt; rename(real_time = mortality), by = c(\"geo_value\", \"time_value\"))\n\n# Step 2: Calculate the absolute error between actual and nowcasted values\nmae_data &lt;- mae_data |&gt; \n  mutate(nc_abs_error = abs(mortality - nowcast),\n         rt_abs_error = abs(mortality - real_time))  \n\n# Step 3: Compute the MAE (mean of absolute errors)\nmae_value &lt;- mae_data |&gt; \n  summarise(nc_MAE = mean(nc_abs_error),\n            rt_MAE = mean(rt_abs_error))\nknitr::kable(mae_value)\n\n\n\n\nnc_MAE\nrt_MAE\n\n\n\n\n28.88889\n71.44444"
  },
  {
    "objectID": "slides/day1-afternoon.html#evaluation-using-mae-2",
    "href": "slides/day1-afternoon.html#evaluation-using-mae-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Evaluation using MAE",
    "text": "Evaluation using MAE\nFinally, we may visualize the distribution of errors across time:\n\nWe can see that the absolute errors are almost always lower for nowcasting."
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-moving-from-one-signal-to-two",
    "href": "slides/day1-afternoon.html#nowcasting-moving-from-one-signal-to-two",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting: Moving from one signal to two",
    "text": "Nowcasting: Moving from one signal to two\n\nRecall that in nowcasting the goal is to predict a finalized value from a provisional value.\nNow, we’ll move from one signal to two, creating a simple linear model to nowcast.\nExogenous features (predictors) could include relevant signals, such as Google symptom search trends.\nWe will use these signals to nowcast hospital admissions related to influenza."
  },
  {
    "objectID": "slides/day1-afternoon.html#data-sources-google-searches-hospital-admissions",
    "href": "slides/day1-afternoon.html#data-sources-google-searches-hospital-admissions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Data Sources: Google searches & hospital admissions",
    "text": "Data Sources: Google searches & hospital admissions\n\nGoogle Search Trends: Symptoms like cough, fever, and shortness of breath.\n\ns01: Cough, Phlegm, Sputum, Upper respiratory tract infection\n\ns02: Nasal congestion, Post nasal drip, Sinusitis, Common cold\n\nHospital Admissions: Data from the Department of Health & Human Services on confirmed influenza admissions.\nUsing these, we will nowcast hospital admissions by using Google symptom search trends for GA from April to June 2023.\nThe first step is to fetch this data…"
  },
  {
    "objectID": "slides/day1-afternoon.html#data-sources-google-searches-hospital-admissions-1",
    "href": "slides/day1-afternoon.html#data-sources-google-searches-hospital-admissions-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Data Sources: Google searches & hospital admissions",
    "text": "Data Sources: Google searches & hospital admissions\n\n# Fetch Google symptom data for s01 and s02\nx1 &lt;- pub_covidcast(\n  source = \"google-symptoms\",\n  signals = \"s01_smoothed_search\", \n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"ga\",\n  time_values = epirange(20230401, 20230701),\n  issues = \"*\"\n) |&gt;\n  select(geo_value, time_value, version = issue, avg_search_vol_s01 = value) |&gt;\n  as_epi_archive(compactify = FALSE)\n\nx2 &lt;- pub_covidcast(\n  source = \"google-symptoms\",\n  signals = \"s02_smoothed_search\",\n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"ga\",\n  time_values = epirange(20230401, 20230701),\n  issues = \"*\"\n) |&gt;\n  select(geo_value, time_value, version = issue, avg_search_vol_s02 = value) |&gt;\n  as_epi_archive(compactify = FALSE)\n\n# Fetch hospital admissions data\ny1 &lt;- pub_covidcast(\n  source = \"hhs\",\n  signals = \"confirmed_admissions_influenza_1d\",\n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"ga\",\n  time_values = epirange(20230401, 20230701),\n  issues = \"*\"\n) |&gt;\n  select(geo_value, time_value, version = issue, admissions = value) |&gt;\n  as_epi_archive(compactify = FALSE)"
  },
  {
    "objectID": "slides/day1-afternoon.html#merging-the-archives",
    "href": "slides/day1-afternoon.html#merging-the-archives",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Merging the archives",
    "text": "Merging the archives\n\nWe’ll merge the symptom search trends (x1, x2) with hospital admissions data (y) using epix_merge() from epiprocess.\nThis allows us to match data by time and geography, & fill any missing values with the most recent observation (LOCF)."
  },
  {
    "objectID": "slides/day1-afternoon.html#linear-model-a-simple-approach-for-nowcasting",
    "href": "slides/day1-afternoon.html#linear-model-a-simple-approach-for-nowcasting",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Linear Model: A simple approach for nowcasting",
    "text": "Linear Model: A simple approach for nowcasting\n\nAside from ratios, one of the simplest approach to nowcasting is to use a linear regression model.\nWe model the relationship between provisional (predictor) data and response data.\nThis model helps us make predictions for the finalized data based on the current (provisional) signals."
  },
  {
    "objectID": "slides/day1-afternoon.html#linear-regression",
    "href": "slides/day1-afternoon.html#linear-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Linear regression",
    "text": "Linear regression\n\nGoal: Estimate the coefficients \\(\\beta_0\\) and \\(\\beta_1\\) that describe the relationship between the predictor \\(x_i\\) and the outcome \\(y_i\\).\nLinear Model: The relationship is assumed to be:\n\\[y_i \\approx \\beta_0 + \\beta_1 x_i \\]\nwhere \\(\\beta_0\\) is the intercept, \\(\\beta_1\\) is the slope.\nIn R: Use lm(y ~ x) to estimate the coefficients, where y is the outcome variable and x is the predictor."
  },
  {
    "objectID": "slides/day1-afternoon.html#multiple-linear-regression",
    "href": "slides/day1-afternoon.html#multiple-linear-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nGoal: Estimate coefficients \\(\\beta_0, \\beta_1, \\dots, \\beta_p\\) that describe the relationship between multiple predictors \\(x_{i1}, x_{i2}, \\dots, x_{ip}\\) and the outcome \\(y_i\\).\nModel: The relationship is assumed to be:\n\\[y_i \\approx \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip}\\]\nwhere: \\(\\beta_0\\) is the intercept, \\(\\beta_1, \\dots, \\beta_p\\) are the coefficients.\nIn R: Use lm(y ~ x1 + x2 + ... + xp) to estimate the coefficients, where y is the outcome and x1, x2, ..., xp are the predictors."
  },
  {
    "objectID": "slides/day1-afternoon.html#multiple-linear-regression-model",
    "href": "slides/day1-afternoon.html#multiple-linear-regression-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Multiple linear regression model",
    "text": "Multiple linear regression model\n\nA linear model is a good choice to describe the relationship between search trends and hospital admissions.\nThe model will include two predictors (s01 and s02).\nWe’ll use these two search trend signals to predict hospital admissions (response)."
  },
  {
    "objectID": "slides/day1-afternoon.html#multiple-linear-regression-model-1",
    "href": "slides/day1-afternoon.html#multiple-linear-regression-model-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Multiple linear regression model",
    "text": "Multiple linear regression model\n\n# Define the function for lm model fit and prediction\nlm_mod_pred &lt;- function(data, gk, rtv, ...) {\n  \n  # Fit the linear model\n  model &lt;- lm(admissions ~ avg_search_vol_s01 + avg_search_vol_s02, data = data)\n  \n  # Make predictions\n  predictions = predict(model,\n                        newdata = data |&gt;\n                          # Use tidyr::fill() for LOCF if predictor data is incomplete \n                          fill(avg_search_vol_s01, .direction = \"down\") |&gt; \n                          fill(avg_search_vol_s02, .direction = \"down\") |&gt;\n                          filter(time_value == max(time_value)),\n                        interval = \"prediction\", level = 0.9\n  )\n\n  # Pull off true time value for comparison to target\n  real_time_val = data |&gt; filter(time_value == max(time_value)) |&gt; pull(admissions)\n\n  return(data.frame(predictions, actual_nowcast_date = max(data$time_value), real_time_val = real_time_val))\n}\n\nNote that this code is intentionally simple; while it can be refined to handle cases like negatives or other boundary conditions, we aim to avoid unnecessary complexity."
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-with-epix_slide",
    "href": "slides/day1-afternoon.html#nowcasting-with-epix_slide",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting with epix_slide()",
    "text": "Nowcasting with epix_slide()\n\nWe will use epix_slide() to create a sliding window of training data.\nThe model will be trained on a 14-day window before the target date, and predictions will be made for the target date.\nThe beauty of this function is that it is version-aware - the sliding computation at any given reference time t is performed on data that would have been available as of t automatically."
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-with-epix_slide-1",
    "href": "slides/day1-afternoon.html#nowcasting-with-epix_slide-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting with epix_slide()",
    "text": "Nowcasting with epix_slide()\n\n# Define the reference time points for nowcasting\ntargeted_nowcast_dates &lt;- seq(as.Date(\"2023-04-15\"), as.Date(\"2023-06-15\"), by = \"1 week\")\nref_time_values = targeted_nowcast_dates + 2  # Adjust for the systematic 2-day latency in the response\n# Determine this from revision_summary(y1, print_inform = TRUE) \n\n# Perform nowcasting using epix_slide\nnowcast_res &lt;- archive |&gt;\n  group_by(geo_value) |&gt;\n  epix_slide(\n    .f = lm_mod_pred,\n    .before = 14,  # 14-day training period\n    .versions = ref_time_values, \n    .new_col_name = \"res\"\n  ) |&gt;\n  unnest() |&gt; # Nesting creates a list-column of data frames; unnesting flattens it back out into regular columns. \n  mutate(targeted_nowcast_date = targeted_nowcast_dates, time_value = actual_nowcast_date) |&gt;\n  ungroup()\n\n# View results\nhead(nowcast_res, n=2)\n\n# A tibble: 2 × 9\n  geo_value version      fit    lwr   upr actual_nowcast_date real_time_val\n  &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;                      &lt;dbl&gt;\n1 ga        2023-04-17  4.64 -0.122  9.39 2023-04-15                      4\n2 ga        2023-04-24  7.36  1.56  13.2  2023-04-22                      4\n# ℹ 2 more variables: targeted_nowcast_date &lt;date&gt;, time_value &lt;date&gt;"
  },
  {
    "objectID": "slides/day1-afternoon.html#compare-with-the-actual-admissions",
    "href": "slides/day1-afternoon.html#compare-with-the-actual-admissions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Compare with the actual admissions",
    "text": "Compare with the actual admissions\nAfter making predictions, we compare them to the actual hospital admissions.\n\n# Left join with latest results \n# Latest snapshot of data (with the latest/finalized admissions)\nx_latest &lt;- epix_as_of(archive, max(archive$DT$version)) |&gt; select(-c(avg_search_vol_s01, avg_search_vol_s02))\n\nres &lt;- nowcast_res |&gt; left_join(x_latest, by = join_by(geo_value, time_value))\nhead(res)\n\n# A tibble: 6 × 10\n  geo_value version      fit    lwr   upr actual_nowcast_date real_time_val\n  &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;                      &lt;dbl&gt;\n1 ga        2023-04-17  4.64 -0.122  9.39 2023-04-15                      4\n2 ga        2023-04-24  7.36  1.56  13.2  2023-04-22                      4\n3 ga        2023-05-01  6.06  1.57  10.5  2023-04-29                      5\n4 ga        2023-05-08  5.01  1.28   8.74 2023-05-06                      6\n5 ga        2023-05-15  8.14  5.69  10.6  2023-05-11                      8\n6 ga        2023-05-22  3.43 -2.35   9.21 2023-05-20                      4\n# ℹ 3 more variables: targeted_nowcast_date &lt;date&gt;, time_value &lt;date&gt;,\n#   admissions &lt;dbl&gt;"
  },
  {
    "objectID": "slides/day1-afternoon.html#visualizing-the-nowcast-results",
    "href": "slides/day1-afternoon.html#visualizing-the-nowcast-results",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Visualizing the nowcast results",
    "text": "Visualizing the nowcast results\nWe can then visualize the nowcast results alongside the true values using ggplot2:"
  },
  {
    "objectID": "slides/day1-afternoon.html#evaluation-using-mae-3",
    "href": "slides/day1-afternoon.html#evaluation-using-mae-3",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Evaluation using MAE",
    "text": "Evaluation using MAE\n\nAs before, we can evaluate our point nowcasts numerically using MAE.\n\n\n# Calculate the absolute error between actual and nowcasted values\nmae_data_admissions &lt;- res |&gt; \n  mutate(nc_abs_error = abs(admissions - fit),  # Nowcast vs Finalized admissions\n         rt_abs_error = abs(admissions - real_time_val))  # Real-Time vs Finalized admissions\n\n# Compute the MAE (mean of absolute errors)\nmae_value_admissions &lt;- mae_data_admissions |&gt; \n  summarise(nc_MAE = mean(nc_abs_error),\n            rt_MAE = mean(rt_abs_error))\nknitr::kable(mae_value_admissions)\n\n\n\n\nnc_MAE\nrt_MAE\n\n\n\n\n1.180965\n2.333333\n\n\n\n\n\n\nBased off of comparing these simple error measures, the nowcast MAE is clearly better."
  },
  {
    "objectID": "slides/day1-afternoon.html#evaluation-using-mae-4",
    "href": "slides/day1-afternoon.html#evaluation-using-mae-4",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Evaluation using MAE",
    "text": "Evaluation using MAE\nHowever, when we visualize the distribution of errors across time, it is not so cut-and-dry:\n\nThe main driver behind the real-time MAE being greater is the “outlier-like” May 25 AE.\nSo visualizing can provide an important perspective that is missed from a simple numerical summary of error."
  },
  {
    "objectID": "slides/day1-afternoon.html#key-takeaways-linear-regression-nowcasting-example",
    "href": "slides/day1-afternoon.html#key-takeaways-linear-regression-nowcasting-example",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Key Takeaways: Linear regression nowcasting example",
    "text": "Key Takeaways: Linear regression nowcasting example\n\nProvisional Data as Predictors: Using Google symptom search trends to predict influenza hospital admissions.\nSimple Linear Model: A linear regression model captures the relationship between symptom searches and hospital admissions.\nActionable Predictions: Nowcasts provide timely insights for hospital admissions, even before data is finalized.\nSliding Window Approach: Predictions are based on data up to the current time, ensuring no future information influences the nowcast.\nEvaluation: Predictions are compared with actual admissions using numerical and visual perspectives."
  },
  {
    "objectID": "slides/day1-afternoon.html#goal-of-this-case-study",
    "href": "slides/day1-afternoon.html#goal-of-this-case-study",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Goal of this case study",
    "text": "Goal of this case study\nGoal: Nowcast COVID-19 Cases for MA using the estimated percentage of COVID-related doctor’s visits (%CLI), based on outpatient data from Optum.\n\n%CLI is contained in the Epidata API.\nCases by specimen collection date are not. They are from the MA gov website.\nCases in the API (JHU) are aligned by report date, not specimen collection/test date.\nWorking with cases aligned by test date allows us to avoid the more unpredictable delays introduced by the report date."
  },
  {
    "objectID": "slides/day1-afternoon.html#summary-of-main-steps",
    "href": "slides/day1-afternoon.html#summary-of-main-steps",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Summary of main steps",
    "text": "Summary of main steps\nThe workflow is similar to the previous example where we nowcasted using two variables, only more involved. The main steps are…\n\nFetch Data: Retrieve %CLI and COVID-19 case data (by specimen collection date) for MA.\nMerge Data: Align %CLI and case data using epix_merge, filling missing values via last observation carried forward (LOCF).\nModel & Prediction: Fit a linear model to predict cases based on %CLI, trained on a 30-day rolling window.\nNowcast Execution: Use epix_slide to nowcast the cases dynamically.\nVisualization: Plot actual vs. nowcasted cases with confidence intervals to assess model accuracy.\n\nSo the first step is to fetch the data…"
  },
  {
    "objectID": "slides/day1-afternoon.html#construct-an-epi_archive-from-scratch",
    "href": "slides/day1-afternoon.html#construct-an-epi_archive-from-scratch",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Construct an epi_archive from scratch",
    "text": "Construct an epi_archive from scratch\nHere’s the archive of COVID-19 case excel files from the MA gov website, which we’ll use to construct our own epi_archive.   Brief summary of this data:\n\nFirst release: Raw .xlsx data was first released early January 2021.\nChange in reporting: Starting July 1, 2021, the dashboard shifted from 7 days/week to 5 days/week (Monday-Friday).\nFriday, Saturday, and Sunday data is included in the Monday dashboard.\nWhen Monday is a holiday, the Friday through Monday data is posted on Tuesday."
  },
  {
    "objectID": "slides/day1-afternoon.html#construct-an-epi_archive-from-scratch-1",
    "href": "slides/day1-afternoon.html#construct-an-epi_archive-from-scratch-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Construct an epi_archive from scratch",
    "text": "Construct an epi_archive from scratch\n\nPurpose: To create an epi_archive object for storing versioned time series data.\nRequired Columns:\n\ngeo_value: Geographic data (e.g., region).\ntime_value: Time-related data (e.g., date, time).\nversion: Tracks when the data was available (enables version-aware forecasting).\n\nConstructor:\n\nnew_epi_archive(): For manual construction of epi_archive (assumes validation of inputs).\n\nRecommended Method:\n\nas_epi_archive(): Simplifies the creation process, ensuring proper formatting and validation. We’ll use this one when we download some data from the MA gov website!"
  },
  {
    "objectID": "slides/day1-afternoon.html#main-steps-to-construct-the-epi_archive",
    "href": "slides/day1-afternoon.html#main-steps-to-construct-the-epi_archive",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Main steps to construct the epi_archive",
    "text": "Main steps to construct the epi_archive\n\nLoad necessary Libraries: Such as tidyverse, readxl, epiprocess.\nProcess Each Date’s Data:\n\nA function we’ll make (process_covid_data) downloads and processes daily COVID-19 data from the MA gov Excel files on their website.\nThe data is cleaned and formatted with columns: geo_value, time_value, version, and values.\n\nHandle Missing Data: Checks if a date’s data is available (handle 404 errors).\nCreate epi_archive:\n\nCombine processed data into a tibble.\nConvert the tibble to an epi_archive object using as_epi_archive()."
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---code-for-one-date",
    "href": "slides/day1-afternoon.html#fetch-data---code-for-one-date",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - Code for one date",
    "text": "Fetch Data - Code for one date\n\n# Load required libraries\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(httr)\nlibrary(tibble)\nlibrary(epiprocess)\n\n# Function to download and process each Excel file for a given date\nprocess_covid_data &lt;- function(Date) {\n  # Generate the URL for the given date\n  url &lt;- paste0(\"https://www.mass.gov/doc/covid-19-raw-data-\", tolower(gsub(\"-0\", \"-\", format(Date, \"%B-%d-%Y\"))), \"/download\") \n  # Applies gsub(\"-0\", \"-\", ...) to replace any occurrence of -0 (such as in \"April-01\") with just - (resulting in \"April-1\").\n  \n  # Check if the URL exists (handle the 404 error by skipping that date)\n  response &lt;- GET(url)\n  \n  if (status_code(response) != 200) {\n    return(NULL)  # Skip if URL doesn't exist (404)\n  }\n  \n  # Define the destination file path for the Excel file\n  file_path &lt;- tempfile(fileext = \".xlsx\")\n  \n  # Download the Excel file\n  GET(url, write_disk(file_path, overwrite = TRUE))\n  \n  # Read the relevant sheet from the Excel file\n  data &lt;- read_excel(file_path, sheet = \"CasesByDate (Test Date)\")\n  \n  # Process the data: rename columns and convert Date\n  data &lt;- data |&gt;\n    rename(\n      Date = `Date`,\n      Positive_Total = `Positive Total`,\n      Positive_New = `Positive New`,\n      Case_Average_7day = `7-day confirmed case average`\n    ) |&gt;\n    mutate(Date = as.Date(Date))  # Convert to Date class\n  \n  # Create a tibble with the required columns for the epi_archive\n  tib &lt;- tibble(\n    geo_value = \"ma\",  # Massachusetts (geo_value)\n    time_value = data$Date,  # Date from the data\n    version = Date,  # The extracted version date\n    case_rate_7d_av = data$Case_Average_7day  # 7-day average case value\n  )\n  \n  return(tib)\n}"
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---code-breakdown",
    "href": "slides/day1-afternoon.html#fetch-data---code-breakdown",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - Code breakdown",
    "text": "Fetch Data - Code breakdown\n\nThis purpose of this function is to download and process each Excel file as of a date.\nURL Creation: Dynamically generates the URL based on the date, removing leading zeros in day values (e.g., “April-01” → “April-1”).\nCheck URL: Sends a request (GET(url)) and skips the date if the URL returns a non-200 status (e.g., 404 error).\nDownload File: Saves the Excel file to a temporary path using tempfile() and GET().\nRead Data: Loads the relevant sheet (“CasesByDate”) from the Excel file using read_excel().\nTibble Creation: Constructs a tibble with geo_value, time_value, version, and case_rate_7d_av to later compile into an epi_archive (you can think of an epi_archive as being a comprised of many epi_dfs)."
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---process-eange-of-dates",
    "href": "slides/day1-afternoon.html#fetch-data---process-eange-of-dates",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - Process eange of dates",
    "text": "Fetch Data - Process eange of dates\n\nNote that process_covid_data() works on one date at a time.\nSo now, we need a function that iterates over a date range and applies process_covid_data() to each date & combines the resulting tibbles into an epi_archive.\nWe call this function process_data_for_date_range()…"
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---process-range-of-dates",
    "href": "slides/day1-afternoon.html#fetch-data---process-range-of-dates",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - Process range of dates",
    "text": "Fetch Data - Process range of dates\n\n# Function to process data for a range of dates\nprocess_data_for_date_range &lt;- function(start_date, end_date) {\n  # Generate a sequence of dates between start_date and end_date\n  date_sequence &lt;- seq(as.Date(start_date), as.Date(end_date), by = \"day\")\n  \n  # Process data for each date and combine results\n  covid_data_list &lt;- lapply(date_sequence, function(Date) {\n    process_covid_data(Date)  # Skip over dates with no data (NULLs will be ignored)\n  })\n  \n  # Combine all non-null individual tibbles into one data frame\n  combined_data &lt;- bind_rows(covid_data_list[!sapply(covid_data_list, is.null)])\n  \n  # Convert the combined data into an epi_archive object\n  if (nrow(combined_data) &gt; 0) {\n    epi_archive_data &lt;- combined_data |&gt;\n      as_epi_archive(compactify = FALSE)\n    \n    return(epi_archive_data)\n  } else {\n    message(\"No valid data available for the given date range.\")\n    return(NULL)\n  }\n}"
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---code-breakdown-1",
    "href": "slides/day1-afternoon.html#fetch-data---code-breakdown-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - Code breakdown",
    "text": "Fetch Data - Code breakdown\nHere’s a summary of what process_data_for_date_range() does: 1. Generates Date Range: Creates a sequence of dates between start_date and end_date.\n\nProcesses Data: Applies the process_covid_data function to each date in the range (skip over dates with no data).\nCombines Results: Combines all valid (non-NULL) tibbles into one single data frame.\nCreates epi_archive: Converts the combined data into an epi_archive object."
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---run-the-function-inspect-archive",
    "href": "slides/day1-afternoon.html#fetch-data---run-the-function-inspect-archive",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - Run the function & inspect archive",
    "text": "Fetch Data - Run the function & inspect archive\n\nNow, let’s run the function & inspect the resulting epi_archive of 7-day avg. COVID-19 case counts:\nExpect building the archive to some time (enough for a cup of coffee or to meditate on life).\n\n\n\n# Example usage: process data between Jan. 10, 2021, and Dec. 1, 2021\ny &lt;- process_data_for_date_range(\"2021-01-10\", \"2021-12-01\")  # Raw .xlsx data is first released on Jan. 4, 2021\ny\n\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-01-29 / 2021-11-30\nℹ First/last version with update: 2021-01-10 / 2021-12-01\nℹ Versions end: 2021-12-01\nℹ A preview of the table (135549 rows x 4 columns):\nKey: &lt;geo_value, time_value, version&gt;\n        geo_value time_value    version case_rate_7d_av\n           &lt;char&gt;     &lt;Date&gt;     &lt;Date&gt;           &lt;num&gt;\n     1:        ma 2020-01-29 2021-01-10              NA\n     2:        ma 2020-01-29 2021-01-11              NA\n     3:        ma 2020-01-29 2021-01-12              NA\n     4:        ma 2020-01-29 2021-01-13              NA\n     5:        ma 2020-01-29 2021-01-14              NA\n    ---                                                \n135545:        ma 2021-11-28 2021-11-30        2196.000\n135546:        ma 2021-11-28 2021-12-01        2352.286\n135547:        ma 2021-11-29 2021-11-30        1735.714\n135548:        ma 2021-11-29 2021-12-01        2371.286\n135549:        ma 2021-11-30 2021-12-01        1972.143\n\n\n\nAlternatively, you may run the following to load y that was previously saved as an RDS file:\n\n\ny &lt;- readRDS(\"_data/ma_case_archive.rds\")"
  },
  {
    "objectID": "slides/day1-afternoon.html#fetch-data---outpatient-doctors-visits-for-cli",
    "href": "slides/day1-afternoon.html#fetch-data---outpatient-doctors-visits-for-cli",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fetch Data - % Outpatient doctors visits for CLI",
    "text": "Fetch Data - % Outpatient doctors visits for CLI\n\nNow, from the Epidata API, let’s download the estimated percentage of outpatient doctor visits primarily for COVID-related symptoms, based on health system data.\nComes pre-smoothed in time using a Gaussian linear smoother\nThis will be the predictor when we nowcast COVID-19 cases in MA.\n\n\n# Step 1: Fetch Versioned Data \nx &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"ma\", # Just for MA to keep it simple (& to go with the case data by test date for that state)\n  time_values = epirange(20210301, 20211231),\n  issues = epirange(20210301, 20211231)\n) |&gt;\n  select(geo_value, time_value,\n         version = issue,\n         percent_cli = value\n  ) |&gt;\n  as_epi_archive(compactify = FALSE)"
  },
  {
    "objectID": "slides/day1-afternoon.html#use-epix_merge-to-merge-the-two-archives",
    "href": "slides/day1-afternoon.html#use-epix_merge-to-merge-the-two-archives",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Use epix_merge() to merge the two archives",
    "text": "Use epix_merge() to merge the two archives\nNow we’ll use epix_merge() to combine the two epi_archives that share the same geo_value & time_value.\n\n\narchive &lt;- epix_merge(\n  x, y,\n  sync = \"locf\",\n  compactify = FALSE\n)\narchive\n\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-01-29 / 2021-12-13\nℹ First/last version with update: 2021-01-10 / 2021-12-17\nℹ Versions end: 2021-12-17\nℹ A preview of the table (139190 rows x 5 columns):\nKey: &lt;geo_value, time_value, version&gt;\n        geo_value time_value    version percent_cli case_rate_7d_av\n           &lt;char&gt;     &lt;Date&gt;     &lt;Date&gt;       &lt;num&gt;           &lt;num&gt;\n     1:        ma 2020-01-29 2021-01-10          NA              NA\n     2:        ma 2020-01-29 2021-01-11          NA              NA\n     3:        ma 2020-01-29 2021-01-12          NA              NA\n     4:        ma 2020-01-29 2021-01-13          NA              NA\n     5:        ma 2020-01-29 2021-01-14          NA              NA\n    ---                                                            \n139186:        ma 2021-12-11 2021-12-16    2.306966              NA\n139187:        ma 2021-12-11 2021-12-17    2.281141              NA\n139188:        ma 2021-12-12 2021-12-16    2.333759              NA\n139189:        ma 2021-12-12 2021-12-17    2.369756              NA\n139190:        ma 2021-12-13 2021-12-17    2.256551              NA"
  },
  {
    "objectID": "slides/day1-afternoon.html#fitting-and-predicting-with-linear-model",
    "href": "slides/day1-afternoon.html#fitting-and-predicting-with-linear-model",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fitting and predicting with linear model",
    "text": "Fitting and predicting with linear model\n\nDefine lm_mod_pred(): A function that fits a linear model to forecast cases based on the percent_cli predictor.\nUse predict() with a 90% prediction interval.\nSave the actual cases to compare to the nowcasts later.\n\n\nlm_mod_pred &lt;- function(data, ...) {\n  # Linear model\n  model &lt;- lm(case_rate_7d_av ~ percent_cli, data = data)\n\n  # Make predictions\n  predictions = predict(model,\n                        newdata = data |&gt;\n                          fill(percent_cli, .direction = \"down\") |&gt; \n                          filter(time_value == max(time_value)),\n                        interval = \"prediction\", level = 0.9)\n  \n  # Pull off real-time value for later comparison to the nowcast value\n  real_time_val = data |&gt; filter(time_value == max(time_value)) |&gt; pull(case_rate_7d_av)\n  \n  # Could clip predictions and bounds at 0\n  return(data.frame(predictions, actual_nowcast_date = max(data$time_value), real_time_val = real_time_val)) \n}"
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-with-epix_slide-2",
    "href": "slides/day1-afternoon.html#nowcasting-with-epix_slide-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting with epix_slide()",
    "text": "Nowcasting with epix_slide()\n\nSpecify targets: Define the target dates for nowcasting (e.g., 1st of each month) & adjust training data to include the lag for the latent case data.\nSliding window: Use epix_slide() to apply the linear model across a sliding window of data for each region.\nTraining-test split: Use the last 30 days of data to train and predict cases for each target nowcast date."
  },
  {
    "objectID": "slides/day1-afternoon.html#nowcasting-with-epix_slide-3",
    "href": "slides/day1-afternoon.html#nowcasting-with-epix_slide-3",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Nowcasting with epix_slide()",
    "text": "Nowcasting with epix_slide()\n\n# Define the reference time points (to give the training/test split)\ntargeted_nowcast_dates &lt;- seq(as.Date(\"2021-04-01\"), as.Date(\"2021-11-01\"), by = \"1 month\") \nref_time_values = targeted_nowcast_dates + 1 # + 1 because the case data is 1 day latent. \n# Determine this from revision_summary(y)\n\n# Use epix_slide to perform the nowcasting with a training-test split\nnowcast_res &lt;- archive |&gt;\n  group_by(geo_value) |&gt;\n  epix_slide(\n    .f = lm_mod_pred,  # Pass the function defined above\n    .before = 30,   # Training period of 30 days\n    .versions = ref_time_values, # Determines the day where training data goes up to (not inclusive)\n    .new_col_name = \"res\"\n  ) |&gt;\n  unnest() |&gt;\n  mutate(targeted_nowcast_date = targeted_nowcast_dates,\n         time_value = actual_nowcast_date)\n\n# Take a peek at the results\nhead(nowcast_res, n = 1)\n\n# A tibble: 1 × 9\n# Groups:   geo_value [1]\n  geo_value version      fit   lwr   upr actual_nowcast_date real_time_val\n  &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;                      &lt;dbl&gt;\n1 ma        2021-04-02 2114. 1975. 2254. 2021-04-01                  1556.\n# ℹ 2 more variables: targeted_nowcast_date &lt;date&gt;, time_value &lt;date&gt;"
  },
  {
    "objectID": "slides/day1-afternoon.html#visualizing-nowcasts-vs.-actual-values",
    "href": "slides/day1-afternoon.html#visualizing-nowcasts-vs.-actual-values",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Visualizing nowcasts vs. actual values",
    "text": "Visualizing nowcasts vs. actual values\nMerge the nowcast results with the latest data for more direct comparison:\n\nx_latest &lt;- epix_as_of(archive, max(archive$DT$version)) |&gt;\n  select(-percent_cli) \n\nres &lt;- nowcast_res |&gt; left_join(x_latest, by = join_by(geo_value, time_value))\n\nres\n\n# A tibble: 8 × 10\n# Groups:   geo_value [1]\n  geo_value version       fit    lwr   upr actual_nowcast_date real_time_val\n  &lt;chr&gt;     &lt;date&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;                      &lt;dbl&gt;\n1 ma        2021-04-02 2114.  1975.  2254. 2021-04-01                  1556.\n2 ma        2021-05-02 1083.   851.  1316. 2021-05-01                   869.\n3 ma        2021-06-02  353.   164.   541. 2021-06-01                   117.\n4 ma        2021-07-02   57.1   11.3  103. 2021-07-01                    59 \n5 ma        2021-08-02  513.   284.   742. 2021-08-01                   572.\n6 ma        2021-09-02 1207.   888.  1527. 2021-09-01                  1099.\n7 ma        2021-10-02 1575.  1357.  1793. 2021-09-30                  1069 \n8 ma        2021-11-02 1299.  1257.  1340. 2021-11-01                   891.\n# ℹ 3 more variables: targeted_nowcast_date &lt;date&gt;, time_value &lt;date&gt;,\n#   case_rate_7d_av &lt;dbl&gt;"
  },
  {
    "objectID": "slides/day1-afternoon.html#visualizing-nowcasts-vs.-actual-values-1",
    "href": "slides/day1-afternoon.html#visualizing-nowcasts-vs.-actual-values-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Visualizing nowcasts vs. actual values",
    "text": "Visualizing nowcasts vs. actual values\nNow, plot the predictions & real-time values on top of latest COVID-19 cases using ggplot2:"
  },
  {
    "objectID": "slides/day1-afternoon.html#evaluation-using-mae-5",
    "href": "slides/day1-afternoon.html#evaluation-using-mae-5",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Evaluation using MAE",
    "text": "Evaluation using MAE\n\nFinally, we numerically evaluate our nowcasts using MAE.\nShows that the nowcast errors are lower than those of the real-time estimates.\n\n\n# Calculate the absolute error between actual and nowcasted COVID-19 cases\nmae_data_cases &lt;- res |&gt; \n  mutate(nc_abs_error = abs(case_rate_7d_av - fit),  # Nowcast vs Finalized cases (7-day average)\n         rt_abs_error = abs(case_rate_7d_av - real_time_val))  # Real-Time vs Finalized cases\n\n# Compute the MAE (mean of absolute errors)\nmae_value_cases &lt;- mae_data_cases |&gt; \n  summarise(nc_MAE = mean(nc_abs_error),\n            rt_MAE = mean(rt_abs_error))\nknitr::kable(mae_value_cases)\n\n\n\n\ngeo_value\nnc_MAE\nrt_MAE\n\n\n\n\nma\n152.5013\n228.5357"
  },
  {
    "objectID": "slides/day1-afternoon.html#evaluation-using-mae-6",
    "href": "slides/day1-afternoon.html#evaluation-using-mae-6",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Evaluation using MAE",
    "text": "Evaluation using MAE\n\nThe elevated errors at both ends highlight periods where the discrepancies between the real-time and nowcast estimates are most pronounced."
  },
  {
    "objectID": "slides/day1-afternoon.html#takeaways",
    "href": "slides/day1-afternoon.html#takeaways",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Takeaways",
    "text": "Takeaways\nGoal: Predict COVID-19 cases using %CLI, overcoming delays in report data.\nMain Steps:\n\nFetch Data: Collect case and %CLI data.\nMerge Data: Align datasets with epix_merge() and fill missing values.\nModel: Fit a linear model to predict cases.\nNowcast: Apply dynamic forecasting with epix_slide().\nEvaluate: Calculate error measures and numerically and visually assess the results.\n\nOverall, nowcasting, based on the linear model, provided a closer approximation of true cases compared to the real-time values."
  },
  {
    "objectID": "slides/day2-afternoon.html#section",
    "href": "slides/day2-afternoon.html#section",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Forecasting With {epipredict} and Other Advanced Topics",
    "text": "Forecasting With {epipredict} and Other Advanced Topics\nInsightNet Forecasting Workshop 2024\n\nAlice Cima, Rachel Lobay, Daniel McDonald, Ryan Tibshirani\nwith huge thanks to Logan Brooks, Xueda Shen, and also to Nat DeFries, Dmitry Shemetov, and David Weber\n12 December – Afternoon"
  },
  {
    "objectID": "slides/day2-afternoon.html#outline",
    "href": "slides/day2-afternoon.html#outline",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Outline",
    "text": "Outline\n\n{epipredict}\nCustomizing arx_forecaster()\nAdvanced Customizations\nBuilding a Forecaster\nA Flu Forecaster\nAdvanced Topics"
  },
  {
    "objectID": "slides/day2-afternoon.html#epipredict-1",
    "href": "slides/day2-afternoon.html#epipredict-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "{epipredict}",
    "text": "{epipredict}\nhttps://cmu-delphi.github.io/epipredict\nInstallation\n\n# Stable version\n# pak::pkg_install(\"cmu-delphi/epipredict@main\")\n# Development version\npak::pkg_install(\"cmu-delphi/epipredict@dev\")"
  },
  {
    "objectID": "slides/day2-afternoon.html#what-epipredict-provides-i",
    "href": "slides/day2-afternoon.html#what-epipredict-provides-i",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What {epipredict} provides (i)",
    "text": "What {epipredict} provides (i)\nBasic and easy to use “canned” forecasters:\n\nBaseline flat forecaster\nAutoregressive forecaster (ARX)\nAutoregressive classifier\nCDC FluSight flatline forecaster"
  },
  {
    "objectID": "slides/day2-afternoon.html#what-epipredict-provides-ii",
    "href": "slides/day2-afternoon.html#what-epipredict-provides-ii",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "What {epipredict} provides (ii)",
    "text": "What {epipredict} provides (ii)\n\nA framework for creating custom forecasters out of modular components.\nThere are four types of components:\n\nPreprocessor: do things to the data before model training\nTrainer: train a model on data, resulting in a fitted model object\nPredictor: make predictions, using a fitted model object\nPostprocessor: do things to the predictions before returning"
  },
  {
    "objectID": "slides/day2-afternoon.html#examples-of-pre-processing",
    "href": "slides/day2-afternoon.html#examples-of-pre-processing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Examples of pre-processing",
    "text": "Examples of pre-processing\n\nEDA type stuff\n\nMaking locations/signals commensurate (scaling)\nDealing with revisions\nDetecting and removing outliers\nImputing or removing missing data\n\n\n\nFeature engineering\n\nCreating lagged predictors\nDay of Week effects\nRolling averages for smoothing\nLagged differences\nGrowth rates instead of raw signals\nThe sky’s the limit"
  },
  {
    "objectID": "slides/day2-afternoon.html#get-the-data",
    "href": "slides/day2-afternoon.html#get-the-data",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Get the data",
    "text": "Get the data\n\nlibrary(epidatr)\nlibrary(epiprocess)\nlibrary(epipredict)\n\ncases &lt;- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_incidence_num\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20200401, 20230401),\n  geo_values = \"*\") |&gt;\n  select(geo_value, time_value, cases = value)\n\ndeaths &lt;- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"deaths_incidence_num\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20200401, 20230401),\n  geo_values = \"*\") |&gt;\n  select(geo_value, time_value, deaths = value)"
  },
  {
    "objectID": "slides/day2-afternoon.html#create-an-epi_df",
    "href": "slides/day2-afternoon.html#create-an-epi_df",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Create an epi_df",
    "text": "Create an epi_df\n\ndf &lt;- left_join(cases, deaths, by = c(\"time_value\", \"geo_value\")) |&gt;\n  as_epi_df()\n\ndf\n\nAn `epi_df` object, 60,036 x 4 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-12-02 13:03:04.888576\n\n# A tibble: 60,036 × 4\n   geo_value time_value cases deaths\n * &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n 1 ak        2020-04-01    13      0\n 2 al        2020-04-01   112      4\n 3 ar        2020-04-01    61      2\n 4 as        2020-04-01     0      0\n 5 az        2020-04-01   124      7\n 6 ca        2020-04-01  1254     29\n 7 co        2020-04-01  4655    388\n 8 ct        2020-04-01   429     16\n 9 dc        2020-04-01    91      0\n10 de        2020-04-01    49     10\n# ℹ 60,026 more rows"
  },
  {
    "objectID": "slides/day2-afternoon.html#pre-processing-data-scaling",
    "href": "slides/day2-afternoon.html#pre-processing-data-scaling",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Pre-processing: data scaling",
    "text": "Pre-processing: data scaling\nScale cases and deaths by population and multiply by 100K\n\ndf &lt;- left_join(\n  x = df,\n  y = state_census |&gt; select(pop, abbr),   # state_census is available in epipredict\n  by = c(\"geo_value\" = \"abbr\")) |&gt;\n    mutate(cases = cases / pop * 1e5, \n           deaths = deaths / pop * 1e5) |&gt; \n    select(-pop)"
  },
  {
    "objectID": "slides/day2-afternoon.html#scaled-covid-cases-and-deaths",
    "href": "slides/day2-afternoon.html#scaled-covid-cases-and-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Scaled COVID cases and deaths",
    "text": "Scaled COVID cases and deaths\n\n\nCode\ndf |&gt; \n  filter(geo_value %in% c(\"ca\", \"ma\", \"ny\", \"tx\")) |&gt;\n  autoplot(cases, deaths)"
  },
  {
    "objectID": "slides/day2-afternoon.html#pre-processing-smoothing",
    "href": "slides/day2-afternoon.html#pre-processing-smoothing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Pre-processing: smoothing",
    "text": "Pre-processing: smoothing\nSmooth the data by computing 7-day averages of cases and deaths for each state\n\ndf &lt;- df |&gt;\n  group_by(geo_value) |&gt;\n  epi_slide(cases_7dav = mean(cases, na.rm = T),\n            deaths_7dav = mean(deaths, na.rm = T),\n            .window_size = 7) |&gt;\n  ungroup() |&gt;\n  select(!c(cases, deaths)) |&gt;\n  rename(cases = cases_7dav, \n         deaths = deaths_7dav)"
  },
  {
    "objectID": "slides/day2-afternoon.html#scaled-and-smoothed-covid-cases-deaths",
    "href": "slides/day2-afternoon.html#scaled-and-smoothed-covid-cases-deaths",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Scaled and smoothed COVID cases deaths",
    "text": "Scaled and smoothed COVID cases deaths\n\n\nCode\ndf |&gt; \n  filter(geo_value %in% c(\"ca\", \"ma\", \"ny\", \"tx\")) |&gt;\n  autoplot(cases, deaths)"
  },
  {
    "objectID": "slides/day2-afternoon.html#pre-processing-fix-outliers-and-negative-values",
    "href": "slides/day2-afternoon.html#pre-processing-fix-outliers-and-negative-values",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Pre-processing: fix outliers and negative values",
    "text": "Pre-processing: fix outliers and negative values\n\n\nCode\ndetection_methods &lt;- dplyr::bind_rows(\n  dplyr::tibble(method = \"rm\", args = list(list(detect_negatives = TRUE)), abbr = \"rm\")#,\n  #dplyr::tibble(method = \"stl\", args = list(list(detect_negatives = TRUE, seasonal_period = 7)),\n  #              abbr = \"stl_seasonal\")\n  )\n\ndeaths_outlr &lt;- df |&gt; \n  group_by(geo_value) |&gt;\n  mutate(outlier_info = detect_outlr(x = time_value, \n                                     y = deaths, \n                                     methods = detection_methods, \n                                     combiner = \"median\"\n                                     )) |&gt;\n  ungroup() |&gt;\n  unnest(outlier_info)"
  },
  {
    "objectID": "slides/day2-afternoon.html#fit-arx_forecaster-on-training-set",
    "href": "slides/day2-afternoon.html#fit-arx_forecaster-on-training-set",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fit arx_forecaster on training set",
    "text": "Fit arx_forecaster on training set\n\nBack to the ARX(1) model for COVID deaths: \\(\\quad \\hat y_{t+28} = \\hat\\phi + \\hat\\phi_0 y_{t} + \\hat\\beta_0 x_{t}\\)\nOnly focus on California (for now)\nUsing {epipredict}\n\n\n# split into train and test \nca &lt;- df |&gt; filter(geo_value == \"ca\")\nt0_date &lt;- as.Date('2021-04-01')\ntrain &lt;- ca |&gt; filter(time_value &lt;= t0_date)\ntest &lt;- ca |&gt; filter(time_value &gt; t0_date)\n\n# fit ARX\nepi_arx &lt;- arx_forecaster(epi_data = train |&gt; as_epi_df(), \n                          outcome = \"deaths\", \n                          predictors = c(\"cases\", \"deaths\"),\n                          trainer = linear_reg() |&gt; set_engine(\"lm\"),\n                          args_list = arx_args_list(lags = 0, ahead = 28,\n                                                    quantile_levels = c(0.1, 0.9)))"
  },
  {
    "objectID": "slides/day2-afternoon.html#arx_forecaster-output",
    "href": "slides/day2-afternoon.html#arx_forecaster-output",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "arx_forecaster output",
    "text": "arx_forecaster output\n\nA fitted model object which can be used any time in the future to create forecasts ($epi_workflow).\nA forecast (point prediction + interval) for 28 days after the last available time value in the data ($predictions)."
  },
  {
    "objectID": "slides/day2-afternoon.html#arx_forecaster-output-1",
    "href": "slides/day2-afternoon.html#arx_forecaster-output-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "arx_forecaster output",
    "text": "arx_forecaster output\n\nepi_arx \n\n══ A basic forecaster of type ARX Forecaster ═══════════════════════════════════\n\n\n\n\n\nThis forecaster was fit on 2024-12-02 13:03:43.\n\n\n\n\n\nTraining data was an &lt;epi_df&gt; with:\n\n\n• Geography: state,\n\n\n• Time type: day,\n\n\n• Using data up-to-date as of: 2024-12-02 13:03:04.\n\n\n• With the last data available on 2021-04-01\n\n\n\n\n\n── Predictions ─────────────────────────────────────────────────────────────────\n\n\n\n\n\nA total of 1 prediction is available for\n\n\n• 1 unique geographic region,\n\n\n• At forecast date: 2021-04-01,\n\n\n• For target date: 2021-04-29,"
  },
  {
    "objectID": "slides/day2-afternoon.html#extract-fitted-object",
    "href": "slides/day2-afternoon.html#extract-fitted-object",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extract fitted object",
    "text": "Extract fitted object\n\n\nepi_arx$epi_workflow\n\n\n\n\n══ Epi Workflow [trained] ══════════════════════════════════════════════════════\n\n\nPreprocessor: Recipe\n\n\nModel: linear_reg()\n\n\nPostprocessor: Frosting\n\n\n\n\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n\n\n\n\n\n6 Recipe steps.\n\n\n1. step_epi_lag()\n\n\n2. step_epi_lag()\n\n\n3. step_epi_ahead()\n\n\n4. step_naomit()\n\n\n5. step_naomit()\n\n\n6. step_training_window()\n\n\n\n\n\n── Model ───────────────────────────────────────────────────────────────────────\n\n\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n (Intercept)   lag_0_cases  lag_0_deaths  \n    0.075387      0.009953      0.201329  \n\n\n\n\n\n── Postprocessor ───────────────────────────────────────────────────────────────\n\n\n\n\n\n5 Frosting layers.\n\n\n1. layer_predict()\n\n\n2. layer_residual_quantiles()\n\n\n3. layer_add_forecast_date()\n\n\n4. layer_add_target_date()\n\n\n5. layer_threshold()"
  },
  {
    "objectID": "slides/day2-afternoon.html#epi_workflow",
    "href": "slides/day2-afternoon.html#epi_workflow",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "$epi_workflow",
    "text": "$epi_workflow\nContains information on\n\nPre-processing steps automatically performed by arx_forecaster (e.g. compute lags of the predictors)\nFitted model\nPost-processing steps automatically performed by arx_forecaster (e.g. compute quantiles)"
  },
  {
    "objectID": "slides/day2-afternoon.html#extract-predictions",
    "href": "slides/day2-afternoon.html#extract-predictions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extract predictions",
    "text": "Extract predictions\n\nepi_arx$predictions\n\n# A tibble: 1 × 5\n  geo_value .pred        .pred_distn forecast_date target_date\n  &lt;chr&gt;     &lt;dbl&gt;             &lt;dist&gt; &lt;date&gt;        &lt;date&gt;     \n1 ca        0.218 quantiles(0.22)[2] 2021-04-01    2021-04-29 \n\n\n\n\n\nNote\n\n\n\n.pred_distn is actually a “distribution”, parameterized by its quantiles\narx_forecaster estimates the quantiles in a different way than lm"
  },
  {
    "objectID": "slides/day2-afternoon.html#extract-predictions-1",
    "href": "slides/day2-afternoon.html#extract-predictions-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Extract predictions",
    "text": "Extract predictions\nWe can extract the distribution into a “long” epi_df\n\nepi_arx$predictions |&gt;\n  pivot_quantiles_longer(.pred_distn)\n\n# A tibble: 2 × 6\n  geo_value .pred values quantile_levels forecast_date target_date\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;           &lt;dbl&gt; &lt;date&gt;        &lt;date&gt;     \n1 ca        0.218  0.137             0.1 2021-04-01    2021-04-29 \n2 ca        0.218  0.300             0.9 2021-04-01    2021-04-29 \n\n\nor into a “wide” epi_df\n\nepi_arx$predictions |&gt;\n  pivot_quantiles_wider(.pred_distn)\n\n# A tibble: 1 × 6\n  geo_value .pred forecast_date target_date `0.1` `0.9`\n  &lt;chr&gt;     &lt;dbl&gt; &lt;date&gt;        &lt;date&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 ca        0.218 2021-04-01    2021-04-29  0.137 0.300"
  },
  {
    "objectID": "slides/day2-afternoon.html#predict-with-fitted-arx-split-sample",
    "href": "slides/day2-afternoon.html#predict-with-fitted-arx-split-sample",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predict with fitted ARX (split-sample)",
    "text": "Predict with fitted ARX (split-sample)\n\narx_forecaster fits a model to the training set, and outputs only one prediction (for time \\(t_0+h\\)).\nTo get predictions for the test set:\n\n\npredict(epi_arx$epi_workflow, test)\n\nAn `epi_df` object, 707 x 6 with metadata:\n* geo_type  = state\n* time_type = day\n* other_keys = geo_value, time_value\n* as_of     = 2024-12-02 13:03:04.888576\n\n# A tibble: 707 × 6\n   geo_value time_value .pred        .pred_distn forecast_date target_date\n * &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;             &lt;dist&gt; &lt;date&gt;        &lt;date&gt;     \n 1 ca        2021-04-02 0.213 quantiles(0.21)[2] 2021-04-01    2021-04-29 \n 2 ca        2021-04-03 0.202  quantiles(0.2)[2] 2021-04-01    2021-04-29 \n 3 ca        2021-04-04 0.197  quantiles(0.2)[2] 2021-04-01    2021-04-29 \n 4 ca        2021-04-05 0.201  quantiles(0.2)[2] 2021-04-01    2021-04-29 \n 5 ca        2021-04-06 0.199  quantiles(0.2)[2] 2021-04-01    2021-04-29 \n 6 ca        2021-04-07 0.195  quantiles(0.2)[2] 2021-04-01    2021-04-29 \n 7 ca        2021-04-08 0.195  quantiles(0.2)[2] 2021-04-01    2021-04-29 \n 8 ca        2021-04-09 0.196  quantiles(0.2)[2] 2021-04-01    2021-04-29 \n 9 ca        2021-04-10 0.208 quantiles(0.21)[2] 2021-04-01    2021-04-29 \n10 ca        2021-04-11 0.213 quantiles(0.21)[2] 2021-04-01    2021-04-29 \n# ℹ 697 more rows"
  },
  {
    "objectID": "slides/day2-afternoon.html#predict-with-arx-when-re-fitting",
    "href": "slides/day2-afternoon.html#predict-with-arx-when-re-fitting",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predict with ARX (when re-fitting)",
    "text": "Predict with ARX (when re-fitting)\n\nIn practice, if we want to re-train the forecasters as new data arrive, we fit and predict combining arx_forecaster with epix_slide\nFrom now on, we will only used versioned data, and make predictions once a week"
  },
  {
    "objectID": "slides/day2-afternoon.html#predict-with-arx-re-fitting-on-trailing-window",
    "href": "slides/day2-afternoon.html#predict-with-arx-re-fitting-on-trailing-window",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predict with ARX (re-fitting on trailing window)",
    "text": "Predict with ARX (re-fitting on trailing window)\n\nh &lt;- 28         #horizon\nw &lt;- 120 + h    #trailing window length\n\n# Specify the forecast dates\nfc_time_values &lt;- seq(from = t0_date, to = as.Date(\"2023-02-09\"), by = \"1 week\")\n\n# Slide the arx_forecaster over the epi_archive\npred_arx &lt;- ca_archive |&gt;\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"cases\", \"deaths\"), \n                     trainer = linear_reg() |&gt; set_engine(\"lm\"),\n                     args_list = arx_args_list(lags = 0, ahead = h,\n                                               quantile_levels = c(0.1, 0.9))\n                     )$predictions |&gt;\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)"
  },
  {
    "objectID": "slides/day2-afternoon.html#predict-with-arx",
    "href": "slides/day2-afternoon.html#predict-with-arx",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predict with ARX",
    "text": "Predict with ARX\n\n\n\nNote (window length)\n\n\nWe set \\(w = 120 + h\\) to match the window size of the ARX model we fitted manually. Previously, when considering a window from \\(t-w\\) to \\(t\\), we had access to all outcomes in that window, and to all predictors between \\(t-w-h\\) and \\(t-h\\). (That’s because we lagged \\(x\\) before applying the window.) So we were “cheating” by saying that the trailing window had length \\(w=120\\), as its actual size was \\(120+h\\)!\n\n\n\n\n\n\nNote (all past)\n\n\nThe method fitting on all past data up to the forecasting date can be implemented by setting:\n.window_size = Inf in epi_slide."
  },
  {
    "objectID": "slides/day2-afternoon.html#predict-with-arx-re-fitting-on-trailing-window-1",
    "href": "slides/day2-afternoon.html#predict-with-arx-re-fitting-on-trailing-window-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predict with ARX (re-fitting on trailing window)",
    "text": "Predict with ARX (re-fitting on trailing window)\n\n\npred_arx \n\nAn `epi_df` object, 98 x 9 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2024-12-02 13:03:04.888576\n\n# A tibble: 98 × 9\n# Groups:   geo_value [1]\n   geo_value time_value cases deaths  .pred forecast_date target_date  `0.1`\n * &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;date&gt;        &lt;date&gt;       &lt;dbl&gt;\n 1 ca        2021-04-01  6.77 0.375  0.332  2021-04-01    2021-04-29  0.219 \n 2 ca        2021-04-08  6.97 0.250  0.317  2021-04-08    2021-05-06  0.190 \n 3 ca        2021-04-15  8.33 0.230  0.313  2021-04-15    2021-05-13  0.191 \n 4 ca        2021-04-22  6.07 0.181  0.245  2021-04-22    2021-05-20  0.123 \n 5 ca        2021-04-29  4.98 0.138  0.174  2021-04-29    2021-05-27  0.0325\n 6 ca        2021-05-06  4.68 0.183  0.144  2021-05-06    2021-06-03  0.0122\n 7 ca        2021-05-13  4.25 0.0994 0.0838 2021-05-13    2021-06-10  0     \n 8 ca        2021-05-20  3.51 0.0828 0.0600 2021-05-20    2021-06-17  0     \n 9 ca        2021-05-27  4.58 0.128  0.0686 2021-05-27    2021-06-24  0     \n10 ca        2021-06-03  2.36 0.0676 0.0139 2021-06-03    2021-07-01  0     \n# ℹ 88 more rows\n# ℹ 1 more variable: `0.9` &lt;dbl&gt;"
  },
  {
    "objectID": "slides/day2-afternoon.html#predict-with-arx-re-fitting-on-trailing-window-2",
    "href": "slides/day2-afternoon.html#predict-with-arx-re-fitting-on-trailing-window-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predict with ARX (re-fitting on trailing window)",
    "text": "Predict with ARX (re-fitting on trailing window)\n\n\n\n         MAE     MASE  Coverage\n1 0.07889637 264.5207 0.4285714"
  },
  {
    "objectID": "slides/day2-afternoon.html#customizing-arx_forecaster",
    "href": "slides/day2-afternoon.html#customizing-arx_forecaster",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Customizing arx_forecaster",
    "text": "Customizing arx_forecaster\n\narx_forecaster(epi_data = train |&gt; as_epi_df(), \n               outcome = \"deaths\", \n               predictors = c(\"cases\", \"deaths\"),\n               trainer = linear_reg() |&gt; set_engine(\"lm\"),\n               args_list = arx_args_list(lags = 0, ahead = 28,\n                                         quantile_levels = c(0.1, 0.9)))\n\n\n\nModify predictors to add/drop predictors\n\ne.g. drop deaths for regression with a lagged predictor, or drop cases to get AR model\ndefault: predictors = outcome"
  },
  {
    "objectID": "slides/day2-afternoon.html#customizing-arx_forecaster-1",
    "href": "slides/day2-afternoon.html#customizing-arx_forecaster-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Customizing arx_forecaster",
    "text": "Customizing arx_forecaster\n\narx_forecaster(epi_data = train |&gt; as_epi_df(), \n               outcome = \"deaths\", \n               predictors = c(\"cases\", \"deaths\"),\n               trainer = linear_reg() |&gt; set_engine(\"lm\"),\n               args_list = arx_args_list(lags = 0, ahead = 28,\n                                         quantile_levels = c(0.1, 0.9)))\n\n\nModify arx_args_list to change lags, horizon, quantile levels, …\n\n\n\narx_args_list(\n  lags = c(0L, 7L, 14L),\n  ahead = 7L,\n  n_training = Inf,\n  forecast_date = NULL,\n  target_date = NULL,\n  adjust_latency = c(\"none\", \"extend_ahead\", \"extend_lags\", \"locf\"),\n  warn_latency = TRUE,\n  quantile_levels = c(0.05, 0.95),\n  symmetrize = TRUE,\n  nonneg = TRUE,\n  quantile_by_key = character(0L),\n  check_enough_data_n = NULL,\n  check_enough_data_epi_keys = NULL,\n  ...\n)"
  },
  {
    "objectID": "slides/day2-afternoon.html#customizing-arx_forecaster-2",
    "href": "slides/day2-afternoon.html#customizing-arx_forecaster-2",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Customizing arx_forecaster",
    "text": "Customizing arx_forecaster\nChange predictors: doctor visits instead of cases\n\ndv_archive &lt;- pub_covidcast(\n  source = \"doctor-visits\",\n  signals = \"smoothed_adj_cli\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20200401, 20230401),\n  geo_values = \"*\",\n  issues = epirange(20200401, 20230401)) |&gt;\n  select(geo_value, time_value, version = issue, doctor_visits = value) |&gt;\n  arrange(geo_value, time_value) |&gt;\n  as_epi_archive(compactify = FALSE)"
  },
  {
    "objectID": "slides/day2-afternoon.html#customizing-arx_forecaster-3",
    "href": "slides/day2-afternoon.html#customizing-arx_forecaster-3",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Customizing arx_forecaster",
    "text": "Customizing arx_forecaster\nChange predictors: doctor visits instead of cases\n\npred_arx_hosp &lt;- ca_archive_dv |&gt;\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"doctor_visits\"), \n                     trainer = linear_reg() |&gt; set_engine(\"lm\"),\n                     args_list = arx_args_list(lags = 0, ahead = 28,\n                                               quantile_levels = c(0.1, 0.9))\n                     )$predictions |&gt;\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)"
  },
  {
    "objectID": "slides/day2-afternoon.html#predictions-doctor-visits-instead-of-cases-in-predictor-set",
    "href": "slides/day2-afternoon.html#predictions-doctor-visits-instead-of-cases-in-predictor-set",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions (doctor visits instead of cases in predictor set)",
    "text": "Predictions (doctor visits instead of cases in predictor set)\n\n\n\n         MAE     MASE  Coverage\n1 0.06880739 230.6948 0.4795918"
  },
  {
    "objectID": "slides/day2-afternoon.html#customizing-arx_forecaster-4",
    "href": "slides/day2-afternoon.html#customizing-arx_forecaster-4",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Customizing arx_forecaster",
    "text": "Customizing arx_forecaster\nAdd more lags\n\npred_arx_more_lags &lt;- ca_archive_dv |&gt;\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"doctor_visits\"), \n                     trainer = linear_reg() |&gt; set_engine(\"lm\"),\n                     args_list = arx_args_list(\n                       lags = c(0, 7, 14),\n                       ahead = 28,\n                       quantile_levels = c(0.1, 0.9))\n                     )$predictions |&gt;\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)"
  },
  {
    "objectID": "slides/day2-afternoon.html#predictions-more-lags",
    "href": "slides/day2-afternoon.html#predictions-more-lags",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions (more lags)",
    "text": "Predictions (more lags)\n\n\n\n         MAE     MASE  Coverage\n1 0.07753913 259.9702 0.3877551"
  },
  {
    "objectID": "slides/day2-afternoon.html#customizing-arx_forecaster-5",
    "href": "slides/day2-afternoon.html#customizing-arx_forecaster-5",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Customizing arx_forecaster",
    "text": "Customizing arx_forecaster\nMultiple horizons\n\nforecast_times &lt;- seq(from = t0_date, to = as.Date(\"2023-02-23\"), by = \"1 month\")\npred_h_days_ahead &lt;- function(epi_archive, ahead = 7) {\n  epi_archive |&gt;\n    epix_slide(\n      ~ arx_forecaster(epi_data = .x,\n                       outcome = \"deaths\", \n                       predictors = c(\"deaths\", \"doctor_visits\"), \n                       trainer = linear_reg() |&gt; set_engine(\"lm\"),\n                       args_list = arx_args_list(\n                         lags = 0,  \n                         ahead = ahead,\n                         quantile_levels = c(0.1, 0.9))\n      )$predictions |&gt; \n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = forecast_times\n  )\n}\nh &lt;- c(7, 14, 21, 28)\nforecasts &lt;- bind_rows(map(h, ~ pred_h_days_ahead(ca_archive_dv, ahead = .x)))"
  },
  {
    "objectID": "slides/day2-afternoon.html#predictions-multiple-horizons",
    "href": "slides/day2-afternoon.html#predictions-multiple-horizons",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions (multiple horizons)",
    "text": "Predictions (multiple horizons)"
  },
  {
    "objectID": "slides/day2-afternoon.html#changing-trainer",
    "href": "slides/day2-afternoon.html#changing-trainer",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Changing trainer",
    "text": "Changing trainer\n\narx_forecaster(epi_data = train |&gt; as_epi_df(), \n               outcome = \"deaths\", \n               predictors = c(\"cases\", \"deaths\"),\n               trainer = linear_reg() |&gt; set_engine(\"lm\"),\n               args_list = arx_args_list(lags = 0, ahead = 28,\n                                         quantile_levels = c(0.1, 0.9)))\n\n\nModify trainer to use a model that is not lm (default)\n\n e.g. trainer = rand_forest()\ncan use any {parsnip} models, see list"
  },
  {
    "objectID": "slides/day2-afternoon.html#changing-trainer-1",
    "href": "slides/day2-afternoon.html#changing-trainer-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Changing trainer",
    "text": "Changing trainer\n\npred_arx_rf &lt;- ca_archive_dv |&gt;\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"doctor_visits\"), \n                     trainer = parsnip::rand_forest(mode = \"regression\"), # defaults to ranger\n                     args_list = arx_args_list(\n                       lags = 0,\n                       ahead = 28,\n                       quantile_levels = c(0.1, 0.9))\n                     )$predictions |&gt;\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)"
  },
  {
    "objectID": "slides/day2-afternoon.html#predictions-trained-using-random-forest",
    "href": "slides/day2-afternoon.html#predictions-trained-using-random-forest",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions (trained using random forest)",
    "text": "Predictions (trained using random forest)\n\n\n\n         MAE     MASE  Coverage\n1 0.07878542 264.1487 0.1734694"
  },
  {
    "objectID": "slides/day2-afternoon.html#warning",
    "href": "slides/day2-afternoon.html#warning",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Warning!",
    "text": "Warning!\nRandom forests has really poor coverage here. Can change engine to get better coverage:\nspecify engine = \"grf_quantiles\" in the rand_forest call"
  },
  {
    "objectID": "slides/day2-afternoon.html#geo-pooling",
    "href": "slides/day2-afternoon.html#geo-pooling",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Geo-pooling",
    "text": "Geo-pooling\n\nAssume we observe data over time from multiple locations (e.g. states or counties).\nWe could\n\nEstimate coefficients separately for each location (as we have done so far), or\nFit one model using all locations together at each time point (geo-pooling). Estimated coefficients will not be location specific.\n\nWe will now pool data from all US states to make predictions."
  },
  {
    "objectID": "slides/day2-afternoon.html#geo-pooling-1",
    "href": "slides/day2-afternoon.html#geo-pooling-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Geo-pooling",
    "text": "Geo-pooling\n\npred_arx_geo_pool &lt;- usa_archive_dv |&gt;\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"doctor_visits\"), \n                     trainer = linear_reg() |&gt; set_engine(\"lm\"),\n                     args_list = arx_args_list(\n                       lags = 0, #c(0, 7, 14),\n                       ahead = 28,\n                       quantile_levels = c(0.1, 0.9))\n                     )$predictions |&gt;\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)"
  },
  {
    "objectID": "slides/day2-afternoon.html#predictions-geo-pooling-h28",
    "href": "slides/day2-afternoon.html#predictions-geo-pooling-h28",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions (geo-pooling, \\(h=28\\))",
    "text": "Predictions (geo-pooling, \\(h=28\\))\n\n\n\n         MAE     MASE  Coverage\nCA 0.1470889 493.1541 0.7857143\nMA 0.1200766 297.0973 0.8041237\nNY 0.1313441 323.6736 0.8556701\nTX 0.1653687 354.3137 0.8350515"
  },
  {
    "objectID": "slides/day2-afternoon.html#predictions-without-geo-pooling-h28",
    "href": "slides/day2-afternoon.html#predictions-without-geo-pooling-h28",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions (without geo-pooling, \\(h=28\\))",
    "text": "Predictions (without geo-pooling, \\(h=28\\))\n\n\n\n          MAE     MASE  Coverage\nCA 0.06880739 230.6948 0.4795918\nMA 0.30060740 738.1141 0.3673469\nNY 0.20230208 495.6936 0.5306122\nTX 0.13918463 301.3190 0.5204082"
  },
  {
    "objectID": "slides/day2-afternoon.html#geo-pooling-or-not",
    "href": "slides/day2-afternoon.html#geo-pooling-or-not",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Geo-pooling or not?",
    "text": "Geo-pooling or not?\nFor horizon \\(h=28\\) we observe that\n\nGeo-pooled predictions have actual coverage near the nominal 80% while non-geo-pooled predictions have lower coverage\nPoint predictions without geo-pooling are significantly better than with geo-pooling for California only\nPoint predictions without geo-pooling for the other states are less stable and can largely overshoot the target\n\nIf we decrease the horizon to \\(h=7\\), the benefits of geo-pooling in stabilizing the point predictions for these four states disappear (short horizons are easier to predict)"
  },
  {
    "objectID": "slides/day2-afternoon.html#predictions-geo-pooling-h-7",
    "href": "slides/day2-afternoon.html#predictions-geo-pooling-h-7",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions (geo-pooling, \\(h = 7\\))",
    "text": "Predictions (geo-pooling, \\(h = 7\\))\n\n\n\n          MAE     MASE  Coverage\nCA 0.09839097 326.3738 0.8979592\nMA 0.09503113 240.6570 0.8247423\nNY 0.09129227 224.7966 0.9278351\nTX 0.11654398 246.4872 0.8762887"
  },
  {
    "objectID": "slides/day2-afternoon.html#predictions-without-geo-pooling-h7",
    "href": "slides/day2-afternoon.html#predictions-without-geo-pooling-h7",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions (without geo-pooling, \\(h=7\\))",
    "text": "Predictions (without geo-pooling, \\(h=7\\))\n\n\n\n          MAE     MASE  Coverage\nCA 0.04169336 138.3015 0.6224490\nMA 0.06797487 173.9328 0.5918367\nNY 0.05490976 136.6173 0.6428571\nTX 0.06114222 129.6758 0.7040816"
  },
  {
    "objectID": "slides/day2-afternoon.html#quantile-regression",
    "href": "slides/day2-afternoon.html#quantile-regression",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Quantile regression",
    "text": "Quantile regression\n\nQuantile regression is a different estimation method, which directly targets conditional quantiles of the outcome over time\nIt needs more data to estimate quantiles appropriately, so\n\nunsuitable for settings with small training set (e.g. trailing window on one state)\ncan benefit by combination with geo-pooling (much more data to train on)\n\n\n\nlibrary(quantreg)\n\npred_qr_geo_pool &lt;- usa_archive_dv |&gt;\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"doctor_visits\"), \n                     trainer = quantile_reg(),\n                     args_list = arx_args_list(\n                       lags = 0, #c(0, 7, 14),\n                       ahead = 28,\n                       quantile_levels = c(0.1, 0.9))\n                     )$predictions |&gt;\n        pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)"
  },
  {
    "objectID": "slides/day2-afternoon.html#predictions-geo-pooling-quantile-regression-h28",
    "href": "slides/day2-afternoon.html#predictions-geo-pooling-quantile-regression-h28",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions (geo-pooling + quantile regression, \\(h=28\\))",
    "text": "Predictions (geo-pooling + quantile regression, \\(h=28\\))\n\n\n\n         MAE     MASE  Coverage\nCA 0.1604641 537.9980 0.8775510\nMA 0.1218543 301.4959 0.7216495\nNY 0.1359666 335.0649 0.7628866\nTX 0.1627874 348.7831 0.7628866"
  },
  {
    "objectID": "slides/day2-afternoon.html#anatomy-of-a-forecaster",
    "href": "slides/day2-afternoon.html#anatomy-of-a-forecaster",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Anatomy of a forecaster",
    "text": "Anatomy of a forecaster\n\nWe should build up modular components\nBe able to add/remove layers of complexity sequentially\n\n\n\nPreprocessor: do things to the data before model training\nTrainer: train a model on data, resulting in a fitted model object\nPredictor: make predictions, using a fitted model object\nPostprocessor: do things to the predictions before returning"
  },
  {
    "objectID": "slides/day2-afternoon.html#fit-a-forecaster-from-scratch",
    "href": "slides/day2-afternoon.html#fit-a-forecaster-from-scratch",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fit a forecaster from scratch",
    "text": "Fit a forecaster from scratch\nSo far, we performed some manual pre-processing, and then relied on a canned forecaster to automatically perform more pre-processing, training, predicting, and post-processing.\n\n\n\nWhat if we want more direct control on each single step?"
  },
  {
    "objectID": "slides/day2-afternoon.html#fit-a-forecaster-from-scratch-1",
    "href": "slides/day2-afternoon.html#fit-a-forecaster-from-scratch-1",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Fit a forecaster from scratch",
    "text": "Fit a forecaster from scratch\n\n# A preprocessing \"recipe\" that turns raw data into features / response\nr &lt;- epi_recipe(ca) |&gt;\n  step_epi_lag(cases, lag = c(0, 7, 14)) |&gt;\n  step_epi_lag(deaths, lag = c(0, 7, 14)) |&gt;\n  step_epi_ahead(deaths, ahead = 28) |&gt;\n  step_epi_naomit()\n\n# Training engine\ne &lt;- quantile_reg(quantile_levels = c(.1, .5, .9))\n\n# A post-processing routine describing what to do to the predictions\nf &lt;- frosting() |&gt;\n  layer_predict() |&gt;\n  layer_threshold(.pred, lower = 0) |&gt; # predictions / intervals should be non-negative\n  layer_add_target_date() |&gt;\n  layer_add_forecast_date()\n\n# Bundle up the preprocessor, training engine, and postprocessor\n# We use quantile regression\newf &lt;- epi_workflow(r, e, f)\n\n# Fit it to data (we could fit this to ANY data that has the same format)\ntrained_ewf &lt;- ewf |&gt; fit(ca)\n\n# examines the recipe to determine what we need to make the prediction\nlatest &lt;- get_test_data(r, ca)\n\n# we could make predictions using the same model on ANY test data\npreds &lt;- trained_ewf |&gt; predict(new_data = latest)"
  },
  {
    "objectID": "slides/day2-afternoon.html#flu-data-archive",
    "href": "slides/day2-afternoon.html#flu-data-archive",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Flu data archive",
    "text": "Flu data archive\n\n\n→ An `epi_archive` object, with metadata:\nℹ Min/max time values: 2020-01-01 / 2024-03-20\nℹ First/last version with update: 2023-10-04 / 2024-03-27\nℹ Versions end: 2024-03-27\nℹ A preview of the table (14420 rows x 4 columns):\n          version geo_value time_value hhs\n    1: 2023-10-04        ak 2020-07-15  67\n    2: 2023-10-04        ak 2020-07-22 120\n    3: 2023-10-04        ak 2020-07-29  99\n    4: 2023-10-04        ak 2020-08-05 108\n    5: 2023-10-04        ak 2020-08-12  76\n   ---                                    \n14416: 2024-03-20        wy 2024-03-06  51\n14417: 2024-03-27        wy 2024-03-06  47\n14418: 2024-03-20        wy 2024-03-13  58\n14419: 2024-03-27        wy 2024-03-13  43\n14420: 2024-03-27        wy 2024-03-20  39"
  },
  {
    "objectID": "slides/day2-afternoon.html#build-forecaster",
    "href": "slides/day2-afternoon.html#build-forecaster",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Build forecaster",
    "text": "Build forecaster\n\n# A preprocessing \"recipe\" that turns raw data into features / response\nr &lt;- epi_recipe(flu) |&gt;\n  #drop_non_seasons() |&gt;\n  step_population_scaling(\n    hhs,\n    df = epidatasets::state_census,\n    df_pop_col = \"pop\",\n    create_new = FALSE,\n    rate_rescaling = 1e5,\n    by = c(\"geo_value\" = \"abbr\")) |&gt;\n  step_epi_lag(hhs, lag = c(0, 7, 14)) |&gt;\n  step_epi_ahead(hhs, ahead = 14) |&gt;\n  step_epi_naomit()\n\n# Training engine\ne &lt;- quantile_reg(quantile_levels = c(0.01, 0.025, 1:19 / 20, 0.975, 0.99)) # 23 ForecastHub quantiles\n\n# A post-processing routine describing what to do to the predictions\nf &lt;- frosting() |&gt;\n  layer_predict() |&gt;\n  layer_threshold(.pred, lower = 0) |&gt; # predictions / intervals should be non-negative\n  layer_population_scaling(\n    .pred, \n    df = epidatasets::state_census,\n    df_pop_col = \"pop\",\n    create_new = FALSE,\n    rate_rescaling = 1e5,\n    by = c(\"geo_value\" = \"abbr\")) |&gt;\n  layer_add_target_date() |&gt;\n  layer_add_forecast_date()\n\n# Bundle up the preprocessor, training engine, and postprocessor\n# We use quantile regression\newf &lt;- epi_workflow(r, e, f)\n\n# Fit it to data (we could fit this to ANY data that has the same format)\ntrained_ewf &lt;- ewf |&gt; fit(flu)\n\n# examines the recipe to determine what we need to make the prediction\nlatest &lt;- get_test_data(r, flu)\n\n# we could make predictions using the same model on ANY test data\npreds &lt;- trained_ewf |&gt; predict(new_data = latest)"
  },
  {
    "objectID": "slides/day2-afternoon.html#predictions-at-one-forecast-date",
    "href": "slides/day2-afternoon.html#predictions-at-one-forecast-date",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Predictions at one forecast date",
    "text": "Predictions at one forecast date\n\n\n# A tibble: 21 × 27\n   geo_value time_value target_date forecast_date `0.01` `0.025` `0.05` `0.1`\n   &lt;chr&gt;     &lt;date&gt;     &lt;date&gt;      &lt;date&gt;         &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 al        2023-11-08 2023-11-22  2023-11-08      218.    218.   228.  242.\n 2 az        2023-11-08 2023-11-22  2023-11-08      706.    706.   741.  837.\n 3 ca        2023-11-08 2023-11-22  2023-11-08     1823.   1823.  1917. 2019.\n 4 ga        2023-11-08 2023-11-22  2023-11-08      527.    527.   563.  596.\n 5 hi        2023-11-08 2023-11-22  2023-11-08      138.    138.   152.  161.\n 6 il        2023-11-08 2023-11-22  2023-11-08      939.    939.  1015. 1109.\n 7 in        2023-11-08 2023-11-22  2023-11-08      298.    298.   316.  333.\n 8 ks        2023-11-08 2023-11-22  2023-11-08      169.    169.   175.  192.\n 9 ky        2023-11-08 2023-11-22  2023-11-08      281.    281.   304.  328.\n10 mi        2023-11-08 2023-11-22  2023-11-08      435.    435.   457.  481.\n# ℹ 11 more rows\n# ℹ 19 more variables: `0.15` &lt;dbl&gt;, `0.2` &lt;dbl&gt;, `0.25` &lt;dbl&gt;, `0.3` &lt;dbl&gt;,\n#   `0.35` &lt;dbl&gt;, `0.4` &lt;dbl&gt;, `0.45` &lt;dbl&gt;, `0.5` &lt;dbl&gt;, `0.55` &lt;dbl&gt;,\n#   `0.6` &lt;dbl&gt;, `0.65` &lt;dbl&gt;, `0.7` &lt;dbl&gt;, `0.75` &lt;dbl&gt;, `0.8` &lt;dbl&gt;,\n#   `0.85` &lt;dbl&gt;, `0.9` &lt;dbl&gt;, `0.95` &lt;dbl&gt;, `0.975` &lt;dbl&gt;, `0.99` &lt;dbl&gt;"
  },
  {
    "objectID": "slides/day2-afternoon.html#slide-forecaster",
    "href": "slides/day2-afternoon.html#slide-forecaster",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Slide forecaster",
    "text": "Slide forecaster\n\nflu_forecast &lt;- function(epi_archive, forecast_date, ahead = 14) {\n  flu &lt;- epi_archive$DT |&gt; \n    filter(version == forecast_date) |&gt;\n    as_epi_df()\n\n  r &lt;- epi_recipe(flu) |&gt;\n    #drop_non_seasons() |&gt;\n    step_population_scaling(\n      hhs,\n      df = epidatasets::state_census,\n      df_pop_col = \"pop\",\n      create_new = FALSE,\n      rate_rescaling = 1e5,\n      by = c(\"geo_value\" = \"abbr\")) |&gt;\n    step_epi_lag(hhs, lag = c(0, 7, 14)) |&gt;\n    step_epi_ahead(hhs, ahead = ahead) |&gt;\n    step_epi_naomit()\n  \n  ewf &lt;- epi_workflow(r, e, f)\n  trained_ewf &lt;- ewf |&gt; fit(flu)\n  latest &lt;- get_test_data(r, flu)\n  preds &lt;- trained_ewf |&gt; predict(new_data = latest)\n  return(preds)\n}\n\nforecast_dates &lt;- seq.Date(as.Date(\"2023-10-04\"), as.Date(\"2024-03-27\"), by = 7L)\nforecasts &lt;- bind_rows(map(forecast_dates, \n                           ~ flu_forecast(weekly_archive, forecast_date = .x, ahead = 14)))"
  },
  {
    "objectID": "slides/day2-afternoon.html#version-aware-predictions",
    "href": "slides/day2-afternoon.html#version-aware-predictions",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Version-aware predictions",
    "text": "Version-aware predictions"
  },
  {
    "objectID": "slides/day2-afternoon.html#ensembling",
    "href": "slides/day2-afternoon.html#ensembling",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Ensembling",
    "text": "Ensembling\nInstead of choosing one model, we can combine the predictions from multiple base models. Ensemble types:\n\nuntrained: combine base models, agnostic to past performance\ntrained: weight base models, accounting for past performance\n\nSimplest untrained method: simple average of base model forecasts\n\\[\n\\hat{y}^{\\text{avg}}_{t+h|t} = \\frac{1}{p} \\sum_{j=1}^p \\hat{y}^j_{t+h|t}\n\\]\nA more robust option: simple median of base model forecasts\n\\[\n\\hat{y}^{\\text{med}}_{t+h|t} = \\mathrm{median}\\Big\\{ \\hat{y}^j_{t+h|t} : j = 1,\\dots,p \\Big\\}\n\\]"
  },
  {
    "objectID": "slides/day2-afternoon.html#example-from-the-covid-19-forecast-hub",
    "href": "slides/day2-afternoon.html#example-from-the-covid-19-forecast-hub",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Example from the Covid-19 Forecast Hub",
    "text": "Example from the Covid-19 Forecast Hub"
  },
  {
    "objectID": "slides/day2-afternoon.html#two-key-goals-of-ensembling",
    "href": "slides/day2-afternoon.html#two-key-goals-of-ensembling",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Two key goals of ensembling",
    "text": "Two key goals of ensembling\n1 Compete-with-best: ensemble should have accuracy competitive with best individual constituent model\n\nRobustness-over-all: ensemble should have greater robustness than any individual constituent model\n\nTypically these are hard to accomplish simultaneously, and untrained methods excel at point 2, whereas trained methods can achieve point 1"
  },
  {
    "objectID": "slides/day2-afternoon.html#linear-stacking",
    "href": "slides/day2-afternoon.html#linear-stacking",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Linear stacking",
    "text": "Linear stacking\nOne of the simplest trained ensemble methods is to directly fit a weighted combination of base forecasts to optimize accuracy (MSE, MAE, etc.), often called linear stacking: e.g., to form the forecast at time \\(t\\), we solve\n\\[\\begin{alignat*}{2}\n&\\min_{w \\in \\R^p} && \\hspace{-6pt} \\sum_{s=t_0+1}^t \\bigg( y_s - \\sum_{j=1}^p\nw_j \\cdot \\hat{y}^j_{s|s-h} \\bigg)^2 \\\\   \n&\\st \\quad && \\sum_{j=1}^p w_j = 1, \\;\\;\\text{and} \\;\\; w_j \\geq 0, \\;\nj=1,\\dots,p   \n\\end{alignat*}\\]\nthen use\n\\[\n\\hat{y}^{\\text{stack}}_{t+h|t} = \\sum_{j=1}^p \\hat{w}^t_j \\cdot\n\\hat{y}^j_{t+h|t}\n\\]\nNote that the stacking optimization problem uses forward-looking predictions (as in time series cross-validation)"
  },
  {
    "objectID": "slides/day2-afternoon.html#recalibration",
    "href": "slides/day2-afternoon.html#recalibration",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Recalibration",
    "text": "Recalibration\n\nWe have seen that prediction intervals often have empirical coverage &lt;&lt; nominal coverage, e.g., our 80% predictive intervals in practice cover \\(\\approx\\) 60% of the time\nRecalibration methods aim at adjusting the intervals so that nominal coverage \\(\\approx\\) empirical coverage"
  },
  {
    "objectID": "slides/day2-afternoon.html#quantile-tracking",
    "href": "slides/day2-afternoon.html#quantile-tracking",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Quantile tracking",
    "text": "Quantile tracking\nQuantile tracking is a method for producing calibrated prediction intervals from base forecasts and scores. In the simplest case, we can take the score to be absolute error of point forecasts:\n\\[e_t = |y_t - \\hat y_{t|t-1}|\\]\n\nLet \\(\\hat q_{t}^{1-\\alpha}\\) be a predicted level \\(1-\\alpha\\) quantile of the distribution of \\(e_t\\)\nDefine \\(I_{t|t-1}^{1-\\alpha} = [\\hat{y}_{t|t-1} - \\hat{q}_t^{1-\\alpha}, \\;     \\hat{y}_{t|t-1} + \\hat{q}_t^{1-\\alpha}]\\). Note that\n\\[\n  e_t \\leq \\hat{q}_t^{1-\\alpha} \\iff y_t \\in I_{t|t-1}^{1-\\alpha}\n  \\]\nTherefore we the reduced the problem of producing prediction intervals \\(I_{t|t-1}^{1-\\alpha}\\) to one of tracking a quantile of \\(e_t\\)"
  },
  {
    "objectID": "slides/day2-afternoon.html#quantile-updates",
    "href": "slides/day2-afternoon.html#quantile-updates",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Quantile updates",
    "text": "Quantile updates\nWe begin with some estimate \\(\\hat{q}_{t_0+1}^{1-\\alpha}\\) based on a burn-in set. Then repeat the following updates as \\(t\\) increases, for a step size \\(\\eta &gt; 0\\):\n\\[\\hat q_{t+1}^{1-\\alpha} = \\begin{cases}\n\\hat q_{t}^{1-\\alpha} + \\eta(1-\\alpha) \\quad \\text{if } y_t\\notin I_{t|t-1}^{1-\\alpha} \\\\\n\\hat q_{t}^{1-\\alpha} - \\eta\\alpha \\quad \\quad \\quad \\,\\,\\, \\text{if } y_t\\in I_{t|t-1}^{1-\\alpha}\n\\end{cases}\\]\nIn words:\n\nif the latest interval does not cover, then we increase the quantile (make the next interval wider),\notherwise we decrease the quantile by (make the next interval narrower).\n\nThis method has the following guarantee:\n\\[\n\\Bigg| \\frac{1}{T} \\sum_{t=t_0+1}^{t_0+T} 1 \\big\\{ y_t \\in I_{t|t-1}^{1-\\alpha} \\big\\} - (1-\\alpha) \\Bigg| \\leq \\frac{b/\\eta + 1}{T}\n\\]\nwhere \\(b\\) is a bound on the errors (largest error possible/observable)."
  },
  {
    "objectID": "slides/day2-afternoon.html#multi-horizon-smoothing",
    "href": "slides/day2-afternoon.html#multi-horizon-smoothing",
    "title": "InsightNet EpiData Workshop 2024",
    "section": "Multi-horizon smoothing",
    "text": "Multi-horizon smoothing"
  }
]