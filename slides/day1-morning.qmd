---
talk-title: "Signal Discovery, Data Fetching, & Panel Data"
talk-short-title: "Panel Data"
talk-subtitle: "InsightNet Forecasting Workshop 2024"
author: "Ailce Cima, Rachel Lobay, Daniel McDonald, Ryan Tibshirani"
repo-address: "cmu-delphi/insightnet-workshop-2024"
talk-date: "11 December -- Morning"
format: revealjs
---

{{< include _titleslide.qmd >}}

```{r theme-load-pkg}
#| cache: false
library(tidymodels)
library(gridExtra)
library(grid)
library(epidatasets)
library(epipredict)
library(epidatr)
ggplot2::theme_set(ggplot2::theme_bw())
```

```

## Outline

1. Delphi 

1. Panel Data

1. Versioned Data

1. Epidata API

1. Epidatr

1. Find Data Sources and Signals

1. Versioning in epidatr


# Delphi

## About Delphi

* Founded in 2012 at Carnegie Mellon University, now expanded to UC Berkeley, and University of British Columbia.

* Currently 5 faculty, ~10 PhD students, ~15 staff (mostly software engineers).

* Easy to join us from anywhere (lots of volunteers during Covid-19 pandemic).

* We are:
    + CDC Center of Excellence for Influenza and Covid-19 Forecasting (2019-24).
    + CDC Innovation Center for Outbreak Analytics and Disease Modeling (2024-29).

[**Our mission:**]{.primary} To develop the theory and practice of [epidemic detection, tracking and forecasting]{.primary}, and their use in decision making, both public and private.

## What does Delphi do?

* Procure [real-time, aggregated data streams]{.primary} informative of infectious diseases and syndromes, in collaboration with partners in industry and government.

* Extract signals and make them widely available via the [Epidata platform & API]{.primary}.

* Develop and deploy algorithms for [epidemic detection, tracking, forecasting]{.primary}.

* Develop and maintain statistical software packages for these tasks.

* Make it all production-grade, maximally-accessible, and open-source (to serve CDC, state and local public health agencies, epi-forecasting researchers, data journalists, the public)

## What we provide

![](gfx/web_of_parts.svg){fig-align=center}

# Panel Data

## Panel data

* [**Panel data**](https://en.wikipedia.org/wiki/Panel_data) or longitudinal data, contain cross-sectional measurements of subjects over time.

* Since we're working with aggregated data, the subjects are geographic units (e.g. counties, states) and not individuals.

* In table form, panel data is a time index + one or more locations/keys.

* For example: The estimated percentage of outpatient doctor visits that are COVID-related in WA from Dec. 2021 to Feb. 2022 ([docs](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/doctor-visits.html)):
```{r panel-wa-ex}
#| echo: false
x1 <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  geo_type = "state",
  time_type = "day",
  geo_values = "wa", # Just for WA to keep it simple (& to go with the case data by test date for that state)
  time_value = epirange(20211201, 20220201), 
  issues = epirange(20211201, 20220201)
)

x <- x1 |>
  select(geo_value, time_value,
         version = issue,
         percent_cli = value
  ) |>
  as_epi_archive(compactify = FALSE)

head(epix_as_of(x, max_version = max(x$DT$version)))
```

## Examples of panel data - COVID-19 cases

[[**JHU CSSE COVID cases per 100k **]{.primary}](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/jhu-csse.html) estimates the daily number of new confirmed COVID-19 cases per 100,000 population, averaged over the past 7 days.

```{r examples-panel-covid}
#| echo: false
#| eval: false
SOURCES <- c("jhu-csse", "chng", "chng", "hhs")
SIGNALS <- c("confirmed_7dav_incidence_prop",
             "smoothed_adj_outpatient_cli",
             "smoothed_adj_outpatient_covid",
             "confirmed_admissions_covid_1d_prop_7dav")

data_list <- list()

for (i in seq_along(SOURCES)) {
  data_list[[i]] <- pub_covidcast(
    source = SOURCES[i],
    signals = SIGNALS[i],
    geo_type = "state",
    geo_values = c("ca", "fl", "nc", "wa"), 
    time_type = "day",
    time_values = epirange(20210915, 20220915)
  )
}
saveRDS(data_list, "_data/four_covidcast_signals.rds")
```

```{r examples-panel-covid2}
#| echo: false
data_list <- read_rds("_data/four_covidcast_signals.rds")
colors <- c("black", scales::hue_pal()(4))
names <- c("COVID-19 cases", "CHNG-CLI", "CHNG-COVID", "COVID-19 hospital admissions")
units <- c("Reported cases per 100k people",
           "% doctor's visits due to CLI",
           "% doctor's visits due to COVID-19",
           "Hospital admissions per 100k people")

as_epi_df(data_list[[1]]) %>%
  autoplot("value") +
  scale_color_delphi() +
  theme(legend.title = element_blank()) +
  xlab("Date") + ylab(units[1]) +
  scale_y_continuous(expand = expansion(c(0, 0.05)))
```

::: {.notes}

* WA switch to weekly reporting in 2022
* FL reports "whenever" (weekly, biweekly, three days in a row, then 4 zeros, etc.)

:::

<!--

## Examples of panel data - CHNG-CLI

[[**Change Healthcare COVID-like illness (CHNG-CLI)**]{.primary}](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/chng.html) reports the percentage of outpatient visits for COVID-related symptoms, based on deidentified Change Healthcare claims data.

```{r examples-chng-cli}
#| echo: false
as_epi_df(data_list[[2]]) %>%
  autoplot("value") +
  scale_color_delphi() +
  theme(legend.title = element_blank()) +
  xlab("Date") + ylab(units[2]) +
  scale_y_continuous(expand = expansion(c(0, 0.05)))
```

## Examples of panel data - CHNG-COVID

[[**Change Healthcare COVID (CHNG-COVID)**]{.primary}](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/chng.html) reports the percentage of outpatient visits with confirmed COVID-19, based on Change Healthcare claims data.

```{r examples-chng-covid}
#| echo: false
as_epi_df(data_list[[3]]) %>%
  autoplot("value") +
  scale_color_delphi() +
  theme(legend.title = element_blank()) +
  xlab("Date") + ylab(units[3]) +
  scale_y_continuous(expand = expansion(c(0, 0.05)))
```

-->

<!--  Numerator = denote the Covid counts. Denominator be the total count of visits. Scaling by population is not necessary here because the signal is already normalized to the total number of visits, which acts as a proxy for population size. -->

## Examples of panel data - HHS Admissions

[[**Confirmed COVID-19 Hospital Admissions per 100k**]{.primary}](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/hhs.html) estimates the daily sum of adult and pediatric confirmed COVID-19 hospital admissions, per 100,000 population, averaged over the past 7 days.

```{r examples-hhs-admissions}
#| echo: false
as_epi_df(data_list[[4]]) %>%
  autoplot("value") +
  scale_color_delphi() +
  theme(legend.title = element_blank()) +
  xlab("Date") + ylab(units[4]) +
  scale_y_continuous(expand = expansion(c(0, 0.05)))
```

<!-- 
## All together - Visualizing multiple panel data signals
Example: gathering different signals + visualizing panel data

```{r multiple-signals-unscale}
#| echo: false
# turn list into dataframe
df <- list_rbind(data_list)
df$signal <- factor(df$signal, labels = names)

ggplot(df, aes(x = time_value, y = value, color = signal)) +
  geom_line() +
  scale_color_manual(breaks = names, values = colors) +
  labs(x = "Date", y = "Signal value") +
  scale_x_date(date_breaks = "3 months", date_labels = "%b %Y",
               date_minor_breaks = "1 month") +
  theme_bw() +
  theme(legend.position = "bottom", legend.title = element_blank())
```

## All together - Visualizing multiple panel data signals
Example: gathering different signals + **scaling** + visualizing panel data

```{r multiple-signals-scale}
#| echo: FALSE
#| include: FALSE
# HIDE THIS: function that rescales signal value according to specified range
epi_rescale_signal = function(df, variable, scale_to = c(0, 1)) {
  Min <- function(x) min(x, na.rm = TRUE)
  Max <- function(x) max(x, na.rm = TRUE)
  rescaled <- df |>
    group_by(signal) |>
      mutate("{{variable}}" := ({{variable}} - Min({{variable}})) / 
               (Max({{variable}}) - Min({{variable}})) * scale_to[2] + 
               scale_to[1]) |>
    ungroup()
  return(rescaled)
}
```


```{r scaled-signals}
#| echo: false
# minimum and maximum of cases (used to rescale data)
case_min <- min(data_list[[1]]$value)
case_max <- max(data_list[[1]]$value)

# rescale data
rescaled_df <- epi_rescale_signal(df, value, scale_to = c(case_min, case_max))

# plot
rescaled_df$signal <- factor(rescaled_df$signal, labels = names)

ggplot(rescaled_df, aes(x = time_value, y = value, color = signal)) +
  geom_line() +
  scale_color_manual(breaks = names, values = colors) +
  labs(x = "Date", y = "Signal value (scaled)") +
  scale_x_date(date_breaks = "3 months", date_labels = "%b %Y",
               date_minor_breaks = "1 month") +
  theme_bw() +
  theme(legend.position = "bottom", legend.title = element_blank())

#ggsave("fig_covidcast_signals/time_trends_national.pdf", width = 5, height = 3)
```
<div style="text-align: center;">
<small>[Figure 1 from Reinhart et al. (2021)](https://www.pnas.org/doi/10.1073/pnas.2111452118)</small>
</div>

**Takeaway:** The auxiliary signals track changes in the official reported cases quite well. This is clearer when they have all been placed on the same range as reported cases per 100,000 people.
-->

## Examples of panel data - COVID-19 cases and deaths in CA
* [**Takeaway**]{.primary}: Cases appear to strongly correlate with deaths several weeks later.
* We'll see this again in an upcoming session...

```{r plot-ca-cases-deaths}
#| echo: false
source(here::here("_code/ca_cases_deaths.R"))
ggplot(ca |> 
         mutate(deaths = trans21(deaths)) |>
         pivot_longer(cols = c(cases, deaths), names_to = 'name'),
       aes(x = time_value, y = value)) + 
  geom_line(aes(color = name), key_glyph = "timeseries") +
  scale_color_delphi() +
  scale_y_continuous(
    expand = expansion(c(0, 0.05)),
    name = "Incident cases per 100k people", 
    limits = range1,
    sec.axis = sec_axis(
      trans = trans12, 
      name = "Incident deaths per 100k people")) +
  labs(x = "Date") +
  theme(legend.position = "right", legend.title = element_blank()) 
```

# Versioned Data

## Intro to versioned data
* In panel data, we've seen that time is indicated by `time_value`.

* Now, we add a second time index to indicate the data version...
```{r versioned-wa-ex}
#| echo: false
states <- c("fl", "ca", "ny", "tx")
head(x$DT) |> as_tibble()
```

* Note that this feature can be indicated in different ways (ex. `version`, `issue`, `release`, `as_of`). 

## Versioned panel data
Estimated percentage of outpatient visits due to CLI in [FL]{.primary} across multiple issue dates, 
with updates and revisions to past data as new issue dates are released:

```{r versioned-panel-multi-states-ex}
#| echo: false
#| eval: false
dv <- pub_covidcast(source = "doctor-visits", 
                    signals = "smoothed_adj_cli", 
                    geo_type = "state", 
                    geo_values = "fl,ca,ny,tx", 
                    time_type = "day",
                    time_values = epirange(20200601, 20211201),
                    issues = epirange(20200601, 20211201)
) |>
  select(time_value, geo_value, percent_cli = value, version = issue)
dv_final <- pub_covidcast(source = "doctor-visits", 
                    signals = "smoothed_adj_cli", 
                    geo_type = "state", 
                    geo_values = "fl,ca,ny,tx", 
                    time_type = "day",
                    time_values = epirange(20200601, 20211201)
) |>
  select(time_value, geo_value, percent_cli = value, version = issue)
write_rds(list(dv_version = dv, dv_final = dv_final), 
          "slides/_data/four-state-dv-all-versions.rds")
```


```{r versioned-panel-multi-states-ex-2}
dvall <- read_rds("_data/four-state-dv-all-versions.rds")
dv_archive <- dvall[["dv_version"]] |>
  as_epi_archive(compactify = TRUE)
dv_final <- dvall[["dv_final"]]
max_version <- max(dv_archive$DT$version)
versions <- seq(as.Date("2020-06-01"), max_version - 1, by = "1 week")
weekly_snapshots <- map(versions, function(v) {
  epix_as_of(dv_archive, v) %>% mutate(version = v)
}) |> list_rbind()
weekly_snapshots |>
  filter(geo_value == "fl") |>
  ggplot(aes(x = time_value, y = percent_cli)) +
  geom_line(aes(color = factor(version))) +
  # geom_vline(aes(color = factor(version), xintercept = version), lty = 3) +
  geom_line(data = dv_final |> filter(geo_value == "fl"), color = "black") +
  labs(x = "Date", y = "% doctor's visits with CLI") +
  expand_limits(y = 0) +
  scale_x_date(date_labels = "%b %Y", expand = expansion(0)) +
  scale_y_continuous(expand = expansion(c(0, 0.05))) +
  theme_bw() +
  theme(legend.position = "none") +
  scale_color_viridis_d() 

#ggsave("fig_covidcast_signals/dv_as_of.pdf", width = 5, height = 4)
```

## Latency and revision in signals

* [**Latency**]{.primary} refers to the delay between data collection and availability.

**Example**: A signal based on medical insurance claims may take several days to appear but is subject to delays as claims are processed over weeks.

* [**Revision**]{.primary} occurs when data is updated or corrected after initial publication, often due to new information or late reporting.

**Example**: COVID-19 case reports are revised frequently after initial publication as new data comes in or reporting backlogs are cleared.

## Latency and revision in signals - Example

* Recall the first example of panel & versioned data we've seen... 

* This signal is 4 days [**latent**]{.primary} (min(`version` - `time_value`))

```{r latency-wa-ex}
#| echo: false
x_dt_with_diff = x$DT |> mutate(version_time_diff = version - time_value) 
head(x_dt_with_diff |> group_by(time_value) |> slice(1) |> ungroup()) 
```

* And clearly undergoes [**revision**]{.primary} over time (ex. consider Dec. 1's `percent_cli` across `version`):

```{r revision-wa-ex}
#| echo: false
head(x_dt_with_diff) |> as_tibble()
```

<!-- min_lag: the minimum time to any value min(as.integer(version) - as.integer(time_value)  -->
<!-- max_lag: the amount of time until the final (new) version -->
<!-- revision_summary computes some basic statistics about the revision behavior of an archive, returning a tibble summarizing the revisions per time_value+epi_key features. -->

## Revision triangle, Outpatient visits in WA 2022 

* 7-day trailing average to smooth day-of-week effects

```{r revision-triangle}
#| echo: false
#| dpi: 300
#| fig-format: png
#| fig-width: 8
#| fig-height: 4.5
dv_cli <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_cli",
  geo_type = "state",
  time_type = "day",
  geo_values = "wa",
  time_values = epirange(20211201, 20220201),
  issues = epirange(20211201, 20220201)
) |>
  select(time_value, value, issue)

dv_cli_finalized <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_cli",
  geo_type = "state",
  time_type = "day",
  geo_values = "wa",
  time_values = epirange(20211201, 20220201),
  as_of = "2022-02-01"
) |>
  select(time_value, final_value = value)

dv_cli <- left_join(dv_cli, dv_cli_finalized, by = join_by(time_value)) |>
  mutate(value = zoo::rollmeanr(value, k = 7, na.pad = TRUE), 
         final_value = zoo::rollmeanr(final_value, k = 7, na.pad = TRUE),
         .by = issue)

p1 <- dv_cli |>
  filter(time_value > ymd("2021-12-31"), issue >= "2021-12-31") |>
  ggplot(aes(time_value, issue, fill = value / final_value * 100)) +
  geom_tile() +
  scale_x_date(expand = expansion(), name = "Date") +
  scale_y_date(expand = expansion(), name = "Report date") +
  scale_fill_viridis_c(
    name = "% final", 
    option = "B",
    direction = -1
  ) +
  theme_bw() +
  theme(legend.position = "bottom", legend.key.width = unit(1, "cm")) 

p2 <- dv_cli |>
  filter(issue >= "2021-12-31", time_value > ymd("2021-12-31")) |>
  ggplot(aes(time_value)) +
  geom_line(aes(y = value, colour = issue, group = issue)) +
  scale_x_date(expand = expansion(), name = "Date") +
  scale_y_continuous(
    expand = expansion(), 
    name = "% Outpatient visits b/c CLI",
  ) +
  scale_colour_viridis_c(
    name = "Report Date", 
    direction = -1,
    trans = "date",
    labels = scales::label_date("%b %d"),
    option = "B"
  ) +
  geom_line(aes(y = final_value), color = "black") +
  theme_bw() +
  theme(legend.position = "bottom", legend.key.width = unit(1, "cm")) 

cowplot::plot_grid(p1, p2)
```

## Revisions
Many data sources are subject to revisions:

* Case and death counts are frequently corrected or adjusted by authorities.

* Medical claims data can take weeks to be submitted and processed.

<!--* In the previous slide's example because doctor's visits may be reported to the health system partners several days after they occur, these signals are typically available with several days of lag. This means that estimates for a specific day are only available several days later. -->

* Lab tests and medical records can be backlogged for a variety of reasons.

* Surveys are not always completed promptly.

* [**Key**]{.primary}: An accurate revision log is crucial for researchers building forecasts. 

**A forecast that is made today can should rely on information we have access to today.**

## Three types of revisions
1. [**Sources that don't revise**]{.primary} - Ex. Facebook or Google symptoms (provisional and final are the same)

1. [**Predictable revisions**]{.secondary} - Ex. Claims data (CHNG) and public health reports aligned by test, hosp., or death date

1. [**Revisions that are large and erratic to predict**]{.tertiary} - Ex. COVID cases and deaths, especially when aligned by report date (which can be highly variable & less predictable compared to test data). 

## Types of revisions - Comparison between 2. and 3.

* Revision behavior for two indicators in the HRR containing Charlotte, NC.

<!-- Each colored line corresponds to the data as reported on a particular date (as of dates varying from 28 September through 19 October). -->
* [**DV-CLI signal (left)**]{.secondary} was regularly revised throughout the period, although effects fade farther back.

* [**JHU CSSE cases (right)**]{.tertiary} remain "as reported" on Sept. 28, with a spike toward the end of this period, until a major correction is made on Oct. 19, which brings this down & affects prior data.


```{r fig1-McDonald}
#| echo: false
# This is Figure 1 from https://www.pnas.org/doi/pdf/10.1073/pnas.2111453118

as_ofs <- seq(as.Date("2020-09-28"), as.Date("2020-10-19"), by = "week")
cases_as_of <- map_dfr(as_ofs, function(as_of) {
  pub_covidcast(source = "jhu-csse", 
                signals = "confirmed_7dav_incidence_prop",
                geo_type = "hrr", 
                time_type = "day",
                geo_values = "311",
                as_of = as_of,
                time_values = epirange(20200815, 20200926)) |>
    mutate(as_of = as_of)
})
dv_as_of <-  map_dfr(as_ofs, function(as_of) {
  pub_covidcast(source = "doctor-visits", 
                signals = "smoothed_adj_cli", # Estimated % of outpatient doctor visits primarily about COVID-related symptoms
                geo_type = "hrr",
                time_type = "day",
                geo_values = "311", 
                as_of = as_of,
                time_values = epirange(20200815, 20200926)) |>
    mutate(as_of = as_of)
})
  
p1 <- dv_as_of |>
  mutate(as_of = fct_relabel(factor(as_of), function(x) strftime(x, "%b %d"))) |>
  ggplot(aes(x = time_value, y = value)) + 
  geom_line(aes(color = factor(as_of))) + 
  labs(title = "DV-CLI", x = "", y = "% doctor's visits due to CLI",
       color = "As of:") +
  theme_bw() + 
  theme(legend.position = "bottom") +
  scale_color_viridis_d(end = .9, begin = .1) +
  guides(color = guide_legend(nrow = 1))

p2 <- cases_as_of |>
  mutate(as_of = fct_relabel(factor(as_of), function(x) strftime(x, "%b %d"))) |>
  ggplot(aes(x = time_value, y = value)) + 
  geom_line(aes(color = factor(as_of))) + 
  labs(title = "Cases", x = "", y = "Cases per 100,000 people",
       color = "As of:") +
  theme_bw() + 
  theme(legend.position = "bottom") +
  scale_color_viridis_d(end = .9, begin = .1) +
  guides(color = guide_legend(nrow = 1))

# From https://github.com/tidyverse/ggplot2/wiki/Share-a-legend-between-two-ggplot2-graphs
grid_arrange_shared_legend <- function(...,
                                       ncol = length(list(...)),
                                       nrow = 1,
                                       position = c("bottom", "right")) {

  plots <- list(...)
  position <- match.arg(position)
  g <- ggplotGrob(plots[[1]] + theme(legend.position = position))$grobs
  legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]]
  lheight <- sum(legend$height)
  lwidth <- sum(legend$width)
  gl <- lapply(plots, function(x) x + theme(legend.position="none"))
  gl <- c(gl, ncol = ncol, nrow = nrow)

  combined <- switch(position,
                     "bottom" = arrangeGrob(do.call(arrangeGrob, gl),
                                            legend,
                                            ncol = 1,
                                            heights = unit.c(unit(1, "npc") - lheight, lheight)),
                     "right" = arrangeGrob(do.call(arrangeGrob, gl),
                                           legend,
                                           ncol = 2,
                                           widths = unit.c(unit(1, "npc") - lwidth, lwidth)))

  grid.newpage()
  invisible(grid.draw(combined))

  # return gtable invisibly
  invisible(combined)

}

p3 <- grid_arrange_shared_legend(p1, p2)
invisible(p3)
```
<div style="text-align: center;">
<small>[Figure 1 from McDonald et al. (2021)](https://www.pnas.org/doi/pdf/10.1073/pnas.2111453118)</small>
</div>

## Key takeaways

* [**Medical claims revisions**]{.secondary}: More systematic and predictable.
* [**COVID-19 case report revisions**]{.tertiary}: Erratic and often unpredictable.
* Large spikes or anomalies can occur as
    + [**Reporting backlogs**]{.tertiary} are cleared.
    + [**Changes in case definitions**]{.tertiary} are implemented.

## Reporting backlogs - Example

* **Left**: Reported cases per day in Bexar County, Texas, during the summer of 2020. On July 16, 4,810 [backlogged cases]{.primary} were reported, reflecting a 2-week delay. This caused a prolonged spike due to the 7-day trailing average applied to the counts.

* **Right**: CTIS estimates of CLI-in-community showed more stable underlying trends.


```{r fig4-Reinhart}
#| echo: false
#| message: false
#| fig-width: 6.5
#| fig-height: 3

# Figure 4 from https://www.pnas.org/doi/10.1073/pnas.2111452118
sa_fips <- "48029"
sa_start <- "2020-06-15"
sa_end <- "2020-08-15"
sa_anomaly_date <- as.Date("2020-07-16")
sources <- c("jhu-csse", "fb-survey", "doctor-visits", "google-symptoms", "chng")
signals <- c("confirmed_7dav_incidence_num", "smoothed_whh_cmnty_cli",
             "smoothed_adj_cli", "sum_anosmia_ageusia_smoothed_search", 
             "smoothed_adj_outpatient_cli")
reinhart <- map2(sources, signals, 
                 ~ pub_covidcast(.x, .y, time_type = "day", geo_type = "county",
                                 time_values = epirange(sa_start, sa_end),
                                 geo_values = sa_fips) |>
                   select(source, time_value, value))
sa_cross <- reinhart[[1]]$value[33]
sa_scale <- sd(reinhart[[1]]$value, na.rm = TRUE)
reinhart[-1] <- map(
  reinhart[-1], 
  ~ mutate(.x, value = (value - value[33]) / sd(value, na.rm = TRUE) *
             sa_scale + sa_cross))
reinhart <- list_rbind(reinhart)

g1 <- ggplot(reinhart |> filter(source == "jhu-csse"), aes(x = time_value, y = value)) +
  geom_vline(xintercept = sa_anomaly_date, color = "gray", linetype = "dashed",
             alpha = 0.75) +
  geom_line() +
  labs(x = "", y = "Cases", title = "Cases") +
  theme_bw()

labels <- c(
  `fb-survey` = "Survey-based CLI",
  chng = "Outpatient CLI",
  `google-symptoms` = "Google searches",
  `doctor-visits` = "Insurance claims"
)


g2 <- reinhart |>
  filter(source != "jhu-csse") |>
  ggplot(aes(x = time_value, y = value, color = source)) +
  geom_vline(xintercept = sa_anomaly_date, color = "gray", linetype = "dashed",
             size = 0.75, alpha = 0.75) +
  geom_line() +
  scale_color_delphi(labels = labels, name = "") +
  labs(x = "", y = "Signal value (rescaled)", title = "Auxiliary signals") +
  theme_bw()

cowplot::plot_grid(g1, g2, ncol = 2, rel_widths = c(.35, .65))
```

## Reporting backlogs - Key takeaways

* [**Reporting issues been common across U.S. jurisdictions**]{.primary}.

* For example, audits have regularly discovered [**misclassified or unreported cases and deaths**]{.primary}.

* This underscores the value of [**cross-checking data with external sources**]{.primary} not part of the same reporting systems.


# Epidata API

## Goals of Delphi Epidata platform and repository

<div style="font-size: 0.9em;">
1. **Be the one-stop shop for aggregated epi-surveillance time-series ("epi-signals")**
    + Hence: include also signals available elsewhere, especially if they don't keep data revisions - E.g. CDC's own NSSP, NWSS
    + Be the national historical repository of record & preserve the raw data

2. **Be the national clearinghouse for epi-signals, including those held elsewhere**
    + The go-to place for signal discovery

3. **Add value to existing signals and synthesize new ones**
    + Added value: see next slide
    + Synthesize new: via signal fusion, e.g. nowcasting

4. **Be the focal point for community-wide efforts to open up privately held data**
    + Better positioned than government or industry
</div>


## The bigger goal
The goal is to make epi-surveillance [more nimble, complete, standardized, robust, and real-time]{.primary} and

[less burdensome on the health system itself]{.primary}. 

Epidata is not the solution; but we hope it is a blueprint towards such a solution.


## What is the Epidata repository

[**Epidata**]{.primary} is a repository of aggregated epi-surveillance time series. To the full extent we can, we make everything [free and open-source]{.primary}.

* To date, it has accumulated over 5 billion records (each record is the value of a signal, at a particular date, and a particular location).

* At the peak of the pandemic, we were receiving millions of API queries per day.

* [**Data comes from**]{.primary}: public health reporting, medical insurance claims, medical device data, Google search queries, wastewater, app-based mobility patterns.

* Many of our data streams simply aren't available anywhere else.

* [**Added value we provide**]{.primary}: revision tracking, anomaly detection, trend detection, smoothing, imputation, geo-temporal-demographic disaggregation

## Features of Delphi Epidata

* Built-in support for:
    + Data revisions ("backfill").  Concepts of "reporting date" and "as of".
    + Backfill projection and alerting to changes in backfill dynamics
    + Geo levels w/ auto-aggregation: county, MSA, HRR, state, HHS region, nation
        - Also esoteric ones: DMA, sewer sheds
    + Demographic breakdown
    + Representation for missingness and censoring
    + Population sizes and fine-grained population density
    
* Pre-computed smoothing and normalization (customization planned)

* Access control

* Code is Open Source.  Signals are as accessible (w/ API, SDK) as allowed by DUAs


## Epidata API 

* [Delphi's Epidata API](https://cmu-delphi.github.io/delphi-epidata/) provides real-time access to epidemiological surveillance data. 

* The [main endpoint](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html) (covidcast) providing daily updates about current COVID-19 and influenza activity across the United States.

* A [variety of other endpoints](https://cmu-delphi.github.io/delphi-epidata/api/README.html), providing primarily historical data about various diseases including COVID-19, influenza, dengue fever, and norovirus in several countries.

* A [full-featured R client](https://cmu-delphi.github.io/delphi-epidata/api/client_libraries.html) is available for quick access to all data. 

* A [Legacy Python client](https://cmu-delphi.github.io/delphi-epidata/api/client_libraries.html#python) is available, full-featured Python client in development.

## Some of our data sources
### Ongoing Sources:
* [**Insurance claims**]{.primary}: %Covid {inpatient, outpatient}, by {county x day}
* [**Google Symptom searches**]{.primary}: 7 symptoms groups, by {county x day}
* [**Quidel/Ortho antigen tests**]{.primary}: %Covid by age group, by {county x day}
* [**NCHS Deaths**]{.primary}: all-cause, pneumonia, flu, Covid, by {state x week}
* [**NSSP ED visits**]{.primary}: %Covid, %flu, %RSV, by {county x week}  (new!)
* [**NWSS Covid**]{.primary}, by {sampling-site x day}  (in progress)

## Some of our data sources
### Active during pandemic, could be restarted for the next PHE:
* [**HHS Hosp/ICU beds**]{.primary}: Covid, flu, by age-group, by {state x day}, {facility x week}
* [**CTIS ("Delphi Facebook Survey")**]{.primary}: many dozens of questions, by (county x day)
* [**STLT-reported**]{.primary}: {cases, deaths} via {JHU, USAFacts}, by (country x day)
* [**Safegraph mobility**]{.primary}: misc measures by {county x day},{county x week}




## Some of our pre-pandemic data sources
* FluView ILINet, by {state x week}

* FluView Clinical (% positive flu, PH and clinical labs)

* Google Health Trends (GHT), precursor to Google Symptoms

* Google Flu Trends (GFT), precursor to to GHT

* Twitter flu

* Access counts for flu-related CDC pages, by {city x week}

* Access counts for flu-related Wikipedia entries by {day x hour}

* Flu-surv (flu hosp rates, now expanded to RESP-NET)

* Misc signals for dengue, norovirus

* Misc signals for PAHO countries, ECDC, KCDC, Taiwan,...

* Delphi ILI nowcasts, by {state x week}, visualized in "ILI Nearby" website

* Delphi ILI forecasts, by {state x week}

## Severity pyramid

![](gfx/severity-pyramid.svg){fig-align=center}

# Epidatr

## Installing `epidatr`
Installing the package in R is straightforward...

Install the CRAN version

```{r install-epidatr-cran}
#| echo: true
#| eval: false
# Install the CRAN version
pak::pkg_install("epidatr")
```

<br>

or the development version

```{r install-epidatr-dev}
#| eval: false
#| echo: true
# Install the development version from the GitHub dev branch
# pak::pkg_install("cmu-delphi/epidatr@dev")
```

The CRAN listing is [here](https://cran.r-project.org/package=epidatr/index.html).

## Python

In Python, install [`delphi-epidata` from PyPI](https://pypi.org/project/delphi-epidata/) with 

``` sh
pip install delphi-epidata
```

<br>

`delphi-epidata` is soon to be replaced with `epidatpy`.

``` sh
# Latest dev version
pip install -e "git+https://github.com/cmu-delphi/epidatpy.git#egg=epidatpy"

# PyPI version (not yet available)
pip install epidatpy
```




## Using `epidatr` and `epidatpy`
The following shows how to import the library and fetch all confirmed influenza hospital admissions occurring each day for North Carolina:

```{r hhs-influenza-pub-covidcast}
#| echo: true
library(epidatr)
res <- pub_covidcast('hhs', 'confirmed_admissions_influenza_1d', 'state', 'day', geo_values = 'nc',
                     time_values = c(20240401, 20240405:20240414))
head(res, n = 3)
```

<br>

Python equivalent:
``` python
res = Epidata.covidcast('hhs', 'confirmed_admissions_influenza_1d', 'day', 'state', [20240401, Epidata.range(20240405, 20240414)], 'nc')
print(res['result'], res['message'], len(res['epidata']))
```



## API keys

* Anyone may access the Epidata API anonymously without providing any personal data. 

* Anonymous API access is subject to the following restrictions:
  1) public datasets only; 2) rate limited to 60 requests per hour; 3) only two parameters may have multiple selections

* An API key grants priviledged access to the API and can be obtained by [registering with us](https://api.delphi.cmu.edu/epidata/admin/registration_form). 

* Privileges of registration:
  1) no rate limit; 2) no limit on multiple selections

::: {.callout-tip}
## Tip
The `epidatr` client automatically searches for the key in the `DELPHI_EPIDATA_KEY` environment variable. We recommend storing it in your `.Renviron` file, which R reads by default. More on setting your API key [here](https://rdrr.io/cran/epidatr/man/get_api_key.html).
:::



# Find Data Sources & Signals

## Finding data sources and signals of interest

* Diverse Data Streams
    +  [**Variety of Data**]{.primary}: Access to medical claims data, cases and deaths, mobility data, and more.
    +  [**Geographic Coverage**]{.primary}: Includes multiple regions, making it comprehensive yet complex.
    +  [**Challenge**]{.primary}: Difficulty in pinpointing the specific data stream of interest.

* Using the Documentation
    +  [**Comprehensive Listings**]{.primary}: Documentation details all available data sources and signals for both [COVID-19](https://cmu-delphi.github.io/delphi-epidata/api/covidcast_signals.html) and other [endpoints](https://cmu-delphi.github.io/delphi-epidata/api/README.html#source-specific-parameters).

* Docs are great for a deep dive into the data, whereas the apps & tools are useful to see what is available...




## Cheatsheet of web-based apps we provide
We provide...

* A [signal discovery app](https://delphi.cmu.edu/signals/), to explore what epi-signals are available in Delphi Epidata and elsewhere in the community.

* A [general signal visualization tool](https://delphi.cmu.edu/epivis/).

* A [signal dashboard](https://delphi.cmu.edu/covidcast/) and a "classic" [map-based version](https://delphi.cmu.edu/covidcast/classic/) to visualize a core set of COVID-19 and flu indicators.

* A [COVID-19 signal export app](https://delphi.cmu.edu/covidcast/export/), a [dashboard builder](https://delphi.cmu.edu/covidcast/dashboard/), and more!

## Signal dashboard - For COVID-19 & flu data

::: flex
::: w-40

* The [signal dashboard](https://delphi.cmu.edu/covidcast/) displays a selection of signals for COVID-19 & flu.

<br>

* Browse by location or indicator to choose which signal you are interested in & then export the data for analysis.

<br>

* **Example**: Google symptom search trends in NC.

<!-- 
* Includes "Data Export" to pull a selected signal & download as a CSV. -->
:::
::: w-60

<a href="https://delphi.cmu.edu/covidcast/indicator/?date=20240426&region=NC">
  <img src="gfx/google_symptoms_signal_dash.jpg" alt="Signal Discover Screenshot">
</a>

:::
:::


## Signal discovery app - Browse for more data
* [**Signal discovery app**]{.primary}: An easy way to find data sources and signals (no programming required).
    +  Search tool that is a good to browse & find data.
* [Let's try it out together!](https://delphi.cmu.edu/signals/)
<a href="https://delphi.cmu.edu/signals/">
  <img src="gfx/signal_discover_screenshot.jpg" alt="Signal Discover Screenshot" style="height: auto; width: auto;">
</a>

## Example - NCHS weekly flu mortality data in states

<a href="https://delphi.cmu.edu/signals/">
  <img src="gfx/signal_discover_screenshot_ex.jpg" alt="Signal Discover Screenshot" style="height: auto; width: auto;">
</a>

<!-- To reproduce: Pathogen/Syndrom = flu, Severity pyramid = Dead (top of pyramid), Geo-level = ADM1 (e.g. U.S. states) -->

## Interactive tooling in R 

* Moving from initial web-based browsing to programming, [**how do we find sources and signals in R?**]{.primary}

* Functions to enhance data discovery in `epidatr`:

`avail_endpoints()` Function:
    +  Lists all endpoints with brief descriptions.
    + Highlights specific endpoints that cover non-US locations, facilitating targeted searches.
    
[**Output Format**]{.primary}: Returns a tibble for easy viewing and analysis of available data sources.

```{r avail-endpoints-fun}
#| echo: true
#| results: hide
avail_endpoints() 
```

##  Using the `covidcast_epidata()` function 

* **Function Overview**: `covidcast_epidata()` provides detailed insights into data sources from the COVIDcast endpoint.

* **Source List**: Each data source is listed in `covid_sources$sources`, with associated tibbles describing included signals.
    
* **Editor Support**: In RStudio or similar editors, use tab completion to explore:

    + **Data Sources**: Type `covid_sources$source$` to view available data sources.
        
    + **Signals**: Type `covid_sources$signals$` to see signal options with autocomplete assistance.
        
* **Filtering Convenience**: Signal names are prefixed with their respective data source for easier navigation.

```{r covidcast-epidata-fun}
#| echo: true
#| results: hide
covid_sources <- covidcast_epidata()
head(covid_sources$sources, n = 2) # head(list, n = 2) will print the first two elements of the list
```

## Fetching data - COVIDcast main endpoint 

* Fetching data from the Delphi Epidata API is simple. 

* The `pub_covidcast()` function lets us access the `covidcast` endpoint.

* We need to specify the following six arguments...
    1. `source`: Data source name
    2. `signals`: Signal name
    3. `geo_type`: Geographic level 
    4. `time_type`: Time resolution
    5. `geo_values`: Location(s)
    6. `time_values`: times of interest
    
* Let's give this a try!


## Fetching data - COVIDcast main endpoint 

```{r us-jhu-pub-covidcast}
#| echo: true
library(epidatr)
library(dplyr)

epidata <- pub_covidcast(
  source = "jhu-csse",
  signals = "confirmed_7dav_incidence_prop", 
  geo_type = "nation",
  time_type = "day",
  geo_values = "us",
  time_values = epirange(20210101, 20210401)
)
```

```{r head-us-jhu-pub-covidcast}
#| echo = FALSE 
head(epidata, n = 3) |> select(geo_value, signal, source, geo_type, time_value, issue, lag, value)
```
Here `value` is the requested signal – in this case, the number of daily new confirmed COVID-19 cases per 100,000 population from January to April 2021. <!-- (and standard error if it is applicable to the metric). -->


## Returned data - COVIDcast main endpoint 

* `pub_covidcast()` outputs a tibble, where each row represents one observation.

* Each observation covers a set of events aggregated by time and by geographic region is a record in our database. Each such record includes:
* `time_value`: time period when the events occurred.
* `geo_value`: geographic region where the events occurred.
* `value`: estimated value.
* `stderr`: standard error of the estimate, usually referring to the sampling error.
* `sample_size`: number of events used in the estimation.

<!--For example, a number of COVID-19 antigen tests were performed in the state of New York on August 1. The `time_value` would be August 1, with `geo_value` indicating the state of New York, while the remaining fields would give the estimated test positivity rate (the percentage of tests that were positive for COVID-19), its standard error, and the number of tests used to calculate the estimate.-->

## Returned data - COVIDcast main endpoint 
Crucially—and unlike most other sources of COVID-19 data—our API reports two additional fields with each record:

* `issue`: The time period when this observation was published.

* `lag`: The time delay between when the events occurred and when this observation was published.

* Meaning that unlike most other sources of COVID data, it tracks the complete revision history of every signal.

* This allows for historical reconstructions of what information was available at specific times. [**More on this soon!**]{.primary}


## Geographic levels

* The Epidata API makes signals available at different geographic levels, depending on the endpoint.
* For the `confirmed_7dav_incidence_prop` signal, we can obtain values for each state.

* Simply change `geo_type` and `geo_values` in the previous example to get...

```{r state-jhu-pub-covidcast}
#| echo: true
# Obtain the most up-to-date version of the smoothed covid-like illness (CLI)
# signal from the COVID-19 Trends and Impact survey for all states
state_epidata <- pub_covidcast(
  source = "jhu-csse",
  signals = "confirmed_7dav_incidence_prop",
  geo_type = "state",
  time_type = "day",
  geo_values = "*",
  time_values = epirange(20210101, 20210401)
)
```

```{r head-state-jhu-pub-covidcast}
#| echo = FALSE 
head(state_epidata) |> select(geo_value, signal, source, geo_type, time_value, issue, lag, value)
```


## COVIDcast main endpoint - Example query 
County `geo_values` are [FIPS codes](https://en.wikipedia.org/wiki/List_of_United_States_FIPS_codes_by_county) and are discussed in the API docs [here](https://cmu-delphi.github.io/delphi-epidata/api/covidcast_geography.html). The example below is for Orange County, California. 

```{r county-jhu-pub-covid}
#| echo: true
jhu_county_data <- pub_covidcast(
  source = "jhu-csse",
  signals = "confirmed_7dav_incidence_prop",
  geo_type = "county",
  time_type = "day",
  time_values = epirange(20210101, 20210401),
  geo_values = "06059"
)
```

```{r head-county-jhu-pub-covid}
#| echo = FALSE 
head(jhu_county_data) |> select(geo_value, signal, source, geo_type, time_value, issue, lag, value)
```

::: {.callout-important icon="false"}

## Note

The `covidcast` endpoint supports `*` in its time and geo fields. Try to obtain the signal values for all available counties by replacing `geo_values = "06059"` with `geo_values = "*"`.
:::

## Example queries - Other endpoints: Hospitalizations

[**COVID-19 Hospitalization: Facility Lookup**]{.primary}

<small> API docs: <https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp_facility_lookup.html> </small>

```{r hosp-facility-lookup}
#| echo: true
pub_covid_hosp_facility_lookup(city = "southlake")
```

<br> 

```{r hosp-facility-lookup-wy}
#| echo: true
pub_covid_hosp_facility_lookup(state = "WY") |> head()
# A non-example (there is no city called New York in Wyoming)
# pub_covid_hosp_facility_lookup(state = "WY", city = "New York")
```


## Example queries - Other endpoints: Hospitalizations

[**COVID-19 Hospitalization by Facility**]{.primary}

<small> API docs: <https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp_facility.html> </small>
```{r hosp-by-facility}
#| echo: true
pub_covid_hosp_facility(
  hospital_pks = "100075",
  collection_weeks = epirange(20200101, 20200501)
) |> head()
```

[**COVID-19 Hospitalization by State**]{.primary}

<small> API docs: <https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp.html> </small>
```{r hosp-by-state}
#| echo: true
#| results: hide
pub_covid_hosp_state_timeseries(states = "MA", dates = "20200510")
```

## Example queries - Other endpoints: Flu endpoints

[**FluSurv hospitalization data**]{.primary} -- Data ends around 2020

<small> API docs: <https://cmu-delphi.github.io/delphi-epidata/api/flusurv.html> </small>
```{r flusurv}
#| echo: true
#| results: hide
pub_flusurv(locations = "ca", epiweeks = 202001) 
```

[**Fluview data**]{.primary} -- Remains active

<small> API docs: <https://cmu-delphi.github.io/delphi-epidata/api/fluview.html> </small>
```{r fluview}
#| echo: true
#| results: hide
pub_fluview(regions = "nat", epiweeks = epirange(201201, 202001))
```

::: {.callout-tip}
## Tip - public vs private methods

Aside from these public methods we've gone through (these start with `pub_`),
there are private methods (these start with `pvt_` when you type `avail_endpoints()`).
These require private access keys to use (separate from the Delphi Epidata API key). 
To run these locally, you will need to store these secrets in your `.Reviron` file, or set them as environmental variables.
See [Private methods](https://cmu-delphi.github.io/epidatr/articles/signal-discovery.html) for examples of using private endpoints.
:::

## Signal metadata

* Some endpoints provide additional metadata for signals.
    + [**Time Information**]{.primary}: Details on available time frames and last update times.
    + [**Geography Information**]{.primary}: Details on available geography types. 

* Key Endpoints for Metadata
    + `pub_covidcast_meta()`: Access metadata for the COVIDcast endpoint.
    + `pub_fluview_meta()`: Get metadata for the FluView endpoint.
    + `pub_meta()`: General metadata for the Delphi Epidata API.

# Versioning in `epidatr`

## Versioned data in `epidatr`

* Epidata API contains comprehensive data record, capturing each signal's estimate, location, date, and update timeline.

* Requesting Specific Data Versions:
    + Use `as_of` or `issues` arguments to specify data availability.
    + Use `as_of` to fetch one version and `issues` to fetch multiple.
    + Only one argument can be used at a time; not all endpoints support both
    
* Let's start with fetching one version...

## Obtaining data "as of" a specific date

* **Example**: [Doctor Visits Signal](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/doctor-visits.html) (from the `covidcast` endpoint)
    + Estimates the percentage of outpatient doctor visits that are COVID-related.
To give a specific example, let's consider the estimate for PA on May 1, 2020:

```{r pa-may-1st-as-of}
#| echo: true
epidata <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-01"),
  geo_type = "state",
  geo_values = "pa",
  as_of = "2020-05-07"
)
```

```{r head-pa-may-1st-as-of}
#| echo = FALSE 
head(epidata) |> select(geo_value, signal, source, time_value, issue, lag, value)
```

* Initial estimate was *issued* on May 7, 2020 (due to delay from aggregation and ingestion by the API).

## Obtaining data "as of" a specific date

[**Default behaviour:**]{.primary} If we don't specify `as_of`, we get the most recent estimate:

```{r pa-may-1st-most-recent}
#| echo: true
epidata <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-01"),
  geo_type = "state",
  geo_values = "pa"
)
```

```{r head-pa-may-1st-most-recent}
#| echo = FALSE 
head(epidata) |> select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```

* [**Substantial Estimate Change**]{.primary}:
    + Estimate increased from <3% to almost 6% after May 7, reflecting new data on visits from May 1.
    
* [**Versioning is Important in Forecasting**]{.primary}:
    + Accurate backtesting requires using data available at the time of model fitting, not later updates, for accurate forecasting results.


## Obtaining multiple specific issues for one state
By using the `issues` argument, we can request all issues in a certain time period:

```{r pa-multiple-issues}
#| echo: true
epidata <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-01"),
  geo_type = "state",
  geo_values = "pa",
  issues = epirange("2020-05-01", "2020-05-15")
)
```

```{r head-pa-multiple-issues}
#| echo = FALSE 
head(epidata) |> select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```

## Obtaining multiple issues for one state

To ensure that you've captured all issues up to a specific date (e.g., "2020-05-15"), set an extreme lower bound: `issues = epirange("1900-01-01", "2020-05-15")`.

```{r extreme-lb-multiple-issues}
#| echo: true
epidata <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-01"),
  geo_type = "state",
  geo_values = "pa",
  issues = epirange("1900-01-01", "2020-05-15")
)
```

```{r head-extreme-lb-multiple-issues}
#| echo = FALSE 
head(epidata) |> select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```

* This doesn't change anything here, but it may matter for other types of data where you don't know the latency or reporting lag.

* When in doubt, refer to the [signal's API documentation](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/doctor-visits.html)
to find the earliest date available.

## Obtaining multiple issues for one state

* Once the maximum issue is reached and there are no more issues to come, the data is considered finalized, regardless of the maximum issue you requested.

* For example, the last issue is from July 2020 and so the data is finalized as of July 2020 (not the last issue we requested).

```{r extreme-lb-ub-multiple-issues}
#| echo: true
epidata <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-01"),
  geo_type = "state",
  geo_values = "pa",
  issues = epirange("1900-01-01", "2024-12-11") # From the 1900s to today
)
```

```{r head-extreme-lb-ub-multiple-issues}
#| echo = FALSE 
tail(epidata) |> select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```

* We caution against starting queries with too late a minimum issue or too early maximum issue, as it could lead to incorrect or misleading results. You're safest bet to capture all issues is on the next slide...



## Obtaining all issues for one state

The fast way to obtain all available issues for PA, set `issues` to be `*`:

```{r pa-all-issues}
#| echo: true
epidata <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-07"),
  geo_type = "state",
  geo_values = "pa",
  issues = "*"
)
```

```{r head-pa-all-issues}
#| echo = FALSE 
head(epidata, n = 8) |> select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```

## Obtaining all issues for all states

A very useful feature is the ability to extract all `geo_values` and `issues` by using `*` in both.

```{r all-the-states-and-issues}
#| echo: true
epidata <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-07"),
  geo_type = "state",
  geo_values = "*",
  issues = "*"
)
```

```{r head-all-the-states-and-issues}
#| echo = FALSE 
head(epidata) |> select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```

So, now we obtain all available issues for all states (not just PA) for the specified date range. Neat!

## Last but not least... The do nothing approach 

![](gfx/do-nothing.jpg){height="550px"}

## Last but not least... The do nothing approach 
**Final question:** What do you think happens when we adopt a "do nothing" approach to `geo_values` and `issues` (take both of them out) for this example?

<small> **Hint**: remember a couple slides ago, when we removed `as_of`, we got the most recent estimate for PA. </small>

```{r do-nothing}
#| echo: true
epidata <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-07"),
  geo_type = "state"
)
```

## Obtaining one issue for all states
[**Final question:**]{.primary}  What do you think happens when we adopt a "do nothing" approach to `geo_values` and `issues` (take both of them out)?

<small> [**Hint**]{.primary}: remember a couple slides ago, when we removed `as_of`, we got the most recent estimate for PA. </small>

```{r one-issue-all-states}
#| echo: true
epidata <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-07"),
  geo_type = "state"
)
```

```{r head-one-issue-all-states}
#| echo = FALSE 
head(epidata) |> select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```

We get the [**most recent issue**]{.primary} for [**all states**]{.primary}!


<!-- ## Observations issued with a specific lag
<div style="font-size: 0.8em;">
* We can use the `lag` argument to request only data reported with a certain lag. 

* **Example**: Request  a lag of 7 days fetches only data issued exactly 7 days after the corresponding `time_value`:

```{r specific lag}
#| echo: true
epidata <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-07"),
  geo_type = "state",
  geo_values = "pa",
  lag = 7
)
```

```{r}
#| echo = FALSE 
head(epidata) |> select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```
</div>

## Query results exclusion
<div style="font-size: 0.8em;">
* Although the query we ran on the previous slide requested values from May 1 to May 7, May 3 and May 4 were not included due to a 7-day lag.

* Results for those dates appear only if updates are issued on the corresponding lag day (e.g., May 10).

```{r query results exclusion}
#| echo: true
epidata <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-03", "2020-05-03"),
  geo_type = "state",
  geo_values = "pa",
  issues = epirange("2020-05-09", "2020-05-15")
)
```

```{r}
#| echo = FALSE 
head(epidata) |> select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```
</div>
-->

## Main takeaways

* [**Delphi Epidata:**]{.primary} A one-stop platform for real-time epidemic data, providing aggregated signals for disease tracking and forecasting from diverse sources like health records, mobility patterns, and more.
    
* [**Epidata API:**]{.primary} Open-access API delivering up-to-date, granular epidemiological data + makes all historical versions available.

* [**Epidatr:**]{.primary} Enables you to access Delphi's epidemiological data through R and Python, offering easy installation, powerful API functions, and interactive tools for discovering and analyzing health signals.

* [**Versioned Data and Latency:**]{.primary} Panel data captures time-series trends, which are often subject to revision.  A standout feature of this API is its inclusion of two critical fields...

    1. `as_of`:  One version of the data, and referring to the specific date when the data was last update (i.e. the data was updated `as_of` this date)
    
    2. `issues`: Multiple versions of the data, each corresponding to different `as_of` dates, capturing revisions over time.
    
Their purpose is to manage the record of revisions for transparency and accuracy in data analysis.


